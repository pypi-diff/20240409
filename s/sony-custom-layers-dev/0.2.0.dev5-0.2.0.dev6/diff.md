# Comparing `tmp/sony_custom_layers_dev-0.2.0.dev5-py3-none-any.whl.zip` & `tmp/sony_custom_layers_dev-0.2.0.dev6-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,25 +1,25 @@
-Zip file size: 26602 bytes, number of entries: 23
--rw-r--r--  2.0 unx     1320 b- defN 24-Apr-02 15:29 sony_custom_layers/__init__.py
--rw-r--r--  2.0 unx       27 b- defN 24-Apr-02 15:29 sony_custom_layers/version.py
--rw-r--r--  2.0 unx     1105 b- defN 24-Apr-02 15:29 sony_custom_layers/keras/__init__.py
--rw-r--r--  2.0 unx     1394 b- defN 24-Apr-02 15:29 sony_custom_layers/keras/base_custom_layer.py
--rw-r--r--  2.0 unx     2172 b- defN 24-Apr-02 15:29 sony_custom_layers/keras/custom_objects.py
--rw-r--r--  2.0 unx      922 b- defN 24-Apr-02 15:29 sony_custom_layers/keras/object_detection/__init__.py
--rw-r--r--  2.0 unx     1404 b- defN 24-Apr-02 15:29 sony_custom_layers/keras/object_detection/box_utils.py
--rw-r--r--  2.0 unx     4590 b- defN 24-Apr-02 15:29 sony_custom_layers/keras/object_detection/faster_rcnn_box_decode.py
--rw-r--r--  2.0 unx      964 b- defN 24-Apr-02 15:29 sony_custom_layers/keras/object_detection/score_converter.py
--rw-r--r--  2.0 unx     6964 b- defN 24-Apr-02 15:29 sony_custom_layers/keras/object_detection/ssd_post_process.py
--rw-r--r--  2.0 unx     2900 b- defN 24-Apr-02 15:29 sony_custom_layers/pytorch/__init__.py
--rw-r--r--  2.0 unx      919 b- defN 24-Apr-02 15:29 sony_custom_layers/pytorch/object_detection/__init__.py
--rw-r--r--  2.0 unx    10097 b- defN 24-Apr-02 15:29 sony_custom_layers/pytorch/object_detection/nms.py
--rw-r--r--  2.0 unx     2255 b- defN 24-Apr-02 15:29 sony_custom_layers/pytorch/object_detection/nms_onnx.py
--rw-r--r--  2.0 unx     1518 b- defN 24-Apr-02 15:29 sony_custom_layers/pytorch/object_detection/nms_ort.py
--rw-r--r--  2.0 unx      776 b- defN 24-Apr-02 15:29 sony_custom_layers/util/__init__.py
--rw-r--r--  2.0 unx     2291 b- defN 24-Apr-02 15:29 sony_custom_layers/util/import_util.py
--rw-r--r--  2.0 unx     1158 b- defN 24-Apr-02 15:29 sony_custom_layers/util/test_util.py
--rw-r--r--  2.0 unx    10174 b- defN 24-Apr-02 15:29 sony_custom_layers_dev-0.2.0.dev5.dist-info/LICENSE.md
--rw-r--r--  2.0 unx     5338 b- defN 24-Apr-02 15:29 sony_custom_layers_dev-0.2.0.dev5.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Apr-02 15:29 sony_custom_layers_dev-0.2.0.dev5.dist-info/WHEEL
--rw-r--r--  2.0 unx       19 b- defN 24-Apr-02 15:29 sony_custom_layers_dev-0.2.0.dev5.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     2349 b- defN 24-Apr-02 15:29 sony_custom_layers_dev-0.2.0.dev5.dist-info/RECORD
-23 files, 60748 bytes uncompressed, 22632 bytes compressed:  62.7%
+Zip file size: 26974 bytes, number of entries: 23
+-rw-r--r--  2.0 unx     1320 b- defN 24-Apr-09 10:14 sony_custom_layers/__init__.py
+-rw-r--r--  2.0 unx       27 b- defN 24-Apr-09 10:14 sony_custom_layers/version.py
+-rw-r--r--  2.0 unx     1199 b- defN 24-Apr-09 10:14 sony_custom_layers/keras/__init__.py
+-rw-r--r--  2.0 unx     1394 b- defN 24-Apr-09 10:14 sony_custom_layers/keras/base_custom_layer.py
+-rw-r--r--  2.0 unx     2223 b- defN 24-Apr-09 10:14 sony_custom_layers/keras/custom_objects.py
+-rw-r--r--  2.0 unx      993 b- defN 24-Apr-09 10:14 sony_custom_layers/keras/object_detection/__init__.py
+-rw-r--r--  2.0 unx     1404 b- defN 24-Apr-09 10:14 sony_custom_layers/keras/object_detection/box_utils.py
+-rw-r--r--  2.0 unx     4850 b- defN 24-Apr-09 10:14 sony_custom_layers/keras/object_detection/faster_rcnn_box_decode.py
+-rw-r--r--  2.0 unx      964 b- defN 24-Apr-09 10:14 sony_custom_layers/keras/object_detection/score_converter.py
+-rw-r--r--  2.0 unx     8311 b- defN 24-Apr-09 10:14 sony_custom_layers/keras/object_detection/ssd_post_process.py
+-rw-r--r--  2.0 unx     3578 b- defN 24-Apr-09 10:14 sony_custom_layers/pytorch/__init__.py
+-rw-r--r--  2.0 unx      919 b- defN 24-Apr-09 10:14 sony_custom_layers/pytorch/object_detection/__init__.py
+-rw-r--r--  2.0 unx    10741 b- defN 24-Apr-09 10:14 sony_custom_layers/pytorch/object_detection/nms.py
+-rw-r--r--  2.0 unx     2255 b- defN 24-Apr-09 10:14 sony_custom_layers/pytorch/object_detection/nms_onnx.py
+-rw-r--r--  2.0 unx     1518 b- defN 24-Apr-09 10:14 sony_custom_layers/pytorch/object_detection/nms_ort.py
+-rw-r--r--  2.0 unx      776 b- defN 24-Apr-09 10:14 sony_custom_layers/util/__init__.py
+-rw-r--r--  2.0 unx     2291 b- defN 24-Apr-09 10:14 sony_custom_layers/util/import_util.py
+-rw-r--r--  2.0 unx     1158 b- defN 24-Apr-09 10:14 sony_custom_layers/util/test_util.py
+-rw-r--r--  2.0 unx    10174 b- defN 24-Apr-09 10:14 sony_custom_layers_dev-0.2.0.dev6.dist-info/LICENSE.md
+-rw-r--r--  2.0 unx     4010 b- defN 24-Apr-09 10:14 sony_custom_layers_dev-0.2.0.dev6.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-09 10:14 sony_custom_layers_dev-0.2.0.dev6.dist-info/WHEEL
+-rw-r--r--  2.0 unx       19 b- defN 24-Apr-09 10:14 sony_custom_layers_dev-0.2.0.dev6.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     2349 b- defN 24-Apr-09 10:14 sony_custom_layers_dev-0.2.0.dev6.dist-info/RECORD
+23 files, 62565 bytes uncompressed, 23004 bytes compressed:  63.2%
```

## zipnote {}

```diff
@@ -48,23 +48,23 @@
 
 Filename: sony_custom_layers/util/import_util.py
 Comment: 
 
 Filename: sony_custom_layers/util/test_util.py
 Comment: 
 
-Filename: sony_custom_layers_dev-0.2.0.dev5.dist-info/LICENSE.md
+Filename: sony_custom_layers_dev-0.2.0.dev6.dist-info/LICENSE.md
 Comment: 
 
-Filename: sony_custom_layers_dev-0.2.0.dev5.dist-info/METADATA
+Filename: sony_custom_layers_dev-0.2.0.dev6.dist-info/METADATA
 Comment: 
 
-Filename: sony_custom_layers_dev-0.2.0.dev5.dist-info/WHEEL
+Filename: sony_custom_layers_dev-0.2.0.dev6.dist-info/WHEEL
 Comment: 
 
-Filename: sony_custom_layers_dev-0.2.0.dev5.dist-info/top_level.txt
+Filename: sony_custom_layers_dev-0.2.0.dev6.dist-info/top_level.txt
 Comment: 
 
-Filename: sony_custom_layers_dev-0.2.0.dev5.dist-info/RECORD
+Filename: sony_custom_layers_dev-0.2.0.dev6.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## sony_custom_layers/version.py

```diff
@@ -1 +1 @@
-__version__ = '0.2.0.dev5'
+__version__ = '0.2.0.dev6'
```

## sony_custom_layers/keras/__init__.py

```diff
@@ -17,7 +17,9 @@
 from sony_custom_layers.util.import_util import validate_pip_requirements
 from sony_custom_layers import requirements
 
 validate_pip_requirements(requirements['tf'])
 
 from .object_detection import FasterRCNNBoxDecode, SSDPostProcess, ScoreConverter    # noqa: E402
 from .custom_objects import custom_layers_scope    # noqa: E402
+
+__all__ = ['FasterRCNNBoxDecode', 'ScoreConverter', 'SSDPostProcess', 'custom_layers_scope']
```

## sony_custom_layers/keras/custom_objects.py

```diff
@@ -18,34 +18,37 @@
 import tensorflow as tf
 
 
 def custom_layers_scope(*args: dict):
     """
     Scope context manager that can be used to deserialize Keras models containing custom layers
 
-    If a model contains custom layers only from this package:
-        from sony_custom_layers.keras import custom_layers_scope
-        with custom_layers_scope():
-            tf.keras.models.load_model(path)
-
+    If the model contains custom layers only from this package:
+    ```
+    from sony_custom_layers.keras import custom_layers_scope
+    with custom_layers_scope():
+        tf.keras.models.load_model(path)
+    ```
     If the model contains additional custom layers from other sources, there are two ways:
     1. Pass a list of dictionaries {layer_name: layer_object} as *args.
-
+        ```
         with custom_layers_scope({'Op1': Op1, 'Op2': Op2}, {'Op3': Op3}):
             tf.keras.models.load_model(path)
-
+        ```
     2. Combined with other scopes based on tf.keras.utils.custom_object_scope:
-
+        ```
         with custom_layers_scope(), another_scope():
             tf.keras.models.load_model(path)
+
         # or:
+
         with custom_layers_scope():
             with another_scope():
                 tf.keras.models.load_model(path)
-
+        ```
     Args:
         *args: a list of dictionaries for other custom layers
 
     Returns:
         Scope context manager
     """
     return tf.keras.utils.custom_object_scope(*args + (_custom_objects, ))
```

## sony_custom_layers/keras/object_detection/__init__.py

```diff
@@ -13,7 +13,9 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # -----------------------------------------------------------------------------
 
 from .faster_rcnn_box_decode import FasterRCNNBoxDecode
 from .score_converter import ScoreConverter
 from .ssd_post_process import SSDPostProcess
+
+__all__ = ['FasterRCNNBoxDecode', 'ScoreConverter', 'SSDPostProcess']
```

## sony_custom_layers/keras/object_detection/faster_rcnn_box_decode.py

```diff
@@ -22,28 +22,45 @@
 from sony_custom_layers.keras.base_custom_layer import CustomLayer
 from sony_custom_layers.keras.object_detection.box_utils import corners_to_centroids, centroids_to_corners
 from sony_custom_layers.keras.custom_objects import register_layer
 
 
 @register_layer
 class FasterRCNNBoxDecode(CustomLayer):
+    """
+    Box decoding as per Faster R-CNN <https://arxiv.org/abs/1506.01497>.
+
+    Args:
+        anchors: Anchors with a shape of (n_boxes, 4) in corner coordinates (y_min, x_min, y_max, x_max).
+        scale_factors: Scaling factors in the format (y, x, height, width).
+        clip_window: Clipping window in the format (y_min, x_min, y_max, x_max).
+
+    Inputs:
+        **rel_codes** (Tensor): Relative codes (encoded offsets) with a shape of (batch, n_boxes, 4) in centroid
+                                coordinates (y_center, x_center, h, w).
+
+    Returns:
+        Decoded boxes with a shape of (batch, n_boxes, 4) in corner coordinates (y_min, x_min, y_max, x_max).
+
+    Raises:
+        ValueError: If provided with invalid arguments or an input tensor with unexpected shape
+
+    Example:
+        ```
+        from sony_custom_layers.keras import FasterRCNNBoxDecode
+
+        box_decode = FasterRCNNBoxDecode(anchors,
+                                         scale_factors=(10, 10, 5, 5),
+                                         clip_window=(0, 0, 1, 1))
+        decoded_boxes = box_decode(rel_codes)
+        ```
+    """
 
     def __init__(self, anchors: Union[np.ndarray, tf.Tensor, List[List[float]]],
                  scale_factors: Sequence[Union[float, int]], clip_window: Sequence[Union[float, int]], **kwargs):
-        """
-        Box decoding as per Faster R-CNN (https://arxiv.org/abs/1506.01497).
-
-        Args:
-            anchors: Anchors with a shape of (n_boxes, 4) in corner coordinates (y_min, x_min, y_max, x_max).
-            scale_factors: Scaling factors in the format (y, x, height, width).
-            clip_window: Clipping window in the format (y_min, x_min, y_max, x_max).
-
-        Raises:
-            ValueError: If provided with invalid parameters.
-        """
         super().__init__(**kwargs)
         anchors = tf.constant(anchors)
         if not (len(anchors.shape) == 2 and anchors.shape[-1] == 4):
             raise ValueError(f'Invalid anchors shape {anchors.shape}. Expected shape (n_boxes, 4).')
         self.anchors = anchors
 
         if len(scale_factors) != 4:
@@ -51,25 +68,15 @@
         self.scale_factors = tf.constant(scale_factors, dtype=tf.float32)
 
         if len(clip_window) != 4:
             raise ValueError(f'Invalid clip window {clip_window}. Expected 4 values for (y_min, x_min, y_max, x_max).')
         self.clip_window = clip_window
 
     def call(self, rel_codes: tf.Tensor, *args, **kwargs) -> tf.Tensor:
-        """
-        Args:
-            rel_codes: Relative codes (encoded offsets) with a shape of (batch, n_boxes, 4) in centroid coordinates
-                       (y_center, x_center, h, w).
-
-        Returns:
-            Decoded boxes with a shape of (batch, n_boxes, 4) in corner coordinates (y_min, x_min, y_max, x_max).
-
-        Raises:
-            ValueError: If an input tensor with an unexpected shape is received.
-        """
+        """ """
         if len(rel_codes.shape) != 3 or rel_codes.shape[-1] != 4:
             raise ValueError(f'Invalid input tensor shape {rel_codes.shape}. Expected shape (batch, n_boxes, 4).')
         if rel_codes.shape[-2] != self.anchors.shape[-2]:
             raise ValueError(f'Mismatch in the number of boxes between input tensor ({rel_codes.shape[-2]}) '
                              f'and anchors ({self.anchors.shape[-2]})')
 
         scaled_codes = rel_codes / self.scale_factors
@@ -85,14 +92,15 @@
         boxes = tf.stack([box_y_min, box_x_min, box_y_max, box_x_max], axis=-1)
 
         y_low, x_low, y_high, x_high = self.clip_window
         boxes = tf.clip_by_value(boxes, [y_low, x_low, y_low, x_low], [y_high, x_high, y_high, x_high])
         return boxes
 
     def get_config(self) -> dict:
+        """ """
         config = super().get_config()
         config.update({
             'anchors': self.anchors.numpy().tolist(),
             'scale_factors': self.scale_factors.numpy().tolist(),
             'clip_window': self.clip_window,
         })
         return config
```

## sony_custom_layers/keras/object_detection/ssd_post_process.py

```diff
@@ -38,72 +38,98 @@
 
     def as_dict(self):
         return dataclasses.asdict(self)
 
 
 @register_layer
 class SSDPostProcess(CustomLayer):
+    """
+    SSD Post Processing, based on <https://arxiv.org/abs/1512.02325>.
+
+    Args:
+        anchors (Tensor | np.ndarray): Anchors with a shape of (n_boxes, 4) in corner coordinates
+                                       (y_min, x_min, y_max, x_max).
+        scale_factors (list | tuple): Box decoding scaling factors in the format (y, x, height, width).
+        clip_size (list | tuple): Clipping size in the format (height, width). The decoded boxes are clipped to the
+                                  range y=[0, height] and x=[0, width]. Typically, the clipping size is (1, 1) for
+                                  normalized boxes and the image size for boxes in pixel coordinates.
+        score_converter (ScoreConverter): Conversion to apply to the input logits (sigmoid, softmax, or linear).
+        score_threshold (float): Score threshold for non-maximum suppression.
+        iou_threshold (float): Intersection over union threshold for non-maximum suppression.
+        max_detections (int): The number of detections to return.
+        remove_background (bool) : If True, the first class is removed from the input scores (after the score_converter
+                                   is applied).
+
+    Inputs:
+        A list or tuple of:
+        - **rel_codes** (Tensor): Relative codes (encoded offsets) with a shape of (batch, n_boxes, 4) in centroid
+                            coordinates (y_center, x_center, w, h).
+        - **scores** (Tensor): Scores or logits with a shape of (batch, n_boxes, n_labels).
+
+    Returns:
+        'CombinedNonMaxSuppression' named tuple:
+        - nmsed_boxes: Selected boxes sorted by scores in descending order, with a shape of
+                         (batch, max_detections, 4),in corner coordinates (y_min, x_min, y_max, x_max).
+        - nmsed_scores: Scores corresponding to the selected boxes, with a shape of (batch, max_detections).
+        - nmsed_classes: Labels corresponding to the selected boxes, with a shape of (batch, max_detections).
+                           Each label corresponds to the class index of the selected score in the input scores.
+        - valid_detections: The number of valid detections out of max_detections.
+
+    Raises:
+        ValueError: If provided with invalid arguments or input tensors with unexpected or non-matching shapes.
+
+    Example:
+        ```
+        from sony_custom_layers.keras import SSDPostProcessing, ScoreConverter
+
+        post_process = SSDPostProcess(anchors=anchors,
+                                      scale_factors=(10, 10, 5, 5),
+                                      clip_size=(320, 320),
+                                      score_converter=ScoreConverter.SIGMOID,
+                                      score_threshold=0.01,
+                                      iou_threshold=0.6,
+                                      max_detections=200,
+                                      remove_background=True)
+        res = post_process([rel_codes, logits])
+        boxes = res.nmsed_boxes
+        ```
+    """
 
     def __init__(self,
                  anchors: Union[np.ndarray, tf.Tensor, List[List[float]]],
                  scale_factors: Sequence[Union[int, float]],
                  clip_size: Sequence[Union[int, float]],
                  score_converter: Union[ScoreConverter, str],
                  score_threshold: float,
                  iou_threshold: float,
                  max_detections: int,
                  remove_background: bool = False,
                  **kwargs):
-        """
-        SSD Post Processing, based on https://arxiv.org/abs/1512.02325.
-
-        Args:
-            anchors: Anchors with a shape of (n_boxes, 4) in corner coordinates (y_min, x_min, y_max, x_max).
-            scale_factors: Box decoding scaling factors in the format (y, x, height, width).
-            clip_size: Clipping size in the format (height, width). The decoded boxes are clipped to the
-                       range y=[0, height] and x=[0, width]. Typically, the clipping size is (1, 1) for normalized boxes
-                       and the image size for boxes in pixel coordinates.
-            score_converter: Conversion to apply to the input logits (sigmoid, softmax, or linear).
-            score_threshold: Score threshold for non-maximum suppression.
-            iou_threshold: Intersection over union threshold for non-maximum suppression.
-            max_detections: The number of detections to return.
-            remove_background: If True, the first class is removed from the input scores (after the score_converter is
-                               applied).
-        """
+        """ """
         super().__init__(**kwargs)
+
+        if not 0 <= score_threshold <= 1:
+            raise ValueError(f'Invalid score_threshold {score_threshold} not in range [0, 1]')
+        if not 0 <= iou_threshold <= 1:
+            raise ValueError(f'Invalid iou_threshold {iou_threshold} not in range [0, 1]')
+        if max_detections <= 0:
+            raise ValueError(f'Invalid non-positive max_detections {max_detections}')
+
         self.cfg = SSDPostProcessCfg(anchors=anchors,
                                      scale_factors=scale_factors,
                                      clip_size=clip_size,
                                      score_converter=score_converter,
                                      score_threshold=score_threshold,
                                      iou_threshold=iou_threshold,
                                      max_detections=max_detections,
                                      remove_background=remove_background)
         self._box_decode = FasterRCNNBoxDecode(anchors, scale_factors, (0, 0, *clip_size))
 
     def call(self, inputs: Sequence[tf.Tensor], *args, **kwargs) -> Tuple[tf.Tensor]:
-        """
-        Args:
-            inputs: A list or tuple consisting of (rel_codes, scores).
-              0: Relative codes (encoded offsets) with a shape of (batch, n_boxes, 4) in centroid coordinates
-                 (y_center, x_center, w, h).
-              1: Scores or logits with a shape of (batch, n_boxes, n_labels).
-
-        Returns:
-            0: Selected boxes sorted by scores in descending order, with a shape of (batch, max_detections, 4),
-               in corner coordinates (y_min, x_min, y_max, x_max).
-            1: Scores corresponding to the selected boxes, with a shape of (batch, max_detections).
-            2: Labels corresponding to the selected boxes, with a shape of (batch, max_detections).
-               Each label corresponds to the class index of the selected score in the input scores.
-            3: The number of valid detections out of max_detections.
-
-        Raises:
-            ValueError: If provided input tensors have unexpected or non-matching shapes.
-        """
-
+        """ """
         rel_codes, scores = inputs
         if len(rel_codes.shape) != 3 and rel_codes.shape[-1] != 4:
             raise ValueError(f'Invalid input offsets shape {rel_codes.shape}. '
                              f'Expected shape (batch, n_boxes, 4).')
         if len(scores.shape) != 3:
             raise ValueError(f'Invalid input scores shape {scores.shape}. '
                              f'Expected shape (batch, n_boxes, n_labels).')
@@ -128,12 +154,13 @@
                                                         iou_threshold=self.cfg.iou_threshold,
                                                         score_threshold=self.cfg.score_threshold,
                                                         pad_per_class=False,
                                                         clip_boxes=False)
         return outputs
 
     def get_config(self) -> dict:
+        """ """
         config = super().get_config()
         d = self.cfg.as_dict()
         d['anchors'] = tf.constant(d['anchors']).numpy().tolist()
         config.update(d)
         return config
```

## sony_custom_layers/pytorch/__init__.py

```diff
@@ -34,27 +34,47 @@
     Load custom ops for torch and, optionally, for onnxruntime.
     If 'load_ort' is True or 'ort_session_ops' is passed, registers the custom ops implementation for onnxruntime, and
     sets up the SessionOptions object for onnxruntime session.
 
     Note: this is a must for onnxruntime. To trigger torch ops registration any import from sony_custom_layers.pytorch
     is technically sufficient. This is just a dummy api to prevent unused import (e.g. when loading exported pt2 model)
 
-    Usage:
-        # for onnxruntime
-        so = load_custom_ops(load_ort=True)
-        session = ort.InferenceSession(model_path, sess_options=so)
-        session.run(...)
-
     Args:
         load_ort: whether to register the custom ops for onnxruntime.
         ort_session_ops: SessionOptions object to register the custom ops library on. If None (and 'load_ort' is True),
                         creates a new object.
 
     Returns:
         SessionOptions object if ort registration was requested, otherwise None
+
+    Example:
+        *ONNXRuntime*:
+            ```
+            import onnxruntime as ort
+            from sony_custom_layers.pytorch import load_custom_ops
+
+            so = load_custom_ops(load_ort=True)
+            session = ort.InferenceSession(model_path, sess_options=so)
+            session.run(...)
+            ```
+            You can also pass your own SessionOptions object upon which to register the custom ops
+            ```
+            load_custom_ops(ort_session_options=so)
+            ```
+
+        *PT2 model*:<br>
+            If sony_custom_layers.pytorch is already imported no action is needed. Otherwise, you can use:
+
+            ```
+            from sony_custom_layers.pytorch import load_custom_ops
+            load_custom_ops()
+
+            prog = torch.export.load(model_path)
+            y = prog.module()(x)
+            ```
     """
     if load_ort or ort_session_ops:
         validate_pip_requirements(requirements['torch_ort'])
 
         # trigger onnxruntime op registration
         from .object_detection import nms_ort
```

## sony_custom_layers/pytorch/object_detection/nms.py

```diff
@@ -26,29 +26,30 @@
 MULTICLASS_NMS_TORCH_OP = 'multiclass_nms'
 MULTICLASS_NMS_TORCH_OP_QUALNAME = CUSTOM_LIB_NAME + '::' + MULTICLASS_NMS_TORCH_OP
 
 __all__ = ['multiclass_nms', 'NMSResults']
 
 
 class NMSResults(NamedTuple):
+    """ Container for non-maximum suppression results """
     boxes: Tensor
     scores: Tensor
     labels: Tensor
     n_valid: Tensor
 
     def detach(self) -> 'NMSResults':
-        """ detach all tensors and return a new NMSResults object """
+        """ Detach all tensors and return a new NMSResults object """
         return self.apply(lambda t: t.detach())
 
     def cpu(self) -> 'NMSResults':
-        """ move all tensors to cpu and return a new NMSResults object """
+        """ Move all tensors to cpu and return a new NMSResults object """
         return self.apply(lambda t: t.cpu())
 
     def apply(self, f: Callable[[Tensor], Tensor]) -> 'NMSResults':
-        """ apply any function to all tensors and return a NMSResults new object """
+        """ Apply any function to all tensors and return a NMSResults new object """
         return NMSResults(*[f(t) for t in self])
 
 
 def multiclass_nms(boxes, scores, score_threshold: float, iou_threshold: float, max_detections: int) -> NMSResults:
     """
     Multi-class non-maximum suppression.
     Detections are returned in descending order of their scores.
@@ -61,18 +62,36 @@
         scores (Tensor): Input scores with shape [batch, n_boxes, n_classes].
         score_threshold (float): The score threshold. Candidates with scores below the threshold are discarded.
         iou_threshold (float): The Intersection Over Union (IOU) threshold for boxes overlap.
         max_detections (int): The number of detections to return.
 
     Returns:
         'NMSResults' named tuple:
-            boxes (Tensor): The selected boxes with shape [batch, max_detections, 4].
-            scores (Tensor): The corresponding scores in descending order with shape [batch, max_detections].
-            labels (Tensor): The labels for each box with shape [batch, max_detections].
-            n_valid (Tensor): The number of valid detections out of 'max_detections' with shape [batch, 1]
+        - boxes: The selected boxes with shape [batch, max_detections, 4].
+        - scores: The corresponding scores in descending order with shape [batch, max_detections].
+        - labels: The labels for each box with shape [batch, max_detections].
+        - n_valid: The number of valid detections out of 'max_detections' with shape [batch, 1]
+
+    Raises:
+        ValueError: If provided with invalid arguments or input tensors with unexpected or non-matching shapes.
+
+    Example:
+        ```
+        from sony_custom_layers.pytorch import multiclass_nms
+
+        # batch size=1, 1000 boxes, 50 classes
+        boxes = torch.rand(1, 1000, 4)
+        scores = torch.rand(1, 1000, 50)
+        res = multiclass_nms(boxes,
+                             scores,
+                             score_threshold=0.1,
+                             iou_threshold=0.6,
+                             max_detections=300)
+        # res.boxes, res.scores, res.labels, res.n_valid
+        ```
     """
     return NMSResults(*torch.ops.sony.multiclass_nms(boxes, scores, score_threshold, iou_threshold, max_detections))
 
 
 custom_lib = torch.library.Library(CUSTOM_LIB_NAME, "DEF")
 schema = (MULTICLASS_NMS_TORCH_OP +
           "(Tensor boxes, Tensor scores, float score_threshold, float iou_threshold, SymInt max_detections) "
```

## Comparing `sony_custom_layers_dev-0.2.0.dev5.dist-info/LICENSE.md` & `sony_custom_layers_dev-0.2.0.dev6.dist-info/LICENSE.md`

 * *Files identical despite different names*

## Comparing `sony_custom_layers_dev-0.2.0.dev5.dist-info/METADATA` & `sony_custom_layers_dev-0.2.0.dev6.dist-info/METADATA`

 * *Files 24% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: sony-custom-layers-dev
-Version: 0.2.0.dev5
+Version: 0.2.0.dev6
 Summary: Sony Custom Layers package
 Classifier: Programming Language :: Python :: 3
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Operating System :: OS Independent
 Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
 Requires-Python: <3.12,>=3.8
 Description-Content-Type: text/markdown
@@ -23,15 +23,19 @@
 # Sony Custom Layers (SCL)
 
 Sony Custom Layers (SCL) is an open-source project implementing detection post process NN layers not supported by the TensorFlow Keras API or Torch's torch.nn for the easy integration of those layers into pretrained models.
 
 ## Table of Contents
 
 - [Getting Started](#getting-started)
-- [Implemented Layers](#implemented-layers)
+  - [Installation](#installation)
+  - [Supported Versions](#supported-versions)
+- [API](#api)
+  - [TensorFlow API](#tensorflow-api)
+  - [PyTorch API](#pytorch-api)
 - [License](#license)
 
 
 ## Getting Started
 
 This section provides an installation and a quick starting guide.
 
@@ -65,56 +69,28 @@
 
 #### PyTorch
 
 | **Tested FW versions**                                                                                                   | **Tested Python version** | **Serialization**                                                               |
 |--------------------------------------------------------------------------------------------------------------------------|---------------------------|---------------------------------------------------------------------------------|
 | torch 2.0-2.2<br/>torchvision 0.15-0.17<br/>onnxruntime 1.15-1.17<br/>onnxruntime_extensions 0.8-0.10<br/>onnx 1.14-1.15 | 3.8-3.11                  | .onnx (via torch.onnx.export)<br/>.pt2 (via torch.export.export, torch2.2 only) |
 
-## Implemented Layers
-SCL currently includes implementations of the following layers:
-### TensorFlow
+## API
+For sony-custom-layers API see https://sony.github.io/custom_layers
 
-| **Layer Name**      | **Description**                                      | **API documentation**     |
-|---------------------|---------------------------------------------|---------------------------|
-| FasterRCNNBoxDecode | Box decoding per [Faster R-CNN](https://arxiv.org/abs/1506.01497) with clipping |  [doc](./sony_custom_layers/keras/object_detection/ssd_pp.md)              |            
-| SSDPostProcess      | Post process as described in [SSD: Single Shot MultiBox Detector](https://arxiv.org/abs/1512.02325)  |[doc](./sony_custom_layers/keras/object_detection/faster_rcnn_box_decode.md)                | 
+### TensorFlow API
+For TensorFlow layers see
+[KerasAPI](https://sony.github.io/custom_layers/sony_custom_layers/keras.html)
 
-### PyTorch
-| **Op/Layer Name** | **Description**                                                                                      | **API documentation**                                                  |
-|-------------------|------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------|
-| multiclass_nms    | Multi-class non-maximum suppression  | [doc](./sony_custom_layers/pytorch/object_detection/multiclass_nms.md) |            
+To load a model with custom layers in TensorFlow, see [custom_layers_scope](https://sony.github.io/custom_layers/sony_custom_layers/keras.html#custom_layers_scope)
 
-## Loading the model
-### TensorFlow
-```
-with sony_custom_layers.keras.custom_layers_scope():
-    model = tf.keras.models.load_model(path)
-```
-See [source](sony_custom_layers/keras/custom_objects.py) for further details.
-### PyTorch
-#### ONNX 
-No special handling is required for torch.onnx.export and onnx.load  
-To enable OnnxRuntime inference:
-```
-import onnxruntime as ort
+### PyTorch API
+For PyTorch layers see
+[PyTorchAPI](https://sony.github.io/custom_layers/sony_custom_layers/pytorch.html)
 
-from sony_custom_layers.pytorch import load_custom_ops
+No special handling is required for torch.onnx.export and onnx.load.
+
+For OnnxRuntime / PT2 support see [load_custom_ops](https://sony.github.io/custom_layers/sony_custom_layers/pytorch.html#load_custom_ops) 
 
-so = load_custom_ops(load_ort=True)
-session = ort.InferenceSession(model_path, sess_options=so)
-session.run(...)
-```
-Alternatively, you can pass your own SessionOptions object upon which to register the custom ops
-```
-load_custom_ops(ort_session_options=so)
-```
-#### PT2
-To load a model exported by torch.export.export:
-```
-from sony_custom_layers.pytorch import load_custom_ops
-load_custom_ops()
-m = torch.export.load(model_path)
-```
 ## License
 [Apache License 2.0](LICENSE.md).
```

## Comparing `sony_custom_layers_dev-0.2.0.dev5.dist-info/RECORD` & `sony_custom_layers_dev-0.2.0.dev6.dist-info/RECORD`

 * *Files 15% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 sony_custom_layers/__init__.py,sha256=dFtIzlm6xMtvQtSWgPKO4-YjNKke4vrx2FQUK1DSAo4,1320
-sony_custom_layers/version.py,sha256=L8wwpYk4pxSMK613B82Se3M-Ekw4NpAfI7kQvOxIzPs,27
-sony_custom_layers/keras/__init__.py,sha256=lgk5wpT4zNh3M8wCPO76yKOG3rt5WyhawSr27n7lAV0,1105
+sony_custom_layers/version.py,sha256=nv13Pc_nOgEDVjpLCxWbnyYWo3bHusPgN4ahgXjJ6oI,27
+sony_custom_layers/keras/__init__.py,sha256=ivJ1aVBivgt3vSwTnQpJZrb5zt6aysuUtcpdcNNZIpE,1199
 sony_custom_layers/keras/base_custom_layer.py,sha256=gkoW0AAS_NNcalUPr80ziyepwu4oJsKq0JPxxiSMYzs,1394
-sony_custom_layers/keras/custom_objects.py,sha256=GSsrbOTsqAoVei_dBgohOg7fGcIDfUHUhtE1xTt16G4,2172
-sony_custom_layers/keras/object_detection/__init__.py,sha256=jPNtRCaco2uAoDM8zOgQ_IUEWHLH16SazyGhZVG_H14,922
+sony_custom_layers/keras/custom_objects.py,sha256=HU13alTHU6QGAUU0ukKKy4F8zeYpLtDHxpznTyxsIzw,2223
+sony_custom_layers/keras/object_detection/__init__.py,sha256=5SgVUxEHrCXtOsv1vJ96RY0VSI6XNs-Oe03ecoeHAcQ,993
 sony_custom_layers/keras/object_detection/box_utils.py,sha256=x991XdrDqXhJ8vArOqGrUMY5bUh2nJdmZFUkB6N24Ss,1404
-sony_custom_layers/keras/object_detection/faster_rcnn_box_decode.py,sha256=eiHJcSo3jwHzPm2WSQRPPjao2FVH6TIkgiQU0ol6X7o,4590
+sony_custom_layers/keras/object_detection/faster_rcnn_box_decode.py,sha256=s2qDZUBdG19fHcW70yt25DU4WwjGD_FBb0RZq5215xQ,4850
 sony_custom_layers/keras/object_detection/score_converter.py,sha256=eZhkU9guUdcIIWEtkOypivbj6kA-bUkLHYCkvXQjH3Y,964
-sony_custom_layers/keras/object_detection/ssd_post_process.py,sha256=CkNUxF9Ol94fKAf3V6u6TaG9XmaKobWBedBjcJNg5rc,6964
-sony_custom_layers/pytorch/__init__.py,sha256=jwoK168osnfzJMa8nKum8YdQvNlBdNsCYz45xlS7oVM,2900
+sony_custom_layers/keras/object_detection/ssd_post_process.py,sha256=kI5HzGNKzmX3DsGMBXiMj6igDQXKFhKLPGu1POzCkwk,8311
+sony_custom_layers/pytorch/__init__.py,sha256=6PNkcJ2vdoC4TF05d1oo7UYMtZZMS-2EmzZ9BaWYRl0,3578
 sony_custom_layers/pytorch/object_detection/__init__.py,sha256=_6u7X7Ukqh3sNSyIRG4mdKI1pbWYVEFHfBaTxHRc5M8,919
-sony_custom_layers/pytorch/object_detection/nms.py,sha256=UQsJoL0xycosfsmfobTeyj4ondbhMmv2Nkat7DBOBcE,10097
+sony_custom_layers/pytorch/object_detection/nms.py,sha256=ZGyXP0IOA1BVccAky2iYn7s3ABDvO1DslHd3U9i_ssw,10741
 sony_custom_layers/pytorch/object_detection/nms_onnx.py,sha256=2AwcwLvVCtRIF4feAJC54CmcbzpTsSgk0AJI5yZ3Y14,2255
 sony_custom_layers/pytorch/object_detection/nms_ort.py,sha256=DNIedsOGAdPUeZao9J3iFgh4y_zaP6KL-Q9O0IIiHfE,1518
 sony_custom_layers/util/__init__.py,sha256=3im4heL_oxqk0MrDWUh5qNzCr_IUCSK2LKFVJirWoeM,776
 sony_custom_layers/util/import_util.py,sha256=D97FIrnxhB0m0dHvUs-8YJSKpglpXdb-_acDtAxl0aQ,2291
 sony_custom_layers/util/test_util.py,sha256=rIbiVbJ43itxCDTnPqjaWxaHcrcogekji-6_d7t9oJw,1158
-sony_custom_layers_dev-0.2.0.dev5.dist-info/LICENSE.md,sha256=aYSSIb-5AFPeITTvXm1UAoe0uYBiMmSS8flvXaaFUks,10174
-sony_custom_layers_dev-0.2.0.dev5.dist-info/METADATA,sha256=pDQ-qYNB2s5kzInij1EyAHV18e7Cq4ozqIDG-hL4RlE,5338
-sony_custom_layers_dev-0.2.0.dev5.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
-sony_custom_layers_dev-0.2.0.dev5.dist-info/top_level.txt,sha256=6WQ2Nj4dM4zZx83IcW6fboO88Uat46wXOKcStv4sl_4,19
-sony_custom_layers_dev-0.2.0.dev5.dist-info/RECORD,,
+sony_custom_layers_dev-0.2.0.dev6.dist-info/LICENSE.md,sha256=aYSSIb-5AFPeITTvXm1UAoe0uYBiMmSS8flvXaaFUks,10174
+sony_custom_layers_dev-0.2.0.dev6.dist-info/METADATA,sha256=oU-AJRJGjCAHI3_qPe0SIp21Km0SeqUnsZdMyitmTHc,4010
+sony_custom_layers_dev-0.2.0.dev6.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+sony_custom_layers_dev-0.2.0.dev6.dist-info/top_level.txt,sha256=6WQ2Nj4dM4zZx83IcW6fboO88Uat46wXOKcStv4sl_4,19
+sony_custom_layers_dev-0.2.0.dev6.dist-info/RECORD,,
```

