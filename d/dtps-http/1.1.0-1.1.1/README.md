# Comparing `tmp/dtps_http-1.1.0-py3-none-any.whl.zip` & `tmp/dtps_http-1.1.1-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,42 +1,44 @@
-Zip file size: 150857 bytes, number of entries: 40
+Zip file size: 154949 bytes, number of entries: 42
 -rw-r--r--  2.0 unx      235 b- defN 80-Jan-01 00:00 dtps/__init__.py
--rw-r--r--  2.0 unx     6717 b- defN 80-Jan-01 00:00 dtps/config.py
+-rw-r--r--  2.0 unx     6709 b- defN 80-Jan-01 00:00 dtps/config.py
 -rw-r--r--  2.0 unx    12056 b- defN 80-Jan-01 00:00 dtps/ergo_create.py
--rw-r--r--  2.0 unx     7594 b- defN 80-Jan-01 00:00 dtps/ergo_ui.py
--rw-r--r--  2.0 unx    12698 b- defN 80-Jan-01 00:00 dtps/ergo_use.py
+-rw-r--r--  2.0 unx     7597 b- defN 80-Jan-01 00:00 dtps/ergo_ui.py
+-rw-r--r--  2.0 unx    12733 b- defN 80-Jan-01 00:00 dtps/ergo_use.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 dtps/py.typed
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 dtps/structures.py
 -rw-r--r--  2.0 unx      655 b- defN 80-Jan-01 00:00 dtps_http/__init__.py
--rw-r--r--  2.0 unx     4148 b- defN 80-Jan-01 00:00 dtps_http/blob_manager.py
--rw-r--r--  2.0 unx    62285 b- defN 80-Jan-01 00:00 dtps_http/client.py
+-rw-r--r--  2.0 unx     5973 b- defN 80-Jan-01 00:00 dtps_http/blob_manager.py
+-rw-r--r--  2.0 unx    62576 b- defN 80-Jan-01 00:00 dtps_http/client.py
 -rw-r--r--  2.0 unx     3456 b- defN 80-Jan-01 00:00 dtps_http/constants.py
 -rw-r--r--  2.0 unx     1349 b- defN 80-Jan-01 00:00 dtps_http/ergo_utils.py
 -rw-r--r--  2.0 unx      369 b- defN 80-Jan-01 00:00 dtps_http/exceptions.py
 -rw-r--r--  2.0 unx     1672 b- defN 80-Jan-01 00:00 dtps_http/link_headers.py
--rw-r--r--  2.0 unx     9712 b- defN 80-Jan-01 00:00 dtps_http/object_queue.py
+-rw-r--r--  2.0 unx    10313 b- defN 80-Jan-01 00:00 dtps_http/object_queue.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 dtps_http/py.typed
--rw-r--r--  2.0 unx    74375 b- defN 80-Jan-01 00:00 dtps_http/server.py
+-rw-r--r--  2.0 unx    74898 b- defN 80-Jan-01 00:00 dtps_http/server.py
 -rw-r--r--  2.0 unx     9695 b- defN 80-Jan-01 00:00 dtps_http/server_start.py
--rw-r--r--  2.0 unx    16036 b- defN 80-Jan-01 00:00 dtps_http/structures.py
--rw-r--r--  2.0 unx     3547 b- defN 80-Jan-01 00:00 dtps_http/types.py
--rw-r--r--  2.0 unx    21518 b- defN 80-Jan-01 00:00 dtps_http/types_of_source.py
+-rw-r--r--  2.0 unx    16233 b- defN 80-Jan-01 00:00 dtps_http/structures.py
+-rw-r--r--  2.0 unx     3555 b- defN 80-Jan-01 00:00 dtps_http/types.py
+-rw-r--r--  2.0 unx    21400 b- defN 80-Jan-01 00:00 dtps_http/types_of_source.py
 -rw-r--r--  2.0 unx     4336 b- defN 80-Jan-01 00:00 dtps_http/urls.py
--rw-r--r--  2.0 unx     6138 b- defN 80-Jan-01 00:00 dtps_http/utils.py
+-rw-r--r--  2.0 unx     6114 b- defN 80-Jan-01 00:00 dtps_http/utils.py
 -rw-r--r--  2.0 unx      838 b- defN 80-Jan-01 00:00 dtps_http/utils_every_once_in_a_while.py
 -rw-r--r--  2.0 unx      257 b- defN 80-Jan-01 00:00 dtps_http_programs/__init__.py
 -rw-r--r--  2.0 unx     3671 b- defN 80-Jan-01 00:00 dtps_http_programs/dtps_listen.py
 -rw-r--r--  2.0 unx     1721 b- defN 80-Jan-01 00:00 dtps_http_programs/dtps_proxy.py
 -rw-r--r--  2.0 unx     1338 b- defN 80-Jan-01 00:00 dtps_http_programs/dtps_send_continuous.py
 -rw-r--r--  2.0 unx     3112 b- defN 80-Jan-01 00:00 dtps_http_programs/dtps_stats.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 dtps_http_programs/py.typed
 -rw-r--r--  2.0 unx     1789 b- defN 80-Jan-01 00:00 dtps_http_programs/server_clock.py
 -rw-r--r--  2.0 unx     4676 b- defN 80-Jan-01 00:00 dtps_http_programs/test_memory.py
+-rw-r--r--  2.0 unx     3267 b- defN 80-Jan-01 00:00 dtps_http_programs/test_memory_dashboard.py
+-rw-r--r--  2.0 unx     5251 b- defN 80-Jan-01 00:00 dtps_http_programs/test_memory_use.py
 -rw-r--r--  2.0 unx      129 b- defN 80-Jan-01 00:00 static/favicon.png
--rw-r--r--  2.0 unx     7894 b- defN 80-Jan-01 00:00 static/send.js
+-rw-r--r--  2.0 unx     7885 b- defN 80-Jan-01 00:00 static/send.js
 -rw-r--r--  2.0 unx     1472 b- defN 80-Jan-01 00:00 static/style.css
--rw-r--r--  2.0 unx    75933 b- defN 80-Jan-01 00:00 dtps_http-1.1.0.dist-info/LICENSE.pdf
--rw-r--r--  2.0 unx     1001 b- defN 80-Jan-01 00:00 dtps_http-1.1.0.dist-info/METADATA
--rw-r--r--  2.0 unx       88 b- defN 80-Jan-01 00:00 dtps_http-1.1.0.dist-info/WHEEL
--rw-r--r--  2.0 unx      379 b- defN 80-Jan-01 00:00 dtps_http-1.1.0.dist-info/entry_points.txt
-?rw-r--r--  2.0 unx     3199 b- defN 16-Jan-01 00:00 dtps_http-1.1.0.dist-info/RECORD
-40 files, 366088 bytes uncompressed, 145821 bytes compressed:  60.2%
+-rw-r--r--  2.0 unx    75933 b- defN 80-Jan-01 00:00 dtps_http-1.1.1.dist-info/LICENSE.pdf
+-rw-r--r--  2.0 unx     1001 b- defN 80-Jan-01 00:00 dtps_http-1.1.1.dist-info/METADATA
+-rw-r--r--  2.0 unx       88 b- defN 80-Jan-01 00:00 dtps_http-1.1.1.dist-info/WHEEL
+-rw-r--r--  2.0 unx      379 b- defN 80-Jan-01 00:00 dtps_http-1.1.1.dist-info/entry_points.txt
+?rw-r--r--  2.0 unx     3394 b- defN 16-Jan-01 00:00 dtps_http-1.1.1.dist-info/RECORD
+42 files, 378125 bytes uncompressed, 149601 bytes compressed:  60.4%
```

## zipnote {}

```diff
@@ -90,32 +90,38 @@
 
 Filename: dtps_http_programs/server_clock.py
 Comment: 
 
 Filename: dtps_http_programs/test_memory.py
 Comment: 
 
+Filename: dtps_http_programs/test_memory_dashboard.py
+Comment: 
+
+Filename: dtps_http_programs/test_memory_use.py
+Comment: 
+
 Filename: static/favicon.png
 Comment: 
 
 Filename: static/send.js
 Comment: 
 
 Filename: static/style.css
 Comment: 
 
-Filename: dtps_http-1.1.0.dist-info/LICENSE.pdf
+Filename: dtps_http-1.1.1.dist-info/LICENSE.pdf
 Comment: 
 
-Filename: dtps_http-1.1.0.dist-info/METADATA
+Filename: dtps_http-1.1.1.dist-info/METADATA
 Comment: 
 
-Filename: dtps_http-1.1.0.dist-info/WHEEL
+Filename: dtps_http-1.1.1.dist-info/WHEEL
 Comment: 
 
-Filename: dtps_http-1.1.0.dist-info/entry_points.txt
+Filename: dtps_http-1.1.1.dist-info/entry_points.txt
 Comment: 
 
-Filename: dtps_http-1.1.0.dist-info/RECORD
+Filename: dtps_http-1.1.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## dtps/__init__.py

```diff
@@ -1,8 +1,8 @@
-__version__ = "1.1.0"
+__version__ = "1.1.1"
 
 from logging import DEBUG, getLogger
 
 logger = getLogger(__name__)
 logger.setLevel(DEBUG)
 
 from .config import *
```

## dtps/config.py

```diff
@@ -69,16 +69,15 @@
         return context_manager.get_context()
 
 
 if TYPE_CHECKING:
 
     def context_cleanup(
         base_name: str = "self", environment: Optional[Mapping[str, str]] = None
-    ) -> AsyncContextManager[DTPSContext]:
-        ...
+    ) -> AsyncContextManager[DTPSContext]: ...
 
 else:
 
     @asynccontextmanager
     async def context_cleanup(
         base_name: str = "self", environment: Optional[Mapping[str, str]] = None
     ) -> AsyncIterator[DTPSContext]:
```

## dtps/ergo_ui.py

```diff
@@ -14,14 +14,15 @@
 
 __all__ = [
     "ConnectionInterface",
     "DTPSContext",
     "HistoryInterface",
     "PatchType",
     "PublisherInterface",
+    "RPCFunction",
     "SubscriptionInterface",
 ]
 
 _ = Sequence
 RPCFunction = Callable[[RawData], Awaitable[ObjectTransformResult]]
 
 PatchType = List[Dict[str, Any]]
@@ -82,22 +83,20 @@
     @abstractmethod
     async def get_node_id(self) -> Optional[NodeID]:
         """Returns the node_id if this is a DTPS node."""
 
     # creation and deletion
 
     @abstractmethod
-    async def remove(self) -> None:
-        ...
+    async def remove(self) -> None: ...
 
     # getting
 
     @abstractmethod
-    async def data_get(self) -> RawData:
-        ...
+    async def data_get(self) -> RawData: ...
 
     @abstractmethod
     async def subscribe(
         self,
         on_data: Callable[[RawData], Awaitable[None]],
         /,
         max_frequency: Optional[float] = None,
```

## dtps/ergo_use.py

```diff
@@ -1,15 +1,15 @@
 import asyncio
 import time
 from contextlib import asynccontextmanager
-from typing import Any, AsyncIterator, Awaitable, Callable, cast, Dict, List, Optional, Tuple, Sequence
+from typing import Any, AsyncIterator, Awaitable, Callable, cast, Dict, List, Optional, Tuple
 
 import cbor2
 from aiohttp import ClientResponseError
-
+from typing import Sequence
 from dtps_http import (
     CONTENT_TYPE_PATCH_CBOR,
     ContentInfo,
     DTPSClient,
     join,
     MIME_OCTET,
     NodeID,
@@ -99,15 +99,15 @@
             url_topic, queue_in=self.queue_in, queue_out=self.queue_out
         )
 
     async def publish(self, rd: RawData, /) -> None:
         await self.queue_in.put(rd)
         success = await self.queue_out.get()
         if not success:
-            raise Exception(f"Could not push {rd!r}")
+            raise Exception(f"Could not push {rd.short_description()}")
 
     async def terminate(self) -> None:
         self.task_push.cancel()
 
 
 class ContextManagerUseSubscription(SubscriptionInterface):
     def __init__(self, ldi: ListenDataInterface):
```

## dtps_http/__init__.py

```diff
@@ -1,8 +1,8 @@
-__version__ = "1.1.0"
+__version__ = "1.1.1"
 
 import coloredlogs  # type: ignore
 
 coloredlogs.install(level="DEBUG")  # type: ignore
 
 from logging import getLogger, INFO, WARNING
```

## dtps_http/blob_manager.py

```diff
@@ -1,11 +1,14 @@
+import base64
 import time
+import uuid
 from dataclasses import dataclass
 from typing import Dict, Set, Tuple
 
+from .types import URLString
 from .structures import (
     Digest,
     get_digest,
 )
 
 __all__ = [
     "BlobManager",
@@ -14,15 +17,29 @@
 from .utils_every_once_in_a_while import EveryOnceInAWhile
 
 
 @dataclass
 class SavedBlob:
     content: bytes
     who_needs_it: Set[Tuple[str, int]]
-    deadline: float
+
+    # token with deadline
+    outstanding_tokens: Dict[str, float]
+
+    @classmethod
+    def make(cls, content: bytes) -> "SavedBlob":
+        return cls(content, set(), {})
+
+    def clean_old(self, now: float) -> None:
+        for token, deadline in list(self.outstanding_tokens.items()):
+            if deadline < now:
+                self.outstanding_tokens.pop(token, None)
+
+    def someone_needs_it(self) -> bool:
+        return len(self.who_needs_it) > 0 or len(self.outstanding_tokens) > 0
 
 
 class BlobManager:
     blobs: Dict[Digest, SavedBlob]
     blobs_forgotten: Dict[Digest, float]
 
     forget_forgetting_interval: float
@@ -41,17 +58,16 @@
             self.cleanup_blobs()
 
     def cleanup_blobs(self) -> None:
         now = time.time()
         todrop = []
 
         for digest, sb in list(self.blobs.items()):
-            no_one_needs_it = len(sb.who_needs_it) == 0
-            deadline_passed = now > sb.deadline
-            if no_one_needs_it and deadline_passed:
+            sb.clean_old(now)
+            if not sb.someone_needs_it():
                 todrop.append(digest)
 
         for digest in todrop:
             # print(f"Dropping blob {digest} because deadline passed")
             self.blobs.pop(digest, None)
             self.blobs_forgotten[digest] = now
 
@@ -65,62 +81,99 @@
         if digest not in self.blobs:
             if digest in self.blobs_forgotten:
                 raise KeyError(f"Blob {digest} was forgotten")
             raise KeyError(f"Blob {digest} not found and never known")
         sb = self.blobs[digest]
         return sb.content
 
+    def get_blob_once(self, digest: Digest, token: str) -> bytes:
+        if digest not in self.blobs:
+            if digest in self.blobs_forgotten:
+                raise KeyError(f"Blob {digest} was forgotten")
+            raise KeyError(f"Blob {digest} not found and never known")
+        sb = self.blobs[digest]
+        if token not in sb.outstanding_tokens:
+            pass
+            # raise KeyError(f"Token {token} not found for blob {digest}")
+        else:
+            sb.outstanding_tokens.pop(token, None)
+
+        if not sb.someone_needs_it():
+            self.blobs.pop(digest, None)
+            self.blobs_forgotten[digest] = time.time()
+        return sb.content
+
     def release_blob(self, digest: Digest, who_needs_it: Tuple[str, int]):
         if digest not in self.blobs:
             return
         sb = self.blobs[digest]
+
         sb.who_needs_it.remove(who_needs_it)
-        if len(sb.who_needs_it) == 0:
-            deadline_passed = time.time() > sb.deadline
-            if deadline_passed:
-                self.blobs.pop(digest, None)
-                self.blobs_forgotten[digest] = time.time()
+        now = time.time()
+        sb.clean_old(now)
+        if not sb.someone_needs_it():
+            self.blobs.pop(digest, None)
+            self.blobs_forgotten[digest] = time.time()
 
-    def save_blob(self, content: bytes, who_needs_it: Tuple[str, int]) -> Digest:
+    def save_blob_for_queue(self, content: bytes, who_needs_it: Tuple[str, int]) -> Digest:
         self.cleanup_blobs_if_its_time()
         digest = get_digest(content)
-        if digest not in self.blobs:
-            self.blobs[digest] = SavedBlob(
-                content=content,
-                who_needs_it={who_needs_it},
-                deadline=time.time(),
-            )
-        else:
-            sb = self.blobs[digest]
-            sb.who_needs_it.add(who_needs_it)
+        sb = self._save_blob(digest, content)
+        sb.who_needs_it.add(who_needs_it)
+
         return digest
 
-    def save_blob_deadline(self, content: bytes, deadline: float) -> Digest:
+    def get_use_once_link_store(
+        self, digest: Digest, content: bytes, content_type: str, max_availability_s: float
+    ) -> URLString:
+        sb = self._save_blob(digest, content)
+
+        token = str(uuid.uuid4())
         now = time.time()
-        if deadline < now - 3:
-            raise ValueError(f"The deadline {deadline} is supposed to be a time in the future")
-        self.cleanup_blobs_if_its_time()
-        digest = get_digest(content)
+        sb.outstanding_tokens[token] = now + max_availability_s
+
+        return encode_url2(digest, content_type, token)
+
+    def _save_blob(self, digest: Digest, content: bytes) -> SavedBlob:
         if digest not in self.blobs:
             self.blobs[digest] = SavedBlob(
                 content=content,
                 who_needs_it=set(),
-                deadline=deadline,
+                outstanding_tokens={},
             )
-        else:
-            sb = self.blobs[digest]
-            sb.deadline = max(deadline, sb.deadline)
-        return digest
+        return self.blobs[digest]
 
-    def get_blob_deadline(self, digest: Digest) -> float:
-        if digest not in self.blobs:
-            raise ValueError(f"Blob {digest} not found")
-        sb = self.blobs[digest]
-        return sb.deadline
+    # def save_blob_deadline(self, content: bytes, deadline: float) -> Digest:
+    #     now = time.time()
+    #     if deadline < now - 3:
+    #         raise ValueError(f"The deadline {deadline} is supposed to be a time in the future")
+    #     self.cleanup_blobs_if_its_time()
+    #     digest = get_digest(content)
+    #     if digest not in self.blobs:
+    #         self.blobs[digest] = SavedBlob.make(content)
+    #     else:
+    #         sb = self.blobs[digest]
+    #         sb.deadline = max(deadline, sb.deadline)
+    #     return digest
+
+    # def get_blob_deadline(self, digest: Digest) -> float:
+    #     if digest not in self.blobs:
+    #         raise ValueError(f"Blob {digest} not found")
+    #     sb = self.blobs[digest]
+    #     return sb.deadline
+
+    # def extend_deadline(self, digest: Digest, seconds: float) -> float:
+    #     if digest not in self.blobs:
+    #         raise ValueError(f"Blob {digest} not found")
+    #     sb = self.blobs[digest]
+    #     new_deadline = time.time() + seconds
+    #     sb.deadline = max(sb.deadline, new_deadline)
+    #     return sb.deadline
+
+
+def encode_url2(digest: Digest, content_type: str, token: str) -> URLString:
+    if not content_type:
+        raise ValueError(f"Cannot encode url for empty content type")
+    b64 = base64.urlsafe_b64encode(content_type.encode()).decode("ascii")
 
-    def extend_deadline(self, digest: Digest, seconds: float) -> float:
-        if digest not in self.blobs:
-            raise ValueError(f"Blob {digest} not found")
-        sb = self.blobs[digest]
-        new_deadline = time.time() + seconds
-        sb.deadline = max(sb.deadline, new_deadline)
-        return sb.deadline
+    url = URLString(f"./:blobs/{digest}/{b64}/{token}")
+    return url
```

## dtps_http/client.py

```diff
@@ -164,14 +164,16 @@
     async def wait_for_done(self) -> None:
         raise NotImplementedError()
 
     async def wait_for_done_or_stop_on_event(self, shutdown_event: asyncio.Event) -> None:
         wait1 = asyncio.create_task(shutdown_event.wait())
         wait2 = asyncio.create_task(self.wait_for_done())
         done, pending = await asyncio.wait([wait1, wait2], return_when=asyncio.FIRST_COMPLETED)
+        for f in pending:
+            f.cancel()
         if shutdown_event.is_set():
             wait2.cancel()
             await self.stop()
         else:
             return
 
 
@@ -212,16 +214,15 @@
 
 class DTPSClient:
     if TYPE_CHECKING:
 
         @classmethod
         def create(
             cls, nickname: Optional[str] = None, shutdown_event: Optional[asyncio.Event] = None
-        ) -> "AsyncContextManager[DTPSClient]":
-            ...
+        ) -> "AsyncContextManager[DTPSClient]": ...
 
     else:
 
         @classmethod
         @asynccontextmanager
         async def create(
             cls, nickname: Optional[str] = None, shutdown_event: Optional[asyncio.Event] = None
@@ -574,16 +575,15 @@
 
         return res
 
     if TYPE_CHECKING:
 
         def my_session(
             self, url: URL, /, *, conn_timeout: Optional[float] = None
-        ) -> AsyncContextManager[Tuple[aiohttp.ClientSession, URLString]]:
-            ...
+        ) -> AsyncContextManager[Tuple[aiohttp.ClientSession, URLString]]: ...
 
     else:
 
         @asynccontextmanager
         async def my_session(
             self, url: URL, /, *, conn_timeout: Optional[float] = None
         ) -> AsyncIterator[Tuple[aiohttp.ClientSession, URLString]]:
@@ -700,15 +700,15 @@
         except CancelledError:
             raise
         except:
             self.logger.error(f"cannot connect to {url=!r} {use_url=!r} \n{traceback.format_exc()}")
             raise
 
     async def get(self, url0: URL, accept: Optional[str]) -> RawData:
-        headers = {}
+        headers: dict[str, str] = {}
         if accept is not None:
             headers["accept"] = accept
 
         url = self._look_cache(url0)
         use_url = None
         try:
             async with self.my_session(url, conn_timeout=HTTP_TIMEOUT) as (session, use_url):
@@ -743,15 +743,15 @@
         except TopicOriginUnavailable:
             raise
         except:
             self.logger.error(f"cannot connect to {url=!r} {use_url=!r} \n{traceback.format_exc()}")
             raise
 
     async def delete(self, url0: URL) -> None:
-        headers = {}
+        headers: dict[str, str] = {}
 
         url = self._look_cache(url0)
         use_url = None
         async with self.my_session(url, conn_timeout=HTTP_TIMEOUT) as (session, use_url):
             async with session.delete(use_url) as resp:
                 res_bytes: bytes = await resp.read()
                 resp.raise_for_status()
@@ -1034,37 +1034,34 @@
         return ListenDataImpl(stop_condition, task)
 
     async def _wait_until_shutdown(self, a: "asyncio.Task[X]", condition: Event) -> X:
         """Waits for an event, or for the shutdown event. In that case we raise ShutdownAsked.
         if the condition is set, we raise ConditionSatistied.
         """
         t_wait = asyncio.create_task(self.shutdown_event.wait())
-        condition_wait = asyncio.create_task(condition.wait())
-        tasks = [t_wait, a, condition_wait]
-        try:
-            finished, unfinished = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)
-        except CancelledError:
-            a.cancel()
-            t_wait.cancel()
-            condition_wait.cancel()
-            raise
+        t_condition_wait = asyncio.create_task(condition.wait())
+        tasks = [t_wait, a, t_condition_wait]
+
+        done, not_done = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)
+
+        for t in not_done:
+            t.cancel()
 
+        # case 1: the shutdown was asked
         if self.shutdown_event.is_set():
-            a.cancel()
-            condition_wait.cancel()
+            # logger.info('shutdown was asked')
             raise ShutdownAsked()
         elif condition.is_set():
-            a.cancel()
-            t_wait.cancel()
+            # logger.info('condition is now set')
+            # case2: the condition was satisfied
             raise ConditionSatistied()
-
         else:
-            t_wait.cancel()
-            assert len(finished) == 1
-            return finished.pop().result()
+            res = await a
+            # logger.info(f'the result is obtained: {res}')
+            return res
 
     async def _download_from_urls(self, urlbase: URL, dr: DataReady) -> RawData:
         url_datas = [join(urlbase, _.url) for _ in dr.availability]
 
         #  logger.info(f"url_datas {url_datas}")
         if not url_datas:
             self.logger.error(f"no url_datas in {dr}")
@@ -1095,20 +1092,20 @@
         inline_data: bool,
         add_silence: Optional[float],
         callback: Callable[[ListenURLEvents], Awaitable[None]],
         stop_condition: "asyncio.Event",
         max_frequency: Optional[float],
     ) -> None:
         """Iterates using direct data in websocket."""
-        # self.logger.info(f"listen_url_events_with_data_inline {url_websockets}")
+        self.logger.info(f"listen_url_events_ {url_websockets}")
         nreceived = 0
         received_first = False
         async with self.my_session(url_websockets) as (session, use_url):
             ws: ClientWebSocketResponse
-            headers = {}
+            headers: dict[str, str] = {}
             if max_frequency is not None:
                 headers[HEADER_MAX_FREQUENCY] = str(max_frequency)
 
             async with session.ws_connect(use_url, headers=headers) as ws:
                 # await callback(ConnectionEstablished(comment=f"opened session to {url_websockets}"))
                 #  noinspection PyProtectedMember
                 # headers = "".join(f"{k}: {v}\n" for k, v in ws._response.headers.items())
@@ -1118,18 +1115,17 @@
                         if ws.closed:
                             if nreceived == 0:
                                 await callback(ErrorMsg(comment="Closed, but not even one event received"))
 
                             await callback(FinishedMsg(comment="closed"))
                             break
 
-                        wmsg_task = asyncio.create_task(
-                            self._wait_until_shutdown(asyncio.create_task(ws.receive()), stop_condition)
+                        wmsg_task = self._wait_until_shutdown(
+                            asyncio.create_task(ws.receive()), stop_condition
                         )
-
                         try:
                             if add_silence is not None:
                                 try:
                                     wm = await asyncio.wait_for(wmsg_task, timeout=add_silence)
                                 except asyncio.exceptions.TimeoutError:
                                     # logger.debug(f"add_silence {add_silence} expired")
                                     await callback(
@@ -1153,14 +1149,18 @@
 
                         if wm.type == aiohttp.WSMsgType.CLOSE:  # aiohttp-specific
                             if nreceived == 0:
                                 await callback(ErrorMsg(comment="Closed, but not even one event received"))
 
                             await callback(FinishedMsg(comment="closed"))
                             break
+
+                        if wm.type == aiohttp.WSMsgType.CLOSED:
+                            await callback(FinishedMsg(comment="closed"))
+                            break
                         elif wm.type == aiohttp.WSMsgType.CLOSING:  # aiohttp-specific
                             if nreceived == 0:
                                 await callback(ErrorMsg(comment="Closing, but not even one event received"))
                             await callback(FinishedMsg(comment="closing"))
                             break
                         elif wm.type == aiohttp.WSMsgType.ERROR:
                             await callback(ErrorMsg(comment=str(wm.data)))
@@ -1306,14 +1306,16 @@
                         rd = RawData(content_type=content_type, content=data)
 
                         await ws.send_bytes(get_tagged_cbor(rd))
                         while True:
                             response = await ws.receive()
                             if response.type == aiohttp.WSMsgType.CLOSE:
                                 return False
+                            if response.type == aiohttp.WSMsgType.CLOSED:
+                                return False
 
                             elif response.type == aiohttp.WSMsgType.BINARY:
                                 pr = parse_cbor_tagged(response.data, PushResult)
                                 return pr.result
                             else:
                                 logger.error(f"unexpected {response}")
                                 continue
@@ -1511,16 +1513,15 @@
             success = await p.push_through(rd.content, rd.content_type)
             queue_in.task_done()
             queue_out.put_nowait(success)
 
 
 class PushInterface(ABC):
     @abstractmethod
-    async def push_through(self, data: bytes, content_type: ContentType) -> bool:
-        ...
+    async def push_through(self, data: bytes, content_type: ContentType) -> bool: ...
 
 
 def escape_json_pointer(s: str) -> str:
     return s.replace("~", "~0").replace("/", "~1")
 
 
 def unescape_json_pointer(s: str) -> str:
```

## dtps_http/object_queue.py

```diff
@@ -71,15 +71,15 @@
 
 
 async def transform_identity(otc: ObjectTransformContext) -> RawData:
     return otc.raw_data
 
 
 # tolerance for removal of blobs after they are not needed anymore
-TOLERANCE_REMOVAL = 0.0
+# TOLERANCE_REMOVAL = 0.0
 
 
 class ObjectQueue:
     stored: List[int]
     saved: Dict[int, DataSaved]
     # _data: Dict[str, RawData]
     _seq: int
@@ -113,14 +113,16 @@
         self.saved = {}
         self._transform = transform
         self.listeners = {}
         self.nlisteners = 0
         self.blob_manager = blob_manager
         self.name_for_blob_manager = name.as_relative_url()
 
+        self.request_counter = 0
+
     def get_channel_info(self) -> ChannelInfo:
         if not self.stored:
             newest = None
             oldest = None
         else:
             ds_oldest = self.saved[self.stored[0]]
             ds_newest = self.saved[self.stored[-1]]
@@ -165,15 +167,15 @@
             logger.error(f"Error while transforming {obj0}: {obj}")
             return obj
 
         use_seq = self._seq
         self._seq += 1
         # digest = obj.digest()
         clocks = self.current_clocks()
-        digest = self.blob_manager.save_blob(obj.content, (self.name_for_blob_manager, use_seq))
+        digest = self.blob_manager.save_blob_for_queue(obj.content, (self.name_for_blob_manager, use_seq))
         ds = DataSaved(
             origin_node=self.tr.origin_node,
             unique_id=self.tr.unique_id,
             index=use_seq,
             time_inserted=time.time_ns(),
             digest=digest,
             content_type=obj.content_type,
@@ -181,23 +183,26 @@
             clocks=clocks,
         )
 
         # self._data[digest] = obj
         self.stored.append(use_seq)
         self.saved[use_seq] = ds
 
+        # logger.info(
+        #    f'pushing, bounds = {self.bounds}  stored = {len(self.stored)}  saved = {len(self.saved)} '
+        #    f'blobs={len(self.blob_manager.blobs)}')
         if self.bounds.max_size is not None:  # TODO: implement the semantics for others
             while len(self.stored) > self.bounds.max_size:
                 x_old: int = self.stored.pop(0)
                 if x_old in self.saved:  # should always be true
                     ds_old = self.saved.pop(x_old)
-                    if TOLERANCE_REMOVAL is not None:
-                        # extend deadline by an arbitrary 10 seconds
-                        # (should not be needed, but just in case)
-                        self.blob_manager.extend_deadline(ds_old.digest, TOLERANCE_REMOVAL)
+                    # if TOLERANCE_REMOVAL is not None and TOLERANCE_REMOVAL > 0:
+                    #     # extend deadline by an arbitrary 10 seconds
+                    #     # (should not be needed, but just in case)
+                    #     self.blob_manager.extend_deadline(ds_old.digest, TOLERANCE_REMOVAL)
                     self.blob_manager.release_blob(ds_old.digest, (self.name_for_blob_manager, x_old))
 
         inot = InsertNotification(ds, obj0)
         self._pub.publish(
             Key(self._name.as_relative_url(), K_INDEX), inot
         )  # logger.debug(f"published #{self._seq} {self._name}: {obj!r}")
 
@@ -251,20 +256,27 @@
         key, callback = self.listeners.pop(sub_id)
         try:
             await self._sub.remove_listener(key, callback)
         except Exception as e:
             logger.error(f"Could not unsubscribe {sub_id}: {e}")
 
     def get_data_ready(self, ds: DataSaved, inline_data: bool) -> DataReady:
-        from .server import encode_url
 
         available_interval = 60
-        available_until = self.blob_manager.extend_deadline(ds.digest, available_interval)
+        available_until = time.time() + available_interval
+        content = self.blob_manager.get_blob(ds.digest)
+        actual_url = self.blob_manager.get_use_once_link_store(
+            ds.digest, content, ds.content_type, available_interval
+        )
+        # available_until = self.blob_manager.extend_deadline(ds.digest, available_interval)
+
+        # who = (self.name_for_blob_manager + '-request', self.request_counter)
+        # self.request_counter += 1
 
-        actual_url = encode_url(digest=ds.digest, content_type=ds.content_type)
+        # actual_url = encode_url(digest=ds.digest, content_type=ds.content_type)
         # rel_url = get_relative_url(actual_url, presented_as)
         if inline_data:
             nchunks = 1
             availability_ = []
         else:
             nchunks = 0
             availability_ = [ResourceAvailability(url=actual_url, available_until=available_until)]
```

## dtps_http/server.py

```diff
@@ -90,15 +90,14 @@
 from .structures import (
     Bounds,
     ChannelMsgs,
     Chunk,
     ConnectionEstablished,
     ContentInfo,
     DataReady,
-    Digest,
     ErrorMsg,
     FinishedMsg,
     InsertNotification,
     is_image,
     is_structure,
     LinkBenchmark,
     ListenURLEvents,
@@ -165,15 +164,15 @@
     urls: List[URLString]
     expect_node_id: Optional[NodeID]
 
     established: Optional[ForwardInfoEstablished]
     mask_origin: bool
     task: "asyncio.Task[Any]"
 
-    def __post_init__(self):
+    def __post_init__(self) -> None:
         for u in self.urls:
             parse_url_unescape(u)
 
 
 def get_static_dir() -> str:
     options = [
         pathlib.Path(__file__).parent / "static",
@@ -248,15 +247,17 @@
         # routes.get("/data/{digest}/")(self.serve_data_get)
         routes.post("/{topic:.*}")(self.serve_post)
         routes.patch("/{topic:.*}")(self.serve_patch)
 
         routes.get("/{topic:.*}")(self.serve_get)
         routes.delete("/{topic:.*}")(self.serve_delete)
 
-        self.blob_manager = BlobManager(cleanup_interval=5.0, forget_forgetting_interval=5.0)
+        self.blob_manager = BlobManager(
+            cleanup_interval=5.0, forget_forgetting_interval=5.0
+        )  # TODO: make smaller than 5
 
         # mount a static directory for the web interface
         static_dir = get_static_dir()
         self.logger.debug(f"Using static dir: {static_dir}")
         self.app.add_routes([web.static("/static", static_dir)])
         self.app.add_routes(routes)
 
@@ -565,14 +566,15 @@
         name: TopicNameV,
         content_info: ContentInfo,
         *,
         tp: Optional[TopicProperties],
         bounds: Optional[Bounds],
         transform: ObjectTransformFunction = transform_identity,
     ) -> ObjectQueue:
+        # self.logger.info(f"Creating {name} tp = {tp} bounds = {bounds}")
         if bounds is None:
             bounds = Bounds.default()
         if name in self._forwarded:
             raise ValueError(f"Topic '{name.as_dash_sep()}' is a forwarded one")
         if name in self._oqs:
             return self._oqs[name]
 
@@ -614,18 +616,18 @@
             unique_id=get_unique_id(self.node_id, ROOT),
             origin_node=self.node_id,
             app_data={},
             reachability=[],
             content_info=content_info,
             properties=TopicProperties.streamable_readonly(),
             created=time.time_ns(),
-            bounds=Bounds.max_length(10),
+            bounds=Bounds.max_length(1),
         )
         self._oqs[ROOT] = ObjectQueue(
-            self.hub, ROOT, tr, blob_manager=self.blob_manager, bounds=Bounds.max_length(10)
+            self.hub, ROOT, tr, blob_manager=self.blob_manager, bounds=Bounds.max_length(1)
         )
         index = self.create_root_index()
         wire = index.to_wire()
         as_cbor = cbor2.dumps(asdict(wire))
         await self._oqs[ROOT].publish(RawData(content=as_cbor, content_type=CONTENT_TYPE_DTPS_INDEX_CBOR))
 
         content_info = ContentInfo.simple(MIME_JSON)
@@ -633,62 +635,62 @@
             unique_id=get_unique_id(self.node_id, TOPIC_LIST),
             origin_node=self.node_id,
             app_data={},
             reachability=[],
             content_info=content_info,
             properties=TopicProperties.streamable_readonly(),
             created=time.time_ns(),
-            bounds=Bounds.max_length(10),
+            bounds=Bounds.max_length(1),
         )
         self._oqs[TOPIC_LIST] = ObjectQueue(
             self.hub,
             TOPIC_LIST,
             tr,
             blob_manager=self.blob_manager,
-            bounds=Bounds.max_length(10),
+            bounds=Bounds.max_length(1),
         )
 
         await self.create_oq(
             TOPIC_LOGS, content_info=ContentInfo.simple(MIME_JSON), tp=None, bounds=Bounds.max_length(100)
         )
         if self.enable_clock:
             await self.create_oq(
                 TOPIC_CLOCK,
                 content_info=ContentInfo.simple(MIME_JSON),
                 tp=None,
-                bounds=Bounds.max_length(10),
+                bounds=Bounds.max_length(1),
             )
         await self.create_oq(
             TOPIC_AVAILABILITY,
             content_info=ContentInfo.simple(MIME_JSON),
             tp=None,
-            bounds=Bounds.max_length(10),
+            bounds=Bounds.max_length(1),
         )
         await self.create_oq(
             TOPIC_STATE_SUMMARY,
             content_info=ContentInfo.simple(MIME_JSON),
             tp=None,
-            bounds=Bounds.max_length(10),
+            bounds=Bounds.max_length(1),
         )
 
         oq = await self.create_oq(
             TOPIC_PROXIED,
             content_info=ContentInfo.simple(MIME_JSON),
             tp=None,
-            bounds=Bounds.max_length(10),
+            bounds=Bounds.max_length(1),
         )
         rd = RawData(content=b"{}", content_type=MIME_JSON)
         await oq.publish(rd)
         oq.subscribe(self.on_proxied_changed)
 
         await self.create_oq(
             TOPIC_STATE_NOTIFICATION,
             content_info=ContentInfo.simple(MIME_CBOR),
             tp=None,
-            bounds=Bounds.max_length(10),
+            bounds=Bounds.max_length(1),
         )
 
         if self.enable_clock:
             self.remember_task(asyncio.create_task(update_clock(self, TOPIC_CLOCK, 1.0, 0.0)))
 
         for f in self._more_on_startup:
             await f(self)
@@ -1355,14 +1357,16 @@
             rd = RawData(content=data, content_type=ContentType(content_type))
 
             source: Source = self._resolve(request)
 
             headers = self._headers(request)
 
             presented_as = request.url.path
+
+            # self.logger.info(f"serve_post: {request.url!r} -> {source!r}")
             pr: PostResult = await source.publish(presented_as, self, rd)
 
             if isinstance(pr, TransformError):
                 return web.Response(status=pr.http_code, text=pr.message, headers=headers)
             elif isinstance(pr, DataReady):
                 data = get_simple_cbor(pr.as_data_saved())
                 for r in pr.availability:
@@ -1469,15 +1473,15 @@
                 elif isinstance(operation, AddOperation):
                     # logger.info(f"op: {operation.__dict__}, {operation.pointer.parts}")
                     topic = topic_name_from_json_pointer(operation.location)
 
                     if topic.is_root():
                         raise ValueError(f"Cannot create root topic (path = {operation.path!r})")
 
-                    value = operation.operation["value"]  #  type: ignore
+                    value = operation.operation["value"]  # type: ignore
                     trf = TopicRefAdd.from_json(value)
                     await self.create_oq(topic, trf.content_info, tp=trf.properties, bounds=trf.bounds)
                     self.logger.info(f"created new topic: '{topic.as_dash_sep()}'")
 
                 elif isinstance(operation, (ReplaceOperation, MoveOperation, TestOperation, CopyOperation)):
                     return web.Response(status=405)
                 else:
@@ -1772,16 +1776,15 @@
                 raise
             except:
                 self.logger.error(f"Exception in serve_events_forwarder_one: {traceback.format_exc()}")
                 await asyncio.sleep(1)
 
     if TYPE_CHECKING:
 
-        def _client(self, nickname: Optional[str] = None) -> AsyncContextManager[DTPSClient]:
-            ...
+        def _client(self, nickname: Optional[str] = None) -> AsyncContextManager[DTPSClient]: ...
 
     else:
 
         @asynccontextmanager
         async def _client(self, nickname: Optional[str] = None) -> AsyncIterator[DTPSClient]:
             async with DTPSClient.create(nickname=nickname, shutdown_event=self.shutdown_event) as client:
                 yield client
@@ -1811,15 +1814,15 @@
         ws: web.WebSocketResponse,
         presented_as: str,
         url: URLWS,
         inline_data_receive: bool,
         inline_data_send: bool,
         max_frequency: Optional[float],
     ) -> None:
-        available_for = 60.0
+        available_for = 10.0
         assert isinstance(url, URL)
         self.logger.debug(f"serve_events_forwarder_one: {url} {inline_data_receive=} {inline_data_send=}")
 
         async with self._client() as client:
 
             @async_error_catcher
             async def callback(lue: ListenURLEvents) -> None:
@@ -1828,17 +1831,22 @@
 
                 if isinstance(lue, InsertNotification):
                     ds = lue.data_saved
                     if inline_data_send:
                         availability = []
                         chunks_arriving = 1
                     else:
-                        the_url, available_until = get_data_url(
-                            self.blob_manager, lue.raw_data, available_for
+                        available_until = time.time() + available_for
+                        digest = ds.digest
+                        the_url = self.blob_manager.get_use_once_link_store(
+                            digest, lue.raw_data.content, lue.raw_data.content_type, available_for
                         )
+                        # the_url, available_until = get_data_url(
+                        #     self.blob_manager, lue.raw_data, available_for
+                        # )
                         self.logger.debug(
                             f"serve_events_forwarder_one: sending ref {the_url} {available_until}"
                         )
                         availability = [ResourceAvailability(the_url, available_until)]
                         chunks_arriving = 0
                     dr2 = DataReady(
                         index=ds.index,
@@ -1956,21 +1964,21 @@
         if not p:
             continue
         components.append(p)
 
     return TopicNameV.from_components(components)
 
 
-def get_data_url(blob_manager: BlobManager, rd: RawData, available_for: float) -> Tuple[URLString, float]:
-    now = time.time()
-    deadline = now + available_for
-    digest = blob_manager.save_blob_deadline(rd.content, deadline)
-    return encode_url(digest, rd.content_type), deadline
-
-
-def encode_url(digest: Digest, content_type: str) -> URLString:
-    if not content_type:
-        raise ValueError(f"Cannot encode url for empty content type")
-    b64 = base64.urlsafe_b64encode(content_type.encode()).decode("ascii")
+# def get_data_url(blob_manager: BlobManager, rd: RawData, available_for: float) -> Tuple[URLString, float]:
+#     now = time.time()
+#     deadline = now + available_for
+#     digest = blob_manager.save_blob_deadline(rd.content, deadline)
+#     return encode_url(digest, rd.content_type), deadline
 
-    url = URLString(f"./:blobs/{digest}/{b64}")
-    return url
+#
+# def encode_url(digest: Digest, content_type: str) -> URLString:
+#     if not content_type:
+#         raise ValueError(f"Cannot encode url for empty content type")
+#     b64 = base64.urlsafe_b64encode(content_type.encode()).decode("ascii")
+#
+#     url = URLString(f"./:blobs/{digest}/{b64}")
+#     return url
```

## dtps_http/structures.py

```diff
@@ -12,14 +12,15 @@
 from .urls import join, parse_url_unescape, URL, url_to_string, URLIndexer
 from .utils import pydantic_parse
 
 __all__ = [
     "Bounds",
     "ChannelInfo",
     "ChannelInfoDesc",
+    "ChannelMsgs",
     "Chunk",
     "Clocks",
     "ConnectionEstablished",
     "ContentInfo",
     "DataDesc",
     "DataReady",
     "DataSaved",
@@ -38,16 +39,18 @@
     "ResourceAvailability",
     "SilenceMsg",
     "TopicProperties",
     "TopicReachability",
     "TopicRef",
     "TopicRefAdd",
     "TopicsIndex",
+    "TopicsIndexWire",
     "TransportData",
     "WarningMsg",
+    "is_image",
     "is_structure",
 ]
 
 
 @dataclass
 class LinkBenchmark:
     complexity: int  # 0 for local, 1 for using named unix socket, +2 for each network hop
@@ -124,15 +127,15 @@
     answering: NodeID
 
     # mostly for debugging
     forwarders: List[ForwardingStep]
 
     benchmark: LinkBenchmark
 
-    def __post_init__(self):
+    def __post_init__(self) -> None:
         # s = url_to_string(self.url)
         if "///" in self.url:
             msg = f"Invalid URL: {self.url!r}"
             raise ValueError(msg)
 
     def to_wire(self) -> "TopicReachabilityWire":
         return TopicReachabilityWire(
@@ -186,14 +189,17 @@
 
 
 @dataclass
 class RawData:
     content: bytes
     content_type: ContentType
 
+    def short_description(self) -> str:
+        return f"RawData({self.content_type}; {len(self.content)} bytes)"
+
     @classmethod
     def simple_string(cls, s: str) -> "RawData":
         return cls(content=s.encode("utf-8"), content_type=MIME_TEXT)
 
     @classmethod
     def cbor_from_native_object(cls, ob: object) -> "RawData":
         return cls(content=cbor2.dumps(ob), content_type=MIME_CBOR)
@@ -464,15 +470,15 @@
         return pydantic_parse(cls, s)
 
 
 @dataclass
 class TopicsIndex:
     topics: Dict[TopicNameV, TopicRef]
 
-    def __post_init__(self):
+    def __post_init__(self) -> None:
         for k, v in self.topics.items():
             if not v.reachability:
                 msg = f"Topic {k.as_dash_sep()!r} has no reachability"
                 raise AssertionError(msg)
 
     def to_wire(self) -> "TopicsIndexWire":
         topics = {}
@@ -605,15 +611,15 @@
     urls: List[URLString]
     mask_origin: bool
 
     @classmethod
     def from_json(cls, s: Any) -> "ProxyJob":
         return pydantic_parse(cls, s)
 
-    def __post_init__(self):
+    def __post_init__(self) -> None:
         if not self.urls:
             msg = "Empty urls"
             raise ValueError(msg)
         for u in self.urls:
             parse_url_unescape(u)
```

## dtps_http/types.py

```diff
@@ -22,15 +22,15 @@
 ContentType = str
 
 
 @dataclass(frozen=True)
 class TopicNameV:
     components: Tuple[str, ...]
 
-    def __post_init__(self):
+    def __post_init__(self) -> None:
         for c in self.components:
             if "/" in c:
                 raise ValueError(f"Invalid component {c!r} in {self!r}")
 
     def as_relative_url(self) -> URLString:
         """returns either "" or a/b/c/ (with ending /)"""
         if not self.components:
```

## dtps_http/types_of_source.py

```diff
@@ -77,53 +77,46 @@
             return self.get_inside(first).resolve_extra(tuple(rest), extra)
 
     @abstractmethod
     def get_properties(self, server: "DTPSServer") -> TopicProperties:
         raise NotImplementedError(f"Source.get_properties() for {self}")
 
     @abstractmethod
-    def get_inside_after(self, s: str) -> "Source":
-        ...
+    def get_inside_after(self, s: str) -> "Source": ...
 
     @abstractmethod
     def get_inside(self, s: str, /) -> "Source":
         """source / "a" / "b" """
         ...
 
     @abstractmethod
-    async def get_resolved_data(self, presented_as: str, server: "DTPSServer") -> "ResolvedData":
-        ...
+    async def get_resolved_data(self, presented_as: str, server: "DTPSServer") -> "ResolvedData": ...
 
     @abstractmethod
     async def get_meta_info(self, presented_as: str, server: "DTPSServer") -> "TopicsIndex":
         raise NotImplementedError(f"Source.get_meta_info() for {self}")
 
     @abstractmethod
-    async def patch(self, presented_as: str, server: "DTPSServer", patch: JsonPatch) -> "PostResult":
-        ...
+    async def patch(self, presented_as: str, server: "DTPSServer", patch: JsonPatch) -> "PostResult": ...
 
     @abstractmethod
-    async def publish(self, presented_as: str, server: "DTPSServer", rd: RawData) -> "PostResult":
-        ...
+    async def publish(self, presented_as: str, server: "DTPSServer", rd: RawData) -> "PostResult": ...
 
     @abstractmethod
     async def call(
         self, presented_as: str, server: "DTPSServer", rd: RawData
-    ) -> Union[RawData, TransformError]:
-        ...
+    ) -> Union[RawData, TransformError]: ...
 
     @abstractmethod
-    async def get_source_node_id(self, server: "DTPSServer") -> Optional[NodeID]:
-        ...
+    async def get_source_node_id(self, server: "DTPSServer") -> Optional[NodeID]: ...
 
 
 class Transform(ABC):
     @abstractmethod
-    def transform(self, data: "ResolvedData") -> "ResolvedData":
-        ...
+    def transform(self, data: "ResolvedData") -> "ResolvedData": ...
 
     def get_transform_inside(self, s: str) -> "Transform":
         raise NotImplementedError(f"Transform.get_transform_inside() for {self}")
 
 
 @dataclass
 class GetInside(Transform):
@@ -371,23 +364,22 @@
     locations = resp_data.headers.getall("location")
 
     dr = DataReady.from_data_saved(ds)
     for location in locations:
         url = join(base_url, location)
 
         rd = await client.get(url, accept=ds.content_type)
-        deadline = time.time() + 60.0
-        digest = server.blob_manager.save_blob_deadline(rd.content, deadline)
-        available_until = server.blob_manager.get_blob_deadline(digest)
+        availability_s = 60.0
+        available_until = time.time() + availability_s
 
-        from .server import encode_url
-
-        url = encode_url(digest, content_type=rd.content_type)
+        the_url = server.blob_manager.get_use_once_link_store(
+            dr.digest, rd.content, dr.content_type, availability_s
+        )
 
-        dr.availability.append(ResourceAvailability(url=url, available_until=available_until))
+        dr.availability.append(ResourceAvailability(url=the_url, available_until=available_until))
         break
     else:
         # TODO: how to deal with failure?
         raise ValueError(f"no location in {locations}")
 
     return dr
```

## dtps_http/utils.py

```diff
@@ -52,19 +52,17 @@
 F = TypeVar("F", bound=Callable[..., Any])
 FA = TypeVar("FA", bound=Callable[..., Awaitable[Any]])
 
 FAsync = TypeVar("FAsync", bound=Callable[..., AsyncIterator[Any]])
 
 if TYPE_CHECKING:
 
-    def async_error_catcher(_: FA, /) -> FA:
-        ...
+    def async_error_catcher(_: FA, /) -> FA: ...
 
-    def async_error_catcher_iterator(_: FAsync, /) -> FAsync:
-        ...
+    def async_error_catcher_iterator(_: FAsync, /) -> FAsync: ...
 
 else:
 
     def async_error_catcher(func: Callable[PS, Awaitable[X]]) -> Callable[PS, Awaitable[X]]:
         @functools.wraps(func)
         async def wrapper(*args: PS.args, **kwargs: PS.kwargs) -> X:
             try:
@@ -96,16 +94,15 @@
                 raise
 
         return wrapper
 
 
 if TYPE_CHECKING:
 
-    def method_lru_cache() -> Callable[[F], F]:
-        ...
+    def method_lru_cache() -> Callable[[F], F]: ...
 
 else:
     from methodtools import lru_cache as method_lru_cache
 
 
 def multidict_update(dest: CIMultiDict[X], src: Union[CIMultiDict[X], CIMultiDictProxy[X]]) -> None:
     for k, v in src.items():
```

## dtps_http_programs/__init__.py

```diff
@@ -1,8 +1,8 @@
-__version__ = "1.1.0"
+__version__ = "1.1.1"
 
 from logging import DEBUG, getLogger
 
 logger = getLogger(__name__)
 logger.setLevel(DEBUG)
 
 from .server_clock import *
```

## static/send.js

 * *Format-specific differences are supported for JavaScript files but no file-specific differences were detected; falling back to a binary diff. file(1) reports: ASCII text*

```diff
@@ -277,218 +277,217 @@
 00001140: 6c64 222c 2064 6966 665f 6d73 2c20 276e  ld", diff_ms, 'n
 00001150: 646f 776e 6c6f 6164 735f 6163 7469 7665  downloads_active
 00001160: 272c 206e 646f 776e 6c6f 6164 735f 6163  ', ndownloads_ac
 00001170: 7469 7665 293b 0a20 2020 2020 2020 2020  tive);.         
 00001180: 2020 202f 2f20 2020 2020 7265 7475 726e     //     return
 00001190: 3b0a 2020 2020 2020 2020 2020 2020 2f2f  ;.            //
 000011a0: 207d 0a0a 2020 2020 2020 2020 2020 2020   }..            
-000011b0: 206c 6574 2073 203d 2022 5265 6365 6976   let s = "Receiv
-000011c0: 6564 2074 6869 7320 6e6f 7469 6669 6361  ed this notifica
-000011d0: 7469 6f6e 2077 6974 6820 2220 2b20 6469  tion with " + di
-000011e0: 6666 5f6d 732e 746f 4669 7865 6428 3329  ff_ms.toFixed(3)
-000011f0: 202b 2022 206d 7320 6c61 7465 6e63 793a   + " ms latency:
-00001200: 5c6e 5c6e 223b 0a20 2020 2020 2020 2020  \n\n";.         
-00001210: 2020 202f 2f20 636f 6e73 6f6c 652e 6c6f     // console.lo
-00001220: 6728 274d 6573 7361 6765 2066 726f 6d20  g('Message from 
-00001230: 7365 7276 6572 3a20 272c 206d 6573 7361  server: ', messa
-00001240: 6765 293b 0a0a 2020 2020 2020 2020 2020  ge);..          
-00001250: 2020 6966 2028 6669 656c 6429 207b 0a20    if (field) {. 
-00001260: 2020 2020 2020 2020 2020 2020 2020 202f                 /
-00001270: 2f20 6669 656c 642e 7465 7874 436f 6e74  / field.textCont
-00001280: 656e 7420 3d20 7320 2b20 4a53 4f4e 2e73  ent = s + JSON.s
-00001290: 7472 696e 6769 6679 286d 6573 7361 6765  tringify(message
-000012a0: 302c 206e 756c 6c2c 2034 293b 0a20 2020  0, null, 4);.   
-000012b0: 2020 2020 2020 2020 2020 2020 2066 6965               fie
-000012c0: 6c64 2e74 6578 7443 6f6e 7465 6e74 203d  ld.textContent =
-000012d0: 2073 202b 206a 7379 616d 6c2e 6475 6d70   s + jsyaml.dump
-000012e0: 286d 6573 7361 6765 3029 3b0a 2020 2020  (message0);.    
-000012f0: 2020 2020 2020 2020 7d0a 0a20 2020 2020          }..     
-00001300: 2020 2020 2020 2020 2020 206e 646f 776e             ndown
-00001310: 6c6f 6164 735f 6163 7469 7665 202b 3d20  loads_active += 
-00001320: 313b 0a20 2020 2020 2020 2020 2020 2020  1;.             
-00001330: 2020 2064 6f77 6e6c 6f61 6428 7573 655f     download(use_
-00001340: 7572 6c29 2e74 6865 6e28 7220 3d3e 206e  url).then(r => n
-00001350: 646f 776e 6c6f 6164 735f 6163 7469 7665  downloads_active
-00001360: 202d 3d20 3129 3b0a 0a0a 2020 2020 2020   -= 1);...      
-00001370: 2020 2020 2020 6920 2b3d 2031 3b0a 0a20        i += 1;.. 
-00001380: 2020 2020 2020 207d 2065 6c73 6520 6966         } else if
-00001390: 2028 2743 6861 6e6e 656c 496e 666f 2720   ('ChannelInfo' 
-000013a0: 696e 206d 6573 7361 6765 3029 207b 0a20  in message0) {. 
-000013b0: 2020 2020 2020 2020 2020 202f 2f20 636f             // co
-000013c0: 6e73 6f6c 652e 6c6f 6728 2243 6861 6e6e  nsole.log("Chann
-000013d0: 656c 496e 666f 222c 206d 6573 7361 6765  elInfo", message
-000013e0: 3029 3b0a 2020 2020 2020 2020 2020 2020  0);.            
-000013f0: 6c65 7420 6669 656c 6420 3d20 646f 6375  let field = docu
-00001400: 6d65 6e74 2e67 6574 456c 656d 656e 7442  ment.getElementB
-00001410: 7949 6428 6669 656c 6449 6429 3b0a 2020  yId(fieldId);.  
-00001420: 2020 2020 2020 2020 2020 6966 2028 6669            if (fi
-00001430: 656c 6429 207b 0a20 2020 2020 2020 2020  eld) {.         
-00001440: 2020 2020 2020 2066 6965 6c64 2e74 6578         field.tex
-00001450: 7443 6f6e 7465 6e74 203d 206a 7379 616d  tContent = jsyam
-00001460: 6c2e 6475 6d70 286d 6573 7361 6765 3029  l.dump(message0)
-00001470: 3b0a 2020 2020 2020 2020 2020 2020 7d0a  ;.            }.
-00001480: 0a20 2020 2020 2020 207d 2065 6c73 6520  .        } else 
-00001490: 7b0a 2020 2020 2020 2020 2020 2020 636f  {.            co
-000014a0: 6e73 6f6c 652e 6c6f 6728 2275 6e6b 6e6f  nsole.log("unkno
-000014b0: 776e 206d 6573 7361 6765 222c 206d 6573  wn message", mes
-000014c0: 7361 6765 3029 3b0a 2020 2020 2020 2020  sage0);.        
-000014d0: 2020 2020 6c65 7420 6669 656c 6420 3d20      let field = 
-000014e0: 646f 6375 6d65 6e74 2e67 6574 456c 656d  document.getElem
-000014f0: 656e 7442 7949 6428 6669 656c 6449 6429  entById(fieldId)
-00001500: 3b0a 2020 2020 2020 2020 2020 2020 6966  ;.            if
-00001510: 2028 6669 656c 6429 207b 0a20 2020 2020   (field) {.     
-00001520: 2020 2020 2020 2020 2020 2066 6965 6c64             field
-00001530: 2e74 6578 7443 6f6e 7465 6e74 203d 206a  .textContent = j
-00001540: 7379 616d 6c2e 6475 6d70 286d 6573 7361  syaml.dump(messa
-00001550: 6765 3029 3b0a 2020 2020 2020 2020 2020  ge0);.          
-00001560: 2020 7d0a 0a20 2020 2020 2020 207d 0a20    }..        }. 
-00001570: 2020 207d 293b 0a0a 2020 2020 2f2f 2043     });..    // C
-00001580: 6f6e 6e65 6374 696f 6e20 636c 6f73 6564  onnection closed
-00001590: 0a20 2020 2073 6f63 6b65 742e 6164 6445  .    socket.addE
-000015a0: 7665 6e74 4c69 7374 656e 6572 2827 636c  ventListener('cl
-000015b0: 6f73 6527 2c20 6675 6e63 7469 6f6e 2028  ose', function (
-000015c0: 6576 656e 7429 207b 0a20 2020 2020 2020  event) {.       
-000015d0: 2063 6f6e 736f 6c65 2e6c 6f67 2827 5765   console.log('We
-000015e0: 6253 6f63 6b65 7420 636f 6e6e 6563 7469  bSocket connecti
-000015f0: 6f6e 2063 6c6f 7365 6427 2c20 6576 656e  on closed', even
-00001600: 7429 3b0a 2020 2020 2020 2020 6c65 7420  t);.        let 
-00001610: 6669 656c 6420 3d20 646f 6375 6d65 6e74  field = document
-00001620: 2e67 6574 456c 656d 656e 7442 7949 6428  .getElementById(
-00001630: 6669 656c 6449 6429 3b0a 2020 2020 2020  fieldId);.      
-00001640: 2020 6966 2028 6669 656c 6429 207b 0a20    if (field) {. 
-00001650: 2020 2020 2020 2020 2020 2066 6965 6c64             field
-00001660: 2e74 6578 7443 6f6e 7465 6e74 203d 2066  .textContent = f
-00001670: 6965 6c64 2e74 6578 7443 6f6e 7465 6e74  ield.textContent
-00001680: 202b 2027 5c6e 5765 6253 6f63 6b65 7420   + '\nWebSocket 
-00001690: 636f 6e6e 6563 7469 6f6e 2043 4c4f 5345  connection CLOSE
-000016a0: 4427 3b0a 2020 2020 2020 2020 7d0a 2020  D';.        }.  
-000016b0: 2020 7d29 3b0a 0a20 2020 202f 2f20 436f    });..    // Co
-000016c0: 6e6e 6563 7469 6f6e 2065 7272 6f72 0a20  nnection error. 
-000016d0: 2020 2073 6f63 6b65 742e 6164 6445 7665     socket.addEve
-000016e0: 6e74 4c69 7374 656e 6572 2827 6572 726f  ntListener('erro
-000016f0: 7227 2c20 6675 6e63 7469 6f6e 2028 6576  r', function (ev
-00001700: 656e 7429 207b 0a20 2020 2020 2020 2063  ent) {.        c
-00001710: 6f6e 736f 6c65 2e65 7272 6f72 2827 5765  onsole.error('We
-00001720: 6253 6f63 6b65 7420 6572 726f 723a 2027  bSocket error: '
-00001730: 2c20 6576 656e 7429 3b0a 2020 2020 2020  , event);.      
-00001740: 2020 6c65 7420 6669 656c 6420 3d20 646f    let field = do
-00001750: 6375 6d65 6e74 2e67 6574 456c 656d 656e  cument.getElemen
-00001760: 7442 7949 6428 6669 656c 6449 6429 3b0a  tById(fieldId);.
-00001770: 2020 2020 2020 2020 6966 2028 6669 656c          if (fiel
-00001780: 6429 207b 0a20 2020 2020 2020 2020 2020  d) {.           
-00001790: 2066 6965 6c64 2e74 6578 7443 6f6e 7465   field.textConte
-000017a0: 6e74 203d 2027 5765 6253 6f63 6b65 7420  nt = 'WebSocket 
-000017b0: 6572 726f 7227 3b0a 2020 2020 2020 2020  error';.        
-000017c0: 7d0a 2020 2020 7d29 3b0a 7d0a 0a61 7379  }.    });.}..asy
-000017d0: 6e63 2066 756e 6374 696f 6e20 636f 6e76  nc function conv
-000017e0: 6572 7428 6576 656e 7429 207b 0a20 2020  ert(event) {.   
-000017f0: 2069 6620 2865 7665 6e74 2e64 6174 6120   if (event.data 
-00001800: 696e 7374 616e 6365 6f66 2041 7272 6179  instanceof Array
-00001810: 4275 6666 6572 2920 7b0a 2020 2020 2020  Buffer) {.      
-00001820: 2020 2f2f 2054 6865 2064 6174 6120 6973    // The data is
-00001830: 2061 6e20 4172 7261 7942 7566 6665 7220   an ArrayBuffer 
-00001840: 2d20 6465 636f 6465 2069 7420 6173 2043  - decode it as C
-00001850: 424f 520a 2020 2020 2020 2020 7265 7475  BOR.        retu
-00001860: 726e 2043 424f 522e 6465 636f 6465 2865  rn CBOR.decode(e
-00001870: 7665 6e74 2e64 6174 6129 3b0a 2020 2020  vent.data);.    
-00001880: 7d20 656c 7365 2069 6620 2865 7665 6e74  } else if (event
-00001890: 2e64 6174 6120 696e 7374 616e 6365 6f66  .data instanceof
-000018a0: 2042 6c6f 6229 207b 0a20 2020 2020 2020   Blob) {.       
-000018b0: 2074 7279 207b 0a20 2020 2020 2020 2020   try {.         
-000018c0: 2020 2063 6f6e 7374 2061 7272 6179 4275     const arrayBu
-000018d0: 6666 6572 203d 2061 7761 6974 2072 6561  ffer = await rea
-000018e0: 6446 696c 6541 7341 7272 6179 4275 6666  dFileAsArrayBuff
-000018f0: 6572 2865 7665 6e74 2e64 6174 6129 3b0a  er(event.data);.
-00001900: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00001910: 726e 2043 424f 522e 6465 636f 6465 2861  rn CBOR.decode(a
-00001920: 7272 6179 4275 6666 6572 293b 0a20 2020  rrayBuffer);.   
-00001930: 2020 2020 207d 2063 6174 6368 2028 6572       } catch (er
-00001940: 726f 7229 207b 0a20 2020 2020 2020 2020  ror) {.         
-00001950: 2020 2063 6f6e 736f 6c65 2e65 7272 6f72     console.error
-00001960: 2827 4572 726f 7220 7265 6164 696e 6720  ('Error reading 
-00001970: 626c 6f62 3a20 272c 2065 7272 6f72 293b  blob: ', error);
-00001980: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
-00001990: 7572 6e20 7b27 4572 726f 7227 3a20 6572  urn {'Error': er
-000019a0: 726f 727d 3b0a 2020 2020 2020 2020 7d0a  ror};.        }.
-000019b0: 2020 2020 7d20 656c 7365 207b 0a20 2020      } else {.   
-000019c0: 2020 2020 2063 6f6e 736f 6c65 2e65 7272       console.err
-000019d0: 6f72 2827 556e 6b6e 6f77 6e20 6461 7461  or('Unknown data
-000019e0: 2074 7970 653a 2027 2c20 6576 656e 742e   type: ', event.
-000019f0: 6461 7461 293b 0a20 2020 2020 2020 2072  data);.        r
-00001a00: 6574 7572 6e20 7b27 556e 6b6e 6f77 6e20  eturn {'Unknown 
-00001a10: 6461 7461 2074 7970 6527 3a20 6576 656e  data type': even
-00001a20: 742e 6461 7461 7d3b 0a20 2020 207d 0a0a  t.data};.    }..
-00001a30: 7d0a 0a61 7379 6e63 2066 756e 6374 696f  }..async functio
-00001a40: 6e20 696e 7465 7270 7265 745f 626c 6f62  n interpret_blob
-00001a50: 2864 6174 612c 2063 6f6e 7465 6e74 5f74  (data, content_t
-00001a60: 7970 6529 207b 0a20 2020 2069 6620 2863  ype) {.    if (c
-00001a70: 6f6e 7465 6e74 5f74 7970 652e 696e 6465  ontent_type.inde
-00001a80: 784f 6628 2763 626f 7227 2920 3e3d 2030  xOf('cbor') >= 0
-00001a90: 2920 7b0a 2020 2020 2020 2020 6c65 7420  ) {.        let 
-00001aa0: 636f 6e74 656e 7420 3d20 6177 6169 7420  content = await 
-00001ab0: 6461 7461 2e61 7272 6179 4275 6666 6572  data.arrayBuffer
-00001ac0: 2829 3b0a 2020 2020 2020 2020 7265 7475  ();.        retu
-00001ad0: 726e 2043 424f 522e 6465 636f 6465 2863  rn CBOR.decode(c
-00001ae0: 6f6e 7465 6e74 293b 0a20 2020 207d 2065  ontent);.    } e
-00001af0: 6c73 6520 6966 2028 636f 6e74 656e 745f  lse if (content_
-00001b00: 7479 7065 2e69 6e64 6578 4f66 2827 6a73  type.indexOf('js
-00001b10: 6f6e 2729 203e 3d20 3029 207b 0a20 2020  on') >= 0) {.   
-00001b20: 2020 2020 206c 6574 2063 6f6e 7465 6e74       let content
-00001b30: 203d 2061 7761 6974 2064 6174 612e 7465   = await data.te
-00001b40: 7874 2829 3b0a 2020 2020 2020 2020 7265  xt();.        re
-00001b50: 7475 726e 204a 534f 4e2e 7061 7273 6528  turn JSON.parse(
-00001b60: 636f 6e74 656e 7429 3b0a 2020 2020 7d20  content);.    } 
-00001b70: 656c 7365 2069 6620 2863 6f6e 7465 6e74  else if (content
-00001b80: 5f74 7970 652e 696e 6465 784f 6628 2779  _type.indexOf('y
-00001b90: 616d 6c27 2920 3e3d 2030 2920 7b0a 2020  aml') >= 0) {.  
-00001ba0: 2020 2020 2020 6c65 7420 636f 6e74 656e        let conten
-00001bb0: 7420 3d20 6177 6169 7420 6461 7461 2e74  t = await data.t
-00001bc0: 6578 7428 293b 0a20 2020 2020 2020 2072  ext();.        r
-00001bd0: 6574 7572 6e20 6a73 7961 6d6c 2e6c 6f61  eturn jsyaml.loa
-00001be0: 6428 636f 6e74 656e 7429 0a20 2020 207d  d(content).    }
-00001bf0: 2065 6c73 6520 6966 2028 636f 6e74 656e   else if (conten
-00001c00: 745f 7479 7065 2e69 6e64 6578 4f66 2827  t_type.indexOf('
-00001c10: 7465 7874 2729 203e 3d20 3029 207b 0a20  text') >= 0) {. 
-00001c20: 2020 2020 2020 2072 6574 7572 6e20 6177         return aw
-00001c30: 6169 7420 6461 7461 2e74 6578 7428 293b  ait data.text();
-00001c40: 0a20 2020 207d 2065 6c73 6520 7b0a 2020  .    } else {.  
-00001c50: 2020 2020 2020 7265 7475 726e 2063 6f6e        return con
-00001c60: 7465 6e74 5f74 7970 6520 2b20 2720 2720  tent_type + ' ' 
-00001c70: 2b20 6461 7461 2e74 6f53 7472 696e 6728  + data.toString(
-00001c80: 293b 0a20 2020 207d 0a7d 0a0a 6675 6e63  );.    }.}..func
-00001c90: 7469 6f6e 2072 6561 6446 696c 6541 7341  tion readFileAsA
-00001ca0: 7272 6179 4275 6666 6572 2862 6c6f 6229  rrayBuffer(blob)
-00001cb0: 207b 0a20 2020 2072 6574 7572 6e20 6e65   {.    return ne
-00001cc0: 7720 5072 6f6d 6973 6528 2872 6573 6f6c  w Promise((resol
-00001cd0: 7665 2c20 7265 6a65 6374 2920 3d3e 207b  ve, reject) => {
-00001ce0: 0a20 2020 2020 2020 2063 6f6e 7374 2072  .        const r
-00001cf0: 6561 6465 7220 3d20 6e65 7720 4669 6c65  eader = new File
-00001d00: 5265 6164 6572 2829 3b0a 0a20 2020 2020  Reader();..     
-00001d10: 2020 2072 6561 6465 722e 6f6e 6c6f 6164     reader.onload
-00001d20: 656e 6420 3d20 2829 203d 3e20 7265 736f  end = () => reso
-00001d30: 6c76 6528 7265 6164 6572 2e72 6573 756c  lve(reader.resul
-00001d40: 7429 3b0a 2020 2020 2020 2020 7265 6164  t);.        read
-00001d50: 6572 2e6f 6e65 7272 6f72 203d 2072 656a  er.onerror = rej
-00001d60: 6563 743b 0a0a 2020 2020 2020 2020 7265  ect;..        re
-00001d70: 6164 6572 2e72 6561 6441 7341 7272 6179  ader.readAsArray
-00001d80: 4275 6666 6572 2862 6c6f 6229 3b0a 2020  Buffer(blob);.  
-00001d90: 2020 7d29 3b0a 7d0a 0a0a 646f 6375 6d65    });.}...docume
-00001da0: 6e74 2e61 6464 4576 656e 744c 6973 7465  nt.addEventListe
-00001db0: 6e65 7228 2244 4f4d 436f 6e74 656e 744c  ner("DOMContentL
-00001dc0: 6f61 6465 6422 2c20 6675 6e63 7469 6f6e  oaded", function
-00001dd0: 2028 2920 7b0a 2020 2020 6c65 7420 7320   () {.    let s 
-00001de0: 3d20 2828 7769 6e64 6f77 2e6c 6f63 6174  = ((window.locat
-00001df0: 696f 6e2e 7072 6f74 6f63 6f6c 203d 3d3d  ion.protocol ===
-00001e00: 2022 6874 7470 733a 2229 203f 2022 7773   "https:") ? "ws
-00001e10: 733a 2f2f 2220 3a20 2277 733a 2f2f 2229  s://" : "ws://")
-00001e20: 202b 2077 696e 646f 772e 6c6f 6361 7469   + window.locati
-00001e30: 6f6e 2e68 6f73 7420 2b20 7769 6e64 6f77  on.host + window
-00001e40: 2e6c 6f63 6174 696f 6e2e 7061 7468 6e61  .location.pathna
-00001e50: 6d65 202b 2022 3a65 7665 6e74 732f 223b  me + ":events/";
-00001e60: 0a0a 2020 2020 636f 6e73 6f6c 652e 6c6f  ..    console.lo
-00001e70: 6728 2273 7562 7363 7269 6269 6e67 2074  g("subscribing t
-00001e80: 6f3a 2022 2c20 7329 3b0a 0a20 2020 2073  o: ", s);..    s
-00001e90: 7562 7363 7269 6265 5765 6253 6f63 6b65  ubscribeWebSocke
-00001ea0: 7428 732c 2027 7265 7375 6c74 272c 2027  t(s, 'result', '
-00001eb0: 6461 7461 5f66 6965 6c64 272c 2027 6461  data_field', 'da
-00001ec0: 7461 5f66 6965 6c64 5f69 6d61 6765 2729  ta_field_image')
-00001ed0: 3b0a 7d29 3b0a                           ;.});.
+000011b0: 6c65 7420 7320 3d20 2252 6563 6569 7665  let s = "Receive
+000011c0: 6420 7468 6973 206e 6f74 6966 6963 6174  d this notificat
+000011d0: 696f 6e20 7769 7468 2022 202b 2064 6966  ion with " + dif
+000011e0: 665f 6d73 2e74 6f46 6978 6564 2833 2920  f_ms.toFixed(3) 
+000011f0: 2b20 2220 6d73 206c 6174 656e 6379 3a5c  + " ms latency:\
+00001200: 6e5c 6e22 3b0a 2020 2020 2020 2020 2020  n\n";.          
+00001210: 2020 2f2f 2063 6f6e 736f 6c65 2e6c 6f67    // console.log
+00001220: 2827 4d65 7373 6167 6520 6672 6f6d 2073  ('Message from s
+00001230: 6572 7665 723a 2027 2c20 6d65 7373 6167  erver: ', messag
+00001240: 6529 3b0a 0a20 2020 2020 2020 2020 2020  e);..           
+00001250: 2069 6620 2866 6965 6c64 2920 7b0a 2020   if (field) {.  
+00001260: 2020 2020 2020 2020 2020 2020 2020 2f2f                //
+00001270: 2066 6965 6c64 2e74 6578 7443 6f6e 7465   field.textConte
+00001280: 6e74 203d 2073 202b 204a 534f 4e2e 7374  nt = s + JSON.st
+00001290: 7269 6e67 6966 7928 6d65 7373 6167 6530  ringify(message0
+000012a0: 2c20 6e75 6c6c 2c20 3429 3b0a 2020 2020  , null, 4);.    
+000012b0: 2020 2020 2020 2020 2020 2020 6669 656c              fiel
+000012c0: 642e 7465 7874 436f 6e74 656e 7420 3d20  d.textContent = 
+000012d0: 7320 2b20 6a73 7961 6d6c 2e64 756d 7028  s + jsyaml.dump(
+000012e0: 6d65 7373 6167 6530 293b 0a20 2020 2020  message0);.     
+000012f0: 2020 2020 2020 207d 0a0a 2020 2020 2020         }..      
+00001300: 2020 2020 2020 6e64 6f77 6e6c 6f61 6473        ndownloads
+00001310: 5f61 6374 6976 6520 2b3d 2031 3b0a 2020  _active += 1;.  
+00001320: 2020 2020 2020 2020 2020 646f 776e 6c6f            downlo
+00001330: 6164 2875 7365 5f75 726c 292e 7468 656e  ad(use_url).then
+00001340: 2872 203d 3e20 6e64 6f77 6e6c 6f61 6473  (r => ndownloads
+00001350: 5f61 6374 6976 6520 2d3d 2031 293b 0a0a  _active -= 1);..
+00001360: 0a20 2020 2020 2020 2020 2020 2069 202b  .            i +
+00001370: 3d20 313b 0a0a 2020 2020 2020 2020 7d20  = 1;..        } 
+00001380: 656c 7365 2069 6620 2827 4368 616e 6e65  else if ('Channe
+00001390: 6c49 6e66 6f27 2069 6e20 6d65 7373 6167  lInfo' in messag
+000013a0: 6530 2920 7b0a 2020 2020 2020 2020 2020  e0) {.          
+000013b0: 2020 2f2f 2063 6f6e 736f 6c65 2e6c 6f67    // console.log
+000013c0: 2822 4368 616e 6e65 6c49 6e66 6f22 2c20  ("ChannelInfo", 
+000013d0: 6d65 7373 6167 6530 293b 0a20 2020 2020  message0);.     
+000013e0: 2020 2020 2020 206c 6574 2066 6965 6c64         let field
+000013f0: 203d 2064 6f63 756d 656e 742e 6765 7445   = document.getE
+00001400: 6c65 6d65 6e74 4279 4964 2866 6965 6c64  lementById(field
+00001410: 4964 293b 0a20 2020 2020 2020 2020 2020  Id);.           
+00001420: 2069 6620 2866 6965 6c64 2920 7b0a 2020   if (field) {.  
+00001430: 2020 2020 2020 2020 2020 2020 2020 6669                fi
+00001440: 656c 642e 7465 7874 436f 6e74 656e 7420  eld.textContent 
+00001450: 3d20 6a73 7961 6d6c 2e64 756d 7028 6d65  = jsyaml.dump(me
+00001460: 7373 6167 6530 293b 0a20 2020 2020 2020  ssage0);.       
+00001470: 2020 2020 207d 0a0a 2020 2020 2020 2020       }..        
+00001480: 7d20 656c 7365 207b 0a20 2020 2020 2020  } else {.       
+00001490: 2020 2020 2063 6f6e 736f 6c65 2e6c 6f67       console.log
+000014a0: 2822 756e 6b6e 6f77 6e20 6d65 7373 6167  ("unknown messag
+000014b0: 6522 2c20 6d65 7373 6167 6530 293b 0a20  e", message0);. 
+000014c0: 2020 2020 2020 2020 2020 206c 6574 2066             let f
+000014d0: 6965 6c64 203d 2064 6f63 756d 656e 742e  ield = document.
+000014e0: 6765 7445 6c65 6d65 6e74 4279 4964 2866  getElementById(f
+000014f0: 6965 6c64 4964 293b 0a20 2020 2020 2020  ieldId);.       
+00001500: 2020 2020 2069 6620 2866 6965 6c64 2920       if (field) 
+00001510: 7b0a 2020 2020 2020 2020 2020 2020 2020  {.              
+00001520: 2020 6669 656c 642e 7465 7874 436f 6e74    field.textCont
+00001530: 656e 7420 3d20 6a73 7961 6d6c 2e64 756d  ent = jsyaml.dum
+00001540: 7028 6d65 7373 6167 6530 293b 0a20 2020  p(message0);.   
+00001550: 2020 2020 2020 2020 207d 0a0a 2020 2020           }..    
+00001560: 2020 2020 7d0a 2020 2020 7d29 3b0a 0a20      }.    });.. 
+00001570: 2020 202f 2f20 436f 6e6e 6563 7469 6f6e     // Connection
+00001580: 2063 6c6f 7365 640a 2020 2020 736f 636b   closed.    sock
+00001590: 6574 2e61 6464 4576 656e 744c 6973 7465  et.addEventListe
+000015a0: 6e65 7228 2763 6c6f 7365 272c 2066 756e  ner('close', fun
+000015b0: 6374 696f 6e20 2865 7665 6e74 2920 7b0a  ction (event) {.
+000015c0: 2020 2020 2020 2020 636f 6e73 6f6c 652e          console.
+000015d0: 6c6f 6728 2757 6562 536f 636b 6574 2063  log('WebSocket c
+000015e0: 6f6e 6e65 6374 696f 6e20 636c 6f73 6564  onnection closed
+000015f0: 272c 2065 7665 6e74 293b 0a20 2020 2020  ', event);.     
+00001600: 2020 206c 6574 2066 6965 6c64 203d 2064     let field = d
+00001610: 6f63 756d 656e 742e 6765 7445 6c65 6d65  ocument.getEleme
+00001620: 6e74 4279 4964 2866 6965 6c64 4964 293b  ntById(fieldId);
+00001630: 0a20 2020 2020 2020 2069 6620 2866 6965  .        if (fie
+00001640: 6c64 2920 7b0a 2020 2020 2020 2020 2020  ld) {.          
+00001650: 2020 6669 656c 642e 7465 7874 436f 6e74    field.textCont
+00001660: 656e 7420 3d20 6669 656c 642e 7465 7874  ent = field.text
+00001670: 436f 6e74 656e 7420 2b20 275c 6e57 6562  Content + '\nWeb
+00001680: 536f 636b 6574 2063 6f6e 6e65 6374 696f  Socket connectio
+00001690: 6e20 434c 4f53 4544 273b 0a20 2020 2020  n CLOSED';.     
+000016a0: 2020 207d 0a20 2020 207d 293b 0a0a 2020     }.    });..  
+000016b0: 2020 2f2f 2043 6f6e 6e65 6374 696f 6e20    // Connection 
+000016c0: 6572 726f 720a 2020 2020 736f 636b 6574  error.    socket
+000016d0: 2e61 6464 4576 656e 744c 6973 7465 6e65  .addEventListene
+000016e0: 7228 2765 7272 6f72 272c 2066 756e 6374  r('error', funct
+000016f0: 696f 6e20 2865 7665 6e74 2920 7b0a 2020  ion (event) {.  
+00001700: 2020 2020 2020 636f 6e73 6f6c 652e 6572        console.er
+00001710: 726f 7228 2757 6562 536f 636b 6574 2065  ror('WebSocket e
+00001720: 7272 6f72 3a20 272c 2065 7665 6e74 293b  rror: ', event);
+00001730: 0a20 2020 2020 2020 206c 6574 2066 6965  .        let fie
+00001740: 6c64 203d 2064 6f63 756d 656e 742e 6765  ld = document.ge
+00001750: 7445 6c65 6d65 6e74 4279 4964 2866 6965  tElementById(fie
+00001760: 6c64 4964 293b 0a20 2020 2020 2020 2069  ldId);.        i
+00001770: 6620 2866 6965 6c64 2920 7b0a 2020 2020  f (field) {.    
+00001780: 2020 2020 2020 2020 6669 656c 642e 7465          field.te
+00001790: 7874 436f 6e74 656e 7420 3d20 2757 6562  xtContent = 'Web
+000017a0: 536f 636b 6574 2065 7272 6f72 273b 0a20  Socket error';. 
+000017b0: 2020 2020 2020 207d 0a20 2020 207d 293b         }.    });
+000017c0: 0a7d 0a0a 6173 796e 6320 6675 6e63 7469  .}..async functi
+000017d0: 6f6e 2063 6f6e 7665 7274 2865 7665 6e74  on convert(event
+000017e0: 2920 7b0a 2020 2020 6966 2028 6576 656e  ) {.    if (even
+000017f0: 742e 6461 7461 2069 6e73 7461 6e63 656f  t.data instanceo
+00001800: 6620 4172 7261 7942 7566 6665 7229 207b  f ArrayBuffer) {
+00001810: 0a20 2020 2020 2020 202f 2f20 5468 6520  .        // The 
+00001820: 6461 7461 2069 7320 616e 2041 7272 6179  data is an Array
+00001830: 4275 6666 6572 202d 2064 6563 6f64 6520  Buffer - decode 
+00001840: 6974 2061 7320 4342 4f52 0a20 2020 2020  it as CBOR.     
+00001850: 2020 2072 6574 7572 6e20 4342 4f52 2e64     return CBOR.d
+00001860: 6563 6f64 6528 6576 656e 742e 6461 7461  ecode(event.data
+00001870: 293b 0a20 2020 207d 2065 6c73 6520 6966  );.    } else if
+00001880: 2028 6576 656e 742e 6461 7461 2069 6e73   (event.data ins
+00001890: 7461 6e63 656f 6620 426c 6f62 2920 7b0a  tanceof Blob) {.
+000018a0: 2020 2020 2020 2020 7472 7920 7b0a 2020          try {.  
+000018b0: 2020 2020 2020 2020 2020 636f 6e73 7420            const 
+000018c0: 6172 7261 7942 7566 6665 7220 3d20 6177  arrayBuffer = aw
+000018d0: 6169 7420 7265 6164 4669 6c65 4173 4172  ait readFileAsAr
+000018e0: 7261 7942 7566 6665 7228 6576 656e 742e  rayBuffer(event.
+000018f0: 6461 7461 293b 0a20 2020 2020 2020 2020  data);.         
+00001900: 2020 2072 6574 7572 6e20 4342 4f52 2e64     return CBOR.d
+00001910: 6563 6f64 6528 6172 7261 7942 7566 6665  ecode(arrayBuffe
+00001920: 7229 3b0a 2020 2020 2020 2020 7d20 6361  r);.        } ca
+00001930: 7463 6820 2865 7272 6f72 2920 7b0a 2020  tch (error) {.  
+00001940: 2020 2020 2020 2020 2020 636f 6e73 6f6c            consol
+00001950: 652e 6572 726f 7228 2745 7272 6f72 2072  e.error('Error r
+00001960: 6561 6469 6e67 2062 6c6f 623a 2027 2c20  eading blob: ', 
+00001970: 6572 726f 7229 3b0a 2020 2020 2020 2020  error);.        
+00001980: 2020 2020 7265 7475 726e 207b 2745 7272      return {'Err
+00001990: 6f72 273a 2065 7272 6f72 7d3b 0a20 2020  or': error};.   
+000019a0: 2020 2020 207d 0a20 2020 207d 2065 6c73       }.    } els
+000019b0: 6520 7b0a 2020 2020 2020 2020 636f 6e73  e {.        cons
+000019c0: 6f6c 652e 6572 726f 7228 2755 6e6b 6e6f  ole.error('Unkno
+000019d0: 776e 2064 6174 6120 7479 7065 3a20 272c  wn data type: ',
+000019e0: 2065 7665 6e74 2e64 6174 6129 3b0a 2020   event.data);.  
+000019f0: 2020 2020 2020 7265 7475 726e 207b 2755        return {'U
+00001a00: 6e6b 6e6f 776e 2064 6174 6120 7479 7065  nknown data type
+00001a10: 273a 2065 7665 6e74 2e64 6174 617d 3b0a  ': event.data};.
+00001a20: 2020 2020 7d0a 0a7d 0a0a 6173 796e 6320      }..}..async 
+00001a30: 6675 6e63 7469 6f6e 2069 6e74 6572 7072  function interpr
+00001a40: 6574 5f62 6c6f 6228 6461 7461 2c20 636f  et_blob(data, co
+00001a50: 6e74 656e 745f 7479 7065 2920 7b0a 2020  ntent_type) {.  
+00001a60: 2020 6966 2028 636f 6e74 656e 745f 7479    if (content_ty
+00001a70: 7065 2e69 6e64 6578 4f66 2827 6362 6f72  pe.indexOf('cbor
+00001a80: 2729 203e 3d20 3029 207b 0a20 2020 2020  ') >= 0) {.     
+00001a90: 2020 206c 6574 2063 6f6e 7465 6e74 203d     let content =
+00001aa0: 2061 7761 6974 2064 6174 612e 6172 7261   await data.arra
+00001ab0: 7942 7566 6665 7228 293b 0a20 2020 2020  yBuffer();.     
+00001ac0: 2020 2072 6574 7572 6e20 4342 4f52 2e64     return CBOR.d
+00001ad0: 6563 6f64 6528 636f 6e74 656e 7429 3b0a  ecode(content);.
+00001ae0: 2020 2020 7d20 656c 7365 2069 6620 2863      } else if (c
+00001af0: 6f6e 7465 6e74 5f74 7970 652e 696e 6465  ontent_type.inde
+00001b00: 784f 6628 276a 736f 6e27 2920 3e3d 2030  xOf('json') >= 0
+00001b10: 2920 7b0a 2020 2020 2020 2020 6c65 7420  ) {.        let 
+00001b20: 636f 6e74 656e 7420 3d20 6177 6169 7420  content = await 
+00001b30: 6461 7461 2e74 6578 7428 293b 0a20 2020  data.text();.   
+00001b40: 2020 2020 2072 6574 7572 6e20 4a53 4f4e       return JSON
+00001b50: 2e70 6172 7365 2863 6f6e 7465 6e74 293b  .parse(content);
+00001b60: 0a20 2020 207d 2065 6c73 6520 6966 2028  .    } else if (
+00001b70: 636f 6e74 656e 745f 7479 7065 2e69 6e64  content_type.ind
+00001b80: 6578 4f66 2827 7961 6d6c 2729 203e 3d20  exOf('yaml') >= 
+00001b90: 3029 207b 0a20 2020 2020 2020 206c 6574  0) {.        let
+00001ba0: 2063 6f6e 7465 6e74 203d 2061 7761 6974   content = await
+00001bb0: 2064 6174 612e 7465 7874 2829 3b0a 2020   data.text();.  
+00001bc0: 2020 2020 2020 7265 7475 726e 206a 7379        return jsy
+00001bd0: 616d 6c2e 6c6f 6164 2863 6f6e 7465 6e74  aml.load(content
+00001be0: 290a 2020 2020 7d20 656c 7365 2069 6620  ).    } else if 
+00001bf0: 2863 6f6e 7465 6e74 5f74 7970 652e 696e  (content_type.in
+00001c00: 6465 784f 6628 2774 6578 7427 2920 3e3d  dexOf('text') >=
+00001c10: 2030 2920 7b0a 2020 2020 2020 2020 7265   0) {.        re
+00001c20: 7475 726e 2061 7761 6974 2064 6174 612e  turn await data.
+00001c30: 7465 7874 2829 3b0a 2020 2020 7d20 656c  text();.    } el
+00001c40: 7365 207b 0a20 2020 2020 2020 2072 6574  se {.        ret
+00001c50: 7572 6e20 636f 6e74 656e 745f 7479 7065  urn content_type
+00001c60: 202b 2027 2027 202b 2064 6174 612e 746f   + ' ' + data.to
+00001c70: 5374 7269 6e67 2829 3b0a 2020 2020 7d0a  String();.    }.
+00001c80: 7d0a 0a66 756e 6374 696f 6e20 7265 6164  }..function read
+00001c90: 4669 6c65 4173 4172 7261 7942 7566 6665  FileAsArrayBuffe
+00001ca0: 7228 626c 6f62 2920 7b0a 2020 2020 7265  r(blob) {.    re
+00001cb0: 7475 726e 206e 6577 2050 726f 6d69 7365  turn new Promise
+00001cc0: 2828 7265 736f 6c76 652c 2072 656a 6563  ((resolve, rejec
+00001cd0: 7429 203d 3e20 7b0a 2020 2020 2020 2020  t) => {.        
+00001ce0: 636f 6e73 7420 7265 6164 6572 203d 206e  const reader = n
+00001cf0: 6577 2046 696c 6552 6561 6465 7228 293b  ew FileReader();
+00001d00: 0a0a 2020 2020 2020 2020 7265 6164 6572  ..        reader
+00001d10: 2e6f 6e6c 6f61 6465 6e64 203d 2028 2920  .onloadend = () 
+00001d20: 3d3e 2072 6573 6f6c 7665 2872 6561 6465  => resolve(reade
+00001d30: 722e 7265 7375 6c74 293b 0a20 2020 2020  r.result);.     
+00001d40: 2020 2072 6561 6465 722e 6f6e 6572 726f     reader.onerro
+00001d50: 7220 3d20 7265 6a65 6374 3b0a 0a20 2020  r = reject;..   
+00001d60: 2020 2020 2072 6561 6465 722e 7265 6164       reader.read
+00001d70: 4173 4172 7261 7942 7566 6665 7228 626c  AsArrayBuffer(bl
+00001d80: 6f62 293b 0a20 2020 207d 293b 0a7d 0a0a  ob);.    });.}..
+00001d90: 0a64 6f63 756d 656e 742e 6164 6445 7665  .document.addEve
+00001da0: 6e74 4c69 7374 656e 6572 2822 444f 4d43  ntListener("DOMC
+00001db0: 6f6e 7465 6e74 4c6f 6164 6564 222c 2066  ontentLoaded", f
+00001dc0: 756e 6374 696f 6e20 2829 207b 0a20 2020  unction () {.   
+00001dd0: 206c 6574 2073 203d 2028 2877 696e 646f   let s = ((windo
+00001de0: 772e 6c6f 6361 7469 6f6e 2e70 726f 746f  w.location.proto
+00001df0: 636f 6c20 3d3d 3d20 2268 7474 7073 3a22  col === "https:"
+00001e00: 2920 3f20 2277 7373 3a2f 2f22 203a 2022  ) ? "wss://" : "
+00001e10: 7773 3a2f 2f22 2920 2b20 7769 6e64 6f77  ws://") + window
+00001e20: 2e6c 6f63 6174 696f 6e2e 686f 7374 202b  .location.host +
+00001e30: 2077 696e 646f 772e 6c6f 6361 7469 6f6e   window.location
+00001e40: 2e70 6174 686e 616d 6520 2b20 223a 6576  .pathname + ":ev
+00001e50: 656e 7473 2f22 3b0a 0a20 2020 2063 6f6e  ents/";..    con
+00001e60: 736f 6c65 2e6c 6f67 2822 7375 6273 6372  sole.log("subscr
+00001e70: 6962 696e 6720 746f 3a20 222c 2073 293b  ibing to: ", s);
+00001e80: 0a0a 2020 2020 7375 6273 6372 6962 6557  ..    subscribeW
+00001e90: 6562 536f 636b 6574 2873 2c20 2772 6573  ebSocket(s, 'res
+00001ea0: 756c 7427 2c20 2764 6174 615f 6669 656c  ult', 'data_fiel
+00001eb0: 6427 2c20 2764 6174 615f 6669 656c 645f  d', 'data_field_
+00001ec0: 696d 6167 6527 293b 0a7d 293b 0a         image');.});.
```

## Comparing `dtps_http-1.1.0.dist-info/LICENSE.pdf` & `dtps_http-1.1.1.dist-info/LICENSE.pdf`

 * *Files identical despite different names*

## Comparing `dtps_http-1.1.0.dist-info/METADATA` & `dtps_http-1.1.1.dist-info/METADATA`

 * *Files 7% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: dtps-http
-Version: 1.1.0
+Version: 1.1.1
 Summary: 
 Author: Andrea Censi
 Author-email: AndreaCensi@users.noreply.github.com
 Requires-Python: >=3.8,<4.0
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
```

## Comparing `dtps_http-1.1.0.dist-info/RECORD` & `dtps_http-1.1.1.dist-info/RECORD`

 * *Files 19% similar despite different names*

```diff
@@ -1,40 +1,42 @@
-dtps/__init__.py,sha256=eMVfQdbpQxAPKOciFn_h_xSs9XRN8u6qaWfo5n8AmhE,235
-dtps/config.py,sha256=EuyLSNqcmdJ91FX2kVZ6qP3rmMKXx-vNqNrx144DwNA,6717
+dtps/__init__.py,sha256=U2FUja5RcrO0xRhlL9_-Pw965iPW7JxSDUIY5r091dU,235
+dtps/config.py,sha256=pX8NyQFRER6sxKxiCCNW7rTjUR2lQyg7yi-wcTzwlDA,6709
 dtps/ergo_create.py,sha256=Y_1ucGbaOn_HWTGwNnu_Pcrw1XyHbS4n9tW61Qim-lg,12056
-dtps/ergo_ui.py,sha256=fUvPeFbcVUNOb9sy-lGsV-Bj1h-6FC8o0z8jF_kk7g4,7594
-dtps/ergo_use.py,sha256=YFvsjkhwOMDOh1RH59OHL6jc475AdZii71bdiWAO-vI,12698
+dtps/ergo_ui.py,sha256=lnP4ChQcc2hQkOxDDQEj_FG_SQc2aCEiICEPtRL2dSI,7597
+dtps/ergo_use.py,sha256=GmiZkjqiT4QhA0WprJe4N1tfKaRGD1ND3rgUOmvY4sc,12733
 dtps/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 dtps/structures.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-dtps_http/__init__.py,sha256=wBoI4QhgdvA20MPDHg3ThOtZMJIARhuVu3uz6OEtd-4,655
-dtps_http/blob_manager.py,sha256=MaufvrvlqkVgqYvTHQUBaL42eyIaNh-3JOQiZrwCVPc,4148
-dtps_http/client.py,sha256=-IykfkvuOtEXzplY8DtHlR9f3pp6UaCCltCvyd4COHQ,62285
+dtps_http/__init__.py,sha256=jV_KP43j-wBTANS1GJvj7l2X39gLpEQf-DZD6jNff_w,655
+dtps_http/blob_manager.py,sha256=CO7pp9cILLJyAesdDJsd-3MPkMIs4WTgcbWgNhWGoYs,5973
+dtps_http/client.py,sha256=H6WsskD_DVBNS4n_QUGvgl_MfPtGgvchpnUXi4NaYL8,62576
 dtps_http/constants.py,sha256=KzKfzcr55qMmKx3EivFERUg_WTwpfAl1iuIRpC9IPB8,3456
 dtps_http/ergo_utils.py,sha256=NiHY7Th93zimK-DLT4KkEaFK_wMM9YgbU9uJBl3zf8o,1349
 dtps_http/exceptions.py,sha256=74bXD3KkuYxI5CVHsIt8FEqMaE3W4Z3sWVssp6MAq60,369
 dtps_http/link_headers.py,sha256=ADp5tF-pKU1N7W3M4SISASYTTisL086lTHKYpwDPEo0,1672
-dtps_http/object_queue.py,sha256=NEaQK3NdUEWYaHY0Lwvfw8TSZJMnlnxbeF8tkvPwSUI,9712
+dtps_http/object_queue.py,sha256=yJSS5mAka0ULgwULZnrjA6FEWZWgF9WbRmyiPn0DfE8,10313
 dtps_http/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-dtps_http/server.py,sha256=8X5hU1HkVmOfnK3RRnHmJwB8nyMEkAp3alYJoYoQUnc,74375
+dtps_http/server.py,sha256=nWPaNYPoOkqEkQQqh7N5UoyeMp-Sdu0_zHejpJecId4,74898
 dtps_http/server_start.py,sha256=fK1pNHPveSCeEw8AV5M6WfVqKHz4nyq4xW1tP9JZCtI,9695
-dtps_http/structures.py,sha256=k6Ap5NSCrhzY2NTzhGopZJDJTtCQBZxxMiiY_9hOIFo,16036
-dtps_http/types.py,sha256=yycTqRfF9ND_iS88INAxD9n33dBk_yXGVmMwGramOrM,3547
-dtps_http/types_of_source.py,sha256=YYGQ4TzgloGwCU4FAfSHYp96AVY0ZgGDR072_yc0pcw,21518
+dtps_http/structures.py,sha256=G3V5zol5ROE0vwmgk9ciqYtZ3qV_5qk7mR9OBzuN9EQ,16233
+dtps_http/types.py,sha256=0izHqzwhIqABEFg6lPuf9-fzu8VvxjsukOOlepl9nhQ,3555
+dtps_http/types_of_source.py,sha256=qpq--U-xBYPWPKpGN1z8wq_uOk0oLBahW9Voz-A2NF0,21400
 dtps_http/urls.py,sha256=NmGcqCpanRrco1JhPQGNvn-rLG2jIQ9W7J2G9YyisGQ,4336
-dtps_http/utils.py,sha256=6cQ1tEmTZnPFGOk3FOk-9Yw9GrY_dsM-r_P0pVwg3G4,6138
+dtps_http/utils.py,sha256=ER5mn_u1EVF0KHP34i-LsBRuWtkOVDcebooQlV6SozA,6114
 dtps_http/utils_every_once_in_a_while.py,sha256=nvZsWa1dnK0i8bSkOciUw-VrLxMpT25QZ6pOcXQICig,838
-dtps_http_programs/__init__.py,sha256=yY2FJigkLT-nb1J9rdu7HX_Rah8xw40QsFaYtcM_1JA,257
+dtps_http_programs/__init__.py,sha256=f1W2LssjicOmQJ2ulwC8d9djFknf9kVvZS1Ykmlir0U,257
 dtps_http_programs/dtps_listen.py,sha256=2T-CxSAqnC7mdT5AD-bsYqWBggPABefadL_TjxGrBR0,3671
 dtps_http_programs/dtps_proxy.py,sha256=luhDbyOQeFuQOeAXhIB8CjsYhjW8260rHVN2vVWKiTM,1721
 dtps_http_programs/dtps_send_continuous.py,sha256=M4QHRoAUrZ04Rshm11n-g4CUsEeDjvW_UpdRqUHccvo,1338
 dtps_http_programs/dtps_stats.py,sha256=oC8uEjPFhUN1soZ6wkyzmffPPRLuZxrjESsbqfVBN9A,3112
 dtps_http_programs/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 dtps_http_programs/server_clock.py,sha256=r7aJJjsXN6Gy26Iy6qw_gs0xQ7RbMlgJBcAhZYFZt7M,1789
 dtps_http_programs/test_memory.py,sha256=yPSyKWtflW1XiJP3CWZB79Svcw2l6wdu9KfcM7fiNAQ,4676
+dtps_http_programs/test_memory_dashboard.py,sha256=MwdW9yT4wfNYpEzDLi9UaZRUvzuD39gfxbaMKth6YQ8,3267
+dtps_http_programs/test_memory_use.py,sha256=ctiStocnJJuysOpxsH1Fev81roVaADC3SMhIJcSZESE,5251
 static/favicon.png,sha256=6PxFTHHeynIHwf_FBPsoGbNsXB3-_TdYoem_McubXME,129
-static/send.js,sha256=zaW5Y9UQx-7Oty3q6yuL_H-HGkmrIFo0dGy2YUD1HeU,7894
+static/send.js,sha256=_dvhwM61lpyrlIDd0-3xeJ59RCPgeLzBcMpeDlNqEms,7885
 static/style.css,sha256=hYKy8n6jh47vqXRg-ljM1x3Ket2rtMhH08TpOIHaW_s,1472
-dtps_http-1.1.0.dist-info/LICENSE.pdf,sha256=V1TBclYda54_miAikuVMwqHoWjwkjHw_yoF2zEqpc_k,75933
-dtps_http-1.1.0.dist-info/METADATA,sha256=JQ_QIdMwQH5kpbt5Nu3tf0VAP-FXr6uQdYbtQkOnGeU,1001
-dtps_http-1.1.0.dist-info/WHEEL,sha256=FMvqSimYX_P7y0a7UY-_Mc83r5zkBZsCYPm7Lr0Bsq4,88
-dtps_http-1.1.0.dist-info/entry_points.txt,sha256=0f8h-Ls_gnf01ABr2FNt1iv2hZqrTfchBMIq-hJs6Uc,379
-dtps_http-1.1.0.dist-info/RECORD,,
+dtps_http-1.1.1.dist-info/LICENSE.pdf,sha256=V1TBclYda54_miAikuVMwqHoWjwkjHw_yoF2zEqpc_k,75933
+dtps_http-1.1.1.dist-info/METADATA,sha256=7QPEqKMacN1Pv3YpQMKRT0Xn6faSvaaEKuddnAHhuDg,1001
+dtps_http-1.1.1.dist-info/WHEEL,sha256=FMvqSimYX_P7y0a7UY-_Mc83r5zkBZsCYPm7Lr0Bsq4,88
+dtps_http-1.1.1.dist-info/entry_points.txt,sha256=0f8h-Ls_gnf01ABr2FNt1iv2hZqrTfchBMIq-hJs6Uc,379
+dtps_http-1.1.1.dist-info/RECORD,,
```

