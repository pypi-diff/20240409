# Comparing `tmp/filip-0.3.0.tar.gz` & `tmp/filip-0.4.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "filip-0.3.0.tar", last modified: Thu Dec 28 13:13:35 2023, max compression
+gzip compressed data, was "filip-0.4.0.tar", last modified: Tue Apr  9 16:33:38 2024, max compression
```

## Comparing `filip-0.3.0.tar` & `filip-0.4.0.tar`

### file list

```diff
@@ -1,85 +1,85 @@
-drwxrwxrwx   0        0        0        0 2023-12-28 13:13:35.525918 filip-0.3.0/
--rw-rw-rw-   0        0        0     1532 2023-02-14 15:09:16.000000 filip-0.3.0/LICENSE.md
--rw-rw-rw-   0        0        0    14940 2023-12-28 13:13:35.525918 filip-0.3.0/PKG-INFO
--rw-rw-rw-   0        0        0    13263 2023-12-26 13:15:52.000000 filip-0.3.0/README.md
-drwxrwxrwx   0        0        0        0 2023-12-28 13:13:35.171686 filip-0.3.0/filip/
--rw-rw-rw-   0        0        0      181 2023-12-08 15:02:05.000000 filip-0.3.0/filip/__init__.py
-drwxrwxrwx   0        0        0        0 2023-12-28 13:13:35.225086 filip-0.3.0/filip/clients/
--rw-rw-rw-   0        0        0       48 2022-02-21 07:22:47.000000 filip-0.3.0/filip/clients/__init__.py
--rw-rw-rw-   0        0        0    12136 2023-12-07 10:31:06.000000 filip-0.3.0/filip/clients/base_http_client.py
-drwxrwxrwx   0        0        0        0 2023-12-28 13:13:35.240713 filip-0.3.0/filip/clients/mqtt/
--rw-rw-rw-   0        0        0       99 2022-02-21 07:22:47.000000 filip-0.3.0/filip/clients/mqtt/__init__.py
--rw-rw-rw-   0        0        0    33852 2023-12-07 10:31:06.000000 filip-0.3.0/filip/clients/mqtt/client.py
-drwxrwxrwx   0        0        0        0 2023-12-28 13:13:35.256334 filip-0.3.0/filip/clients/mqtt/encoder/
--rw-rw-rw-   0        0        0       96 2022-02-21 07:22:47.000000 filip-0.3.0/filip/clients/mqtt/encoder/__init__.py
--rw-rw-rw-   0        0        0     3308 2022-02-21 07:22:47.000000 filip-0.3.0/filip/clients/mqtt/encoder/base_encoder.py
--rw-rw-rw-   0        0        0     1294 2022-02-21 07:22:47.000000 filip-0.3.0/filip/clients/mqtt/encoder/json.py
--rw-rw-rw-   0        0        0     2201 2022-02-21 07:22:47.000000 filip-0.3.0/filip/clients/mqtt/encoder/ulralight.py
-drwxrwxrwx   0        0        0        0 2023-12-28 13:13:35.271961 filip-0.3.0/filip/clients/ngsi_ld/
--rw-rw-rw-   0        0        0       74 2022-02-21 07:22:47.000000 filip-0.3.0/filip/clients/ngsi_ld/__init__.py
-drwxrwxrwx   0        0        0        0 2023-12-28 13:13:35.287586 filip-0.3.0/filip/clients/ngsi_v2/
--rw-rw-rw-   0        0        0      210 2022-02-21 07:22:47.000000 filip-0.3.0/filip/clients/ngsi_v2/__init__.py
--rw-rw-rw-   0        0        0    82656 2023-12-07 10:31:06.000000 filip-0.3.0/filip/clients/ngsi_v2/cb.py
--rw-rw-rw-   0        0        0     8543 2023-12-07 10:31:06.000000 filip-0.3.0/filip/clients/ngsi_v2/client.py
--rw-rw-rw-   0        0        0    28307 2023-12-07 10:31:06.000000 filip-0.3.0/filip/clients/ngsi_v2/iota.py
--rw-rw-rw-   0        0        0    51022 2023-12-07 10:31:06.000000 filip-0.3.0/filip/clients/ngsi_v2/quantumleap.py
--rw-rw-rw-   0        0        0     1427 2023-12-07 10:31:06.000000 filip-0.3.0/filip/config.py
--rw-rw-rw-   0        0        0      247 2023-12-07 10:31:06.000000 filip-0.3.0/filip/custom_types.py
-drwxrwxrwx   0        0        0        0 2023-12-28 13:13:35.140435 filip-0.3.0/filip/data/
-drwxrwxrwx   0        0        0        0 2023-12-28 13:13:35.303212 filip-0.3.0/filip/data/unece-units/
--rw-rw-rw-   0        0        0      480 2022-02-21 07:22:47.000000 filip-0.3.0/filip/data/unece-units/levels.csv
--rw-rw-rw-   0        0        0   197077 2022-02-21 07:22:47.000000 filip-0.3.0/filip/data/unece-units/units_of_measure.csv
-drwxrwxrwx   0        0        0        0 2023-12-28 13:13:35.309723 filip-0.3.0/filip/models/
--rw-rw-rw-   0        0        0       30 2022-02-21 07:22:47.000000 filip-0.3.0/filip/models/__init__.py
--rw-rw-rw-   0        0        0     4149 2023-12-08 15:00:34.000000 filip-0.3.0/filip/models/base.py
--rw-rw-rw-   0        0        0      452 2022-02-21 07:22:47.000000 filip-0.3.0/filip/models/mqtt.py
-drwxrwxrwx   0        0        0        0 2023-12-28 13:13:35.309723 filip-0.3.0/filip/models/ngsi_ld/
--rw-rw-rw-   0        0        0       63 2022-02-21 07:22:47.000000 filip-0.3.0/filip/models/ngsi_ld/__init__.py
-drwxrwxrwx   0        0        0        0 2023-12-28 13:13:35.340990 filip-0.3.0/filip/models/ngsi_v2/
--rw-rw-rw-   0        0        0       65 2022-02-21 07:22:47.000000 filip-0.3.0/filip/models/ngsi_v2/__init__.py
--rw-rw-rw-   0        0        0    16706 2023-12-07 10:31:06.000000 filip-0.3.0/filip/models/ngsi_v2/base.py
--rw-rw-rw-   0        0        0    23884 2023-12-07 10:31:06.000000 filip-0.3.0/filip/models/ngsi_v2/context.py
--rw-rw-rw-   0        0        0    24657 2023-12-07 10:31:06.000000 filip-0.3.0/filip/models/ngsi_v2/iot.py
--rw-rw-rw-   0        0        0     6161 2023-12-07 10:31:06.000000 filip-0.3.0/filip/models/ngsi_v2/registrations.py
--rw-rw-rw-   0        0        0    14878 2023-12-07 10:31:06.000000 filip-0.3.0/filip/models/ngsi_v2/subscriptions.py
--rw-rw-rw-   0        0        0     5703 2023-12-07 10:31:06.000000 filip-0.3.0/filip/models/ngsi_v2/timeseries.py
--rw-rw-rw-   0        0        0    11634 2023-12-07 10:31:06.000000 filip-0.3.0/filip/models/ngsi_v2/units.py
-drwxrwxrwx   0        0        0        0 2023-12-28 13:13:35.372238 filip-0.3.0/filip/semantics/
--rw-rw-rw-   0        0        0        0 2022-02-21 07:22:47.000000 filip-0.3.0/filip/semantics/__init__.py
-drwxrwxrwx   0        0        0        0 2023-12-28 13:13:35.387863 filip-0.3.0/filip/semantics/ontology_parser/
--rw-rw-rw-   0        0        0        0 2022-02-21 07:22:47.000000 filip-0.3.0/filip/semantics/ontology_parser/__init__.py
--rw-rw-rw-   0        0        0    29024 2022-02-21 07:22:47.000000 filip-0.3.0/filip/semantics/ontology_parser/post_processer.py
--rw-rw-rw-   0        0        0    36540 2022-02-21 07:22:47.000000 filip-0.3.0/filip/semantics/ontology_parser/rdfparser.py
--rw-rw-rw-   0        0        0     9600 2022-02-21 07:22:47.000000 filip-0.3.0/filip/semantics/ontology_parser/vocabulary_builder.py
--rw-rw-rw-   0        0        0    47357 2023-12-07 10:31:06.000000 filip-0.3.0/filip/semantics/semantics_manager.py
--rw-rw-rw-   0        0        0    61800 2023-12-07 10:31:06.000000 filip-0.3.0/filip/semantics/semantics_models.py
-drwxrwxrwx   0        0        0        0 2023-12-28 13:13:35.441268 filip-0.3.0/filip/semantics/vocabulary/
--rw-rw-rw-   0        0        0      588 2022-02-21 07:22:47.000000 filip-0.3.0/filip/semantics/vocabulary/__init__.py
--rw-rw-rw-   0        0        0     7144 2022-02-21 07:22:47.000000 filip-0.3.0/filip/semantics/vocabulary/combined_relations.py
--rw-rw-rw-   0        0        0    28748 2023-12-07 10:31:06.000000 filip-0.3.0/filip/semantics/vocabulary/entities.py
--rw-rw-rw-   0        0        0    20657 2023-12-07 10:31:06.000000 filip-0.3.0/filip/semantics/vocabulary/relation.py
--rw-rw-rw-   0        0        0     7889 2023-12-07 10:31:06.000000 filip-0.3.0/filip/semantics/vocabulary/source.py
--rw-rw-rw-   0        0        0    19635 2022-02-21 07:22:47.000000 filip-0.3.0/filip/semantics/vocabulary/vocabulary.py
--rw-rw-rw-   0        0        0    34673 2022-08-18 14:02:29.000000 filip-0.3.0/filip/semantics/vocabulary_configurator.py
-drwxrwxrwx   0        0        0        0 2023-12-28 13:13:35.503764 filip-0.3.0/filip/utils/
--rw-rw-rw-   0        0        0      216 2022-02-21 07:22:47.000000 filip-0.3.0/filip/utils/__init__.py
--rw-rw-rw-   0        0        0     5890 2023-12-07 10:31:06.000000 filip-0.3.0/filip/utils/cleanup.py
--rw-rw-rw-   0        0        0     2436 2023-06-12 08:06:50.000000 filip-0.3.0/filip/utils/data.py
--rw-rw-rw-   0        0        0      637 2022-02-21 07:22:47.000000 filip-0.3.0/filip/utils/datetime.py
--rw-rw-rw-   0        0        0     5084 2023-02-14 15:09:16.000000 filip-0.3.0/filip/utils/filter.py
--rw-rw-rw-   0        0        0       46 2022-02-21 07:22:47.000000 filip-0.3.0/filip/utils/geo_ql.py
--rw-rw-rw-   0        0        0     1344 2022-08-18 14:02:29.000000 filip-0.3.0/filip/utils/iot.py
--rw-rw-rw-   0        0        0     5205 2023-12-07 10:31:06.000000 filip-0.3.0/filip/utils/model_generation.py
--rw-rw-rw-   0        0        0    12810 2023-10-30 12:49:29.000000 filip-0.3.0/filip/utils/simple_ql.py
--rw-rw-rw-   0        0        0     5027 2023-12-07 10:31:06.000000 filip-0.3.0/filip/utils/validators.py
-drwxrwxrwx   0        0        0        0 2023-12-28 13:13:35.525918 filip-0.3.0/filip.egg-info/
--rw-rw-rw-   0        0        0    14940 2023-12-28 13:13:34.000000 filip-0.3.0/filip.egg-info/PKG-INFO
--rw-rw-rw-   0        0        0     2013 2023-12-28 13:13:34.000000 filip-0.3.0/filip.egg-info/SOURCES.txt
--rw-rw-rw-   0        0        0        1 2023-12-28 13:13:34.000000 filip-0.3.0/filip.egg-info/dependency_links.txt
--rw-rw-rw-   0        0        0      279 2023-12-28 13:13:34.000000 filip-0.3.0/filip.egg-info/requires.txt
--rw-rw-rw-   0        0        0        6 2023-12-28 13:13:34.000000 filip-0.3.0/filip.egg-info/top_level.txt
--rw-rw-rw-   0        0        0       86 2023-12-28 13:13:35.541547 filip-0.3.0/setup.cfg
--rw-rw-rw-   0        0        0     2876 2023-12-08 15:23:34.000000 filip-0.3.0/setup.py
-drwxrwxrwx   0        0        0        0 2023-12-28 13:13:35.525918 filip-0.3.0/tests/
--rw-rw-rw-   0        0        0     1626 2023-12-07 10:31:06.000000 filip-0.3.0/tests/test_config.py
--rw-rw-rw-   0        0        0     3316 2022-02-21 07:22:47.000000 filip-0.3.0/tests/test_logging.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-09 16:33:38.094662 filip-0.4.0/
+-rw-rw-rw-   0 root         (0) root         (0)     1503 2023-02-07 11:46:33.000000 filip-0.4.0/LICENSE.md
+-rw-r--r--   0 root         (0) root         (0)    15059 2024-04-09 16:33:38.094662 filip-0.4.0/PKG-INFO
+-rw-rw-rw-   0 root         (0) root         (0)    13308 2024-04-09 16:16:47.000000 filip-0.4.0/README.md
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-09 16:33:38.066662 filip-0.4.0/filip/
+-rw-rw-rw-   0 root         (0) root         (0)      174 2024-04-09 16:16:47.000000 filip-0.4.0/filip/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-09 16:33:38.070662 filip-0.4.0/filip/clients/
+-rw-rw-rw-   0 root         (0) root         (0)       46 2022-05-08 11:29:06.000000 filip-0.4.0/filip/clients/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    11772 2024-04-09 14:07:38.000000 filip-0.4.0/filip/clients/base_http_client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-09 16:33:38.070662 filip-0.4.0/filip/clients/mqtt/
+-rw-rw-rw-   0 root         (0) root         (0)       96 2022-05-08 11:29:06.000000 filip-0.4.0/filip/clients/mqtt/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    33015 2024-04-03 12:39:18.000000 filip-0.4.0/filip/clients/mqtt/client.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-09 16:33:38.070662 filip-0.4.0/filip/clients/mqtt/encoder/
+-rw-rw-rw-   0 root         (0) root         (0)       94 2022-05-08 11:29:06.000000 filip-0.4.0/filip/clients/mqtt/encoder/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     3198 2022-05-08 11:29:06.000000 filip-0.4.0/filip/clients/mqtt/encoder/base_encoder.py
+-rw-rw-rw-   0 root         (0) root         (0)     1258 2022-05-08 11:29:06.000000 filip-0.4.0/filip/clients/mqtt/encoder/json.py
+-rw-rw-rw-   0 root         (0) root         (0)     2148 2022-05-08 11:29:06.000000 filip-0.4.0/filip/clients/mqtt/encoder/ulralight.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-09 16:33:38.070662 filip-0.4.0/filip/clients/ngsi_ld/
+-rw-rw-rw-   0 root         (0) root         (0)       72 2022-05-08 11:29:06.000000 filip-0.4.0/filip/clients/ngsi_ld/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-09 16:33:38.074662 filip-0.4.0/filip/clients/ngsi_v2/
+-rw-rw-rw-   0 root         (0) root         (0)      203 2022-05-08 11:29:06.000000 filip-0.4.0/filip/clients/ngsi_v2/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    86424 2024-04-09 16:16:47.000000 filip-0.4.0/filip/clients/ngsi_v2/cb.py
+-rw-rw-rw-   0 root         (0) root         (0)     8321 2024-01-02 12:41:27.000000 filip-0.4.0/filip/clients/ngsi_v2/client.py
+-rw-rw-rw-   0 root         (0) root         (0)    27515 2024-04-09 14:07:38.000000 filip-0.4.0/filip/clients/ngsi_v2/iota.py
+-rw-rw-rw-   0 root         (0) root         (0)    49805 2024-04-09 16:16:47.000000 filip-0.4.0/filip/clients/ngsi_v2/quantumleap.py
+-rw-rw-rw-   0 root         (0) root         (0)     1397 2024-01-02 12:41:27.000000 filip-0.4.0/filip/config.py
+-rw-rw-rw-   0 root         (0) root         (0)      239 2024-01-02 12:41:27.000000 filip-0.4.0/filip/custom_types.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-09 16:33:38.062662 filip-0.4.0/filip/data/
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-09 16:33:38.074662 filip-0.4.0/filip/data/unece-units/
+-rw-rw-rw-   0 root         (0) root         (0)      464 2022-05-08 11:29:06.000000 filip-0.4.0/filip/data/unece-units/levels.csv
+-rw-rw-rw-   0 root         (0) root         (0)   194959 2022-05-08 11:29:06.000000 filip-0.4.0/filip/data/unece-units/units_of_measure.csv
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-09 16:33:38.078662 filip-0.4.0/filip/models/
+-rw-rw-rw-   0 root         (0) root         (0)       30 2024-04-09 14:07:38.000000 filip-0.4.0/filip/models/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     4559 2024-04-09 16:16:47.000000 filip-0.4.0/filip/models/base.py
+-rw-rw-rw-   0 root         (0) root         (0)      437 2022-05-08 11:29:06.000000 filip-0.4.0/filip/models/mqtt.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-09 16:33:38.078662 filip-0.4.0/filip/models/ngsi_ld/
+-rw-rw-rw-   0 root         (0) root         (0)       63 2022-05-08 11:29:06.000000 filip-0.4.0/filip/models/ngsi_ld/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-09 16:33:38.082662 filip-0.4.0/filip/models/ngsi_v2/
+-rw-rw-rw-   0 root         (0) root         (0)       62 2024-04-09 14:07:38.000000 filip-0.4.0/filip/models/ngsi_v2/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    18442 2024-04-09 16:16:47.000000 filip-0.4.0/filip/models/ngsi_v2/base.py
+-rw-rw-rw-   0 root         (0) root         (0)    26010 2024-04-09 16:16:47.000000 filip-0.4.0/filip/models/ngsi_v2/context.py
+-rw-rw-rw-   0 root         (0) root         (0)    24046 2024-04-09 16:16:47.000000 filip-0.4.0/filip/models/ngsi_v2/iot.py
+-rw-rw-rw-   0 root         (0) root         (0)     6020 2024-04-09 14:07:38.000000 filip-0.4.0/filip/models/ngsi_v2/registrations.py
+-rw-rw-rw-   0 root         (0) root         (0)    14721 2024-04-09 14:07:38.000000 filip-0.4.0/filip/models/ngsi_v2/subscriptions.py
+-rw-rw-rw-   0 root         (0) root         (0)     5541 2024-01-02 12:41:27.000000 filip-0.4.0/filip/models/ngsi_v2/timeseries.py
+-rw-rw-rw-   0 root         (0) root         (0)    11295 2024-02-02 14:29:51.000000 filip-0.4.0/filip/models/ngsi_v2/units.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-09 16:33:38.082662 filip-0.4.0/filip/semantics/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2022-05-08 11:29:06.000000 filip-0.4.0/filip/semantics/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-09 16:33:38.086662 filip-0.4.0/filip/semantics/ontology_parser/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2022-05-08 11:29:06.000000 filip-0.4.0/filip/semantics/ontology_parser/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    28335 2022-05-08 11:29:06.000000 filip-0.4.0/filip/semantics/ontology_parser/post_processer.py
+-rw-rw-rw-   0 root         (0) root         (0)    35716 2022-05-08 11:29:06.000000 filip-0.4.0/filip/semantics/ontology_parser/rdfparser.py
+-rw-rw-rw-   0 root         (0) root         (0)     9315 2022-05-08 11:29:06.000000 filip-0.4.0/filip/semantics/ontology_parser/vocabulary_builder.py
+-rw-rw-rw-   0 root         (0) root         (0)    46106 2024-01-02 12:41:27.000000 filip-0.4.0/filip/semantics/semantics_manager.py
+-rw-rw-rw-   0 root         (0) root         (0)    59987 2024-02-02 14:29:51.000000 filip-0.4.0/filip/semantics/semantics_models.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-09 16:33:38.086662 filip-0.4.0/filip/semantics/vocabulary/
+-rw-rw-rw-   0 root         (0) root         (0)      561 2022-05-08 11:29:06.000000 filip-0.4.0/filip/semantics/vocabulary/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     6920 2022-05-08 11:29:06.000000 filip-0.4.0/filip/semantics/vocabulary/combined_relations.py
+-rw-rw-rw-   0 root         (0) root         (0)    27900 2024-01-02 12:41:27.000000 filip-0.4.0/filip/semantics/vocabulary/entities.py
+-rw-rw-rw-   0 root         (0) root         (0)    20101 2024-01-02 12:41:27.000000 filip-0.4.0/filip/semantics/vocabulary/relation.py
+-rw-rw-rw-   0 root         (0) root         (0)     7662 2024-01-02 12:41:27.000000 filip-0.4.0/filip/semantics/vocabulary/source.py
+-rw-rw-rw-   0 root         (0) root         (0)    19010 2022-05-08 11:29:06.000000 filip-0.4.0/filip/semantics/vocabulary/vocabulary.py
+-rw-rw-rw-   0 root         (0) root         (0)    33798 2022-08-18 11:43:30.000000 filip-0.4.0/filip/semantics/vocabulary_configurator.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-09 16:33:38.090662 filip-0.4.0/filip/utils/
+-rw-rw-rw-   0 root         (0) root         (0)      209 2022-05-08 11:29:06.000000 filip-0.4.0/filip/utils/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     5703 2024-04-03 16:20:56.000000 filip-0.4.0/filip/utils/cleanup.py
+-rw-rw-rw-   0 root         (0) root         (0)     2364 2022-05-08 11:29:06.000000 filip-0.4.0/filip/utils/data.py
+-rw-rw-rw-   0 root         (0) root         (0)      607 2022-05-08 11:29:06.000000 filip-0.4.0/filip/utils/datetime.py
+-rw-rw-rw-   0 root         (0) root         (0)     4960 2023-02-07 12:15:27.000000 filip-0.4.0/filip/utils/filter.py
+-rw-rw-rw-   0 root         (0) root         (0)       44 2022-05-08 11:29:06.000000 filip-0.4.0/filip/utils/geo_ql.py
+-rw-rw-rw-   0 root         (0) root         (0)     1312 2022-08-18 11:14:35.000000 filip-0.4.0/filip/utils/iot.py
+-rw-rw-rw-   0 root         (0) root         (0)     5049 2024-01-02 12:41:27.000000 filip-0.4.0/filip/utils/model_generation.py
+-rw-rw-rw-   0 root         (0) root         (0)    12495 2023-10-30 16:39:03.000000 filip-0.4.0/filip/utils/simple_ql.py
+-rw-rw-rw-   0 root         (0) root         (0)     4859 2024-01-02 12:41:27.000000 filip-0.4.0/filip/utils/validators.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-09 16:33:38.090662 filip-0.4.0/filip.egg-info/
+-rw-r--r--   0 root         (0) root         (0)    15059 2024-04-09 16:33:38.000000 filip-0.4.0/filip.egg-info/PKG-INFO
+-rw-r--r--   0 root         (0) root         (0)     2013 2024-04-09 16:33:38.000000 filip-0.4.0/filip.egg-info/SOURCES.txt
+-rw-r--r--   0 root         (0) root         (0)        1 2024-04-09 16:33:38.000000 filip-0.4.0/filip.egg-info/dependency_links.txt
+-rw-r--r--   0 root         (0) root         (0)      349 2024-04-09 16:33:38.000000 filip-0.4.0/filip.egg-info/requires.txt
+-rw-r--r--   0 root         (0) root         (0)        6 2024-04-09 16:33:38.000000 filip-0.4.0/filip.egg-info/top_level.txt
+-rw-rw-rw-   0 root         (0) root         (0)       79 2024-04-09 16:33:38.094662 filip-0.4.0/setup.cfg
+-rw-rw-rw-   0 root         (0) root         (0)     2939 2024-04-09 16:16:47.000000 filip-0.4.0/setup.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-09 16:33:38.090662 filip-0.4.0/tests/
+-rw-rw-rw-   0 root         (0) root         (0)     1575 2024-01-02 12:41:27.000000 filip-0.4.0/tests/test_config.py
+-rw-rw-rw-   0 root         (0) root         (0)     3239 2022-05-08 11:29:06.000000 filip-0.4.0/tests/test_logging.py
```

### Comparing `filip-0.3.0/LICENSE.md` & `filip-0.4.0/LICENSE.md`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,29 +1,29 @@
-BSD 3-Clause License
-
-Copyright (c) 2021-2022
-All rights reserved.
-
-Redistribution and use in source and binary forms, with or without
-modification, are permitted provided that the following conditions are met:
-
-* Redistributions of source code must retain the above copyright notice, this
-  list of conditions and the following disclaimer.
-
-* Redistributions in binary form must reproduce the above copyright notice,
-  this list of conditions and the following disclaimer in the documentation
-  and/or other materials provided with the distribution.
-
-* Neither the name of the copyright holder nor the names of its
-  contributors may be used to endorse or promote products derived from
-  this software without specific prior written permission.
-
-THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
-AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
-IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
-DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
-FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
-DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
-SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
-CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
-OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+BSD 3-Clause License
+
+Copyright (c) 2021-2022
+All rights reserved.
+
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are met:
+
+* Redistributions of source code must retain the above copyright notice, this
+  list of conditions and the following disclaimer.
+
+* Redistributions in binary form must reproduce the above copyright notice,
+  this list of conditions and the following disclaimer in the documentation
+  and/or other materials provided with the distribution.
+
+* Neither the name of the copyright holder nor the names of its
+  contributors may be used to endorse or promote products derived from
+  this software without specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
```

### Comparing `filip-0.3.0/PKG-INFO` & `filip-0.4.0/README.md`

 * *Files 13% similar despite different names*

```diff
@@ -1,335 +1,300 @@
-Metadata-Version: 2.1
-Name: filip
-Version: 0.3.0
-Summary: [FI]WARE [Li]brary for [P]ython
-Home-page: https://github.com/RWTH-EBC/filip
-Download-URL: https://github.com/RWTH-EBC/FiLiP/archive/refs/tags/v0.3.0.tar.gz
-Author: RWTH Aachen University, E.ON Energy Research Center, Institute        of Energy Efficient Buildings and Indoor Climate
-Author-email: tstorek@eonerc.rwth-aachen.de
-Project-URL: Documentation, https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/docs/index.html
-Project-URL: Source, https://github.com/RWTH-EBC/filip
-Project-URL: Download, https://github.com/RWTH-EBC/FiLiP/archive/refs/tags/v0.3.0.tar.gz
-Keywords: iot,fiware,semantic
-Classifier: Development Status :: 3 - Alpha
-Classifier: Topic :: Scientific/Engineering
-Classifier: Intended Audience :: Science/Research
-Classifier: Programming Language :: Python :: 3.7
-Classifier: Programming Language :: Python :: 3.8
-Classifier: Programming Language :: Python :: 3.9
-Classifier: License :: OSI Approved :: BSD License
-Requires-Python: >=3.7
-Description-Content-Type: text/markdown
-License-File: LICENSE.md
-Requires-Dist: aenum~=3.1.15
-Requires-Dist: datamodel_code_generator[http]~=0.25.0
-Requires-Dist: paho-mqtt~=1.6.1
-Requires-Dist: pandas~=1.3.5
-Requires-Dist: pandas_datapackage_reader~=0.18.0
-Requires-Dist: pydantic~=2.5.2
-Requires-Dist: pydantic-settings~=2.0.0
-Requires-Dist: stringcase>=1.2.0
-Requires-Dist: rdflib~=6.0.0
-Requires-Dist: regex~=2023.10.3
-Requires-Dist: requests~=2.31.0
-Requires-Dist: rapidfuzz~=3.4.0
-Requires-Dist: wget~=3.2
-Provides-Extra: semantics
-Requires-Dist: igraph~=0.9.8; extra == "semantics"
-
-![E.ON EBC RWTH Aachen University](https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/logos/EBC_Logo.png)
-
-# FiLiP
-
-[![pylint](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/pylint/pylint.svg)](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/pylint/pylint.html)
-[![Documentation](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/docs/doc.svg)](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/docs/index.html)
-[![coverage](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/coverage/badge.svg)](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/coverage)
-[![License](https://img.shields.io/badge/License-BSD%203--Clause-blue.svg)](https://opensource.org/licenses/BSD-3-Clause)
-[![build](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/build/build.svg)](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/build/build.svg)
-
-FiLiP (Fiware Library for Python) is a python software development kit (SDK) for 
-accelerating the development of web services that use Fiware's Generic 
-Enablers (GEs) as backend.
-
-It is mainly based on the [Pydantic](https://pydantic-docs.helpmanual.io/) 
-package which is a sophisticated library for data validation and settings 
-management using python type annotations.
-Pydantic enforces type hints at runtime, and provides user friendly errors 
-when data is invalid.
-We mainly use the Pydantic model to build our own data model structure required 
-for efficient data model parsing and validation and interaction with FIWARE 
-services' RestAPIs.
-
-For API interaction, FiLiP relies on the well-known 
-[requests](https://docs.python-requests.org/en/latest/) package. 
-It is important to understand that we do not in any way restrict any 
-features of requests.
-
-Furthermore, FiLiP is designed to help with the fast development of FIWARE-based 
-applications and avoid hundreds of lines of boilerplate, but it cannot 
-substitute learning the basic concepts behind the used FIWARE components.
-
-## General Motivation
-
-Why implement a client library when clients can be auto-generated 
-from openapi documentation? 
-A general prerequisite to do so is that the documentation is in depth and of 
-good quality. 
-While FIWARE generally provides 
-[openapi documentation](https://github.com/FIWARE/specifications),
-here are some thoughts on the challenges of auto-generating client code from 
-these documents:
-
-- Auto-generated code tends to become rather bulky and its quality strongly
-  depends on the provided input data.
-- Manipulating generated code can result in a big hassle for maintenance if 
-  additional features need to be integrated.
-- The underlying NGSI (Next Generation Service Interface) for FIWARE is a
-  rather generic specification.
-  Hence, generated models may also be of generic types as lists
-  and dicts in Python. So there is no real benefit.
-  Furthermore, there is no chance for reasonable validation and error handling.
-
-## Getting started
-
-The following section shortly describes how to use the library.
-
-### Prerequisites
-
-Since FiLiP is designed as a client library, it requires a server that provides 
-the target Service-APIs.
-Hence, if you do not yet have a running instance of a FIWARE based platform, 
-using docker is the most convenient way to set it up. 
-Please check [here](https://github.com/N5GEH/n5geh.platform) for a tutorial 
-on this.
-If this is not an option for you, FIWARE also provides a testing server.
-You can register for a testing account 
-[here](https://www.fiware.org/developers/fiware-lab/).
-> **Note**: FiLiP is now compatible to [Pydantic V2](https://docs.pydantic.dev/latest/migration/). If your program still require Pydantic V1.x for some reason, please use release [v0.2.5](https://github.com/RWTH-EBC/FiLiP/releases/tag/v0.2.5) or earlier version of FiLiP. Besides, we recommended to use `pydantic~=1.10` in the `requirements.txt`
-
-### Installation
-
-The easiest way to install the library is via pip:
-
-````
-pip install -U filip
-````
-
-If you want to benefit from the latest changes, use the following command 
-(This will install the current master branch from this repository):
-
-```
-pip install -U git+git://github.com/RWTH-EBC/filip
-```
-
-#### Install semantics module (optional)
-
-If you want to use the optional [semantics module](filip/semantics), use the following command (This will install the libraries that only required for the semantics module):
-````
-pip install -U filip[semantics]
-````
-
-### Introduction to FIWARE
-
-The following section introduces FIWARE. If you are already familiar with 
-FIWARE, you can skip this section and go straight to [Getting Started](#getting-started).
-
-#### What is FIWARE?
-
-FIWARE is a framework of open-source cloud platform components, created 
-to facilitate the development of smart solutions within various application 
-domains. 
-At the moment, the FIWARE 
-[catalogue](https://www.fiware.org/developers/catalogue/) contains over 30 
-interoperable software modules, so-called Generic Enablers 
-(GE) for developing and providing customized IoT platform solutions.
-
-To get familiar with the APIs of the different modules we highly recommend 
-checking the 
-[step-by-step tutorial](https://fiware-tutorials.readthedocs.io/en/latest/). 
-It provides a good overview on FIWARE and its basic usage.
-Whereas the tutorial helps to understand most of the general concepts, 
-for a deep dive, where you can learn about the components in more detail, 
-FIWARE also offers extended lessons through their 
-[academy](https://fiware-academy.readthedocs.io/en/latest/index.html/).
-
-However, usually one only requires a small set of components. 
-Hence, we recommend using the cited pages only as needed.
-
-#### How to set up a FIWARE platform?
-
-The easiest way to set up a FIWARE platform is by using docker as all GEs are 
-open-source and distributed as docker containers on dockerhub.
-
-However, as mentioned before, for most use cases only a subset of GEs is required.
-Hence, we wrote a small [tutorial](https://github.com/N5GEH/n5geh.platform) 
-explaining how to set up a platform suited for most use cases within the energy 
-domain. 
-
-#### FIWARE GEs covered by FiLiP
-
-FiLiP is a library developed on demand.
-Hence, we do not aim to cover the APIs of all GEs that are included in the 
-[catalogue](https://www.fiware.org/developers/catalogue/). 
-This would mean an unnecessary development overhead. 
-Therefore, FiLiP currently only covers the APIs of the following GEs:
-
-- NGSIv2 Context Broker for managing context data. We use its 
-  reference implementation ORION for testing.
-    - [documentation](https://fiware-orion.readthedocs.io/en/master/)
-    - [github](https://github.com/telefonicaid/fiware-orion)
-    - [swagger](https://swagger.lab.fiware.org/)
-    - [NGSI v2 specifications](https://github.com/FIWARE/specifications/tree/master/OpenAPI/ngsiv2)
-    
-    
-- IoT-Agents for managing IoT Devices. IoT agents are implemented using 
-  the FIWARE IoT Agent Node Lib as a common framework.
-    - [documentation](https://iotagent-node-lib.readthedocs.io/en/latest/)
-    - [github](https://github.com/telefonicaid/iotagent-node-lib)
-
-    
-- IoT-Agent-JSON for managing devices using a JSON message payload protocol 
-  format.  
-    - [documentation](https://fiware-iotagent-json.readthedocs.io/en/latest/)
-    - [github](https://github.com/telefonicaid/iotagent-json)
-    - [apiary](https://telefonicaiotiotagents.docs.apiary.io/) 
-    (*partly deprecated*)
-
-  Example payload:
-  
-        {
-            "humidity": "45%",
-            "temperature": "23",
-            "luminosity": "1570"
-        }  
-
-- IoT-Agent-Ultralight for managing devices using an Ultralight 2.0 message 
-  payload protocol.
-  
-    - [documentation](https://fiware-iotagent-ul.readthedocs.io/en/latest/)
-    - [github](https://github.com/telefonicaid/iotagent-ul)
-    - [apiary](https://telefonicaiotiotagents.docs.apiary.io/) 
-      (*partly deprecated*)
-    
-    Example payload:
-  
-        humidity|45%|temperature|23|luminosity|1570
-        
-- QuantumLeap for the management of time series data
-  
-    - [documentation](https://quantumleap.readthedocs.io/en/latest/)
-    - [github](https://github.com/FIWARE-GEs/quantum-leap)
-    - [swagger](https://app.swaggerhub.com/apis/smartsdk/ngsi-tsdb/0.8.3)
-
-## Structure of FiLiP
-
-![Library Structure](https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/diagrams/out/architecture.png)
-
-
-## Documentation
-
-We are still working on the documentation.
-You can find our current documentation 
-[here](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/docs/index.html).
-
-## Running examples
-
-Once you have installed the library, you can check the [examples](/examples)
-to learn how to use the different components. 
-
-Currently, we provide basic examples for the usage of FiLiP for the FIWARE 
-GEs mentioned above.
-We suggest to start in the right order to first understand the 
-configuration of clients.
-Afterwards, you can start modelling context data and interacting with the context 
-broker and use its functionalities before you learn how to connect 
-IoT Devices and store historic data.
-
-## Testing
-
-We use unittests to write our test cases.
-To test the source code of the library in our CI workflow, the CI 
-executes all tests located in the `tests`-directory and prefixed with `test_` .
-
-## How to contribute
-
-Please see our [contribution guide](./CONTRIBUTING.md) for more details on 
-how you can contribute to this project.
-
-## Authors
-
-* [Thomas Storek](https://www.ebc.eonerc.rwth-aachen.de/cms/E-ON-ERC-EBC/Das-Institut/Mitarbeiter/Team2/~lhda/Thomas-Storek/?lidx=1) 
-* [Junsong Du](https://www.ebc.eonerc.rwth-aachen.de/cms/E-ON-ERC-EBC/Das-Institut/Mitarbeiter/Digitale-Energie-Quartiere/~trcib/Du-Junsong/lidx/1/) (corresponding)
-* [Saira Bano](https://www.ebc.eonerc.rwth-aachen.de/cms/E-ON-ERC-EBC/Das-Institut/Mitarbeiter/Systemadministration/~ohhca/Bano-Saira/)
-
-## Alumni
-
-* Jeff Reding
-* Felix Rehmann
-* Daniel Nikolay
-
-## References
-
-We presented or applied the library in the following publications:
-
-- Haghgoo, M., Dognini, A., Storek, T., Plamanescu, R, Rahe, U., 
-  Gheorghe, S, Albu, M., Monti, A., MÃ¼ller, D. (2021) A cloud-based service-oriented architecture to unlock smart energy services
-  https://www.doi.org/10.1186/s42162-021-00143-x
-
-- Baranski, M., Storek, T. P. B., KÃ¼mpel, A., Blechmann, S., Streblow, R., 
-MÃ¼ller, D. et al.,
-(2020). National 5G Energy Hub : Application of the Open-Source Cloud Platform 
-FIWARE for Future Energy Management Systems. 
-https://doi.org/10.18154/RWTH-2020-07876
-
-- T. Storek, J. LohmÃ¶ller, A. KÃ¼mpel, M. Baranski & D. MÃ¼ller (2019). 
-Application of the open-source cloud platform FIWARE for future building 
-energy management systems. 
-Journal of Physics: 
-Conference Series, 1343, 12063. https://doi.org/10.1088/1742-6596/1343/1/012063
-
-## License
-
-This project is licensed under the BSD License - see the [LICENSE](LICENSE) file for details.
-
-## Copyright
-
-<a href="https://www.ebc.eonerc.rwth-aachen.de/"> <img alt="EBC" src="https://www.ebc.eonerc.rwth-aachen.de/global/show_picture.asp?id=aaaaaaaaaakevlz" height="100"> </a>
-
-2021-2022, RWTH Aachen University, E.ON Energy Research Center, Institute for Energy 
-Efficient Buildings and Indoor Climate
-
-[Institute for Energy Efficient Buildings and Indoor Climate (EBC)](https://www.ebc.eonerc.rwth-aachen.de)  
-[E.ON Energy Research Center (E.ON ERC)](https://www.eonerc.rwth-aachen.de)  
-[RWTH University Aachen, Germany](https://www.rwth-aachen.de)
-
-## Disclaimer
-
-This project is part of the cooperation between the RWTH Aachen University and 
-the Research Centre JÃ¼lich.
-
-<a href="https://www.jara.org/de/forschung/jara-energy"> <img alt="JARA 
-ENERGY" src="https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/logos/LogoJARAEnergy.jpg" height="100"> </a>
-
-## Related projects
-
-<a href="https://n5geh.de/"> <img alt="National 5G Energy Hub" 
-src="https://avatars.githubusercontent.com/u/43948851?s=200&v=4" height="100"></a>
-
-<a href="https://fismep.de/"> <img alt="FISMEP" 
-src="https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/logos/FISMEP.png" 
-height="100"></a>
-
-
-## Acknowledgments
-
-We gratefully acknowledge the financial support of the Federal Ministry <br /> 
-for Economic Affairs and Climate Action (BMWK), promotional references 
-03ET1495A, 03ET1551A, 0350018A, 03ET1561B.
-
-<a href="https://www.bmwi.de/Navigation/EN/Home/home.html"> <img alt="BMWK" 
-src="https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/logos/bmwi_logo_en.png" height="100"> </a>
-
-This project has received funding in the framework of the joint programming initiative ERA-Net Smart Grids Plus, with support from the European Unionâ€™s Horizon 2020 research and innovation programme.
-
-<a href="https://www.eranet-smartgridsplus.eu/"> <img alt="ERANET" 
-src="https://fismep.de/wp-content/uploads/2017/09/SmartGridsPlus_rgb-300x55.jpg" height="100"> </a>
+![E.ON EBC RWTH Aachen University](https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/logos/EBC_Logo.png)
+
+# FiLiP
+
+[![pylint](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/pylint/pylint.svg)](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/pylint/pylint.html)
+[![Documentation](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/docs/doc.svg)](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/docs/index.html)
+[![coverage](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/coverage/badge.svg)](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/coverage)
+[![License](https://img.shields.io/badge/License-BSD%203--Clause-blue.svg)](https://opensource.org/licenses/BSD-3-Clause)
+[![build](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/build/build.svg)](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/build/build.svg)
+
+FiLiP (Fiware Library for Python) is a python software development kit (SDK) for 
+accelerating the development of web services that use Fiware's Generic 
+Enablers (GEs) as backend.
+
+It is mainly based on the [Pydantic](https://pydantic-docs.helpmanual.io/) 
+package which is a sophisticated library for data validation and settings 
+management using python type annotations.
+Pydantic enforces type hints at runtime, and provides user friendly errors 
+when data is invalid.
+We mainly use the Pydantic model to build our own data model structure required 
+for efficient data model parsing and validation and interaction with FIWARE 
+services' RestAPIs. 
+
+For API interaction, FiLiP relies on the well-known 
+[requests](https://docs.python-requests.org/en/latest/) package. 
+It is important to understand that we do not in any way restrict any 
+features of requests.
+
+Furthermore, FiLiP is designed to help with the fast development of FIWARE-based 
+applications and avoid hundreds of lines of boilerplate, but it cannot 
+substitute learning the basic concepts behind the used FIWARE components.
+
+## General Motivation
+
+Why implement a client library when clients can be auto-generated 
+from openapi documentation? 
+A general prerequisite to do so is that the documentation is in depth and of 
+good quality. 
+While FIWARE generally provides 
+[openapi documentation](https://github.com/FIWARE/specifications),
+here are some thoughts on the challenges of auto-generating client code from 
+these documents:
+
+- Auto-generated code tends to become rather bulky and its quality strongly
+  depends on the provided input data.
+- Manipulating generated code can result in a big hassle for maintenance if 
+  additional features need to be integrated.
+- The underlying NGSI (Next Generation Service Interface) for FIWARE is a
+  rather generic specification.
+  Hence, generated models may also be of generic types as lists
+  and dicts in Python. So there is no real benefit.
+  Furthermore, there is no chance for reasonable validation and error handling.
+
+## Getting started
+
+The following section shortly describes how to use the library.
+
+### Prerequisites
+
+Since FiLiP is designed as a client library, it requires a server that provides 
+the target Service-APIs.
+Hence, if you do not yet have a running instance of a FIWARE based platform, 
+using docker is the most convenient way to set it up. 
+Please check [here](https://github.com/N5GEH/n5geh.platform) for a tutorial 
+on this.
+If this is not an option for you, FIWARE also provides a testing server.
+You can register for a testing account 
+[here](https://www.fiware.org/developers/fiware-lab/).
+> **Note**: FiLiP is now compatible to [Pydantic V2](https://docs.pydantic.dev/latest/migration/). If your program still require Pydantic V1.x for some reason, please use release [v0.2.5](https://github.com/RWTH-EBC/FiLiP/releases/tag/v0.2.5) or earlier version of FiLiP. Besides, we recommended to use `pydantic~=1.10` in the `requirements.txt`
+
+### Installation
+
+The easiest way to install the library is via pip:
+
+````
+pip install -U filip
+````
+
+If you want to benefit from the latest changes, use the following command 
+(This will install the current master branch from this repository):
+
+```
+pip install -U git+git://github.com/RWTH-EBC/filip
+```
+
+#### Install semantics module (optional)
+
+If you want to use the optional [semantics module](filip/semantics), use the following command (This will install the libraries that only required for the semantics module):
+````
+pip install -U filip[semantics]
+````
+
+### Introduction to FIWARE
+
+The following section introduces FIWARE. If you are already familiar with 
+FIWARE, you can skip this section and go straight to [Getting Started](#getting-started).
+
+#### What is FIWARE?
+
+FIWARE is a framework of open-source cloud platform components, created 
+to facilitate the development of smart solutions within various application 
+domains. 
+At the moment, the FIWARE 
+[catalogue](https://www.fiware.org/developers/catalogue/) contains over 30 
+interoperable software modules, so-called Generic Enablers 
+(GE) for developing and providing customized IoT platform solutions.
+
+To get familiar with the APIs of the different modules we highly recommend 
+checking the 
+[step-by-step tutorial](https://fiware-tutorials.readthedocs.io/en/latest/). 
+It provides a good overview on FIWARE and its basic usage.
+Whereas the tutorial helps to understand most of the general concepts, 
+for a deep dive, where you can learn about the components in more detail, 
+FIWARE also offers extended lessons through their 
+[academy](https://fiware-academy.readthedocs.io/en/latest/index.html/).
+
+However, usually one only requires a small set of components. 
+Hence, we recommend using the cited pages only as needed.
+
+#### How to set up a FIWARE platform?
+
+The easiest way to set up a FIWARE platform is by using docker as all GEs are 
+open-source and distributed as docker containers on dockerhub.
+
+However, as mentioned before, for most use cases only a subset of GEs is required.
+Hence, we wrote a small [tutorial](https://github.com/N5GEH/n5geh.platform) 
+explaining how to set up a platform suited for most use cases within the energy 
+domain. 
+
+#### FIWARE GEs covered by FiLiP
+
+FiLiP is a library developed on demand.
+Hence, we do not aim to cover the APIs of all GEs that are included in the 
+[catalogue](https://www.fiware.org/developers/catalogue/). 
+This would mean an unnecessary development overhead. 
+Therefore, FiLiP currently only covers the APIs of the following GEs:
+
+- NGSIv2 Context Broker for managing context data. We use its 
+  reference implementation ORION for testing.
+    - [documentation](https://fiware-orion.readthedocs.io/en/master/)
+    - [github](https://github.com/telefonicaid/fiware-orion)
+    - [swagger](https://swagger.lab.fiware.org/)
+    - [NGSI v2 specifications](https://github.com/FIWARE/specifications/tree/master/OpenAPI/ngsiv2)
+    
+    
+- IoT-Agents for managing IoT Devices. IoT agents are implemented using 
+  the FIWARE IoT Agent Node Lib as a common framework.
+    - [documentation](https://iotagent-node-lib.readthedocs.io/en/latest/)
+    - [github](https://github.com/telefonicaid/iotagent-node-lib)
+
+    
+- IoT-Agent-JSON for managing devices using a JSON message payload protocol 
+  format.  
+    - [documentation](https://fiware-iotagent-json.readthedocs.io/en/latest/)
+    - [github](https://github.com/telefonicaid/iotagent-json)
+    - [apiary](https://telefonicaiotiotagents.docs.apiary.io/) 
+    (*partly deprecated*)
+
+  Example payload:
+  
+        {
+            "humidity": "45%",
+            "temperature": "23",
+            "luminosity": "1570"
+        }  
+
+- IoT-Agent-Ultralight for managing devices using an Ultralight 2.0 message 
+  payload protocol.
+  
+    - [documentation](https://fiware-iotagent-ul.readthedocs.io/en/latest/)
+    - [github](https://github.com/telefonicaid/iotagent-ul)
+    - [apiary](https://telefonicaiotiotagents.docs.apiary.io/) 
+      (*partly deprecated*)
+    
+    Example payload:
+  
+        humidity|45%|temperature|23|luminosity|1570
+        
+- QuantumLeap for the management of time series data
+  
+    - [documentation](https://quantumleap.readthedocs.io/en/latest/)
+    - [github](https://github.com/FIWARE-GEs/quantum-leap)
+    - [swagger](https://app.swaggerhub.com/apis/smartsdk/ngsi-tsdb/0.8.3)
+
+## Structure of FiLiP
+
+![Library Structure](https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/diagrams/out/architecture.png)
+
+
+## Documentation
+
+We are still working on the documentation.
+You can find our current documentation 
+[here](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/docs/index.html).
+
+## Running examples
+
+Once you have installed the library, you can check the [examples](/examples)
+to learn how to use the different components. 
+
+Currently, we provide basic examples for the usage of FiLiP for the FIWARE 
+GEs mentioned above.
+We suggest to start in the right order to first understand the 
+configuration of clients.
+Afterwards, you can start modelling context data and interacting with the context 
+broker and use its functionalities before you learn how to connect 
+IoT Devices and store historic data.
+
+## Testing
+
+We use unittests to write our test cases.
+To test the source code of the library in our CI workflow, the CI 
+executes all tests located in the `tests`-directory and prefixed with `test_` .
+
+## How to contribute
+
+Please see our [contribution guide](./CONTRIBUTING.md) for more details on 
+how you can contribute to this project.
+
+## Authors
+
+* [Thomas Storek](https://github.com/tstorek) 
+* [Junsong Du](https://www.ebc.eonerc.rwth-aachen.de/cms/E-ON-ERC-EBC/Das-Institut/Mitarbeiter/Digitale-Energie-Quartiere/~trcib/Du-Junsong/lidx/1/) (corresponding)
+* [Saira Bano](https://www.ebc.eonerc.rwth-aachen.de/cms/E-ON-ERC-EBC/Das-Institut/Mitarbeiter/Systemadministration/~ohhca/Bano-Saira/)
+* [Sebastian Blechmann](https://www.ebc.eonerc.rwth-aachen.de/cms/E-ON-ERC-EBC/Das-Institut/Mitarbeiter/Team2/~carjd/Blechmann-Sebastian/)
+
+## Alumni
+
+* Jeff Reding
+* Felix Rehmann
+* Daniel Nikolay
+
+## References
+
+We presented or applied the library in the following publications:
+
+- S. Blechmann, I. Sowa, M. H. Schraven, R. Streblow, D. Müller & A. Monti. Open source platform application for smart building and smart grid controls. Automation in Construction 145 (2023), 104622. ISSN: 0926-5805. https://doi.org/10.1016/j.autcon.2022.104622        
+
+- Haghgoo, M., Dognini, A., Storek, T., Plamanescu, R, Rahe, U., 
+  Gheorghe, S, Albu, M., Monti, A., Müller, D. (2021) A cloud-based service-oriented architecture to unlock smart energy services
+  https://www.doi.org/10.1186/s42162-021-00143-x      
+
+- Baranski, M., Storek, T. P. B., Kümpel, A., Blechmann, S., Streblow, R., 
+Müller, D. et al.,
+(2020). National 5G Energy Hub : Application of the Open-Source Cloud Platform 
+FIWARE for Future Energy Management Systems. 
+https://doi.org/10.18154/RWTH-2020-07876      
+
+- T. Storek, J. Lohmöller, A. Kümpel, M. Baranski & D. Müller (2019). 
+Application of the open-source cloud platform FIWARE for future building 
+energy management systems. 
+Journal of Physics: 
+Conference Series, 1343, 12063. https://doi.org/10.1088/1742-6596/1343/1/012063     
+
+## License
+
+This project is licensed under the BSD License - see the [LICENSE](LICENSE) file for details.
+
+## Copyright
+
+<a href="https://www.ebc.eonerc.rwth-aachen.de/"> <img alt="EBC" src="https://www.ebc.eonerc.rwth-aachen.de/global/show_picture.asp?id=aaaaaaaaaakevlz" height="100"> </a>
+
+2021-2024, RWTH Aachen University, E.ON Energy Research Center, Institute for Energy 
+Efficient Buildings and Indoor Climate
+
+[Institute for Energy Efficient Buildings and Indoor Climate (EBC)](https://www.ebc.eonerc.rwth-aachen.de)  
+[E.ON Energy Research Center (E.ON ERC)](https://www.eonerc.rwth-aachen.de)  
+[RWTH University Aachen, Germany](https://www.rwth-aachen.de)
+
+## Disclaimer
+
+This project is part of the cooperation between the RWTH Aachen University and 
+the Research Centre Jülich.
+
+<a href="https://www.jara.org/de/forschung/jara-energy"> <img alt="JARA 
+ENERGY" src="https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/logos/LogoJARAEnergy.jpg" height="100"> </a>
+
+## Related projects
+
+<a href="https://n5geh.de/"> <img alt="National 5G Energy Hub" 
+src="https://avatars.githubusercontent.com/u/43948851?s=200&v=4" height="100"></a>
+
+<a href="https://fismep.de/"> <img alt="FISMEP" 
+src="https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/logos/FISMEP.png" 
+height="100"></a>
+
+
+## Acknowledgments
+
+We gratefully acknowledge the financial support of the Federal Ministry <br /> 
+for Economic Affairs and Climate Action (BMWK), promotional references 
+03ET1495A, 03ET1551A, 0350018A, 03ET1561B.
+
+<a href="https://www.bmwi.de/Navigation/EN/Home/home.html"> <img alt="BMWK" 
+src="https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/logos/bmwi_logo_en.png" height="100"> </a>
+
+This project has received funding in the framework of the joint programming initiative ERA-Net Smart Grids Plus, with support from the European Union’s Horizon 2020 research and innovation programme.
+
+<a href="https://www.eranet-smartgridsplus.eu/"> <img alt="ERANET" 
+src="https://fismep.de/wp-content/uploads/2017/09/SmartGridsPlus_rgb-300x55.jpg" height="100"> </a>
```

### Comparing `filip-0.3.0/README.md` & `filip-0.4.0/PKG-INFO`

 * *Files 10% similar despite different names*

```diff
@@ -1,297 +1,340 @@
-![E.ON EBC RWTH Aachen University](https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/logos/EBC_Logo.png)
-
-# FiLiP
-
-[![pylint](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/pylint/pylint.svg)](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/pylint/pylint.html)
-[![Documentation](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/docs/doc.svg)](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/docs/index.html)
-[![coverage](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/coverage/badge.svg)](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/coverage)
-[![License](https://img.shields.io/badge/License-BSD%203--Clause-blue.svg)](https://opensource.org/licenses/BSD-3-Clause)
-[![build](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/build/build.svg)](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/build/build.svg)
-
-FiLiP (Fiware Library for Python) is a python software development kit (SDK) for 
-accelerating the development of web services that use Fiware's Generic 
-Enablers (GEs) as backend.
-
-It is mainly based on the [Pydantic](https://pydantic-docs.helpmanual.io/) 
-package which is a sophisticated library for data validation and settings 
-management using python type annotations.
-Pydantic enforces type hints at runtime, and provides user friendly errors 
-when data is invalid.
-We mainly use the Pydantic model to build our own data model structure required 
-for efficient data model parsing and validation and interaction with FIWARE 
-services' RestAPIs.
-
-For API interaction, FiLiP relies on the well-known 
-[requests](https://docs.python-requests.org/en/latest/) package. 
-It is important to understand that we do not in any way restrict any 
-features of requests.
-
-Furthermore, FiLiP is designed to help with the fast development of FIWARE-based 
-applications and avoid hundreds of lines of boilerplate, but it cannot 
-substitute learning the basic concepts behind the used FIWARE components.
-
-## General Motivation
-
-Why implement a client library when clients can be auto-generated 
-from openapi documentation? 
-A general prerequisite to do so is that the documentation is in depth and of 
-good quality. 
-While FIWARE generally provides 
-[openapi documentation](https://github.com/FIWARE/specifications),
-here are some thoughts on the challenges of auto-generating client code from 
-these documents:
-
-- Auto-generated code tends to become rather bulky and its quality strongly
-  depends on the provided input data.
-- Manipulating generated code can result in a big hassle for maintenance if 
-  additional features need to be integrated.
-- The underlying NGSI (Next Generation Service Interface) for FIWARE is a
-  rather generic specification.
-  Hence, generated models may also be of generic types as lists
-  and dicts in Python. So there is no real benefit.
-  Furthermore, there is no chance for reasonable validation and error handling.
-
-## Getting started
-
-The following section shortly describes how to use the library.
-
-### Prerequisites
-
-Since FiLiP is designed as a client library, it requires a server that provides 
-the target Service-APIs.
-Hence, if you do not yet have a running instance of a FIWARE based platform, 
-using docker is the most convenient way to set it up. 
-Please check [here](https://github.com/N5GEH/n5geh.platform) for a tutorial 
-on this.
-If this is not an option for you, FIWARE also provides a testing server.
-You can register for a testing account 
-[here](https://www.fiware.org/developers/fiware-lab/).
-> **Note**: FiLiP is now compatible to [Pydantic V2](https://docs.pydantic.dev/latest/migration/). If your program still require Pydantic V1.x for some reason, please use release [v0.2.5](https://github.com/RWTH-EBC/FiLiP/releases/tag/v0.2.5) or earlier version of FiLiP. Besides, we recommended to use `pydantic~=1.10` in the `requirements.txt`
-
-### Installation
-
-The easiest way to install the library is via pip:
-
-````
-pip install -U filip
-````
-
-If you want to benefit from the latest changes, use the following command 
-(This will install the current master branch from this repository):
-
-```
-pip install -U git+git://github.com/RWTH-EBC/filip
-```
-
-#### Install semantics module (optional)
-
-If you want to use the optional [semantics module](filip/semantics), use the following command (This will install the libraries that only required for the semantics module):
-````
-pip install -U filip[semantics]
-````
-
-### Introduction to FIWARE
-
-The following section introduces FIWARE. If you are already familiar with 
-FIWARE, you can skip this section and go straight to [Getting Started](#getting-started).
-
-#### What is FIWARE?
-
-FIWARE is a framework of open-source cloud platform components, created 
-to facilitate the development of smart solutions within various application 
-domains. 
-At the moment, the FIWARE 
-[catalogue](https://www.fiware.org/developers/catalogue/) contains over 30 
-interoperable software modules, so-called Generic Enablers 
-(GE) for developing and providing customized IoT platform solutions.
-
-To get familiar with the APIs of the different modules we highly recommend 
-checking the 
-[step-by-step tutorial](https://fiware-tutorials.readthedocs.io/en/latest/). 
-It provides a good overview on FIWARE and its basic usage.
-Whereas the tutorial helps to understand most of the general concepts, 
-for a deep dive, where you can learn about the components in more detail, 
-FIWARE also offers extended lessons through their 
-[academy](https://fiware-academy.readthedocs.io/en/latest/index.html/).
-
-However, usually one only requires a small set of components. 
-Hence, we recommend using the cited pages only as needed.
-
-#### How to set up a FIWARE platform?
-
-The easiest way to set up a FIWARE platform is by using docker as all GEs are 
-open-source and distributed as docker containers on dockerhub.
-
-However, as mentioned before, for most use cases only a subset of GEs is required.
-Hence, we wrote a small [tutorial](https://github.com/N5GEH/n5geh.platform) 
-explaining how to set up a platform suited for most use cases within the energy 
-domain. 
-
-#### FIWARE GEs covered by FiLiP
-
-FiLiP is a library developed on demand.
-Hence, we do not aim to cover the APIs of all GEs that are included in the 
-[catalogue](https://www.fiware.org/developers/catalogue/). 
-This would mean an unnecessary development overhead. 
-Therefore, FiLiP currently only covers the APIs of the following GEs:
-
-- NGSIv2 Context Broker for managing context data. We use its 
-  reference implementation ORION for testing.
-    - [documentation](https://fiware-orion.readthedocs.io/en/master/)
-    - [github](https://github.com/telefonicaid/fiware-orion)
-    - [swagger](https://swagger.lab.fiware.org/)
-    - [NGSI v2 specifications](https://github.com/FIWARE/specifications/tree/master/OpenAPI/ngsiv2)
-    
-    
-- IoT-Agents for managing IoT Devices. IoT agents are implemented using 
-  the FIWARE IoT Agent Node Lib as a common framework.
-    - [documentation](https://iotagent-node-lib.readthedocs.io/en/latest/)
-    - [github](https://github.com/telefonicaid/iotagent-node-lib)
-
-    
-- IoT-Agent-JSON for managing devices using a JSON message payload protocol 
-  format.  
-    - [documentation](https://fiware-iotagent-json.readthedocs.io/en/latest/)
-    - [github](https://github.com/telefonicaid/iotagent-json)
-    - [apiary](https://telefonicaiotiotagents.docs.apiary.io/) 
-    (*partly deprecated*)
-
-  Example payload:
-  
-        {
-            "humidity": "45%",
-            "temperature": "23",
-            "luminosity": "1570"
-        }  
-
-- IoT-Agent-Ultralight for managing devices using an Ultralight 2.0 message 
-  payload protocol.
-  
-    - [documentation](https://fiware-iotagent-ul.readthedocs.io/en/latest/)
-    - [github](https://github.com/telefonicaid/iotagent-ul)
-    - [apiary](https://telefonicaiotiotagents.docs.apiary.io/) 
-      (*partly deprecated*)
-    
-    Example payload:
-  
-        humidity|45%|temperature|23|luminosity|1570
-        
-- QuantumLeap for the management of time series data
-  
-    - [documentation](https://quantumleap.readthedocs.io/en/latest/)
-    - [github](https://github.com/FIWARE-GEs/quantum-leap)
-    - [swagger](https://app.swaggerhub.com/apis/smartsdk/ngsi-tsdb/0.8.3)
-
-## Structure of FiLiP
-
-![Library Structure](https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/diagrams/out/architecture.png)
-
-
-## Documentation
-
-We are still working on the documentation.
-You can find our current documentation 
-[here](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/docs/index.html).
-
-## Running examples
-
-Once you have installed the library, you can check the [examples](/examples)
-to learn how to use the different components. 
-
-Currently, we provide basic examples for the usage of FiLiP for the FIWARE 
-GEs mentioned above.
-We suggest to start in the right order to first understand the 
-configuration of clients.
-Afterwards, you can start modelling context data and interacting with the context 
-broker and use its functionalities before you learn how to connect 
-IoT Devices and store historic data.
-
-## Testing
-
-We use unittests to write our test cases.
-To test the source code of the library in our CI workflow, the CI 
-executes all tests located in the `tests`-directory and prefixed with `test_` .
-
-## How to contribute
-
-Please see our [contribution guide](./CONTRIBUTING.md) for more details on 
-how you can contribute to this project.
-
-## Authors
-
-* [Thomas Storek](https://www.ebc.eonerc.rwth-aachen.de/cms/E-ON-ERC-EBC/Das-Institut/Mitarbeiter/Team2/~lhda/Thomas-Storek/?lidx=1) 
-* [Junsong Du](https://www.ebc.eonerc.rwth-aachen.de/cms/E-ON-ERC-EBC/Das-Institut/Mitarbeiter/Digitale-Energie-Quartiere/~trcib/Du-Junsong/lidx/1/) (corresponding)
-* [Saira Bano](https://www.ebc.eonerc.rwth-aachen.de/cms/E-ON-ERC-EBC/Das-Institut/Mitarbeiter/Systemadministration/~ohhca/Bano-Saira/)
-
-## Alumni
-
-* Jeff Reding
-* Felix Rehmann
-* Daniel Nikolay
-
-## References
-
-We presented or applied the library in the following publications:
-
-- Haghgoo, M., Dognini, A., Storek, T., Plamanescu, R, Rahe, U., 
-  Gheorghe, S, Albu, M., Monti, A., Müller, D. (2021) A cloud-based service-oriented architecture to unlock smart energy services
-  https://www.doi.org/10.1186/s42162-021-00143-x
-
-- Baranski, M., Storek, T. P. B., Kümpel, A., Blechmann, S., Streblow, R., 
-Müller, D. et al.,
-(2020). National 5G Energy Hub : Application of the Open-Source Cloud Platform 
-FIWARE for Future Energy Management Systems. 
-https://doi.org/10.18154/RWTH-2020-07876
-
-- T. Storek, J. Lohmöller, A. Kümpel, M. Baranski & D. Müller (2019). 
-Application of the open-source cloud platform FIWARE for future building 
-energy management systems. 
-Journal of Physics: 
-Conference Series, 1343, 12063. https://doi.org/10.1088/1742-6596/1343/1/012063
-
-## License
-
-This project is licensed under the BSD License - see the [LICENSE](LICENSE) file for details.
-
-## Copyright
-
-<a href="https://www.ebc.eonerc.rwth-aachen.de/"> <img alt="EBC" src="https://www.ebc.eonerc.rwth-aachen.de/global/show_picture.asp?id=aaaaaaaaaakevlz" height="100"> </a>
-
-2021-2022, RWTH Aachen University, E.ON Energy Research Center, Institute for Energy 
-Efficient Buildings and Indoor Climate
-
-[Institute for Energy Efficient Buildings and Indoor Climate (EBC)](https://www.ebc.eonerc.rwth-aachen.de)  
-[E.ON Energy Research Center (E.ON ERC)](https://www.eonerc.rwth-aachen.de)  
-[RWTH University Aachen, Germany](https://www.rwth-aachen.de)
-
-## Disclaimer
-
-This project is part of the cooperation between the RWTH Aachen University and 
-the Research Centre Jülich.
-
-<a href="https://www.jara.org/de/forschung/jara-energy"> <img alt="JARA 
-ENERGY" src="https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/logos/LogoJARAEnergy.jpg" height="100"> </a>
-
-## Related projects
-
-<a href="https://n5geh.de/"> <img alt="National 5G Energy Hub" 
-src="https://avatars.githubusercontent.com/u/43948851?s=200&v=4" height="100"></a>
-
-<a href="https://fismep.de/"> <img alt="FISMEP" 
-src="https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/logos/FISMEP.png" 
-height="100"></a>
-
-
-## Acknowledgments
-
-We gratefully acknowledge the financial support of the Federal Ministry <br /> 
-for Economic Affairs and Climate Action (BMWK), promotional references 
-03ET1495A, 03ET1551A, 0350018A, 03ET1561B.
-
-<a href="https://www.bmwi.de/Navigation/EN/Home/home.html"> <img alt="BMWK" 
-src="https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/logos/bmwi_logo_en.png" height="100"> </a>
-
-This project has received funding in the framework of the joint programming initiative ERA-Net Smart Grids Plus, with support from the European Union’s Horizon 2020 research and innovation programme.
-
-<a href="https://www.eranet-smartgridsplus.eu/"> <img alt="ERANET" 
-src="https://fismep.de/wp-content/uploads/2017/09/SmartGridsPlus_rgb-300x55.jpg" height="100"> </a>
+Metadata-Version: 2.1
+Name: filip
+Version: 0.4.0
+Summary: [FI]WARE [Li]brary for [P]ython
+Home-page: https://github.com/RWTH-EBC/filip
+Download-URL: https://github.com/RWTH-EBC/FiLiP/archive/refs/tags/v0.4.0.tar.gz
+Author: RWTH Aachen University, E.ON Energy Research Center, Institute        of Energy Efficient Buildings and Indoor Climate
+Author-email: tstorek@eonerc.rwth-aachen.de
+Project-URL: Documentation, https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/docs/index.html
+Project-URL: Source, https://github.com/RWTH-EBC/filip
+Project-URL: Download, https://github.com/RWTH-EBC/FiLiP/archive/refs/tags/v0.4.0.tar.gz
+Keywords: iot,fiware,semantic
+Classifier: Development Status :: 3 - Alpha
+Classifier: Topic :: Scientific/Engineering
+Classifier: Intended Audience :: Science/Research
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3.9
+Classifier: Programming Language :: Python :: 3.10
+Classifier: Programming Language :: Python :: 3.11
+Classifier: License :: OSI Approved :: BSD License
+Requires-Python: >=3.8
+Description-Content-Type: text/markdown
+License-File: LICENSE.md
+Requires-Dist: aenum~=3.1.15
+Requires-Dist: datamodel_code_generator[http]~=0.25.0
+Requires-Dist: paho-mqtt~=1.6.1
+Requires-Dist: pandas_datapackage_reader~=0.18.0
+Requires-Dist: pydantic~=2.5.2
+Requires-Dist: pydantic-settings~=2.0.0
+Requires-Dist: stringcase>=1.2.0
+Requires-Dist: rdflib~=6.0.0
+Requires-Dist: regex~=2023.10.3
+Requires-Dist: requests~=2.31.0
+Requires-Dist: rapidfuzz~=3.4.0
+Requires-Dist: wget~=3.2
+Provides-Extra: semantics
+Requires-Dist: igraph~=0.11.2; extra == "semantics"
+Requires-Dist: pandas~=1.3.5; python_version < "3.9"
+Requires-Dist: pandas~=2.1.4; python_version >= "3.9"
+
+![E.ON EBC RWTH Aachen University](https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/logos/EBC_Logo.png)
+
+# FiLiP
+
+[![pylint](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/pylint/pylint.svg)](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/pylint/pylint.html)
+[![Documentation](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/docs/doc.svg)](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/docs/index.html)
+[![coverage](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/coverage/badge.svg)](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/coverage)
+[![License](https://img.shields.io/badge/License-BSD%203--Clause-blue.svg)](https://opensource.org/licenses/BSD-3-Clause)
+[![build](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/build/build.svg)](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/build/build.svg)
+
+FiLiP (Fiware Library for Python) is a python software development kit (SDK) for 
+accelerating the development of web services that use Fiware's Generic 
+Enablers (GEs) as backend.
+
+It is mainly based on the [Pydantic](https://pydantic-docs.helpmanual.io/) 
+package which is a sophisticated library for data validation and settings 
+management using python type annotations.
+Pydantic enforces type hints at runtime, and provides user friendly errors 
+when data is invalid.
+We mainly use the Pydantic model to build our own data model structure required 
+for efficient data model parsing and validation and interaction with FIWARE 
+services' RestAPIs. 
+
+For API interaction, FiLiP relies on the well-known 
+[requests](https://docs.python-requests.org/en/latest/) package. 
+It is important to understand that we do not in any way restrict any 
+features of requests.
+
+Furthermore, FiLiP is designed to help with the fast development of FIWARE-based 
+applications and avoid hundreds of lines of boilerplate, but it cannot 
+substitute learning the basic concepts behind the used FIWARE components.
+
+## General Motivation
+
+Why implement a client library when clients can be auto-generated 
+from openapi documentation? 
+A general prerequisite to do so is that the documentation is in depth and of 
+good quality. 
+While FIWARE generally provides 
+[openapi documentation](https://github.com/FIWARE/specifications),
+here are some thoughts on the challenges of auto-generating client code from 
+these documents:
+
+- Auto-generated code tends to become rather bulky and its quality strongly
+  depends on the provided input data.
+- Manipulating generated code can result in a big hassle for maintenance if 
+  additional features need to be integrated.
+- The underlying NGSI (Next Generation Service Interface) for FIWARE is a
+  rather generic specification.
+  Hence, generated models may also be of generic types as lists
+  and dicts in Python. So there is no real benefit.
+  Furthermore, there is no chance for reasonable validation and error handling.
+
+## Getting started
+
+The following section shortly describes how to use the library.
+
+### Prerequisites
+
+Since FiLiP is designed as a client library, it requires a server that provides 
+the target Service-APIs.
+Hence, if you do not yet have a running instance of a FIWARE based platform, 
+using docker is the most convenient way to set it up. 
+Please check [here](https://github.com/N5GEH/n5geh.platform) for a tutorial 
+on this.
+If this is not an option for you, FIWARE also provides a testing server.
+You can register for a testing account 
+[here](https://www.fiware.org/developers/fiware-lab/).
+> **Note**: FiLiP is now compatible to [Pydantic V2](https://docs.pydantic.dev/latest/migration/). If your program still require Pydantic V1.x for some reason, please use release [v0.2.5](https://github.com/RWTH-EBC/FiLiP/releases/tag/v0.2.5) or earlier version of FiLiP. Besides, we recommended to use `pydantic~=1.10` in the `requirements.txt`
+
+### Installation
+
+The easiest way to install the library is via pip:
+
+````
+pip install -U filip
+````
+
+If you want to benefit from the latest changes, use the following command 
+(This will install the current master branch from this repository):
+
+```
+pip install -U git+git://github.com/RWTH-EBC/filip
+```
+
+#### Install semantics module (optional)
+
+If you want to use the optional [semantics module](filip/semantics), use the following command (This will install the libraries that only required for the semantics module):
+````
+pip install -U filip[semantics]
+````
+
+### Introduction to FIWARE
+
+The following section introduces FIWARE. If you are already familiar with 
+FIWARE, you can skip this section and go straight to [Getting Started](#getting-started).
+
+#### What is FIWARE?
+
+FIWARE is a framework of open-source cloud platform components, created 
+to facilitate the development of smart solutions within various application 
+domains. 
+At the moment, the FIWARE 
+[catalogue](https://www.fiware.org/developers/catalogue/) contains over 30 
+interoperable software modules, so-called Generic Enablers 
+(GE) for developing and providing customized IoT platform solutions.
+
+To get familiar with the APIs of the different modules we highly recommend 
+checking the 
+[step-by-step tutorial](https://fiware-tutorials.readthedocs.io/en/latest/). 
+It provides a good overview on FIWARE and its basic usage.
+Whereas the tutorial helps to understand most of the general concepts, 
+for a deep dive, where you can learn about the components in more detail, 
+FIWARE also offers extended lessons through their 
+[academy](https://fiware-academy.readthedocs.io/en/latest/index.html/).
+
+However, usually one only requires a small set of components. 
+Hence, we recommend using the cited pages only as needed.
+
+#### How to set up a FIWARE platform?
+
+The easiest way to set up a FIWARE platform is by using docker as all GEs are 
+open-source and distributed as docker containers on dockerhub.
+
+However, as mentioned before, for most use cases only a subset of GEs is required.
+Hence, we wrote a small [tutorial](https://github.com/N5GEH/n5geh.platform) 
+explaining how to set up a platform suited for most use cases within the energy 
+domain. 
+
+#### FIWARE GEs covered by FiLiP
+
+FiLiP is a library developed on demand.
+Hence, we do not aim to cover the APIs of all GEs that are included in the 
+[catalogue](https://www.fiware.org/developers/catalogue/). 
+This would mean an unnecessary development overhead. 
+Therefore, FiLiP currently only covers the APIs of the following GEs:
+
+- NGSIv2 Context Broker for managing context data. We use its 
+  reference implementation ORION for testing.
+    - [documentation](https://fiware-orion.readthedocs.io/en/master/)
+    - [github](https://github.com/telefonicaid/fiware-orion)
+    - [swagger](https://swagger.lab.fiware.org/)
+    - [NGSI v2 specifications](https://github.com/FIWARE/specifications/tree/master/OpenAPI/ngsiv2)
+    
+    
+- IoT-Agents for managing IoT Devices. IoT agents are implemented using 
+  the FIWARE IoT Agent Node Lib as a common framework.
+    - [documentation](https://iotagent-node-lib.readthedocs.io/en/latest/)
+    - [github](https://github.com/telefonicaid/iotagent-node-lib)
+
+    
+- IoT-Agent-JSON for managing devices using a JSON message payload protocol 
+  format.  
+    - [documentation](https://fiware-iotagent-json.readthedocs.io/en/latest/)
+    - [github](https://github.com/telefonicaid/iotagent-json)
+    - [apiary](https://telefonicaiotiotagents.docs.apiary.io/) 
+    (*partly deprecated*)
+
+  Example payload:
+  
+        {
+            "humidity": "45%",
+            "temperature": "23",
+            "luminosity": "1570"
+        }  
+
+- IoT-Agent-Ultralight for managing devices using an Ultralight 2.0 message 
+  payload protocol.
+  
+    - [documentation](https://fiware-iotagent-ul.readthedocs.io/en/latest/)
+    - [github](https://github.com/telefonicaid/iotagent-ul)
+    - [apiary](https://telefonicaiotiotagents.docs.apiary.io/) 
+      (*partly deprecated*)
+    
+    Example payload:
+  
+        humidity|45%|temperature|23|luminosity|1570
+        
+- QuantumLeap for the management of time series data
+  
+    - [documentation](https://quantumleap.readthedocs.io/en/latest/)
+    - [github](https://github.com/FIWARE-GEs/quantum-leap)
+    - [swagger](https://app.swaggerhub.com/apis/smartsdk/ngsi-tsdb/0.8.3)
+
+## Structure of FiLiP
+
+![Library Structure](https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/diagrams/out/architecture.png)
+
+
+## Documentation
+
+We are still working on the documentation.
+You can find our current documentation 
+[here](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/docs/index.html).
+
+## Running examples
+
+Once you have installed the library, you can check the [examples](/examples)
+to learn how to use the different components. 
+
+Currently, we provide basic examples for the usage of FiLiP for the FIWARE 
+GEs mentioned above.
+We suggest to start in the right order to first understand the 
+configuration of clients.
+Afterwards, you can start modelling context data and interacting with the context 
+broker and use its functionalities before you learn how to connect 
+IoT Devices and store historic data.
+
+## Testing
+
+We use unittests to write our test cases.
+To test the source code of the library in our CI workflow, the CI 
+executes all tests located in the `tests`-directory and prefixed with `test_` .
+
+## How to contribute
+
+Please see our [contribution guide](./CONTRIBUTING.md) for more details on 
+how you can contribute to this project.
+
+## Authors
+
+* [Thomas Storek](https://github.com/tstorek) 
+* [Junsong Du](https://www.ebc.eonerc.rwth-aachen.de/cms/E-ON-ERC-EBC/Das-Institut/Mitarbeiter/Digitale-Energie-Quartiere/~trcib/Du-Junsong/lidx/1/) (corresponding)
+* [Saira Bano](https://www.ebc.eonerc.rwth-aachen.de/cms/E-ON-ERC-EBC/Das-Institut/Mitarbeiter/Systemadministration/~ohhca/Bano-Saira/)
+* [Sebastian Blechmann](https://www.ebc.eonerc.rwth-aachen.de/cms/E-ON-ERC-EBC/Das-Institut/Mitarbeiter/Team2/~carjd/Blechmann-Sebastian/)
+
+## Alumni
+
+* Jeff Reding
+* Felix Rehmann
+* Daniel Nikolay
+
+## References
+
+We presented or applied the library in the following publications:
+
+- S. Blechmann, I. Sowa, M. H. Schraven, R. Streblow, D. Müller & A. Monti. Open source platform application for smart building and smart grid controls. Automation in Construction 145 (2023), 104622. ISSN: 0926-5805. https://doi.org/10.1016/j.autcon.2022.104622        
+
+- Haghgoo, M., Dognini, A., Storek, T., Plamanescu, R, Rahe, U., 
+  Gheorghe, S, Albu, M., Monti, A., Müller, D. (2021) A cloud-based service-oriented architecture to unlock smart energy services
+  https://www.doi.org/10.1186/s42162-021-00143-x      
+
+- Baranski, M., Storek, T. P. B., Kümpel, A., Blechmann, S., Streblow, R., 
+Müller, D. et al.,
+(2020). National 5G Energy Hub : Application of the Open-Source Cloud Platform 
+FIWARE for Future Energy Management Systems. 
+https://doi.org/10.18154/RWTH-2020-07876      
+
+- T. Storek, J. Lohmöller, A. Kümpel, M. Baranski & D. Müller (2019). 
+Application of the open-source cloud platform FIWARE for future building 
+energy management systems. 
+Journal of Physics: 
+Conference Series, 1343, 12063. https://doi.org/10.1088/1742-6596/1343/1/012063     
+
+## License
+
+This project is licensed under the BSD License - see the [LICENSE](LICENSE) file for details.
+
+## Copyright
+
+<a href="https://www.ebc.eonerc.rwth-aachen.de/"> <img alt="EBC" src="https://www.ebc.eonerc.rwth-aachen.de/global/show_picture.asp?id=aaaaaaaaaakevlz" height="100"> </a>
+
+2021-2024, RWTH Aachen University, E.ON Energy Research Center, Institute for Energy 
+Efficient Buildings and Indoor Climate
+
+[Institute for Energy Efficient Buildings and Indoor Climate (EBC)](https://www.ebc.eonerc.rwth-aachen.de)  
+[E.ON Energy Research Center (E.ON ERC)](https://www.eonerc.rwth-aachen.de)  
+[RWTH University Aachen, Germany](https://www.rwth-aachen.de)
+
+## Disclaimer
+
+This project is part of the cooperation between the RWTH Aachen University and 
+the Research Centre Jülich.
+
+<a href="https://www.jara.org/de/forschung/jara-energy"> <img alt="JARA 
+ENERGY" src="https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/logos/LogoJARAEnergy.jpg" height="100"> </a>
+
+## Related projects
+
+<a href="https://n5geh.de/"> <img alt="National 5G Energy Hub" 
+src="https://avatars.githubusercontent.com/u/43948851?s=200&v=4" height="100"></a>
+
+<a href="https://fismep.de/"> <img alt="FISMEP" 
+src="https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/logos/FISMEP.png" 
+height="100"></a>
+
+
+## Acknowledgments
+
+We gratefully acknowledge the financial support of the Federal Ministry <br /> 
+for Economic Affairs and Climate Action (BMWK), promotional references 
+03ET1495A, 03ET1551A, 0350018A, 03ET1561B.
+
+<a href="https://www.bmwi.de/Navigation/EN/Home/home.html"> <img alt="BMWK" 
+src="https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/logos/bmwi_logo_en.png" height="100"> </a>
+
+This project has received funding in the framework of the joint programming initiative ERA-Net Smart Grids Plus, with support from the European Union’s Horizon 2020 research and innovation programme.
+
+<a href="https://www.eranet-smartgridsplus.eu/"> <img alt="ERANET" 
+src="https://fismep.de/wp-content/uploads/2017/09/SmartGridsPlus_rgb-300x55.jpg" height="100"> </a>
```

### Comparing `filip-0.3.0/filip/clients/mqtt/client.py` & `filip-0.4.0/filip/clients/mqtt/client.py`

 * *Ordering differences only*

 * *Files 23% similar despite different names*

```diff
@@ -1,837 +1,837 @@
-"""
-Implementation of an extended MQTT client that automatically handles the
-topic subscription for FIWARE's IoT communication pattern.
-"""
-import itertools
-import logging
-import warnings
-from datetime import datetime
-from typing import Any, Callable, Dict, List, Tuple, Union
-
-import paho.mqtt.client as mqtt
-
-from filip.clients.mqtt.encoder import BaseEncoder, Json, Ultralight
-from filip.models.mqtt import IoTAMQTTMessageType
-from filip.models.ngsi_v2.iot import \
-    Device, \
-    PayloadProtocol, \
-    ServiceGroup, \
-    TransportProtocol
-
-
-class IoTAMQTTClient(mqtt.Client):
-    """
-    This class is an extension to the MQTT client from the well established
-    Eclipse Paho™ MQTT Python Client. The official documentation is located
-    here: https://github.com/eclipse/paho.mqtt.python
-
-    The class adds additional functions to facilitate the communication to
-    FIWARE's IoT-Agent via MQTT. It magically generates and subscribes to all
-    important topics that are necessary to establish a
-    bi-directional communication with the IoT-Agent.
-
-    Note:
-        The client does not sync the device configuration with the IoT-Agent.
-        This is up to the user!
-
-    Note:
-        The extension does not effect the normal workflow or any other
-        functionality known from the original client.
-
-        The client does not yet support the retrieval of command
-        configurations via mqtt documented here:
-        https://fiware-iotagent-json.readthedocs.io/en/latest/usermanual/index.html#api-overview
-
-    Example:
-        This example shows the basic usage of the client. It does not
-        demonstrate its whole capabilities. Please check the single methods
-        for more details. Please also keep in mind that this still requires
-        provisioning of the device in the IoT-Agent and sending the commands
-        via the context broker. For more details check the additional example
-        section::
-
-            from filip.models.ngsi_v2.iot import Device, DeviceAttribute, DeviceCommand, ServiceGroup
-            from filip.clients.mqtt import MQTTClient
-            from filip.clients.mqtt.encoder import IoTA_Json
-
-            # create a device configuration
-            device_attr = DeviceAttribute(name='temperature',
-                                          object_id='t',
-                                          type="Number")
-            device_command = DeviceCommand(name='heater', type="Boolean")
-            device = Device(device_id='MyDevice',
-                            entity_name='MyDevice',
-                            entity_type='Thing',
-                            protocol='IoTA-JSON',
-                            transport='MQTT',
-                            apikey=YourApiKey,
-                            attributes=[device_attr],
-                            commands=[device_command])
-
-            service_group = ServiceGroup(apikey="YourApiKey", resource="/iot")
-
-            mqttc = MQTTClient(client_id="YourID",
-                               userdata=None,
-                               protocol=mqtt.MQTTv5,
-                               transport="tcp",
-                               _devices = [device],
-                               service_groups = [service_group])
-
-            # create a callback function that will be called for incoming
-            # commands and add it for a single device
-            def on_command(client, obj, msg):
-                apikey, device_id, payload = \
-                    client.get_encoder().decode_message(msg=msg)
-
-                # do_something with the message.
-                # For instance write into a queue.
-
-                # acknowledge a command
-                client.publish(device_id=device_id,
-                               command_name=next(iter(payload))
-                               payload=payload)
-
-            mqttc.add_command_callback(on_command)
-
-            # create a non blocking loop
-            mqttc.loop_start()
-
-            # publish a multi-measurement for a device
-            mqttc.publish(device_id='MyDevice', payload={'t': 50})
-
-            # publish a single measurement for a device
-            mqttc.publish(device_id='MyDevice',
-                          attribute_name='temperature',
-                          payload=50)
-
-            # adding timestamps to measurements using the client
-
-
-            # adding timestamps to measurements in payload
-            from datetime import datetime
-
-            mqttc.publish(device_id='MyDevice',
-                          payload={'t': 50,
-                                   'timeInstant': datetime.now().astimezone().isoformat()},
-                          timestamp=true)
-
-            # stop network loop and disconnect cleanly
-            mqttc.loop_stop()
-            mqttc.disconnect()
-
-    """
-
-    def __init__(self,
-                 client_id="",
-                 clean_session=None,
-                 userdata=None,
-                 protocol=mqtt.MQTTv311,
-                 transport="tcp",
-                 devices: List[Device] = None,
-                 service_groups: List[ServiceGroup] = None,
-                 custom_encoder: Dict[str, BaseEncoder] = None):
-        """
-        Args:
-            client_id:
-                Unique client id string used when connecting
-                to the broker. If client_id is zero length or None, then the
-                behaviour is defined by which protocol version is in use. If
-                using MQTT v3.1.1, then a zero length client id will be sent
-                to the broker and the broker will generate a random for the
-                client. If using MQTT v3.1 then an id will be randomly
-                generated. In both cases, clean_session must be True.
-                If this is not the case a ValueError will be raised.
-            clean_session:
-                boolean that determines the client type. If True,
-                the broker will remove all information about this client when it
-                disconnects. If False, the client is a persistent client and
-                subscription information and queued messages will be retained
-                when the client disconnects.
-                Note that a client will never discard its own outgoing
-                messages on disconnect. Calling connect() or reconnect() will
-                cause the messages to be resent.  Use reinitialise() to reset
-                a client to its original state. The clean_session argument
-                only applies to MQTT versions v3.1.1 and v3.1. It is not
-                accepted if the MQTT version is v5.0 - use the clean_start
-                argument on connect() instead.
-            userdata:
-                defined data of any type that is passed as the "userdata"
-                parameter to callbacks. It may be updated at a later point
-                with the user_data_set() function.
-            protocol:
-                explicit setting of the MQTT version to use for this client.
-                Can be paho.mqtt.client.MQTTv311 (v3.1.1),
-                paho.mqtt.client.MQTTv31 (v3.1) or paho.mqtt.client.MQTTv5
-                (v5.0), with the default being v3.1.1.
-            transport:
-                Set to "websockets" to use WebSockets as the transport
-                mechanism. Set to "tcp" to use raw TCP, which is the default.
-            devices:
-                List of device configurations that will be registered
-                with the client. Consequently, the client will be able to
-                subscribe to all registered device topics. Furthermore,
-                after registration messages can simply published by the
-                _devices id.
-            service_groups:
-                List of service group configurations that will be registered
-                with the client. These should be known upon subscribing
-                because the client will check for a matching service group if
-                this is not known or registered with the IoT-Agent service
-                the receiving of commands will fail. Please check the
-                official documentation of the IoT-Agents API for more details.
-            custom_encoder:
-                Custom encoder class that will automatically parse the supported
-                payload formats to a dictionary and vice versa. This
-                essentially saves boiler plate code.
-        """
-        # initialize parent client
-        super().__init__(client_id=client_id,
-                         clean_session=clean_session,
-                         userdata=userdata,
-                         protocol=protocol,
-                         transport=transport)
-
-        # setup logging functionality
-        self.logger = logging.getLogger(
-            name=f"{self.__class__.__module__}."
-                 f"{self.__class__.__name__}")
-        self.logger.addHandler(logging.NullHandler())
-        self.enable_logger(self.logger)
-
-        # create dictionary holding the registered service groups
-        self.service_groups: Dict[Tuple[str, str], ServiceGroup]
-        if service_groups:
-            self.service_groups = {gr.apikey: gr for gr in service_groups}
-        else:
-            self.service_groups = {}
-
-        # create dictionary holding the registered device configurations
-        # check if all _devices have the right transport protocol
-        self._devices: Dict[str, Device] = {}
-        if devices:
-            self.devices = devices
-
-        # create dict with available encoders
-        self._encoders = {'IoTA-JSON': Json(),
-                          'PDI-IoTA-UltraLight': Ultralight()}
-
-        # add custom encoder for message parsing
-        if custom_encoder:
-            self.add_encoder(custom_encoder)
-
-    @property
-    def devices(self):
-        """
-        Returns as list of all registered device configurations
-        Returns:
-
-        """
-        return list(self._devices.values())
-
-    @devices.setter
-    def devices(self, devices: List[Device]):
-        """
-        Sets list of device configurations
-
-        Args:
-            devices: List of device configurations
-
-        Returns:
-            None
-
-        Raises:
-            ValueError: if duplicate device id was found
-        """
-        for device in devices:
-            try:
-                self.add_device(device=device)
-            except ValueError:
-                raise ValueError(f"Duplicate device_id: {device.device_id}")
-
-    def get_encoder(self, encoder: Union[str, PayloadProtocol]):
-        """
-        Returns the encoder by key
-
-        Args:
-            encoder: encoder name
-
-        Returns:
-            Subclass of Baseencoder
-        """
-        return self._encoders.get(encoder)
-
-    def add_encoder(self, encoder: Dict[str, BaseEncoder]):
-        for value in encoder.values():
-            assert isinstance(value, BaseEncoder), \
-                f"Encoder must be a subclass of {type(BaseEncoder)}"
-
-        self._encoders.update(encoder)
-
-    def __validate_device(self, device: Union[Device, Dict]) -> Device:
-        """
-        Validates configuration of an IoT Device
-
-        Args:
-            device: device model to check on
-
-        Returns:
-            Device: validated model
-
-        Raises:
-            AssertionError: for faulty configurations
-        """
-        if isinstance(device, dict):
-            device = Device.model_validate(device)
-
-        assert isinstance(device, Device), "Invalid device configuration!"
-
-        assert device.transport == TransportProtocol.MQTT, \
-            "Unsupported transport protocol found in device configuration!"
-
-        if device.apikey in self.service_groups.keys():
-            pass
-        # check if matching service group is registered
-        else:
-            msg = "Could not find matching service group! " \
-                  "Communication may not work correctly!"
-            self.logger.warning(msg=msg)
-            warnings.warn(message=msg)
-
-        return device
-
-    def __create_topic(self,
-                       *,
-                       topic_type: IoTAMQTTMessageType,
-                       device: Device,
-                       attribute: str = None) -> str:
-        """
-        Creates a topic for a device configuration based on the requested
-        topic type.
-
-        Args:
-            device:
-                Configuration of an IoT device
-            topic_type:
-                type of the topic to be created,
-                'multi' for topics that the device is suppose to publish on.
-                'single' for topics that the device is suppose to publish on.
-                'cmd' for topic the device is expecting its commands on.
-                'cmdexe' for topic the device can acknowledge its commands on.
-                'configuration' for topic the device can request command
-                    configurations on
-            attribute:
-                attribute needs to be set for single measurements
-        Returns:
-            string with topic
-
-        Raises:
-            KeyError:
-                If unknown message type is used
-            ValueError:
-                If attribute name is missing for single measurements
-        """
-        if topic_type == IoTAMQTTMessageType.MULTI:
-            topic = '/'.join((self._encoders[device.protocol].prefix,
-                              device.apikey,
-                              device.device_id,
-                              'attrs'))
-        elif topic_type == IoTAMQTTMessageType.SINGLE:
-            if attribute:
-                attr = next(attr for attr in device.attributes
-                            if attr.name == attribute)
-                if attr.object_id:
-                    attr_suffix = attr.object_id
-                else:
-                    attr_suffix = attr.name
-                topic = '/'.join((self._encoders[device.protocol].prefix,
-                                  device.apikey,
-                                  device.device_id,
-                                  'attrs',
-                                  attr_suffix))
-            else:
-                raise ValueError("Missing argument name for single measurement")
-        elif topic_type == IoTAMQTTMessageType.CMD:
-            topic = '/' + '/'.join((device.apikey, device.device_id, 'cmd'))
-        elif topic_type == IoTAMQTTMessageType.CMDEXE:
-            topic = '/'.join((self._encoders[device.protocol].prefix,
-                              device.apikey,
-                              device.device_id,
-                              'cmdexe'))
-        elif topic_type == IoTAMQTTMessageType.CONFIG:
-            topic = '/'.join((self._encoders[device.protocol].prefix,
-                              device.apikey,
-                              device.device_id,
-                              'configuration'))
-        else:
-            raise KeyError("topic_type not supported")
-        return topic
-
-    def __subscribe_commands(self, *,
-                             device: Device = None,
-                             qos=0,
-                             options=None,
-                             properties=None):
-        """
-        Subscribes commands based on device configuration. If device argument is
-        omitted the function will subscribe to all topics of already registered
-        _devices.
-        Additionally, it will also check if a matching service group is
-        registered with the client. If nor a warning will be raised.
-
-        Args:
-            device: Configuration of an IoT device
-            qos: Quality of service can be 0, 1 or 2
-            options: MQTT v5.0 subscribe options
-            properties: MQTT v5.0 properties
-
-        Returns:
-            None
-        """
-        if Device:
-            if len(device.commands) > 0:
-                topic = self.__create_topic(device=device,
-                                            topic_type=IoTAMQTTMessageType.CMD)
-                super().subscribe(topic=topic,
-                                  qos=qos,
-                                  options=options,
-                                  properties=properties)
-        else:
-            # call itself but with device argument for all registered _devices
-            for device in self._devices.values():
-                self.__subscribe_commands(device=device,
-                                          qos=qos,
-                                          options=options,
-                                          properties=properties)
-
-    def get_service_group(self, apikey: str) -> ServiceGroup:
-        """
-        Returns registered service group configuration
-
-        Args:
-            apikey: Unique APIKey of the service group
-
-        Returns:
-            ServiceGroup
-
-        Raises:
-            KeyError: if service group not yet registered
-
-        Example::
-
-            from filip.clients.mqtt import MQTTClient
-
-            mqttc = MQTTClient()
-            group = mqttc.get_service_group(apikey="MyAPIKEY")
-            print(group.json(indent=2))
-            print(type(group))
-        """
-        group = self.service_groups.get(apikey, None)
-        if group is None:
-            raise KeyError("Service group with apikey %s not found!", apikey)
-        return group
-
-    def add_service_group(self, service_group: Union[ServiceGroup, Dict]):
-        """
-        Registers a device service group with the client
-
-        Args:
-            service_group: Service group configuration
-
-        Returns:
-            None
-
-        Raises:
-            ValueError: if service group already exists
-        """
-        if isinstance(service_group, dict):
-            service_group = ServiceGroup.model_validate(service_group)
-        assert isinstance(service_group, ServiceGroup), \
-            "Invalid content for service group!"
-
-        if self.service_groups.get(service_group.apikey, None) is None:
-            pass
-        else:
-            raise ValueError("Service group already exists! %s",
-                             service_group.apikey)
-        # add service group configuration to the service group list
-        self.service_groups[service_group.apikey] = service_group
-
-    def delete_service_group(self, apikey):
-        """
-        Unregisters a service group and removes
-
-        Args:
-            apikey: Unique APIKey of the service group
-
-        Returns:
-            None
-        """
-        group = self.service_groups.pop(apikey, None)
-        if group:
-            self.logger.info("Successfully unregistered Service Group '%s'!",
-                             apikey)
-        else:
-            self.logger.error("Could not unregister service group '%s'!",
-                              apikey)
-            raise KeyError("Device not found!")
-
-    def update_service_group(self, service_group: Union[ServiceGroup, Dict]):
-        """
-        Updates a registered service group configuration. There is no
-        opportunity to only partially update the device. Hence, your service
-        group model should be complete.
-
-        Args:
-            service_group: Service group configuration
-
-        Returns:
-            None
-
-        Raises:
-            KeyError: if service group not yet registered
-        """
-        if isinstance(service_group, dict):
-            service_group = ServiceGroup.model_validate(service_group)
-        assert isinstance(service_group, ServiceGroup), \
-            "Invalid content for service group"
-
-        if self.service_groups.get(service_group.apikey, None) is None:
-            raise KeyError("Service group not found! %s",
-                           service_group.apikey)
-        # add service group configuration to the service group list
-        self.service_groups[service_group.apikey] = service_group
-
-    def get_device(self, device_id: str) -> Device:
-        """
-        Returns the configuration of a registered device.
-
-        Args:
-            device_id: Id of the requested device
-
-        Returns:
-           Device: Device model of the requested device
-
-        Raises:
-            KeyError: if requested device is not registered with the client
-
-        Example::
-
-            from filip.clients.mqtt import MQTTClient
-
-            mqttc = MQTTClient()
-            device = mqttc.get_device(device_id="MyDeviceId")
-            print(device.json(indent=2))
-            print(type(device))
-        """
-        return self._devices[device_id]
-
-    def add_device(self,
-                   device: Union[Device, Dict],
-                   qos=0,
-                   options=None,
-                   properties=None):
-        """
-        Registers a device config with the mqtt client. Subsequently,
-        the client will magically subscribe to the corresponding topics based
-        on the device config and any matching registered service group config
-        if exists.
-
-        Note:
-            To register the device config only with this client is not
-            sufficient for data streaming the configuration also needs to be
-            registered with IoTA-Agent.
-
-        Args:
-            device: Configuration of an IoT device
-            qos: Quality of service can be 0, 1 or 2
-            options: MQTT v5.0 subscribe options
-            properties: MQTT v5.0 properties
-
-        Returns:
-            None
-
-        Raises:
-            ValueError: if device configuration already exists
-        """
-        device = self.__validate_device(device=device)
-
-        if self._devices.get(device.device_id, None) is None:
-            pass
-        else:
-            raise ValueError("Device already exists! %s", device.device_id)
-        # add device configuration to the device list
-        self._devices[device.device_id] = device
-        # subscribes to the command topic
-        self.__subscribe_commands(device=device,
-                                  qos=qos,
-                                  options=options,
-                                  properties=properties)
-
-    def delete_device(self, device_id: str):
-        """
-        Unregisters a device and removes its subscriptions and callbacks
-
-        Args:
-            device_id: id of and IoT device
-
-        Returns:
-            None
-        """
-        device = self._devices.pop(device_id, None)
-        if device:
-            topic = self.__create_topic(device=device,
-                                        topic_type=IoTAMQTTMessageType.CMD)
-            self.unsubscribe(topic=topic)
-            self.message_callback_remove(sub=topic)
-            self.logger.info("Successfully unregistered Device '%s'!",
-                             device_id)
-        else:
-            self.logger.error("Could not unregister device '%s'", device_id)
-
-    def update_device(self,
-                      device: Union[Device, Dict],
-                      qos=0,
-                      options=None,
-                      properties=None):
-        """
-        Updates a registered device configuration. There is no opportunity
-        to only partially update the device. Hence, your device model should
-        be complete.
-
-        Args:
-            device: Configuration of an IoT device
-            qos: Quality of service can be 0, 1 or 2
-            options: MQTT v5.0 subscribe options
-            properties: MQTT v5.0 properties
-
-        Returns:
-            None
-
-        Raises:
-            KeyError: if device not yet registered
-        """
-        device = self.__validate_device(device=device)
-
-        if self._devices.get(device.device_id, None) is None:
-            raise KeyError("Device not found! %s", device.device_id)
-
-        # update device configuration in the device list
-        self._devices[device.device_id] = device
-        # subscribes to the command topic
-        self.__subscribe_commands(device=device,
-                                  qos=qos,
-                                  options=options,
-                                  properties=properties)
-
-    def add_command_callback(self, device_id: str, callback: Callable):
-        """
-        Adds callback function for a device configuration.
-
-        Args:
-            device_id:
-                id of and IoT device
-            callback:
-                function that will be called for incoming commands.
-                This function should have the following format:
-
-        Example::
-
-            def on_command(client, obj, msg):
-                apikey, device_id, payload = \
-                    client.encoder.decode_message(msg=msg)
-
-                # do_something with the message.
-                # For instance write into a queue.
-
-                # acknowledge a command. Here command are usually single
-                # messages. The first key is equal to the commands name.
-                client.publish(device_id=device_id,
-                               command_name=next(iter(payload)),
-                               payload=payload)
-
-            mqttc.add_command_callback(device_id="MyDevice",
-                                       callback=on_command)
-
-        Returns:
-            None
-        """
-        device = self._devices.get(device_id, None)
-        if device is None:
-            raise KeyError("Device does not exist! %s", device_id)
-        self.__subscribe_commands(device=device)
-        topic = self.__create_topic(device=device,
-                                    topic_type=IoTAMQTTMessageType.CMD)
-        self.message_callback_add(topic, callback)
-
-    def publish(self,
-                topic=None,
-                payload: Union[Dict, Any] = None,
-                qos: int = 0,
-                retain: bool = False,
-                properties=None,
-                device_id: str = None,
-                attribute_name: str = None,
-                command_name: str = None,
-                timestamp: bool = False
-                ):
-        """
-        Publish an MQTT Message to a specified topic. If you want to publish
-        a device specific message to a device use the device_id argument for
-        multi-measurement. The function will then automatically validate
-        against the registered device configuration if the payload keys are
-        valid. If you want to publish a single measurement the attribute_name
-        argument is required as well.
-
-        Note:
-            If the device_id argument is set, the topic argument will be
-            ignored.
-
-        Args:
-            topic:
-                The topic that the message should be published on.
-            payload:
-                The actual message to send. If not given, or set to None a
-                zero length message will be used. Passing an int or float will
-                result in the payload being converted to a string
-                representing that number. If you wish to send a true
-                int/float, use struct.pack() to create the
-                payload you require. For publishing to a device use a dict
-                containing the object_ids as keys.
-            qos:
-                The quality of service level to use.
-            retain:
-                If set to true, the message will be set as the "last known
-                good"/retained message for the topic.
-            properties:
-                (MQTT v5.0 only) the MQTT v5.0 properties to be included.
-                Use the Properties class.
-            device_id:
-                Id of the IoT device you want to publish for. The topics will
-                automatically created. If set, the message type will be
-                assumed to be multi measurement.
-            attribute_name:
-                Name of an attribute of the device. Do only use this for
-                single measurements. If set, `command_name` must
-                be omitted.
-            command_name:
-                Name of a command of the device that should be acknowledged. If
-                set `attribute_name` must be omitted.
-            timestamp:
-                If `true` the client will generate a valid timestamp based on
-                utc and added to the multi measurement payload.
-                If a `timeInstant` is already contained in the
-                message payload it will not overwritten.
-
-        Returns:
-            None
-
-        Raises:
-            KeyError: if device configuration is not registered with client
-            ValueError: if the passed arguments are inconsistent or a
-                timestamp does not match the ISO 8601 format.
-            AssertionError: if the message payload does not match the device
-                configuration.
-        """
-
-        # TODO: time stamps are not tested yet
-
-        if device_id:
-            device = self.get_device(device_id=device_id)
-
-            # create message for multi measurement payload
-            if attribute_name is None and command_name is None:
-                assert isinstance(payload, dict), \
-                    "Payload must be a dictionary"
-
-                if timestamp and 'timeInstant' not in payload.keys():
-                    payload["timeInstant"] = datetime.utcnow()
-                # validate if dict keys match device configuration
-
-                msg_payload = payload.copy()
-                for key in payload.keys():
-                    for attr in device.attributes:
-                        if key in attr.object_id or key == 'timeInstant':
-                            break
-                        elif key == attr.name:
-                            if attr.object_id:
-                                msg_payload[attr.object_id] = \
-                                    msg_payload.pop(key)
-                            break
-                    else:
-                        err_msg = f"Attribute key '{key}' is not allowed " \
-                                  f"in the message payload for this " \
-                                  f"device configuration with device_id " \
-                                  f"'{device_id}'"
-                        raise KeyError(err_msg)
-                topic = self.__create_topic(
-                    device=device,
-                    topic_type=IoTAMQTTMessageType.MULTI)
-                payload = self._encoders[device.protocol].encode_msg(
-                    device_id=device_id,
-                    payload=payload,
-                    msg_type=IoTAMQTTMessageType.MULTI)
-
-            # create message for command acknowledgement
-            elif attribute_name is None and command_name:
-                assert isinstance(payload, Dict), "Payload must be a dictionary"
-                assert len(payload.keys()) == 1, \
-                    "Cannot acknowledge multiple commands simultaneously"
-                assert next(iter(payload.keys())) in \
-                       [cmd.name for cmd in device.commands], \
-                    "Unknown command for this device!"
-                topic = self.__create_topic(
-                    device=device,
-                    topic_type=IoTAMQTTMessageType.CMDEXE)
-                payload = self._encoders[device.protocol].encode_msg(
-                    device_id=device_id,
-                    payload=payload,
-                    msg_type=IoTAMQTTMessageType.CMDEXE)
-
-            # create message for single measurement
-            elif attribute_name and command_name is None:
-                topic = self.__create_topic(
-                    device=device,
-                    topic_type=IoTAMQTTMessageType.SINGLE,
-                    attribute=attribute_name)
-                payload = self._encoders[device.protocol].encode_msg(
-                    device_id=device_id,
-                    payload=payload,
-                    msg_type=IoTAMQTTMessageType.SINGLE)
-            else:
-                raise ValueError("Inconsistent arguments!")
-
-        super().publish(topic=topic,
-                        payload=payload,
-                        qos=qos,
-                        retain=retain,
-                        properties=properties)
-
-    def subscribe(self, topic=None, qos=0, options=None, properties=None):
-        """
-        Extends the normal subscribe function of the paho.mqtt.client.
-        If the topic argument is omitted the client will subscribe to all
-        registered device command topics.
-
-        Args:
-            topic:
-                A string specifying the subscription topic to subscribe to.
-            qos:
-                The desired quality of service level for the subscription.
-                Defaults to 0.
-            options: Not used.
-            properties: Not used.
-
-        Returns:
-            None
-        """
-        if topic:
-            super().subscribe(topic=topic,
-                              qos=qos,
-                              options=options,
-                              properties=properties)
-        else:
-            for device in self._devices.values():
-                self.__subscribe_commands(device=device,
-                                          qos=qos,
-                                          options=options,
-                                          properties=properties)
+"""
+Implementation of an extended MQTT client that automatically handles the
+topic subscription for FIWARE's IoT communication pattern.
+"""
+import itertools
+import logging
+import warnings
+from datetime import datetime
+from typing import Any, Callable, Dict, List, Tuple, Union
+
+import paho.mqtt.client as mqtt
+
+from filip.clients.mqtt.encoder import BaseEncoder, Json, Ultralight
+from filip.models.mqtt import IoTAMQTTMessageType
+from filip.models.ngsi_v2.iot import \
+    Device, \
+    PayloadProtocol, \
+    ServiceGroup, \
+    TransportProtocol
+
+
+class IoTAMQTTClient(mqtt.Client):
+    """
+    This class is an extension to the MQTT client from the well established
+    Eclipse Paho™ MQTT Python Client. The official documentation is located
+    here: https://github.com/eclipse/paho.mqtt.python
+
+    The class adds additional functions to facilitate the communication to
+    FIWARE's IoT-Agent via MQTT. It magically generates and subscribes to all
+    important topics that are necessary to establish a
+    bi-directional communication with the IoT-Agent.
+
+    Note:
+        The client does not sync the device configuration with the IoT-Agent.
+        This is up to the user!
+
+    Note:
+        The extension does not effect the normal workflow or any other
+        functionality known from the original client.
+
+        The client does not yet support the retrieval of command
+        configurations via mqtt documented here:
+        https://fiware-iotagent-json.readthedocs.io/en/latest/usermanual/index.html#api-overview
+
+    Example:
+        This example shows the basic usage of the client. It does not
+        demonstrate its whole capabilities. Please check the single methods
+        for more details. Please also keep in mind that this still requires
+        provisioning of the device in the IoT-Agent and sending the commands
+        via the context broker. For more details check the additional example
+        section::
+
+            from filip.models.ngsi_v2.iot import Device, DeviceAttribute, DeviceCommand, ServiceGroup
+            from filip.clients.mqtt import MQTTClient
+            from filip.clients.mqtt.encoder import IoTA_Json
+
+            # create a device configuration
+            device_attr = DeviceAttribute(name='temperature',
+                                          object_id='t',
+                                          type="Number")
+            device_command = DeviceCommand(name='heater', type="Boolean")
+            device = Device(device_id='MyDevice',
+                            entity_name='MyDevice',
+                            entity_type='Thing',
+                            protocol='IoTA-JSON',
+                            transport='MQTT',
+                            apikey=YourApiKey,
+                            attributes=[device_attr],
+                            commands=[device_command])
+
+            service_group = ServiceGroup(apikey="YourApiKey", resource="/iot")
+
+            mqttc = MQTTClient(client_id="YourID",
+                               userdata=None,
+                               protocol=mqtt.MQTTv5,
+                               transport="tcp",
+                               _devices = [device],
+                               service_groups = [service_group])
+
+            # create a callback function that will be called for incoming
+            # commands and add it for a single device
+            def on_command(client, obj, msg):
+                apikey, device_id, payload = \
+                    client.get_encoder().decode_message(msg=msg)
+
+                # do_something with the message.
+                # For instance write into a queue.
+
+                # acknowledge a command
+                client.publish(device_id=device_id,
+                               command_name=next(iter(payload))
+                               payload=payload)
+
+            mqttc.add_command_callback(on_command)
+
+            # create a non blocking loop
+            mqttc.loop_start()
+
+            # publish a multi-measurement for a device
+            mqttc.publish(device_id='MyDevice', payload={'t': 50})
+
+            # publish a single measurement for a device
+            mqttc.publish(device_id='MyDevice',
+                          attribute_name='temperature',
+                          payload=50)
+
+            # adding timestamps to measurements using the client
+
+
+            # adding timestamps to measurements in payload
+            from datetime import datetime
+
+            mqttc.publish(device_id='MyDevice',
+                          payload={'t': 50,
+                                   'timeInstant': datetime.now().astimezone().isoformat()},
+                          timestamp=true)
+
+            # stop network loop and disconnect cleanly
+            mqttc.loop_stop()
+            mqttc.disconnect()
+
+    """
+
+    def __init__(self,
+                 client_id="",
+                 clean_session=None,
+                 userdata=None,
+                 protocol=mqtt.MQTTv311,
+                 transport="tcp",
+                 devices: List[Device] = None,
+                 service_groups: List[ServiceGroup] = None,
+                 custom_encoder: Dict[str, BaseEncoder] = None):
+        """
+        Args:
+            client_id:
+                Unique client id string used when connecting
+                to the broker. If client_id is zero length or None, then the
+                behaviour is defined by which protocol version is in use. If
+                using MQTT v3.1.1, then a zero length client id will be sent
+                to the broker and the broker will generate a random for the
+                client. If using MQTT v3.1 then an id will be randomly
+                generated. In both cases, clean_session must be True.
+                If this is not the case a ValueError will be raised.
+            clean_session:
+                boolean that determines the client type. If True,
+                the broker will remove all information about this client when it
+                disconnects. If False, the client is a persistent client and
+                subscription information and queued messages will be retained
+                when the client disconnects.
+                Note that a client will never discard its own outgoing
+                messages on disconnect. Calling connect() or reconnect() will
+                cause the messages to be resent.  Use reinitialise() to reset
+                a client to its original state. The clean_session argument
+                only applies to MQTT versions v3.1.1 and v3.1. It is not
+                accepted if the MQTT version is v5.0 - use the clean_start
+                argument on connect() instead.
+            userdata:
+                defined data of any type that is passed as the "userdata"
+                parameter to callbacks. It may be updated at a later point
+                with the user_data_set() function.
+            protocol:
+                explicit setting of the MQTT version to use for this client.
+                Can be paho.mqtt.client.MQTTv311 (v3.1.1),
+                paho.mqtt.client.MQTTv31 (v3.1) or paho.mqtt.client.MQTTv5
+                (v5.0), with the default being v3.1.1.
+            transport:
+                Set to "websockets" to use WebSockets as the transport
+                mechanism. Set to "tcp" to use raw TCP, which is the default.
+            devices:
+                List of device configurations that will be registered
+                with the client. Consequently, the client will be able to
+                subscribe to all registered device topics. Furthermore,
+                after registration messages can simply published by the
+                _devices id.
+            service_groups:
+                List of service group configurations that will be registered
+                with the client. These should be known upon subscribing
+                because the client will check for a matching service group if
+                this is not known or registered with the IoT-Agent service
+                the receiving of commands will fail. Please check the
+                official documentation of the IoT-Agents API for more details.
+            custom_encoder:
+                Custom encoder class that will automatically parse the supported
+                payload formats to a dictionary and vice versa. This
+                essentially saves boiler plate code.
+        """
+        # initialize parent client
+        super().__init__(client_id=client_id,
+                         clean_session=clean_session,
+                         userdata=userdata,
+                         protocol=protocol,
+                         transport=transport)
+
+        # setup logging functionality
+        self.logger = logging.getLogger(
+            name=f"{self.__class__.__module__}."
+                 f"{self.__class__.__name__}")
+        self.logger.addHandler(logging.NullHandler())
+        self.enable_logger(self.logger)
+
+        # create dictionary holding the registered service groups
+        self.service_groups: Dict[Tuple[str, str], ServiceGroup]
+        if service_groups:
+            self.service_groups = {gr.apikey: gr for gr in service_groups}
+        else:
+            self.service_groups = {}
+
+        # create dictionary holding the registered device configurations
+        # check if all _devices have the right transport protocol
+        self._devices: Dict[str, Device] = {}
+        if devices:
+            self.devices = devices
+
+        # create dict with available encoders
+        self._encoders = {'IoTA-JSON': Json(),
+                          'PDI-IoTA-UltraLight': Ultralight()}
+
+        # add custom encoder for message parsing
+        if custom_encoder:
+            self.add_encoder(custom_encoder)
+
+    @property
+    def devices(self):
+        """
+        Returns as list of all registered device configurations
+        Returns:
+
+        """
+        return list(self._devices.values())
+
+    @devices.setter
+    def devices(self, devices: List[Device]):
+        """
+        Sets list of device configurations
+
+        Args:
+            devices: List of device configurations
+
+        Returns:
+            None
+
+        Raises:
+            ValueError: if duplicate device id was found
+        """
+        for device in devices:
+            try:
+                self.add_device(device=device)
+            except ValueError:
+                raise ValueError(f"Duplicate device_id: {device.device_id}")
+
+    def get_encoder(self, encoder: Union[str, PayloadProtocol]):
+        """
+        Returns the encoder by key
+
+        Args:
+            encoder: encoder name
+
+        Returns:
+            Subclass of Baseencoder
+        """
+        return self._encoders.get(encoder)
+
+    def add_encoder(self, encoder: Dict[str, BaseEncoder]):
+        for value in encoder.values():
+            assert isinstance(value, BaseEncoder), \
+                f"Encoder must be a subclass of {type(BaseEncoder)}"
+
+        self._encoders.update(encoder)
+
+    def __validate_device(self, device: Union[Device, Dict]) -> Device:
+        """
+        Validates configuration of an IoT Device
+
+        Args:
+            device: device model to check on
+
+        Returns:
+            Device: validated model
+
+        Raises:
+            AssertionError: for faulty configurations
+        """
+        if isinstance(device, dict):
+            device = Device.model_validate(device)
+
+        assert isinstance(device, Device), "Invalid device configuration!"
+
+        assert device.transport == TransportProtocol.MQTT, \
+            "Unsupported transport protocol found in device configuration!"
+
+        if device.apikey in self.service_groups.keys():
+            pass
+        # check if matching service group is registered
+        else:
+            msg = "Could not find matching service group! " \
+                  "Communication may not work correctly!"
+            self.logger.warning(msg=msg)
+            warnings.warn(message=msg)
+
+        return device
+
+    def __create_topic(self,
+                       *,
+                       topic_type: IoTAMQTTMessageType,
+                       device: Device,
+                       attribute: str = None) -> str:
+        """
+        Creates a topic for a device configuration based on the requested
+        topic type.
+
+        Args:
+            device:
+                Configuration of an IoT device
+            topic_type:
+                type of the topic to be created,
+                'multi' for topics that the device is suppose to publish on.
+                'single' for topics that the device is suppose to publish on.
+                'cmd' for topic the device is expecting its commands on.
+                'cmdexe' for topic the device can acknowledge its commands on.
+                'configuration' for topic the device can request command
+                    configurations on
+            attribute:
+                attribute needs to be set for single measurements
+        Returns:
+            string with topic
+
+        Raises:
+            KeyError:
+                If unknown message type is used
+            ValueError:
+                If attribute name is missing for single measurements
+        """
+        if topic_type == IoTAMQTTMessageType.MULTI:
+            topic = '/'.join((self._encoders[device.protocol].prefix,
+                              device.apikey,
+                              device.device_id,
+                              'attrs'))
+        elif topic_type == IoTAMQTTMessageType.SINGLE:
+            if attribute:
+                attr = next(attr for attr in device.attributes
+                            if attr.name == attribute)
+                if attr.object_id:
+                    attr_suffix = attr.object_id
+                else:
+                    attr_suffix = attr.name
+                topic = '/'.join((self._encoders[device.protocol].prefix,
+                                  device.apikey,
+                                  device.device_id,
+                                  'attrs',
+                                  attr_suffix))
+            else:
+                raise ValueError("Missing argument name for single measurement")
+        elif topic_type == IoTAMQTTMessageType.CMD:
+            topic = '/' + '/'.join((device.apikey, device.device_id, 'cmd'))
+        elif topic_type == IoTAMQTTMessageType.CMDEXE:
+            topic = '/'.join((self._encoders[device.protocol].prefix,
+                              device.apikey,
+                              device.device_id,
+                              'cmdexe'))
+        elif topic_type == IoTAMQTTMessageType.CONFIG:
+            topic = '/'.join((self._encoders[device.protocol].prefix,
+                              device.apikey,
+                              device.device_id,
+                              'configuration'))
+        else:
+            raise KeyError("topic_type not supported")
+        return topic
+
+    def __subscribe_commands(self, *,
+                             device: Device = None,
+                             qos=0,
+                             options=None,
+                             properties=None):
+        """
+        Subscribes commands based on device configuration. If device argument is
+        omitted the function will subscribe to all topics of already registered
+        _devices.
+        Additionally, it will also check if a matching service group is
+        registered with the client. If nor a warning will be raised.
+
+        Args:
+            device: Configuration of an IoT device
+            qos: Quality of service can be 0, 1 or 2
+            options: MQTT v5.0 subscribe options
+            properties: MQTT v5.0 properties
+
+        Returns:
+            None
+        """
+        if Device:
+            if len(device.commands) > 0:
+                topic = self.__create_topic(device=device,
+                                            topic_type=IoTAMQTTMessageType.CMD)
+                super().subscribe(topic=topic,
+                                  qos=qos,
+                                  options=options,
+                                  properties=properties)
+        else:
+            # call itself but with device argument for all registered _devices
+            for device in self._devices.values():
+                self.__subscribe_commands(device=device,
+                                          qos=qos,
+                                          options=options,
+                                          properties=properties)
+
+    def get_service_group(self, apikey: str) -> ServiceGroup:
+        """
+        Returns registered service group configuration
+
+        Args:
+            apikey: Unique APIKey of the service group
+
+        Returns:
+            ServiceGroup
+
+        Raises:
+            KeyError: if service group not yet registered
+
+        Example::
+
+            from filip.clients.mqtt import MQTTClient
+
+            mqttc = MQTTClient()
+            group = mqttc.get_service_group(apikey="MyAPIKEY")
+            print(group.json(indent=2))
+            print(type(group))
+        """
+        group = self.service_groups.get(apikey, None)
+        if group is None:
+            raise KeyError("Service group with apikey %s not found!", apikey)
+        return group
+
+    def add_service_group(self, service_group: Union[ServiceGroup, Dict]):
+        """
+        Registers a device service group with the client
+
+        Args:
+            service_group: Service group configuration
+
+        Returns:
+            None
+
+        Raises:
+            ValueError: if service group already exists
+        """
+        if isinstance(service_group, dict):
+            service_group = ServiceGroup.model_validate(service_group)
+        assert isinstance(service_group, ServiceGroup), \
+            "Invalid content for service group!"
+
+        if self.service_groups.get(service_group.apikey, None) is None:
+            pass
+        else:
+            raise ValueError("Service group already exists! %s",
+                             service_group.apikey)
+        # add service group configuration to the service group list
+        self.service_groups[service_group.apikey] = service_group
+
+    def delete_service_group(self, apikey):
+        """
+        Unregisters a service group and removes
+
+        Args:
+            apikey: Unique APIKey of the service group
+
+        Returns:
+            None
+        """
+        group = self.service_groups.pop(apikey, None)
+        if group:
+            self.logger.info("Successfully unregistered Service Group '%s'!",
+                             apikey)
+        else:
+            self.logger.error("Could not unregister service group '%s'!",
+                              apikey)
+            raise KeyError("Device not found!")
+
+    def update_service_group(self, service_group: Union[ServiceGroup, Dict]):
+        """
+        Updates a registered service group configuration. There is no
+        opportunity to only partially update the device. Hence, your service
+        group model should be complete.
+
+        Args:
+            service_group: Service group configuration
+
+        Returns:
+            None
+
+        Raises:
+            KeyError: if service group not yet registered
+        """
+        if isinstance(service_group, dict):
+            service_group = ServiceGroup.model_validate(service_group)
+        assert isinstance(service_group, ServiceGroup), \
+            "Invalid content for service group"
+
+        if self.service_groups.get(service_group.apikey, None) is None:
+            raise KeyError("Service group not found! %s",
+                           service_group.apikey)
+        # add service group configuration to the service group list
+        self.service_groups[service_group.apikey] = service_group
+
+    def get_device(self, device_id: str) -> Device:
+        """
+        Returns the configuration of a registered device.
+
+        Args:
+            device_id: Id of the requested device
+
+        Returns:
+           Device: Device model of the requested device
+
+        Raises:
+            KeyError: if requested device is not registered with the client
+
+        Example::
+
+            from filip.clients.mqtt import MQTTClient
+
+            mqttc = MQTTClient()
+            device = mqttc.get_device(device_id="MyDeviceId")
+            print(device.json(indent=2))
+            print(type(device))
+        """
+        return self._devices[device_id]
+
+    def add_device(self,
+                   device: Union[Device, Dict],
+                   qos=0,
+                   options=None,
+                   properties=None):
+        """
+        Registers a device config with the mqtt client. Subsequently,
+        the client will magically subscribe to the corresponding topics based
+        on the device config and any matching registered service group config
+        if exists.
+
+        Note:
+            To register the device config only with this client is not
+            sufficient for data streaming the configuration also needs to be
+            registered with IoTA-Agent.
+
+        Args:
+            device: Configuration of an IoT device
+            qos: Quality of service can be 0, 1 or 2
+            options: MQTT v5.0 subscribe options
+            properties: MQTT v5.0 properties
+
+        Returns:
+            None
+
+        Raises:
+            ValueError: if device configuration already exists
+        """
+        device = self.__validate_device(device=device)
+
+        if self._devices.get(device.device_id, None) is None:
+            pass
+        else:
+            raise ValueError("Device already exists! %s", device.device_id)
+        # add device configuration to the device list
+        self._devices[device.device_id] = device
+        # subscribes to the command topic
+        self.__subscribe_commands(device=device,
+                                  qos=qos,
+                                  options=options,
+                                  properties=properties)
+
+    def delete_device(self, device_id: str):
+        """
+        Unregisters a device and removes its subscriptions and callbacks
+
+        Args:
+            device_id: id of and IoT device
+
+        Returns:
+            None
+        """
+        device = self._devices.pop(device_id, None)
+        if device:
+            topic = self.__create_topic(device=device,
+                                        topic_type=IoTAMQTTMessageType.CMD)
+            self.unsubscribe(topic=topic)
+            self.message_callback_remove(sub=topic)
+            self.logger.info("Successfully unregistered Device '%s'!",
+                             device_id)
+        else:
+            self.logger.error("Could not unregister device '%s'", device_id)
+
+    def update_device(self,
+                      device: Union[Device, Dict],
+                      qos=0,
+                      options=None,
+                      properties=None):
+        """
+        Updates a registered device configuration. There is no opportunity
+        to only partially update the device. Hence, your device model should
+        be complete.
+
+        Args:
+            device: Configuration of an IoT device
+            qos: Quality of service can be 0, 1 or 2
+            options: MQTT v5.0 subscribe options
+            properties: MQTT v5.0 properties
+
+        Returns:
+            None
+
+        Raises:
+            KeyError: if device not yet registered
+        """
+        device = self.__validate_device(device=device)
+
+        if self._devices.get(device.device_id, None) is None:
+            raise KeyError("Device not found! %s", device.device_id)
+
+        # update device configuration in the device list
+        self._devices[device.device_id] = device
+        # subscribes to the command topic
+        self.__subscribe_commands(device=device,
+                                  qos=qos,
+                                  options=options,
+                                  properties=properties)
+
+    def add_command_callback(self, device_id: str, callback: Callable):
+        """
+        Adds callback function for a device configuration.
+
+        Args:
+            device_id:
+                id of and IoT device
+            callback:
+                function that will be called for incoming commands.
+                This function should have the following format:
+
+        Example::
+
+            def on_command(client, obj, msg):
+                apikey, device_id, payload = \
+                    client.encoder.decode_message(msg=msg)
+
+                # do_something with the message.
+                # For instance write into a queue.
+
+                # acknowledge a command. Here command are usually single
+                # messages. The first key is equal to the commands name.
+                client.publish(device_id=device_id,
+                               command_name=next(iter(payload)),
+                               payload=payload)
+
+            mqttc.add_command_callback(device_id="MyDevice",
+                                       callback=on_command)
+
+        Returns:
+            None
+        """
+        device = self._devices.get(device_id, None)
+        if device is None:
+            raise KeyError("Device does not exist! %s", device_id)
+        self.__subscribe_commands(device=device)
+        topic = self.__create_topic(device=device,
+                                    topic_type=IoTAMQTTMessageType.CMD)
+        self.message_callback_add(topic, callback)
+
+    def publish(self,
+                topic=None,
+                payload: Union[Dict, Any] = None,
+                qos: int = 0,
+                retain: bool = False,
+                properties=None,
+                device_id: str = None,
+                attribute_name: str = None,
+                command_name: str = None,
+                timestamp: bool = False
+                ):
+        """
+        Publish an MQTT Message to a specified topic. If you want to publish
+        a device specific message to a device use the device_id argument for
+        multi-measurement. The function will then automatically validate
+        against the registered device configuration if the payload keys are
+        valid. If you want to publish a single measurement the attribute_name
+        argument is required as well.
+
+        Note:
+            If the device_id argument is set, the topic argument will be
+            ignored.
+
+        Args:
+            topic:
+                The topic that the message should be published on.
+            payload:
+                The actual message to send. If not given, or set to None a
+                zero length message will be used. Passing an int or float will
+                result in the payload being converted to a string
+                representing that number. If you wish to send a true
+                int/float, use struct.pack() to create the
+                payload you require. For publishing to a device use a dict
+                containing the object_ids as keys.
+            qos:
+                The quality of service level to use.
+            retain:
+                If set to true, the message will be set as the "last known
+                good"/retained message for the topic.
+            properties:
+                (MQTT v5.0 only) the MQTT v5.0 properties to be included.
+                Use the Properties class.
+            device_id:
+                Id of the IoT device you want to publish for. The topics will
+                automatically created. If set, the message type will be
+                assumed to be multi measurement.
+            attribute_name:
+                Name of an attribute of the device. Do only use this for
+                single measurements. If set, `command_name` must
+                be omitted.
+            command_name:
+                Name of a command of the device that should be acknowledged. If
+                set `attribute_name` must be omitted.
+            timestamp:
+                If `true` the client will generate a valid timestamp based on
+                utc and added to the multi measurement payload.
+                If a `timeInstant` is already contained in the
+                message payload it will not overwritten.
+
+        Returns:
+            None
+
+        Raises:
+            KeyError: if device configuration is not registered with client
+            ValueError: if the passed arguments are inconsistent or a
+                timestamp does not match the ISO 8601 format.
+            AssertionError: if the message payload does not match the device
+                configuration.
+        """
+
+        # TODO: time stamps are not tested yet
+
+        if device_id:
+            device = self.get_device(device_id=device_id)
+
+            # create message for multi measurement payload
+            if attribute_name is None and command_name is None:
+                assert isinstance(payload, dict), \
+                    "Payload must be a dictionary"
+
+                if timestamp and 'timeInstant' not in payload.keys():
+                    payload["timeInstant"] = datetime.utcnow()
+                # validate if dict keys match device configuration
+
+                msg_payload = payload.copy()
+                for key in payload.keys():
+                    for attr in device.attributes:
+                        if key in attr.object_id or key == 'timeInstant':
+                            break
+                        elif key == attr.name:
+                            if attr.object_id:
+                                msg_payload[attr.object_id] = \
+                                    msg_payload.pop(key)
+                            break
+                    else:
+                        err_msg = f"Attribute key '{key}' is not allowed " \
+                                  f"in the message payload for this " \
+                                  f"device configuration with device_id " \
+                                  f"'{device_id}'"
+                        raise KeyError(err_msg)
+                topic = self.__create_topic(
+                    device=device,
+                    topic_type=IoTAMQTTMessageType.MULTI)
+                payload = self._encoders[device.protocol].encode_msg(
+                    device_id=device_id,
+                    payload=payload,
+                    msg_type=IoTAMQTTMessageType.MULTI)
+
+            # create message for command acknowledgement
+            elif attribute_name is None and command_name:
+                assert isinstance(payload, Dict), "Payload must be a dictionary"
+                assert len(payload.keys()) == 1, \
+                    "Cannot acknowledge multiple commands simultaneously"
+                assert next(iter(payload.keys())) in \
+                       [cmd.name for cmd in device.commands], \
+                    "Unknown command for this device!"
+                topic = self.__create_topic(
+                    device=device,
+                    topic_type=IoTAMQTTMessageType.CMDEXE)
+                payload = self._encoders[device.protocol].encode_msg(
+                    device_id=device_id,
+                    payload=payload,
+                    msg_type=IoTAMQTTMessageType.CMDEXE)
+
+            # create message for single measurement
+            elif attribute_name and command_name is None:
+                topic = self.__create_topic(
+                    device=device,
+                    topic_type=IoTAMQTTMessageType.SINGLE,
+                    attribute=attribute_name)
+                payload = self._encoders[device.protocol].encode_msg(
+                    device_id=device_id,
+                    payload=payload,
+                    msg_type=IoTAMQTTMessageType.SINGLE)
+            else:
+                raise ValueError("Inconsistent arguments!")
+
+        super().publish(topic=topic,
+                        payload=payload,
+                        qos=qos,
+                        retain=retain,
+                        properties=properties)
+
+    def subscribe(self, topic=None, qos=0, options=None, properties=None):
+        """
+        Extends the normal subscribe function of the paho.mqtt.client.
+        If the topic argument is omitted the client will subscribe to all
+        registered device command topics.
+
+        Args:
+            topic:
+                A string specifying the subscription topic to subscribe to.
+            qos:
+                The desired quality of service level for the subscription.
+                Defaults to 0.
+            options: Not used.
+            properties: Not used.
+
+        Returns:
+            None
+        """
+        if topic:
+            super().subscribe(topic=topic,
+                              qos=qos,
+                              options=options,
+                              properties=properties)
+        else:
+            for device in self._devices.values():
+                self.__subscribe_commands(device=device,
+                                          qos=qos,
+                                          options=options,
+                                          properties=properties)
```

### Comparing `filip-0.3.0/filip/clients/mqtt/encoder/base_encoder.py` & `filip-0.4.0/filip/clients/mqtt/encoder/base_encoder.py`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,110 +1,110 @@
-"""
-Abstract class for all IoTA MQTT message encoders
-"""
-import logging
-from abc import ABC
-from datetime import datetime
-from typing import Dict, Tuple
-from paho.mqtt.client import MQTTMessage
-from filip.models.mqtt import IoTAMQTTMessageType
-from filip.utils import convert_datetime_to_iso_8601_with_z_suffix
-
-
-class BaseEncoder(ABC):
-    """
-    Abstract class for all IoTA MQTT message encoders
-    """
-    prefix: str = ''
-
-    def __init__(self):
-        # setup logging functionality
-        self.logger = logging.getLogger(
-            name=f"{self.__class__.__module__}."
-                 f"{self.__class__.__name__}")
-        self.logger.addHandler(logging.NullHandler())
-
-    def decode_message(self,
-                       msg: MQTTMessage,
-                       decoder: str = 'utf-8') -> Tuple[str, str, str]:
-        """
-        Decode message for ingoing traffic
-        Args:
-            msg: Message class
-            decoder: encoding identifier
-
-        Returns:
-            apikey
-            device_id
-            payload
-        """
-        topic = msg.topic.strip('/')
-        topic = topic.split('/')
-        apikey = None
-        device_id = None
-        payload = msg.payload.decode(decoder)
-        if topic[-1] == 'cmd':
-            apikey = topic[0]
-            device_id = topic[1]
-
-        if any((apikey, device_id, payload)) is None:
-            raise ValueError
-
-        return apikey, device_id, payload
-
-    def encode_msg(self,
-                   device_id: str,
-                   payload: Dict,
-                   msg_type: IoTAMQTTMessageType) -> str:
-        """
-        Encode message for outgoing traffic
-
-        Args:
-            device_id: id of the iot device
-            payload: payload to send
-            msg_type: kind of message to send
-
-        """
-        raise NotImplementedError
-
-    @classmethod
-    def _parse_timestamp(cls, payload: Dict) -> Dict:
-        """
-        Helper function to parse timestamps
-
-        Args:
-            payload: payload to reformat
-
-        Returns:
-            Dictionary containing the formatted payload
-        """
-        if payload.get('timeInstant', None):
-            timestamp = payload['timeInstant']
-            if isinstance(timestamp, str):
-                timestamp = datetime.fromisoformat(payload["timeInstant"])
-            if isinstance(timestamp, datetime):
-                payload['timeInstant'] = \
-                    convert_datetime_to_iso_8601_with_z_suffix(
-                        payload['timeInstant'])
-            else:
-                raise ValueError('Not able to parse datetime')
-        return payload
-
-    @classmethod
-    def _raise_encoding_error(cls,
-                              payload: Dict,
-                              msg_type: IoTAMQTTMessageType):
-        """
-        Helper function to provide consistent error messages
-        Args:
-            payload: Invalid message content
-            msg_type: Invalid message type
-
-        Returns:
-            None
-
-        Raises:
-            ValueError
-        """
-        ValueError(f"Message format not supported! \n "
-                   f"Message Type: {msg_type} \n "
-                   f"Payload: {payload}")
+"""
+Abstract class for all IoTA MQTT message encoders
+"""
+import logging
+from abc import ABC
+from datetime import datetime
+from typing import Dict, Tuple
+from paho.mqtt.client import MQTTMessage
+from filip.models.mqtt import IoTAMQTTMessageType
+from filip.utils import convert_datetime_to_iso_8601_with_z_suffix
+
+
+class BaseEncoder(ABC):
+    """
+    Abstract class for all IoTA MQTT message encoders
+    """
+    prefix: str = ''
+
+    def __init__(self):
+        # setup logging functionality
+        self.logger = logging.getLogger(
+            name=f"{self.__class__.__module__}."
+                 f"{self.__class__.__name__}")
+        self.logger.addHandler(logging.NullHandler())
+
+    def decode_message(self,
+                       msg: MQTTMessage,
+                       decoder: str = 'utf-8') -> Tuple[str, str, str]:
+        """
+        Decode message for ingoing traffic
+        Args:
+            msg: Message class
+            decoder: encoding identifier
+
+        Returns:
+            apikey
+            device_id
+            payload
+        """
+        topic = msg.topic.strip('/')
+        topic = topic.split('/')
+        apikey = None
+        device_id = None
+        payload = msg.payload.decode(decoder)
+        if topic[-1] == 'cmd':
+            apikey = topic[0]
+            device_id = topic[1]
+
+        if any((apikey, device_id, payload)) is None:
+            raise ValueError
+
+        return apikey, device_id, payload
+
+    def encode_msg(self,
+                   device_id: str,
+                   payload: Dict,
+                   msg_type: IoTAMQTTMessageType) -> str:
+        """
+        Encode message for outgoing traffic
+
+        Args:
+            device_id: id of the iot device
+            payload: payload to send
+            msg_type: kind of message to send
+
+        """
+        raise NotImplementedError
+
+    @classmethod
+    def _parse_timestamp(cls, payload: Dict) -> Dict:
+        """
+        Helper function to parse timestamps
+
+        Args:
+            payload: payload to reformat
+
+        Returns:
+            Dictionary containing the formatted payload
+        """
+        if payload.get('timeInstant', None):
+            timestamp = payload['timeInstant']
+            if isinstance(timestamp, str):
+                timestamp = datetime.fromisoformat(payload["timeInstant"])
+            if isinstance(timestamp, datetime):
+                payload['timeInstant'] = \
+                    convert_datetime_to_iso_8601_with_z_suffix(
+                        payload['timeInstant'])
+            else:
+                raise ValueError('Not able to parse datetime')
+        return payload
+
+    @classmethod
+    def _raise_encoding_error(cls,
+                              payload: Dict,
+                              msg_type: IoTAMQTTMessageType):
+        """
+        Helper function to provide consistent error messages
+        Args:
+            payload: Invalid message content
+            msg_type: Invalid message type
+
+        Returns:
+            None
+
+        Raises:
+            ValueError
+        """
+        ValueError(f"Message format not supported! \n "
+                   f"Message Type: {msg_type} \n "
+                   f"Payload: {payload}")
```

### Comparing `filip-0.3.0/filip/clients/mqtt/encoder/json.py` & `filip-0.4.0/filip/clients/mqtt/encoder/json.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,36 +1,36 @@
-"""
-Json encoder class for all IoTA-JSON MQTT message encoders
-"""
-import json
-from typing import Any, Dict, Tuple
-from filip.clients.mqtt.encoder import BaseEncoder
-from filip.models.mqtt import IoTAMQTTMessageType
-
-
-class Json(BaseEncoder):
-    """
-    Json encoder class for all IoTA-JSON MQTT message encoders
-    """
-    prefix = '/json'
-
-    def __init__(self):
-        super().__init__()
-
-    def decode_message(self, msg, decoder='utf-8') -> Tuple[str, str, Dict]:
-        apikey, device_id, payload = super().decode_message(msg=msg,
-                                                            decoder=decoder)
-        payload = json.loads(payload)
-        return apikey, device_id, payload
-
-    def encode_msg(self,
-                   device_id,
-                   payload: Any,
-                   msg_type: IoTAMQTTMessageType) -> str:
-        if msg_type == IoTAMQTTMessageType.SINGLE:
-            return payload
-        elif msg_type == IoTAMQTTMessageType.MULTI:
-            payload = super()._parse_timestamp(payload=payload)
-            return json.dumps(payload, default=str)
-        elif msg_type == IoTAMQTTMessageType.CMDEXE:
-            return json.dumps(payload)
-        super()._raise_encoding_error(payload=payload, msg_type=msg_type)
+"""
+Json encoder class for all IoTA-JSON MQTT message encoders
+"""
+import json
+from typing import Any, Dict, Tuple
+from filip.clients.mqtt.encoder import BaseEncoder
+from filip.models.mqtt import IoTAMQTTMessageType
+
+
+class Json(BaseEncoder):
+    """
+    Json encoder class for all IoTA-JSON MQTT message encoders
+    """
+    prefix = '/json'
+
+    def __init__(self):
+        super().__init__()
+
+    def decode_message(self, msg, decoder='utf-8') -> Tuple[str, str, Dict]:
+        apikey, device_id, payload = super().decode_message(msg=msg,
+                                                            decoder=decoder)
+        payload = json.loads(payload)
+        return apikey, device_id, payload
+
+    def encode_msg(self,
+                   device_id,
+                   payload: Any,
+                   msg_type: IoTAMQTTMessageType) -> str:
+        if msg_type == IoTAMQTTMessageType.SINGLE:
+            return payload
+        elif msg_type == IoTAMQTTMessageType.MULTI:
+            payload = super()._parse_timestamp(payload=payload)
+            return json.dumps(payload, default=str)
+        elif msg_type == IoTAMQTTMessageType.CMDEXE:
+            return json.dumps(payload)
+        super()._raise_encoding_error(payload=payload, msg_type=msg_type)
```

### Comparing `filip-0.3.0/filip/clients/mqtt/encoder/ulralight.py` & `filip-0.4.0/filip/clients/mqtt/encoder/ulralight.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,54 +1,54 @@
-from pydantic import validate_arguments
-from typing import Any, Dict, Tuple, Union
-from filip.clients.mqtt.encoder import BaseEncoder
-from filip.models.mqtt import IoTAMQTTMessageType
-
-class Ultralight(BaseEncoder):
-    prefix = '/ul'
-
-    def __init__(self):
-        super().__init__()
-
-    @staticmethod
-    @validate_arguments
-    def __eval_value(value: Union[bool, float, str]):
-        return value
-
-    def decode_message(self, msg, decoder='utf-8') -> Tuple[str, str, Dict]:
-        apikey, device_id, payload = super().decode_message(msg=msg,
-                                                            decoder=decoder)
-        payload = payload.split('@')
-        if not device_id == payload[0]:
-            self.logger.warning("Received invalid command")
-
-        payload = payload[1].split('|')
-        payload = {payload[i]: self.__eval_value(payload[i + 1])
-                   for i in range(0, len(payload), 2)}
-
-        return apikey, device_id, payload
-
-    def encode_msg(self,
-                   device_id: str,
-                   payload: Any,
-                   msg_type: IoTAMQTTMessageType) -> str:
-        if msg_type == IoTAMQTTMessageType.SINGLE:
-            return payload
-        elif msg_type == IoTAMQTTMessageType.MULTI:
-            payload = super()._parse_timestamp(payload=payload)
-            timestamp = str(payload.pop('timeInstant', ''))
-            data = '|'.join([f"{key}|{value}" for key, value in
-                             payload.items()])
-            data = '|'.join([timestamp, data]).strip('|')
-            return data
-        elif msg_type == IoTAMQTTMessageType.CMDEXE:
-            for key, value in payload.items():
-                if isinstance(value, bool):
-                    value = str(value).lower()
-                elif isinstance(value, (float, int)):
-                    value = str(value)
-                elif isinstance(value, str):
-                    pass
-                else:
-                    raise ValueError("Cannot parse command acknowledgement!")
-                return f"{device_id}@{key}|{value}"
+from pydantic import validate_arguments
+from typing import Any, Dict, Tuple, Union
+from filip.clients.mqtt.encoder import BaseEncoder
+from filip.models.mqtt import IoTAMQTTMessageType
+
+class Ultralight(BaseEncoder):
+    prefix = '/ul'
+
+    def __init__(self):
+        super().__init__()
+
+    @staticmethod
+    @validate_arguments
+    def __eval_value(value: Union[bool, float, str]):
+        return value
+
+    def decode_message(self, msg, decoder='utf-8') -> Tuple[str, str, Dict]:
+        apikey, device_id, payload = super().decode_message(msg=msg,
+                                                            decoder=decoder)
+        payload = payload.split('@')
+        if not device_id == payload[0]:
+            self.logger.warning("Received invalid command")
+
+        payload = payload[1].split('|')
+        payload = {payload[i]: self.__eval_value(payload[i + 1])
+                   for i in range(0, len(payload), 2)}
+
+        return apikey, device_id, payload
+
+    def encode_msg(self,
+                   device_id: str,
+                   payload: Any,
+                   msg_type: IoTAMQTTMessageType) -> str:
+        if msg_type == IoTAMQTTMessageType.SINGLE:
+            return payload
+        elif msg_type == IoTAMQTTMessageType.MULTI:
+            payload = super()._parse_timestamp(payload=payload)
+            timestamp = str(payload.pop('timeInstant', ''))
+            data = '|'.join([f"{key}|{value}" for key, value in
+                             payload.items()])
+            data = '|'.join([timestamp, data]).strip('|')
+            return data
+        elif msg_type == IoTAMQTTMessageType.CMDEXE:
+            for key, value in payload.items():
+                if isinstance(value, bool):
+                    value = str(value).lower()
+                elif isinstance(value, (float, int)):
+                    value = str(value)
+                elif isinstance(value, str):
+                    pass
+                else:
+                    raise ValueError("Cannot parse command acknowledgement!")
+                return f"{device_id}@{key}|{value}"
         super()._raise_encoding_error(payload=payload, msg_type=msg_type)
```

### Comparing `filip-0.3.0/filip/clients/ngsi_v2/cb.py` & `filip-0.4.0/filip/clients/ngsi_v2/cb.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,1922 +1,2178 @@
-"""
-Context Broker Module for API Client
-"""
-from __future__ import annotations
-
-from copy import deepcopy
-from math import inf
-from pkg_resources import parse_version
-from pydantic import \
-    PositiveInt, \
-    PositiveFloat, \
-    AnyHttpUrl
-from pydantic.type_adapter import TypeAdapter
-from typing import Any, Dict, List, Optional, TYPE_CHECKING, Union
-import re
-import requests
-from urllib.parse import urljoin
-import warnings
-from filip.clients.base_http_client import BaseHttpClient
-from filip.config import settings
-from filip.models.base import FiwareHeader, PaginationMethod
-from filip.utils.simple_ql import QueryString
-from filip.models.ngsi_v2.context import \
-    ActionType, \
-    Command, \
-    ContextEntity, \
-    ContextEntityKeyValues, \
-    ContextAttribute, \
-    NamedCommand, \
-    NamedContextAttribute, \
-    Query, \
-    Update, \
-    PropertyFormat
-from filip.models.ngsi_v2.base import AttrsFormat
-from filip.models.ngsi_v2.subscriptions import Subscription, Message
-from filip.models.ngsi_v2.registrations import Registration
-
-if TYPE_CHECKING:
-    from filip.clients.ngsi_v2.iota import IoTAClient
-
-
-class ContextBrokerClient(BaseHttpClient):
-    """
-    Implementation of NGSI Context Broker functionalities, such as creating
-    entities and subscriptions; retrieving, updating and deleting data.
-    Further documentation:
-    https://fiware-orion.readthedocs.io/en/master/
-
-    Api specifications for v2 are located here:
-    https://telefonicaid.github.io/fiware-orion/api/v2/stable/
-
-    Note:
-        We use the reference implementation for development. Therefore, some
-        other brokers may show slightly different behavior!
-    """
-
-    def __init__(self,
-                 url: str = None,
-                 *,
-                 session: requests.Session = None,
-                 fiware_header: FiwareHeader = None,
-                 **kwargs):
-        """
-
-        Args:
-            url: Url of context broker server
-            session (requests.Session):
-            fiware_header (FiwareHeader): fiware service and fiware service path
-            **kwargs (Optional): Optional arguments that ``request`` takes.
-        """
-        # set service url
-        url = url or settings.CB_URL
-        super().__init__(url=url,
-                         session=session,
-                         fiware_header=fiware_header,
-                         **kwargs)
-
-    def __pagination(self,
-                     *,
-                     method: PaginationMethod = PaginationMethod.GET,
-                     url: str,
-                     headers: Dict,
-                     limit: Union[PositiveInt, PositiveFloat] = None,
-                     params: Dict = None,
-                     data: str = None) -> List[Dict]:
-        """
-        NGSIv2 implements a pagination mechanism in order to help clients to
-        retrieve large sets of resources. This mechanism works for all listing
-        operations in the API (e.g. GET /v2/entities, GET /v2/subscriptions,
-        POST /v2/op/query, etc.). This function helps getting datasets that are
-        larger than the limit for the different GET operations.
-
-        https://fiware-orion.readthedocs.io/en/master/user/pagination/index.html
-
-        Args:
-            url: Information about the url, obtained from the original function
-            headers: The headers from the original function
-            params:
-            limit:
-
-        Returns:
-            object:
-
-        """
-        if limit is None:
-            limit = inf
-        if limit > 1000:
-            params['limit'] = 1000  # maximum items per request
-        else:
-            params['limit'] = limit
-
-        if self.session:
-            session = self.session
-        else:
-            session = requests.Session()
-        with session:
-            res = session.request(method=method,
-                                  url=url,
-                                  params=params,
-                                  headers=headers,
-                                  data=data)
-            if res.ok:
-                items = res.json()
-                # do pagination
-                count = int(res.headers['Fiware-Total-Count'])
-
-                while len(items) < limit and len(items) < count:
-                    # Establishing the offset from where entities are retrieved
-                    params['offset'] = len(items)
-                    params['limit'] = min(1000, (limit - len(items)))
-                    res = session.request(method=method,
-                                          url=url,
-                                          params=params,
-                                          headers=headers,
-                                          data=data)
-                    if res.ok:
-                        items.extend(res.json())
-                    else:
-                        res.raise_for_status()
-                self.logger.debug('Received: %s', items)
-                return items
-            res.raise_for_status()
-
-    # MANAGEMENT API
-    def get_version(self) -> Dict:
-        """
-        Gets version of IoT Agent
-        Returns:
-            Dictionary with response
-        """
-        url = urljoin(self.base_url, '/version')
-        try:
-            res = self.get(url=url, headers=self.headers)
-            if res.ok:
-                return res.json()
-            res.raise_for_status()
-        except requests.RequestException as err:
-            self.logger.error(err)
-            raise
-
-    def get_resources(self) -> Dict:
-        """
-        Gets reo
-
-        Returns:
-            Dict
-        """
-        url = urljoin(self.base_url, '/v2')
-        try:
-            res = self.get(url=url, headers=self.headers)
-            if res.ok:
-                return res.json()
-            res.raise_for_status()
-        except requests.RequestException as err:
-            self.logger.error(err)
-            raise
-
-    # STATISTICS API
-    def get_statistics(self) -> Dict:
-        """
-        Gets statistics of context broker
-        Returns:
-            Dictionary with response
-        """
-        url = urljoin(self.base_url, 'statistics')
-        try:
-            res = self.get(url=url, headers=self.headers)
-            if res.ok:
-                return res.json()
-            res.raise_for_status()
-        except requests.RequestException as err:
-            self.logger.error(err)
-            raise
-
-    # CONTEXT MANAGEMENT API ENDPOINTS
-    # Entity Operations
-    def post_entity(self,
-                    entity: ContextEntity,
-                    update: bool = False,
-                    patch: bool = False,
-                    override_attr_metadata: bool = True
-                    ):
-        """
-        Function registers an Object with the NGSI Context Broker,
-        if it already exists it can be automatically updated (overwritten)
-        if the update bool is True.
-        First a post request with the entity is tried, if the response code
-        is 422 the entity is uncrossable, as it already exists there are two
-        options, either overwrite it, if the attribute have changed
-        (e.g. at least one new/new values) (update = True) or leave
-        it the way it is (update=False)
-        If you only want to manipulate the entities values, you need to set
-        patch argument.
-
-        Args:
-            entity (ContextEntity):
-                Context Entity Object
-            update (bool):
-                If the response.status_code is 422, whether the override and
-                existing entity
-            patch (bool):
-                If the response.status_code is 422, whether the manipulate the
-                existing entity. Omitted if update `True`.
-            override_attr_metadata:
-                Only applies for patch equal to `True`.
-                Whether to override or append the attributes metadata.
-                `True` for overwrite or `False` for update/append
-
-        """
-        url = urljoin(self.base_url, 'v2/entities')
-        headers = self.headers.copy()
-        try:
-            res = self.post(
-                url=url,
-                headers=headers,
-                json=entity.model_dump(exclude_unset=True,
-                                       exclude_defaults=True,
-                                       exclude_none=True))
-            if res.ok:
-                self.logger.info("Entity successfully posted!")
-                return res.headers.get('Location')
-            res.raise_for_status()
-        except requests.RequestException as err:
-            if update and err.response.status_code == 422:
-                return self.update_entity(
-                    entity=entity)
-            if patch and err.response.status_code == 422:
-                return self.patch_entity(
-                    entity=entity,
-                    override_attr_metadata=override_attr_metadata)
-            msg = f"Could not post entity {entity.id}"
-            self.log_error(err=err, msg=msg)
-            raise
-
-    def get_entity_list(self,
-                        *,
-                        entity_ids: List[str] = None,
-                        entity_types: List[str] = None,
-                        id_pattern: str = None,
-                        type_pattern: str = None,
-                        q: Union[str, QueryString] = None,
-                        mq: Union[str, QueryString] = None,
-                        georel: str = None,
-                        geometry: str = None,
-                        coords: str = None,
-                        limit: PositiveInt = inf,
-                        attrs: List[str] = None,
-                        metadata: str = None,
-                        order_by: str = None,
-                        response_format: Union[AttrsFormat, str] =
-                        AttrsFormat.NORMALIZED
-                        ) -> List[Union[ContextEntity,
-                                        ContextEntityKeyValues,
-                                        Dict[str, Any]]]:
-        r"""
-        Retrieves a list of context entities that match different criteria by
-        id, type, pattern matching (either id or type) and/or those which
-        match a query or geographical query (see Simple Query Language and
-        Geographical Queries). A given entity has to match all the criteria
-        to be retrieved (i.e., the criteria is combined in a logical AND
-        way). Note that pattern matching query parameters are incompatible
-        (i.e. mutually exclusive) with their corresponding exact matching
-        parameters, i.e. idPattern with id and typePattern with type.
-
-        Args:
-            entity_ids: A comma-separated list of elements. Retrieve entities
-                whose ID matches one of the elements in the list.
-                Incompatible with idPattern,e.g. Boe_Idarium
-            entity_types: comma-separated list of elements. Retrieve entities
-                whose type matches one of the elements in the list.
-                Incompatible with typePattern. Example: Room.
-            id_pattern: A correctly formatted regular expression. Retrieve
-                entities whose ID matches the regular expression. Incompatible
-                with id, e.g. ngsi-ld.* or sensor.*
-            type_pattern: A correctly formatted regular expression. Retrieve
-                entities whose type matches the regular expression.
-                Incompatible with type, e.g. room.*
-            q (SimpleQuery): A query expression, composed of a list of
-                statements separated by ;, i.e.,
-                q=statement1;statement2;statement3. See Simple Query
-                Language specification. Example: temperature>40.
-            mq (SimpleQuery): A  query expression for attribute metadata,
-                composed of a list of statements separated by ;, i.e.,
-                mq=statement1;statement2;statement3. See Simple Query
-                Language specification. Example: temperature.accuracy<0.9.
-            georel: Spatial relationship between matching entities and a
-                reference shape. See Geographical Queries. Example: 'near'.
-            geometry: Geographical area to which the query is restricted.
-                See Geographical Queries. Example: point.
-            coords: List of latitude-longitude pairs of coordinates separated
-                by ';'. See Geographical Queries. Example: 41.390205,
-                2.154007;48.8566,2.3522.
-            limit: Limits the number of entities to be retrieved Example: 20
-            attrs: Comma-separated list of attribute names whose data are to
-                be included in the response. The attributes are retrieved in
-                the order specified by this parameter. If this parameter is
-                not included, the attributes are retrieved in arbitrary
-                order. See "Filtering out attributes and metadata" section
-                for more detail. Example: seatNumber.
-            metadata: A list of metadata names to include in the response.
-                See "Filtering out attributes and metadata" section for more
-                detail. Example: accuracy.
-            order_by: Criteria for ordering results. See "Ordering Results"
-                section for details. Example: temperature,!speed.
-            response_format (AttrsFormat, str): Response Format. Note: That if
-                'keyValues' or 'values' are used the response model will
-                change to List[ContextEntityKeyValues] and to List[Dict[str,
-                Any]], respectively.
-        Returns:
-
-        """
-        url = urljoin(self.base_url, 'v2/entities/')
-        headers = self.headers.copy()
-        params = {}
-
-        if entity_ids and id_pattern:
-            raise ValueError
-        if entity_types and type_pattern:
-            raise ValueError
-        if entity_ids:
-            if not isinstance(entity_ids, list):
-                entity_ids = [entity_ids]
-            params.update({'id': ','.join(entity_ids)})
-        if id_pattern:
-            try:
-                re.compile(id_pattern)
-            except re.error as err:
-                raise ValueError(f'Invalid Pattern: {err}') from err
-            params.update({'idPattern': id_pattern})
-        if entity_types:
-            if not isinstance(entity_types, list):
-                entity_types = [entity_types]
-            params.update({'type': ','.join(entity_types)})
-        if type_pattern:
-            try:
-                re.compile(type_pattern)
-            except re.error as err:
-                raise ValueError(f'Invalid Pattern: {err.msg}') from err
-            params.update({'typePattern': type_pattern})
-        if attrs:
-            params.update({'attrs': ','.join(attrs)})
-        if metadata:
-            params.update({'metadata': ','.join(metadata)})
-        if q:
-            if isinstance(q, str):
-                q = QueryString.parse_str(q)
-            params.update({'q': str(q)})
-        if mq:
-            params.update({'mq': str(mq)})
-        if geometry:
-            params.update({'geometry': geometry})
-        if georel:
-            params.update({'georel': georel})
-        if coords:
-            params.update({'coords': coords})
-        if order_by:
-            params.update({'orderBy': order_by})
-        if response_format not in list(AttrsFormat):
-            raise ValueError(f'Value must be in {list(AttrsFormat)}')
-        response_format = ','.join(['count', response_format])
-        params.update({'options': response_format})
-        try:
-            items = self.__pagination(method=PaginationMethod.GET,
-                                      limit=limit,
-                                      url=url,
-                                      params=params,
-                                      headers=headers)
-            if AttrsFormat.NORMALIZED in response_format:
-                adapter = TypeAdapter(List[ContextEntity])
-                return adapter.validate_python(items)
-            if AttrsFormat.KEY_VALUES in response_format:
-                adapter = TypeAdapter(List[ContextEntityKeyValues])
-                return adapter.validate_python(items)
-            return items
-
-        except requests.RequestException as err:
-            msg = "Could not load entities"
-            self.log_error(err=err, msg=msg)
-            raise
-
-    def get_entity(self,
-                   entity_id: str,
-                   entity_type: str = None,
-                   attrs: List[str] = None,
-                   metadata: List[str] = None,
-                   response_format: Union[AttrsFormat, str] =
-                   AttrsFormat.NORMALIZED) \
-            -> Union[ContextEntity, ContextEntityKeyValues, Dict[str, Any]]:
-        """
-        This operation must return one entity element only, but there may be
-        more than one entity with the same ID (e.g. entities with same ID but
-        different types). In such case, an error message is returned, with
-        the HTTP status code set to 409 Conflict.
-
-        Args:
-            entity_id (String): Id of the entity to be retrieved
-            entity_type (String): Entity type, to avoid ambiguity in case
-                there are several entities with the same entity id.
-            attrs (List of Strings): List of attribute names whose data must be
-                included in the response. The attributes are retrieved in the
-                order specified by this parameter.
-                See "Filtering out attributes and metadata" section for more
-                detail. If this parameter is not included, the attributes are
-                retrieved in arbitrary order, and all the attributes of the
-                entity are included in the response.
-                Example: temperature, humidity.
-            metadata (List of Strings): A list of metadata names to include in
-                the response. See "Filtering out attributes and metadata"
-                section for more detail. Example: accuracy.
-            response_format (AttrsFormat, str): Representation format of
-                response
-        Returns:
-            ContextEntity
-        """
-        url = urljoin(self.base_url, f'v2/entities/{entity_id}')
-        headers = self.headers.copy()
-        params = {}
-        if entity_type:
-            params.update({'type': entity_type})
-        if attrs:
-            params.update({'attrs': ','.join(attrs)})
-        if metadata:
-            params.update({'metadata': ','.join(metadata)})
-        if response_format not in list(AttrsFormat):
-            raise ValueError(f'Value must be in {list(AttrsFormat)}')
-        params.update({'options': response_format})
-
-        try:
-            res = self.get(url=url, params=params, headers=headers)
-            if res.ok:
-                self.logger.info("Entity successfully retrieved!")
-                self.logger.debug("Received: %s", res.json())
-                if response_format == AttrsFormat.NORMALIZED:
-                    return ContextEntity(**res.json())
-                if response_format == AttrsFormat.KEY_VALUES:
-                    return ContextEntityKeyValues(**res.json())
-                return res.json()
-            res.raise_for_status()
-        except requests.RequestException as err:
-            msg = f"Could not load entity {entity_id}"
-            self.log_error(err=err, msg=msg)
-            raise
-
-    def get_entity_attributes(self,
-                              entity_id: str,
-                              entity_type: str = None,
-                              attrs: List[str] = None,
-                              metadata: List[str] = None,
-                              response_format: Union[AttrsFormat, str] =
-                              AttrsFormat.NORMALIZED) -> \
-            Dict[str, ContextAttribute]:
-        """
-        This request is similar to retrieving the whole entity, however this
-        one omits the id and type fields. Just like the general request of
-        getting an entire entity, this operation must return only one entity
-        element. If more than one entity with the same ID is found (e.g.
-        entities with same ID but different type), an error message is
-        returned, with the HTTP status code set to 409 Conflict.
-
-        Args:
-            entity_id (String): Id of the entity to be retrieved
-            entity_type (String): Entity type, to avoid ambiguity in case
-                there are several entities with the same entity id.
-            attrs (List of Strings): List of attribute names whose data must be
-                included in the response. The attributes are retrieved in the
-                order specified by this parameter.
-                See "Filtering out attributes and metadata" section for more
-                detail. If this parameter is not included, the attributes are
-                retrieved in arbitrary order, and all the attributes of the
-                entity are included in the response. Example: temperature,
-                humidity.
-            metadata (List of Strings): A list of metadata names to include in
-                the response. See "Filtering out attributes and metadata"
-                section for more detail. Example: accuracy.
-            response_format (AttrsFormat, str): Representation format of
-                response
-        Returns:
-            Dict
-        """
-        url = urljoin(self.base_url, f'v2/entities/{entity_id}/attrs')
-        headers = self.headers.copy()
-        params = {}
-        if entity_type:
-            params.update({'type': entity_type})
-        if attrs:
-            params.update({'attrs': ','.join(attrs)})
-        if metadata:
-            params.update({'metadata': ','.join(metadata)})
-        if response_format not in list(AttrsFormat):
-            raise ValueError(f'Value must be in {list(AttrsFormat)}')
-        params.update({'options': response_format})
-        try:
-            res = self.get(url=url, params=params, headers=headers)
-            if res.ok:
-                if response_format == AttrsFormat.NORMALIZED:
-                    return {key: ContextAttribute(**values)
-                            for key, values in res.json().items()}
-                return res.json()
-            res.raise_for_status()
-        except requests.RequestException as err:
-            msg = f"Could not load attributes from entity {entity_id} !"
-            self.log_error(err=err, msg=msg)
-            raise
-
-    def update_entity(self,
-                      entity: ContextEntity,
-                      append_strict: bool = False
-                      ):
-        """
-        The request payload is an object representing the attributes to
-        append or update.
-
-        Note:
-            Update means overwriting the existing entity. If you want to
-            manipulate you should rather use patch_entity.
-
-        Args:
-            entity (ContextEntity):
-            append_strict: If `False` the entity attributes are updated (if they
-                previously exist) or appended (if they don't previously exist)
-                with the ones in the payload.
-                If `True` all the attributes in the payload not
-                previously existing in the entity are appended. In addition
-                to that, in case some of the attributes in the payload
-                already exist in the entity, an error is returned.
-                More precisely this means a strict append procedure.
-
-        Returns:
-            None
-        """
-        self.update_or_append_entity_attributes(entity_id=entity.id,
-                                                entity_type=entity.type,
-                                                attrs=entity.get_properties(),
-                                                append_strict=append_strict)
-
-    def delete_entity(self,
-                      entity_id: str,
-                      entity_type: str,
-                      delete_devices: bool = False,
-                      iota_client: IoTAClient = None,
-                      iota_url: AnyHttpUrl = settings.IOTA_URL) -> None:
-
-        """
-        Remove a entity from the context broker. No payload is required
-        or received.
-
-        Args:
-            entity_id:
-                Id of the entity to be deleted
-            entity_type:
-                several entities with the same entity id.
-            delete_devices:
-                If True, also delete all devices that reference this
-                entity (entity_id as entity_name)
-            iota_client:
-                Corresponding IoTA-Client used to access IoTA-Agent
-            iota_url:
-                URL of the corresponding IoT-Agent. This will autogenerate
-                an IoTA-Client, mirroring the information of the
-                ContextBrokerClient, e.g. FiwareHeader, and other headers
-
-        Returns:
-            None
-        """
-        url = urljoin(self.base_url, f'v2/entities/{entity_id}')
-        headers = self.headers.copy()
-        params = {'type': entity_type}
-
-        try:
-            res = self.delete(url=url, params=params, headers=headers)
-            if res.ok:
-                self.logger.info("Entity '%s' successfully deleted!", entity_id)
-            else:
-                res.raise_for_status()
-        except requests.RequestException as err:
-            msg = f"Could not delete entity {entity_id} !"
-            self.log_error(err=err, msg=msg)
-            raise
-
-        if delete_devices:
-            from filip.clients.ngsi_v2 import IoTAClient
-            if iota_client:
-                iota_client_local = deepcopy(iota_client)
-            else:
-                warnings.warn("No IoTA-Client object provided! "
-                              "Will try to generate one. "
-                              "This usage is not recommended.")
-
-                iota_client_local = IoTAClient(
-                    url=iota_url,
-                    fiware_header=self.fiware_headers,
-                    headers=self.headers)
-
-            for device in iota_client_local.get_device_list(
-                    entity_names=[entity_id]):
-                if device.entity_type == entity_type:
-                    iota_client_local.delete_device(device_id=device.device_id)
-
-            iota_client_local.close()
-
-    def delete_entities(self, entities: List[ContextEntity]) -> None:
-        """
-        Remove a list of entities from the context broker. This methode is
-        more efficient than to call delete_entity() for each entity
-
-        Args:
-            entities: List[ContextEntity]: List of entities to be deleted
-
-        Raises:
-            Exception, if one of the entities is not in the ContextBroker
-
-        Returns:
-            None
-        """
-
-        # update() delete, deletes all entities without attributes completely,
-        # and removes the attributes for the other
-        # The entities are sorted based on the fact if they have
-        # attributes.
-        entities_with_attributes: List[ContextEntity] = []
-        for entity in entities:
-            attribute_names = [key for key in entity.model_dump() if key not in
-                               ContextEntity.model_fields]
-            if len(attribute_names) > 0:
-                entities_with_attributes.append(
-                    ContextEntity(id=entity.id, type=entity.type))
-
-        # Post update_delete for those without attribute only once,
-        # for the other post update_delete again but for the changed entity
-        # in the ContextBroker (only id and type left)
-        if len(entities) > 0:
-            self.update(entities=entities, action_type="delete")
-        if len(entities_with_attributes) > 0:
-            self.update(entities=entities_with_attributes, action_type="delete")
-
-    def update_or_append_entity_attributes(
-            self,
-            entity_id: str,
-            entity_type: str,
-            attrs: List[Union[NamedContextAttribute,
-                              Dict[str, ContextAttribute]]],
-            append_strict: bool = False):
-        """
-        The request payload is an object representing the attributes to
-        append or update. This corresponds to a 'POST' request if append is
-        set to 'False'
-
-        Note:
-            Be careful not to update attributes that are
-            provided via context registration, e.g. commands. Commands are
-            removed before sending the request. To avoid breaking things.
-
-        Args:
-            entity_id: Entity id to be updated
-            entity_type: Entity type, to avoid ambiguity in case there are
-                several entities with the same entity id.
-            attrs: List of attributes to update or to append
-            append_strict: If `False` the entity attributes are updated (if they
-                previously exist) or appended (if they don't previously exist)
-                with the ones in the payload.
-                If `True` all the attributes in the payload not
-                previously existing in the entity are appended. In addition
-                to that, in case some of the attributes in the payload
-                already exist in the entity, an error is returned.
-                More precisely this means a strict append procedure.
-
-        Returns:
-            None
-
-        """
-        url = urljoin(self.base_url, f'v2/entities/{entity_id}/attrs')
-        headers = self.headers.copy()
-        params = {}
-        if entity_type:
-            params.update({'type': entity_type})
-        if append_strict:
-            params.update({'options': 'append'})
-
-        entity = ContextEntity(id=entity_id,
-                               type=entity_type)
-        entity.add_attributes(attrs)
-        # exclude commands from the send data,
-        # as they live in the IoTA-agent
-        excluded_keys = {'id', 'type'}
-        excluded_keys.update(
-            entity.get_commands(response_format=PropertyFormat.DICT).keys())
-        try:
-            res = self.post(url=url,
-                            headers=headers,
-                            json=entity.model_dump(exclude=excluded_keys,
-                                                   exclude_unset=True,
-                                                   exclude_none=True),
-                            params=params)
-            if res.ok:
-                self.logger.info("Entity '%s' successfully "
-                                 "updated!", entity.id)
-            else:
-                res.raise_for_status()
-        except requests.RequestException as err:
-            msg = f"Could not update or append attributes of entity" \
-                  f" {entity.id} !"
-            self.log_error(err=err, msg=msg)
-            raise
-
-    def update_existing_entity_attributes(
-            self,
-            entity_id: str,
-            entity_type: str,
-            attrs: List[Union[NamedContextAttribute,
-                              Dict[str, ContextAttribute]]]):
-        """
-        The entity attributes are updated with the ones in the payload.
-        In addition to that, if one or more attributes in the payload doesn't
-        exist in the entity, an error is returned. This corresponds to a
-        'PATcH' request.
-
-        Args:
-            entity_id: Entity id to be updated
-            entity_type: Entity type, to avoid ambiguity in case there are
-                several entities with the same entity id.
-            attrs: List of attributes to update or to append
-
-        Returns:
-            None
-
-        """
-        url = urljoin(self.base_url, f'v2/entities/{entity_id}/attrs')
-        headers = self.headers.copy()
-        params = {"type": entity_type}
-
-        entity = ContextEntity(id=entity_id,
-                               type=entity_type)
-        entity.add_attributes(attrs)
-
-        try:
-            res = self.patch(url=url,
-                             headers=headers,
-                             json=entity.model_dump(exclude={'id', 'type'},
-                                                    exclude_unset=True,
-                                                    exclude_none=True),
-                             params=params)
-            if res.ok:
-                self.logger.info("Entity '%s' successfully "
-                                 "updated!", entity.id)
-            else:
-                res.raise_for_status()
-        except requests.RequestException as err:
-            msg = f"Could not update attributes of entity" \
-                  f" {entity.id} !"
-            self.log_error(err=err, msg=msg)
-            raise
-
-    def replace_entity_attributes(
-            self,
-            entity_id: str,
-            entity_type: str,
-            attrs: List[Union[NamedContextAttribute,
-                              Dict[str, ContextAttribute]]]):
-        """
-        The attributes previously existing in the entity are removed and
-        replaced by the ones in the request. This corresponds to a 'PUT'
-        request.
-
-        Args:
-            entity_id: Entity id to be updated
-            entity_type: Entity type, to avoid ambiguity in case there are
-                several entities with the same entity id.
-            attrs: List of attributes to add to the entity
-        Returns:
-            None
-        """
-        url = urljoin(self.base_url, f'v2/entities/{entity_id}/attrs')
-        headers = self.headers.copy()
-        params = {}
-        if entity_type:
-            params.update({'type': entity_type})
-
-        entity = ContextEntity(id=entity_id,
-                               type=entity_type)
-        entity.add_attributes(attrs)
-
-        try:
-            res = self.put(url=url,
-                           headers=headers,
-                           json=entity.model_dump(exclude={'id', 'type'},
-                                                  exclude_unset=True,
-                                                  exclude_none=True),
-                           params=params)
-            if res.ok:
-                self.logger.info("Entity '%s' successfully "
-                                 "updated!", entity.id)
-            else:
-                res.raise_for_status()
-        except requests.RequestException as err:
-            msg = f"Could not replace attribute of entity {entity.id} !"
-            self.log_error(err=err, msg=msg)
-            raise
-
-    # Attribute operations
-    def get_attribute(self,
-                      entity_id: str,
-                      attr_name: str,
-                      entity_type: str = None,
-                      metadata: str = None,
-                      response_format='') -> ContextAttribute:
-        """
-        Retrieves a specified attribute from an entity.
-
-        Args:
-            entity_id: Id of the entity. Example: Bcn_Welt
-            attr_name: Name of the attribute to be retrieved.
-            entity_type (Optional): Type of the entity to retrieve
-            metadata (Optional): A list of metadata names to include in the
-                response. See "Filtering out attributes and metadata" section
-                for more detail.
-
-        Returns:
-            The content of the retrieved attribute as ContextAttribute
-
-        Raises:
-            Error
-
-        """
-        url = urljoin(self.base_url,
-                      f'v2/entities/{entity_id}/attrs/{attr_name}')
-        headers = self.headers.copy()
-        params = {}
-        if entity_type:
-            params.update({'type': entity_type})
-        if metadata:
-            params.update({'metadata': ','.join(metadata)})
-        try:
-            res = self.get(url=url, params=params, headers=headers)
-            if res.ok:
-                self.logger.debug('Received: %s', res.json())
-                return ContextAttribute(**res.json())
-            res.raise_for_status()
-        except requests.RequestException as err:
-            msg = f"Could not load attribute '{attr_name}' from entity" \
-                  f"'{entity_id}' "
-            self.log_error(err=err, msg=msg)
-            raise
-
-    def update_entity_attribute(self,
-                                entity_id: str,
-                                attr: Union[ContextAttribute,
-                                            NamedContextAttribute],
-                                *,
-                                entity_type: str = None,
-                                attr_name: str = None,
-                                override_metadata: bool = True):
-        """
-        Updates a specified attribute from an entity.
-
-        Args:
-            attr:
-                context attribute to update
-            entity_id:
-                Id of the entity. Example: Bcn_Welt
-            entity_type:
-                Entity type, to avoid ambiguity in case there are
-                several entities with the same entity id.
-            override_metadata:
-                Bool, if set to `True` (default) the metadata will be
-                overwritten. This is for backwards compatibility reasons.
-                If `False` the metadata values will be either updated if
-                already existing or append if not.
-                See also:
-                https://fiware-orion.readthedocs.io/en/master/user/metadata.html
-
-        """
-        headers = self.headers.copy()
-        if not isinstance(attr, NamedContextAttribute):
-            assert attr_name is not None, "Missing name for attribute. " \
-                                          "attr_name must be present if" \
-                                          "attr is of type ContextAttribute"
-        else:
-            assert attr_name is None, "Invalid argument attr_name. Do not set " \
-                                      "attr_name if attr is of type " \
-                                      "NamedContextAttribute"
-            attr_name = attr.name
-
-        url = urljoin(self.base_url,
-                      f'v2/entities/{entity_id}/attrs/{attr_name}')
-        params = {}
-        if entity_type:
-            params.update({'type': entity_type})
-        # set overrideMetadata option (we assure backwards compatibility here)
-        if override_metadata:
-            params.update({'options': 'overrideMetadata'})
-        try:
-            res = self.put(url=url,
-                           headers=headers,
-                           params=params,
-                           json=attr.model_dump(exclude={'name'},
-                                                exclude_unset=True,
-                                                exclude_none=True))
-            if res.ok:
-                self.logger.info("Attribute '%s' of '%s' "
-                                 "successfully updated!", attr_name, entity_id)
-            else:
-                res.raise_for_status()
-        except requests.RequestException as err:
-            msg = f"Could not update attribute '{attr_name}' of entity" \
-                  f"'{entity_id}' "
-            self.log_error(err=err, msg=msg)
-            raise
-
-    def delete_entity_attribute(self,
-                                entity_id: str,
-                                attr_name: str,
-                                entity_type: str = None) -> None:
-        """
-        Removes a specified attribute from an entity.
-
-        Args:
-            entity_id: Id of the entity.
-            attr_name: Name of the attribute to be retrieved.
-            entity_type: Entity type, to avoid ambiguity in case there are
-            several entities with the same entity id.
-        Raises:
-            Error
-
-        """
-        url = urljoin(self.base_url,
-                      f'v2/entities/{entity_id}/attrs/{attr_name}')
-        headers = self.headers.copy()
-        params = {}
-        if entity_type:
-            params.update({'type': entity_type})
-        try:
-            res = self.delete(url=url, headers=headers)
-            if res.ok:
-                self.logger.info("Attribute '%s' of '%s' "
-                                 "successfully deleted!", attr_name, entity_id)
-            else:
-                res.raise_for_status()
-        except requests.RequestException as err:
-            msg = f"Could not delete attribute '{attr_name}' of entity" \
-                  f"'{entity_id}' "
-            self.log_error(err=err, msg=msg)
-            raise
-
-    # Attribute value operations
-    def get_attribute_value(self,
-                            entity_id: str,
-                            attr_name: str,
-                            entity_type: str = None) -> Any:
-        """
-        This operation returns the value property with the value of the
-        attribute.
-
-        Args:
-            entity_id: Id of the entity. Example: Bcn_Welt
-            attr_name: Name of the attribute to be retrieved.
-                Example: temperature.
-            entity_type: Entity type, to avoid ambiguity in case there are
-                several entities with the same entity id.
-
-        Returns:
-
-        """
-        url = urljoin(self.base_url,
-                      f'v2/entities/{entity_id}/attrs/{attr_name}/value')
-        headers = self.headers.copy()
-        params = {}
-        if entity_type:
-            params.update({'type': entity_type})
-        try:
-            res = self.get(url=url, params=params, headers=headers)
-            if res.ok:
-                self.logger.debug('Received: %s', res.json())
-                return res.json()
-            res.raise_for_status()
-        except requests.RequestException as err:
-            msg = f"Could not load value of attribute '{attr_name}' from " \
-                  f"entity'{entity_id}' "
-            self.log_error(err=err, msg=msg)
-            raise
-
-    def update_attribute_value(self, *,
-                               entity_id: str,
-                               attr_name: str,
-                               value: Any,
-                               entity_type: str = None):
-        """
-        Updates the value of a specified attribute of an entity
-
-        Args:
-            value: update value
-            entity_id: Id of the entity. Example: Bcn_Welt
-            attr_name: Name of the attribute to be retrieved.
-                Example: temperature.
-            entity_type: Entity type, to avoid ambiguity in case there are
-                several entities with the same entity id.
-        Returns:
-
-        """
-        url = urljoin(self.base_url,
-                      f'v2/entities/{entity_id}/attrs/{attr_name}/value')
-        headers = self.headers.copy()
-        params = {}
-        if entity_type:
-            params.update({'type': entity_type})
-        try:
-            if not isinstance(value, (dict, list)):
-                headers.update({'Content-Type': 'text/plain'})
-                if isinstance(value, str):
-                    value = f'{value}'
-                res = self.put(url=url,
-                               headers=headers,
-                               json=value,
-                               params=params)
-            else:
-                res = self.put(url=url,
-                               headers=headers,
-                               json=value,
-                               params=params)
-            if res.ok:
-                self.logger.info("Attribute '%s' of '%s' "
-                                 "successfully updated!", attr_name, entity_id)
-            else:
-                res.raise_for_status()
-        except requests.RequestException as err:
-            msg = f"Could not update value of attribute '{attr_name}' from " \
-                  f"entity '{entity_id}' "
-            self.log_error(err=err, msg=msg)
-            raise
-
-    # Types Operations
-    def get_entity_types(self,
-                         *,
-                         limit: int = None,
-                         offset: int = None,
-                         options: str = None) -> List[Dict[str, Any]]:
-        """
-
-        Args:
-            limit: Limit the number of types to be retrieved.
-            offset: Skip a number of records.
-            options: Options dictionary. Allowed: count, values
-
-        Returns:
-
-        """
-        url = urljoin(self.base_url, 'v2/types')
-        headers = self.headers.copy()
-        params = {}
-        if limit:
-            params.update({'limit': limit})
-        if offset:
-            params.update({'offset': offset})
-        if options:
-            params.update({'options': options})
-        try:
-            res = self.get(url=url, params=params, headers=headers)
-            if res.ok:
-                self.logger.debug('Received: %s', res.json())
-                return res.json()
-            res.raise_for_status()
-        except requests.RequestException as err:
-            msg = "Could not load entity types!"
-            self.log_error(err=err, msg=msg)
-            raise
-
-    def get_entity_type(self, entity_type: str) -> Dict[str, Any]:
-        """
-
-        Args:
-            entity_type: Entity Type. Example: Room
-
-        Returns:
-
-        """
-        url = urljoin(self.base_url, f'v2/types/{entity_type}')
-        headers = self.headers.copy()
-        params = {}
-        try:
-            res = self.get(url=url, params=params, headers=headers)
-            if res.ok:
-                self.logger.debug('Received: %s', res.json())
-                return res.json()
-            res.raise_for_status()
-        except requests.RequestException as err:
-            msg = f"Could not load entities of type" \
-                  f"'{entity_type}' "
-            self.log_error(err=err, msg=msg)
-            raise
-
-    # SUBSCRIPTION API ENDPOINTS
-    def get_subscription_list(self,
-                              limit: PositiveInt = inf) -> List[Subscription]:
-        """
-        Returns a list of all the subscriptions present in the system.
-        Args:
-            limit: Limit the number of subscriptions to be retrieved
-        Returns:
-            list of subscriptions
-        """
-        url = urljoin(self.base_url, 'v2/subscriptions/')
-        headers = self.headers.copy()
-        params = {}
-
-        # We always use the 'count' option to check weather pagination is
-        # required
-        params.update({'options': 'count'})
-        try:
-            items = self.__pagination(limit=limit,
-                                      url=url,
-                                      params=params,
-                                      headers=headers)
-            adapter = TypeAdapter(List[Subscription])
-            return adapter.validate_python(items)
-        except requests.RequestException as err:
-            msg = "Could not load subscriptions!"
-            self.log_error(err=err, msg=msg)
-            raise
-
-    def post_subscription(self,
-                          subscription: Subscription,
-                          update: bool = False,
-                          skip_initial_notification: bool = False) -> str:
-        """
-        Creates a new subscription. The subscription is represented by a
-        Subscription object defined in filip.cb.models.
-
-        If the subscription already exists, the adding is prevented and the id
-        of the existing subscription is returned.
-
-        A subscription is deemed as already existing if there exists a
-        subscription with the exact same subject and notification fields. All
-        optional fields are not considered.
-
-        Args:
-            subscription: Subscription
-            update: True - If the subscription already exists, update it
-                    False- If the subscription already exists, throw warning
-            skip_initial_notification: True - Initial Notifications will be
-                send to recipient containing the whole data. This is
-                deprecated and removed from version 3.0 of the context broker.
-                False - skip the initial notification
-        Returns:
-            str: Id of the (created) subscription
-
-        """
-        existing_subscriptions = self.get_subscription_list()
-
-        sub_hash = subscription.model_dump_json(include={'subject', 'notification'})
-        for ex_sub in existing_subscriptions:
-            if sub_hash == ex_sub.model_dump_json(include={'subject', 'notification'}):
-                self.logger.info("Subscription already exists")
-                if update:
-                    self.logger.info("Updated subscription")
-                    subscription.id = ex_sub.id
-                    self.update_subscription(subscription)
-                else:
-                    warnings.warn(f"Subscription existed already with the id"
-                                  f" {ex_sub.id}")
-                return ex_sub.id
-
-        params = {}
-        if skip_initial_notification:
-            version = self.get_version()['orion']['version']
-            if parse_version(version) <= parse_version('3.1'):
-                params.update({'options': "skipInitialNotification"})
-            else:
-                pass
-            warnings.warn(f"Skip initial notifications is a deprecated "
-                          f"feature of older versions <=3.1 of the context "
-                          f"broker. The Context Broker that you requesting has "
-                          f"version: {version}. For newer versions we "
-                          f"automatically skip this option. Consider "
-                          f"refactoring and updating your services",
-                          DeprecationWarning)
-
-        url = urljoin(self.base_url, 'v2/subscriptions')
-        headers = self.headers.copy()
-        headers.update({'Content-Type': 'application/json'})
-        try:
-            res = self.post(
-                url=url,
-                headers=headers,
-                data=subscription.model_dump_json(exclude={'id'},
-                                                  exclude_unset=True,
-                                                  exclude_defaults=True,
-                                                  exclude_none=True),
-                params=params)
-            if res.ok:
-                self.logger.info("Subscription successfully created!")
-                return res.headers['Location'].split('/')[-1]
-            res.raise_for_status()
-        except requests.RequestException as err:
-            msg = "Could not send subscription!"
-            self.log_error(err=err, msg=msg)
-            raise
-
-    def get_subscription(self, subscription_id: str) -> Subscription:
-        """
-        Retrieves a subscription from
-        Args:
-            subscription_id: id of the subscription
-
-        Returns:
-
-        """
-        url = urljoin(self.base_url, f'v2/subscriptions/{subscription_id}')
-        headers = self.headers.copy()
-        try:
-            res = self.get(url=url, headers=headers)
-            if res.ok:
-                self.logger.debug('Received: %s', res.json())
-                return Subscription(**res.json())
-            res.raise_for_status()
-        except requests.RequestException as err:
-            msg = f"Could not load subscription {subscription_id}"
-            self.log_error(err=err, msg=msg)
-            raise
-
-    def update_subscription(self,
-                            subscription: Subscription,
-                            skip_initial_notification: bool = False):
-        """
-        Only the fields included in the request are updated in the subscription.
-
-        Args:
-            subscription: Subscription to update
-            skip_initial_notification: True - Initial Notifications will be
-                send to recipient containing the whole data. This is
-                deprecated and removed from version 3.0 of the context broker.
-                False - skip the initial notification
-
-        Returns:
-            None
-        """
-        params = {}
-        if skip_initial_notification:
-            version = self.get_version()['orion']['version']
-            if parse_version(version) <= parse_version('3.1'):
-                params.update({'options': "skipInitialNotification"})
-            else:
-                pass
-            warnings.warn(f"Skip initial notifications is a deprecated "
-                          f"feature of older versions <3.1 of the context "
-                          f"broker. The Context Broker that you requesting has "
-                          f"version: {version}. For newer versions we "
-                          f"automatically skip this option. Consider "
-                          f"refactoring and updating your services",
-                          DeprecationWarning)
-
-        url = urljoin(self.base_url, f'v2/subscriptions/{subscription.id}')
-        headers = self.headers.copy()
-        headers.update({'Content-Type': 'application/json'})
-        try:
-            res = self.patch(
-                url=url,
-                headers=headers,
-                data=subscription.model_dump_json(exclude={'id'},
-                                                  exclude_unset=True,
-                                                  exclude_defaults=False,
-                                                  exclude_none=True))
-            if res.ok:
-                self.logger.info("Subscription successfully updated!")
-            else:
-                res.raise_for_status()
-        except requests.RequestException as err:
-            msg = f"Could not update subscription {subscription.id}"
-            self.log_error(err=err, msg=msg)
-            raise
-
-    def delete_subscription(self, subscription_id: str) -> None:
-        """
-        Deletes a subscription from a Context Broker
-        Args:
-            subscription_id: id of the subscription
-        """
-        url = urljoin(self.base_url,
-                      f'v2/subscriptions/{subscription_id}')
-        headers = self.headers.copy()
-        try:
-            res = self.delete(url=url, headers=headers)
-            if res.ok:
-                self.logger.info(f"Subscription '{subscription_id}' "
-                                 f"successfully deleted!")
-            else:
-                res.raise_for_status()
-        except requests.RequestException as err:
-            msg = f"Could not delete subscription {subscription_id}"
-            self.log_error(err=err, msg=msg)
-            raise
-
-    # Registration API
-    def get_registration_list(self,
-                              *,
-                              limit: PositiveInt = None) -> List[Registration]:
-        """
-        Lists all the context provider registrations present in the system.
-
-        Args:
-            limit: Limit the number of registrations to be retrieved
-        Returns:
-
-        """
-        url = urljoin(self.base_url, 'v2/registrations/')
-        headers = self.headers.copy()
-        params = {}
-
-        # We always use the 'count' option to check weather pagination is
-        # required
-        params.update({'options': 'count'})
-        try:
-            items = self.__pagination(limit=limit,
-                                      url=url,
-                                      params=params,
-                                      headers=headers)
-            adapter = TypeAdapter(List[Registration])
-            return adapter.validate_python(items)
-        except requests.RequestException as err:
-            msg = "Could not load registrations!"
-            self.log_error(err=err, msg=msg)
-            raise
-
-    def post_registration(self, registration: Registration):
-        """
-        Creates a new context provider registration. This is typically used
-        for binding context sources as providers of certain data. The
-        registration is represented by cb.models.Registration
-
-        Args:
-            registration (Registration):
-
-        Returns:
-
-        """
-        url = urljoin(self.base_url, 'v2/registrations')
-        headers = self.headers.copy()
-        headers.update({'Content-Type': 'application/json'})
-        try:
-            res = self.post(
-                url=url,
-                headers=headers,
-                data=registration.model_dump_json(exclude={'id'},
-                                                  exclude_unset=True,
-                                                  exclude_defaults=True,
-                                                  exclude_none=True))
-            if res.ok:
-                self.logger.info("Registration successfully created!")
-                return res.headers['Location'].split('/')[-1]
-            res.raise_for_status()
-        except requests.RequestException as err:
-            msg = f"Could not send registration {registration.id} !"
-            self.log_error(err=err, msg=msg)
-            raise
-
-    def get_registration(self, registration_id: str) -> Registration:
-        """
-        Retrieves a registration from context broker by id
-
-        Args:
-            registration_id: id of the registration
-
-        Returns:
-            Registration
-        """
-        url = urljoin(self.base_url, f'v2/registrations/{registration_id}')
-        headers = self.headers.copy()
-        try:
-            res = self.get(url=url, headers=headers)
-            if res.ok:
-                self.logger.debug('Received: %s', res.json())
-                return Registration(**res.json())
-            res.raise_for_status()
-        except requests.RequestException as err:
-            msg = f"Could not load registration {registration_id} !"
-            self.log_error(err=err, msg=msg)
-            raise
-
-    def update_registration(self, registration: Registration):
-        """
-        Only the fields included in the request are updated in the registration.
-
-        Args:
-            registration: Registration to update
-        Returns:
-
-        """
-        url = urljoin(self.base_url, f'v2/registrations/{registration.id}')
-        headers = self.headers.copy()
-        headers.update({'Content-Type': 'application/json'})
-        try:
-            res = self.patch(
-                url=url,
-                headers=headers,
-                data=registration.model_dump_json(exclude={'id'},
-                                                  exclude_unset=True,
-                                                  exclude_defaults=True,
-                                                  exclude_none=True))
-            if res.ok:
-                self.logger.info("Registration successfully updated!")
-            else:
-                res.raise_for_status()
-        except requests.RequestException as err:
-            msg = f"Could not update registration {registration.id} !"
-            self.log_error(err=err, msg=msg)
-            raise
-
-    def delete_registration(self, registration_id: str) -> None:
-        """
-        Deletes a subscription from a Context Broker
-        Args:
-            registration_id: id of the subscription
-        """
-        url = urljoin(self.base_url,
-                      f'v2/registrations/{registration_id}')
-        headers = self.headers.copy()
-        try:
-            res = self.delete(url=url, headers=headers)
-            if res.ok:
-                self.logger.info("Registration '%s' "
-                                 "successfully deleted!", registration_id)
-            res.raise_for_status()
-        except requests.RequestException as err:
-            msg = f"Could not delete registration {registration_id} !"
-            self.log_error(err=err, msg=msg)
-            raise
-
-    # Batch operation API
-    def update(self,
-               *,
-               entities: List[ContextEntity],
-               action_type: Union[ActionType, str],
-               update_format: str = None) -> None:
-        """
-        This operation allows to create, update and/or delete several entities
-        in a single batch operation.
-
-        This operation is split in as many individual operations as entities
-        in the entities vector, so the actionType is executed for each one of
-        them. Depending on the actionType, a mapping with regular non-batch
-        operations can be done:
-
-        append: maps to POST /v2/entities (if the entity does not already exist)
-        or POST /v2/entities/<id>/attrs (if the entity already exists).
-
-        appendStrict: maps to POST /v2/entities (if the entity does not
-        already exist) or POST /v2/entities/<id>/attrs?options=append (if the
-        entity already exists).
-
-        update: maps to PATCH /v2/entities/<id>/attrs.
-
-        delete: maps to DELETE /v2/entities/<id>/attrs/<attrName> on every
-            attribute included in the entity or to DELETE /v2/entities/<id> if
-            no attribute were included in the entity.
-
-        replace: maps to PUT /v2/entities/<id>/attrs.
-
-        Args:
-            entities: "an array of entities, each entity specified using the "
-                      "JSON entity representation format "
-            action_type (Update): "actionType, to specify the kind of update
-                    action to do: either append, appendStrict, update, delete,
-                    or replace. "
-            update_format (str): Optional 'keyValues'
-
-        Returns:
-
-        """
-
-        url = urljoin(self.base_url, 'v2/op/update')
-        headers = self.headers.copy()
-        headers.update({'Content-Type': 'application/json'})
-        params = {}
-        if update_format:
-            assert update_format == 'keyValues', \
-                "Only 'keyValues' is allowed as update format"
-            params.update({'options': 'keyValues'})
-        update = Update(actionType=action_type, entities=entities)
-        try:
-            res = self.post(
-                url=url,
-                headers=headers,
-                params=params,
-                json=update.model_dump(by_alias=True))
-            if res.ok:
-                self.logger.info("Update operation '%s' succeeded!",
-                                 action_type)
-            else:
-                res.raise_for_status()
-        except requests.RequestException as err:
-            msg = f"Update operation '{action_type}' failed!"
-            self.log_error(err=err, msg=msg)
-            raise
-
-    def query(self,
-              *,
-              query: Query,
-              limit: PositiveInt = None,
-              order_by: str = None,
-              response_format: Union[AttrsFormat, str] =
-              AttrsFormat.NORMALIZED) -> List[Any]:
-        """
-        Generate api query
-        Args:
-            query (Query):
-            limit (PositiveInt):
-            order_by (str):
-            response_format (AttrsFormat, str):
-        Returns:
-            The response payload is an Array containing one object per matching
-            entity, or an empty array [] if no entities are found. The entities
-            follow the JSON entity representation format (described in the
-            section "JSON Entity Representation").
-        """
-        url = urljoin(self.base_url, 'v2/op/query')
-        headers = self.headers.copy()
-        headers.update({'Content-Type': 'application/json'})
-        params = {'options': 'count'}
-
-        if response_format:
-            if response_format not in list(AttrsFormat):
-                raise ValueError(f'Value must be in {list(AttrsFormat)}')
-            params['options'] = ','.join([response_format, 'count'])
-        try:
-            items = self.__pagination(method=PaginationMethod.POST,
-                                      url=url,
-                                      headers=headers,
-                                      params=params,
-                                      data=query.model_dump_json(exclude_unset=True,
-                                                                 exclude_none=True),
-                                      limit=limit)
-            if response_format == AttrsFormat.NORMALIZED:
-                adapter = TypeAdapter(List[ContextEntity])
-                return adapter.validate_python(items)
-            if response_format == AttrsFormat.KEY_VALUES:
-                adapter = TypeAdapter(List[ContextEntityKeyValues])
-                return adapter.validate_python(items)
-            return items
-        except requests.RequestException as err:
-            msg = "Query operation failed!"
-            self.log_error(err=err, msg=msg)
-            raise
-
-    def notify(self, message: Message) -> None:
-        """
-        This operation is intended to consume a notification payload so that
-        all the entity data included by such notification is persisted,
-        overwriting if necessary. This operation is useful when one NGSIv2
-        endpoint is subscribed to another NGSIv2 endpoint (federation
-        scenarios). The request payload must be an NGSIv2 notification
-        payload. The behaviour must be exactly the same as 'update'
-        with 'action_type' equal to append.
-
-        Args:
-            message: Notification message
-
-        Returns:
-            None
-        """
-        url = urljoin(self.base_url, 'v2/op/notify')
-        headers = self.headers.copy()
-        headers.update({'Content-Type': 'application/json'})
-        params = {}
-        try:
-            res = self.post(
-                url=url,
-                headers=headers,
-                params=params,
-                data=message.model_dump_json(by_alias=True))
-            if res.ok:
-                self.logger.info("Notification message sent!")
-            else:
-                res.raise_for_status()
-        except requests.RequestException as err:
-            msg = f"Sending notifcation message failed! \n " \
-                  f"{message.model_dump_json(inent=2)}"
-            self.log_error(err=err, msg=msg)
-            raise
-
-    def post_command(self,
-                     *,
-                     entity_id: str,
-                     entity_type: str,
-                     command: Union[Command, NamedCommand, Dict],
-                     command_name: str = None) -> None:
-        """
-        Post a command to a context entity this corresponds to 'PATCH' of the
-        specified command attribute.
-
-        Args:
-            entity_id: Entity identifier
-            command: Command
-            entity_type: Entity type
-            command_name: Name of the command in the entity
-
-        Returns:
-            None
-        """
-        if command_name:
-            assert isinstance(command, (Command, dict))
-            if isinstance(command, dict):
-                command = Command(**command)
-            command = {command_name: command.model_dump()}
-        else:
-            assert isinstance(command, (NamedCommand, dict))
-            if isinstance(command, dict):
-                command = NamedCommand(**command)
-
-        self.update_existing_entity_attributes(entity_id=entity_id,
-                                               entity_type=entity_type,
-                                               attrs=[command])
-
-    def does_entity_exist(self,
-                          entity_id: str,
-                          entity_type: str) -> bool:
-        """
-        Test if an entity with given id and type is present in the CB
-
-        Args:
-            entity_id: Entity id
-            entity_type: Entity type
-
-        Returns:
-            bool; True if entity exists
-
-        Raises:
-            RequestException, if any error occurs (e.g: No Connection),
-            except that the entity is not found
-        """
-        url = urljoin(self.base_url, f'v2/entities/{entity_id}')
-        headers = self.headers.copy()
-        params = {'type': entity_type}
-
-        try:
-            res = self.get(url=url, params=params, headers=headers)
-            if res.ok:
-                return True
-            res.raise_for_status()
-        except requests.RequestException as err:
-            if err.response is None or not err.response.status_code == 404:
-                raise
-            return False
-
-    def patch_entity(self,
-                     entity: ContextEntity,
-                     old_entity: Optional[ContextEntity] = None,
-                     override_attr_metadata: bool = True) -> None:
-        """
-        Takes a given entity and updates the state in the CB to match it.
-        It is an extended equivalent to the HTTP method PATCH, which applies
-        partial modifications to a resource.
-
-        Args:
-            entity: Entity to update
-            old_entity: OPTIONAL, if given only the differences between the
-                       old_entity and entity are updated in the CB.
-                       Other changes made to the entity in CB, can be kept.
-                       If type or id was changed, the old_entity will be
-                       deleted.
-            override_attr_metadata:
-                Whether to override or append the attributes metadata.
-                `True` for overwrite or `False` for update/append
-
-        Returns:
-           None
-        """
-
-        new_entity = entity
-
-        if old_entity is None:
-            # If no old entity_was provided we use the current state to compare
-            # the entity to
-            if self.does_entity_exist(entity_id=new_entity.id,
-                                      entity_type=new_entity.type):
-                old_entity = self.get_entity(entity_id=new_entity.id,
-                                             entity_type=new_entity.type)
-            else:
-                # the entity is new, post and finish
-                self.post_entity(new_entity, update=False)
-                return
-
-        else:
-            # An old_entity was provided
-            # check if the old_entity (still) exists else recall methode
-            # and discard old_entity
-            if not self.does_entity_exist(entity_id=old_entity.id,
-                                          entity_type=old_entity.type):
-                self.patch_entity(new_entity,
-                                  override_attr_metadata=override_attr_metadata)
-                return
-
-            # if type or id was changed, the old_entity needs to be deleted
-            # and the new_entity created
-            # In this case we will lose the current state of the entity
-            if old_entity.id != new_entity.id or \
-                    old_entity.type != new_entity.type:
-                self.delete_entity(entity_id=old_entity.id,
-                                   entity_type=old_entity.type)
-
-                if not self.does_entity_exist(entity_id=new_entity.id,
-                                              entity_type=new_entity.type):
-                    self.post_entity(entity=new_entity, update=False)
-                    return
-
-        # At this point we know that we need to patch only the attributes of
-        # the entity
-        # Check the differences between the attributes of old and new entity
-        # Delete the removed attributes, create the new ones,
-        # and update the existing if necessary
-        old_attributes = old_entity.get_attributes()
-        new_attributes = new_entity.get_attributes()
-
-        # Manage attributes that existed before
-        for old_attr in old_attributes:
-            # commands do not exist in the ContextEntity and are only
-            # registrations to the corresponding device. Operations as
-            # delete will fail as it does not technically exists
-            corresponding_new_attr = None
-            for new_attr in new_attributes:
-                if new_attr.name == old_attr.name:
-                    corresponding_new_attr = new_attr
-
-            if corresponding_new_attr is None:
-                # Attribute no longer exists, delete it
-                try:
-                    self.delete_entity_attribute(entity_id=new_entity.id,
-                                                 entity_type=new_entity.type,
-                                                 attr_name=old_attr.name)
-                except requests.RequestException as err:
-                    # if the attribute is provided by a registration the
-                    # deletion will fail
-                    if not err.response.status_code == 404:
-                        raise
-            else:
-                # Check if attributed changed in any way, if yes update
-                # else do nothing and keep current state
-                if old_attr != corresponding_new_attr:
-                    try:
-                        self.update_entity_attribute(
-                            entity_id=new_entity.id,
-                            entity_type=new_entity.type,
-                            attr=corresponding_new_attr,
-                            override_metadata=override_attr_metadata
-                        )
-                    except requests.RequestException as err:
-                        # if the attribute is provided by a registration the
-                        # update will fail
-                        if not err.response.status_code == 404:
-                            raise
-
-        # Create new attributes
-        update_entity = ContextEntity(id=entity.id, type=entity.type)
-        update_needed = False
-        for new_attr in new_attributes:
-            # commands do not exist in the ContextEntity and are only
-            # registrations to the corresponding device. Operations as
-            # delete will fail as it does not technically exists
-            attr_existed = False
-            for old_attr in old_attributes:
-                if new_attr.name == old_attr.name:
-                    attr_existed = True
-
-            if not attr_existed:
-                update_needed = True
-                update_entity.add_attributes([new_attr])
-
-        if update_needed:
-            self.update_entity(update_entity)
-
-#
-#
-#    def check_duplicate_subscription(self, subscription_body, limit: int = 20):
-#        """
-#        Function compares the subject of the subscription body, on whether a subscription
-#        already exists for a device / entity.
-#        :param subscription_body: the body of the new subscripton
-#        :param limit: pagination parameter, to set the number of
-#        subscriptions bodies the get request should grab
-#        :return: exists, boolean -> True, if such a subscription allready
-#        exists
-#        """
-#        exists = False
-#        subscription_subject = json.loads(subscription_body)["subject"]
-#        # Exact keys depend on subscription body
-#        try:
-#            subscription_url = json.loads(subscription_body)[
-#            "notification"]["httpCustom"]["url"]
-#        except KeyError:
-#            subscription_url = json.loads(subscription_body)[
-#            "notification"]["http"]["url"]
-#
-#        # If the number of subscriptions is larger then the limit,
-#        paginations methods have to be used
-#        url = self.url + '/v2/subscriptions?limit=' + str(limit) +
-#        '&options=count'
-#        response = self.session.get(url, headers=self.get_header())
-#
-#        sub_count = float(response.headers["Fiware-Total-Count"])
-#        response = json.loads(response.text)
-#        if sub_count >= limit:
-#            response = self.get_pagination(url=url, headers=self.get_header(),
-#                                           limit=limit, count=sub_count)
-#            response = json.loads(response)
-#
-#        for existing_subscription in response:
-#            # check whether the exact same subscriptions already exists
-#            if existing_subscription["subject"] == subscription_subject:
-#                exists = True
-#                break
-#            try:
-#                existing_url = existing_subscription["notification"][
-#                "http"]["url"]
-#            except KeyError:
-#                existing_url = existing_subscription["notification"][
-#                "httpCustom"]["url"]
-#            # check whether both subscriptions notify to the same path
-#            if existing_url != subscription_url:
-#                continue
-#            else:
-#                # iterate over all entities included in the subscription object
-#                for entity in subscription_subject["entities"]:
-#                    if 'type' in entity.keys():
-#                        subscription_type = entity['type']
-#                    else:
-#                        subscription_type = entity['typePattern']
-#                    if 'id' in entity.keys():
-#                        subscription_id = entity['id']
-#                    else:
-#                        subscription_id = entity["idPattern"]
-#                    # iterate over all entities included in the exisiting
-#                    subscriptions
-#                    for existing_entity in existing_subscription["subject"][
-#                    "entities"]:
-#                        if "type" in entity.keys():
-#                            type_existing = entity["type"]
-#                        else:
-#                            type_existing = entity["typePattern"]
-#                        if "id" in entity.keys():
-#                            id_existing = entity["id"]
-#                        else:
-#                            id_existing = entity["idPattern"]
-#                        # as the ID field is non optional, it has to match
-#                        # check whether the type match
-#                        # if the type field is empty, they match all types
-#                        if (type_existing == subscription_type) or\
-#                                ('*' in subscription_type) or \
-#                                ('*' in type_existing)\
-#                                or (type_existing == "") or (
-#                                subscription_type == ""):
-#                            # check if on of the subscriptions is a pattern,
-#                            or if they both refer to the same id
-#                            # Get the attrs first, to avoid code duplication
-#                            # last thing to compare is the attributes
-#                            # Assumption -> position is the same as the
-#                            entities _list
-#                            # i == j
-#                            i = subscription_subject["entities"].index(entity)
-#                            j = existing_subscription["subject"][
-#                            "entities"].index(existing_entity)
-#                            try:
-#                                subscription_attrs = subscription_subject[
-#                                "condition"]["attrs"][i]
-#                            except (KeyError, IndexError):
-#                                subscription_attrs = []
-#                            try:
-#                                existing_attrs = existing_subscription[
-#                                "subject"]["condition"]["attrs"][j]
-#                            except (KeyError, IndexError):
-#                                existing_attrs = []
-#
-#                            if (".*" in subscription_id) or ('.*' in
-#                            id_existing) or (subscription_id == id_existing):
-#                                # Attributes have to match, or the have to
-#                                be an empty array
-#                                if (subscription_attrs == existing_attrs) or
-#                                (subscription_attrs == []) or (existing_attrs == []):
-#                                        exists = True
-#                            # if they do not match completely or subscribe
-#                            to all ids they have to match up to a certain position
-#                            elif ("*" in subscription_id) or ('*' in
-#                            id_existing):
-#                                    regex_existing = id_existing.find('*')
-#                                    regex_subscription =
-#                                    subscription_id.find('*')
-#                                    # slice the strings to compare
-#                                    if (id_existing[:regex_existing] in
-#                                    subscription_id) or (subscription_id[:regex_subscription] in id_existing) or \
-#                                            (id_existing[regex_existing:] in
-#                                            subscription_id) or (subscription_id[regex_subscription:] in id_existing):
-#                                            if (subscription_attrs ==
-#                                            existing_attrs) or (subscription_attrs == []) or (existing_attrs == []):
-#                                                exists = True
-#                                            else:
-#                                                continue
-#                                    else:
-#                                        continue
-#                            else:
-#                                continue
-#                        else:
-#                            continue
-#                    else:
-#                        continue
-#        return exists
-#
+"""
+Context Broker Module for API Client
+"""
+from __future__ import annotations
+
+from copy import deepcopy
+from math import inf
+from pkg_resources import parse_version
+from pydantic import PositiveInt, PositiveFloat, AnyHttpUrl
+from pydantic.type_adapter import TypeAdapter
+from typing import Any, Dict, List, Optional, TYPE_CHECKING, Union
+import re
+import requests
+from urllib.parse import urljoin
+import warnings
+from filip.clients.base_http_client import BaseHttpClient
+from filip.config import settings
+from filip.models.base import FiwareHeader, PaginationMethod
+from filip.utils.simple_ql import QueryString
+from filip.models.ngsi_v2.context import (
+    ActionType,
+    Command,
+    ContextEntity,
+    ContextEntityKeyValues,
+    ContextAttribute,
+    NamedCommand,
+    NamedContextAttribute,
+    Query,
+    Update,
+    PropertyFormat,
+)
+from filip.models.ngsi_v2.base import AttrsFormat
+from filip.models.ngsi_v2.subscriptions import Subscription, Message
+from filip.models.ngsi_v2.registrations import Registration
+
+if TYPE_CHECKING:
+    from filip.clients.ngsi_v2.iota import IoTAClient
+
+
+class ContextBrokerClient(BaseHttpClient):
+    """
+    Implementation of NGSI Context Broker functionalities, such as creating
+    entities and subscriptions; retrieving, updating and deleting data.
+    Further documentation:
+    https://fiware-orion.readthedocs.io/en/master/
+
+    Api specifications for v2 are located here:
+    https://telefonicaid.github.io/fiware-orion/api/v2/stable/
+
+    Note:
+        We use the reference implementation for development. Therefore, some
+        other brokers may show slightly different behavior!
+    """
+
+    def __init__(
+        self,
+        url: str = None,
+        *,
+        session: requests.Session = None,
+        fiware_header: FiwareHeader = None,
+        **kwargs,
+    ):
+        """
+
+        Args:
+            url: Url of context broker server
+            session (requests.Session):
+            fiware_header (FiwareHeader): fiware service and fiware service path
+            **kwargs (Optional): Optional arguments that ``request`` takes.
+        """
+        # set service url
+        url = url or settings.CB_URL
+        super().__init__(
+            url=url, session=session, fiware_header=fiware_header, **kwargs
+        )
+
+    def __pagination(
+        self,
+        *,
+        method: PaginationMethod = PaginationMethod.GET,
+        url: str,
+        headers: Dict,
+        limit: Union[PositiveInt, PositiveFloat] = None,
+        params: Dict = None,
+        data: str = None,
+    ) -> List[Dict]:
+        """
+        NGSIv2 implements a pagination mechanism in order to help clients to
+        retrieve large sets of resources. This mechanism works for all listing
+        operations in the API (e.g. GET /v2/entities, GET /v2/subscriptions,
+        POST /v2/op/query, etc.). This function helps getting datasets that are
+        larger than the limit for the different GET operations.
+
+        https://fiware-orion.readthedocs.io/en/master/user/pagination/index.html
+
+        Args:
+            url: Information about the url, obtained from the original function
+            headers: The headers from the original function
+            params:
+            limit:
+
+        Returns:
+            object:
+
+        """
+        if limit is None:
+            limit = inf
+        if limit > 1000:
+            params["limit"] = 1000  # maximum items per request
+        else:
+            params["limit"] = limit
+
+        if self.session:
+            session = self.session
+        else:
+            session = requests.Session()
+        with session:
+            res = session.request(
+                method=method, url=url, params=params, headers=headers, data=data
+            )
+            if res.ok:
+                items = res.json()
+                # do pagination
+                count = int(res.headers["Fiware-Total-Count"])
+
+                while len(items) < limit and len(items) < count:
+                    # Establishing the offset from where entities are retrieved
+                    params["offset"] = len(items)
+                    params["limit"] = min(1000, (limit - len(items)))
+                    res = session.request(
+                        method=method,
+                        url=url,
+                        params=params,
+                        headers=headers,
+                        data=data,
+                    )
+                    if res.ok:
+                        items.extend(res.json())
+                    else:
+                        res.raise_for_status()
+                self.logger.debug("Received: %s", items)
+                return items
+            res.raise_for_status()
+
+    # MANAGEMENT API
+    def get_version(self) -> Dict:
+        """
+        Gets version of IoT Agent
+        Returns:
+            Dictionary with response
+        """
+        url = urljoin(self.base_url, "version")
+        try:
+            res = self.get(url=url, headers=self.headers)
+            if res.ok:
+                return res.json()
+            res.raise_for_status()
+        except requests.RequestException as err:
+            self.logger.error(err)
+            raise
+
+    def get_resources(self) -> Dict:
+        """
+        Gets reo
+
+        Returns:
+            Dict
+        """
+        url = urljoin(self.base_url, "v2")
+        try:
+            res = self.get(url=url, headers=self.headers)
+            if res.ok:
+                return res.json()
+            res.raise_for_status()
+        except requests.RequestException as err:
+            self.logger.error(err)
+            raise
+
+    # STATISTICS API
+    def get_statistics(self) -> Dict:
+        """
+        Gets statistics of context broker
+        Returns:
+            Dictionary with response
+        """
+        url = urljoin(self.base_url, "statistics")
+        try:
+            res = self.get(url=url, headers=self.headers)
+            if res.ok:
+                return res.json()
+            res.raise_for_status()
+        except requests.RequestException as err:
+            self.logger.error(err)
+            raise
+
+    # CONTEXT MANAGEMENT API ENDPOINTS
+    # Entity Operations
+    def post_entity(
+        self,
+        entity: ContextEntity,
+        update: bool = False,
+        patch: bool = False,
+        override_attr_metadata: bool = True,
+    ):
+        """
+        Function registers an Object with the NGSI Context Broker,
+        if it already exists it can be automatically updated (overwritten)
+        if the update bool is True.
+        First a post request with the entity is tried, if the response code
+        is 422 the entity is uncrossable, as it already exists there are two
+        options, either overwrite it, if the attribute have changed
+        (e.g. at least one new/new values) (update = True) or leave
+        it the way it is (update=False)
+        If you only want to manipulate the entities values, you need to set
+        patch argument.
+
+        Args:
+            entity (ContextEntity):
+                Context Entity Object
+            update (bool):
+                If the response.status_code is 422, whether the override and
+                existing entity
+            patch (bool):
+                If the response.status_code is 422, whether to manipulate the
+                existing entity. Omitted if update `True`.
+            override_attr_metadata:
+                Only applies for patch equal to `True`.
+                Whether to override or append the attribute's metadata.
+                `True` for overwrite or `False` for update/append
+
+        """
+        url = urljoin(self.base_url, "v2/entities")
+        headers = self.headers.copy()
+        try:
+            res = self.post(
+                url=url, headers=headers, json=entity.model_dump(exclude_none=True)
+            )
+            if res.ok:
+                self.logger.info("Entity successfully posted!")
+                return res.headers.get("Location")
+            res.raise_for_status()
+        except requests.RequestException as err:
+            if update and err.response.status_code == 422:
+                return self.override_entity(
+                    entity=entity)
+            if patch and err.response.status_code == 422:
+                return self.patch_entity(
+                    entity=entity, override_attr_metadata=override_attr_metadata
+                )
+            msg = f"Could not post entity {entity.id}"
+            self.log_error(err=err, msg=msg)
+            raise
+
+    def get_entity_list(
+        self,
+        *,
+        entity_ids: List[str] = None,
+        entity_types: List[str] = None,
+        id_pattern: str = None,
+        type_pattern: str = None,
+        q: Union[str, QueryString] = None,
+        mq: Union[str, QueryString] = None,
+        georel: str = None,
+        geometry: str = None,
+        coords: str = None,
+        limit: PositiveInt = inf,
+        attrs: List[str] = None,
+        metadata: str = None,
+        order_by: str = None,
+        response_format: Union[AttrsFormat, str] = AttrsFormat.NORMALIZED,
+    ) -> List[Union[ContextEntity, ContextEntityKeyValues, Dict[str, Any]]]:
+        r"""
+        Retrieves a list of context entities that match different criteria by
+        id, type, pattern matching (either id or type) and/or those which
+        match a query or geographical query (see Simple Query Language and
+        Geographical Queries). A given entity has to match all the criteria
+        to be retrieved (i.e., the criteria is combined in a logical AND
+        way). Note that pattern matching query parameters are incompatible
+        (i.e. mutually exclusive) with their corresponding exact matching
+        parameters, i.e. idPattern with id and typePattern with type.
+
+        Args:
+            entity_ids: A comma-separated list of elements. Retrieve entities
+                whose ID matches one of the elements in the list.
+                Incompatible with idPattern,e.g. Boe_Idarium
+            entity_types: comma-separated list of elements. Retrieve entities
+                whose type matches one of the elements in the list.
+                Incompatible with typePattern. Example: Room.
+            id_pattern: A correctly formatted regular expression. Retrieve
+                entities whose ID matches the regular expression. Incompatible
+                with id, e.g. ngsi-ld.* or sensor.*
+            type_pattern: A correctly formatted regular expression. Retrieve
+                entities whose type matches the regular expression.
+                Incompatible with type, e.g. room.*
+            q (SimpleQuery): A query expression, composed of a list of
+                statements separated by ;, i.e.,
+                q=statement1;statement2;statement3. See Simple Query
+                Language specification. Example: temperature>40.
+            mq (SimpleQuery): A  query expression for attribute metadata,
+                composed of a list of statements separated by ;, i.e.,
+                mq=statement1;statement2;statement3. See Simple Query
+                Language specification. Example: temperature.accuracy<0.9.
+            georel: Spatial relationship between matching entities and a
+                reference shape. See Geographical Queries. Example: 'near'.
+            geometry: Geographical area to which the query is restricted.
+                See Geographical Queries. Example: point.
+            coords: List of latitude-longitude pairs of coordinates separated
+                by ';'. See Geographical Queries. Example: 41.390205,
+                2.154007;48.8566,2.3522.
+            limit: Limits the number of entities to be retrieved Example: 20
+            attrs: Comma-separated list of attribute names whose data are to
+                be included in the response. The attributes are retrieved in
+                the order specified by this parameter. If this parameter is
+                not included, the attributes are retrieved in arbitrary
+                order. See "Filtering out attributes and metadata" section
+                for more detail. Example: seatNumber.
+            metadata: A list of metadata names to include in the response.
+                See "Filtering out attributes and metadata" section for more
+                detail. Example: accuracy.
+            order_by: Criteria for ordering results. See "Ordering Results"
+                section for details. Example: temperature,!speed.
+            response_format (AttrsFormat, str): Response Format. Note: That if
+                'keyValues' or 'values' are used the response model will
+                change to List[ContextEntityKeyValues] and to List[Dict[str,
+                Any]], respectively.
+        Returns:
+
+        """
+        url = urljoin(self.base_url, "v2/entities/")
+        headers = self.headers.copy()
+        params = {}
+
+        if entity_ids and id_pattern:
+            raise ValueError
+        if entity_types and type_pattern:
+            raise ValueError
+        if entity_ids:
+            if not isinstance(entity_ids, list):
+                entity_ids = [entity_ids]
+            params.update({"id": ",".join(entity_ids)})
+        if id_pattern:
+            try:
+                re.compile(id_pattern)
+            except re.error as err:
+                raise ValueError(f"Invalid Pattern: {err}") from err
+            params.update({"idPattern": id_pattern})
+        if entity_types:
+            if not isinstance(entity_types, list):
+                entity_types = [entity_types]
+            params.update({"type": ",".join(entity_types)})
+        if type_pattern:
+            try:
+                re.compile(type_pattern)
+            except re.error as err:
+                raise ValueError(f"Invalid Pattern: {err.msg}") from err
+            params.update({"typePattern": type_pattern})
+        if attrs:
+            params.update({"attrs": ",".join(attrs)})
+        if metadata:
+            params.update({"metadata": ",".join(metadata)})
+        if q:
+            if isinstance(q, str):
+                q = QueryString.parse_str(q)
+            params.update({"q": str(q)})
+        if mq:
+            params.update({"mq": str(mq)})
+        if geometry:
+            params.update({"geometry": geometry})
+        if georel:
+            params.update({"georel": georel})
+        if coords:
+            params.update({"coords": coords})
+        if order_by:
+            params.update({"orderBy": order_by})
+        if response_format not in list(AttrsFormat):
+            raise ValueError(f"Value must be in {list(AttrsFormat)}")
+        response_format = ",".join(["count", response_format])
+        params.update({"options": response_format})
+        try:
+            items = self.__pagination(
+                method=PaginationMethod.GET,
+                limit=limit,
+                url=url,
+                params=params,
+                headers=headers,
+            )
+            if AttrsFormat.NORMALIZED in response_format:
+                adapter = TypeAdapter(List[ContextEntity])
+                return adapter.validate_python(items)
+            if AttrsFormat.KEY_VALUES in response_format:
+                adapter = TypeAdapter(List[ContextEntityKeyValues])
+                return adapter.validate_python(items)
+            return items
+
+        except requests.RequestException as err:
+            msg = "Could not load entities"
+            self.log_error(err=err, msg=msg)
+            raise
+
+    def get_entity(
+        self,
+        entity_id: str,
+        entity_type: str = None,
+        attrs: List[str] = None,
+        metadata: List[str] = None,
+        response_format: Union[AttrsFormat, str] = AttrsFormat.NORMALIZED,
+    ) -> Union[ContextEntity, ContextEntityKeyValues, Dict[str, Any]]:
+        """
+        This operation must return one entity element only, but there may be
+        more than one entity with the same ID (e.g. entities with same ID but
+        different types). In such case, an error message is returned, with
+        the HTTP status code set to 409 Conflict.
+
+        Args:
+            entity_id (String): Id of the entity to be retrieved
+            entity_type (String): Entity type, to avoid ambiguity in case
+                there are several entities with the same entity id.
+            attrs (List of Strings): List of attribute names whose data must be
+                included in the response. The attributes are retrieved in the
+                order specified by this parameter.
+                See "Filtering out attributes and metadata" section for more
+                detail. If this parameter is not included, the attributes are
+                retrieved in arbitrary order, and all the attributes of the
+                entity are included in the response.
+                Example: temperature, humidity.
+            metadata (List of Strings): A list of metadata names to include in
+                the response. See "Filtering out attributes and metadata"
+                section for more detail. Example: accuracy.
+            response_format (AttrsFormat, str): Representation format of
+                response
+        Returns:
+            ContextEntity
+        """
+        url = urljoin(self.base_url, f"v2/entities/{entity_id}")
+        headers = self.headers.copy()
+        params = {}
+        if entity_type:
+            params.update({"type": entity_type})
+        if attrs:
+            params.update({"attrs": ",".join(attrs)})
+        if metadata:
+            params.update({"metadata": ",".join(metadata)})
+        if response_format not in list(AttrsFormat):
+            raise ValueError(f"Value must be in {list(AttrsFormat)}")
+        params.update({"options": response_format})
+
+        try:
+            res = self.get(url=url, params=params, headers=headers)
+            if res.ok:
+                self.logger.info("Entity successfully retrieved!")
+                self.logger.debug("Received: %s", res.json())
+                if response_format == AttrsFormat.NORMALIZED:
+                    return ContextEntity(**res.json())
+                if response_format == AttrsFormat.KEY_VALUES:
+                    return ContextEntityKeyValues(**res.json())
+                return res.json()
+            res.raise_for_status()
+        except requests.RequestException as err:
+            msg = f"Could not load entity {entity_id}"
+            self.log_error(err=err, msg=msg)
+            raise
+
+    def get_entity_attributes(
+        self,
+        entity_id: str,
+        entity_type: str = None,
+        attrs: List[str] = None,
+        metadata: List[str] = None,
+        response_format: Union[AttrsFormat, str] = AttrsFormat.NORMALIZED,
+    ) -> Dict[str, ContextAttribute]:
+        """
+        This request is similar to retrieving the whole entity, however this
+        one omits the id and type fields. Just like the general request of
+        getting an entire entity, this operation must return only one entity
+        element. If more than one entity with the same ID is found (e.g.
+        entities with same ID but different type), an error message is
+        returned, with the HTTP status code set to 409 Conflict.
+
+        Args:
+            entity_id (String): Id of the entity to be retrieved
+            entity_type (String): Entity type, to avoid ambiguity in case
+                there are several entities with the same entity id.
+            attrs (List of Strings): List of attribute names whose data must be
+                included in the response. The attributes are retrieved in the
+                order specified by this parameter.
+                See "Filtering out attributes and metadata" section for more
+                detail. If this parameter is not included, the attributes are
+                retrieved in arbitrary order, and all the attributes of the
+                entity are included in the response. Example: temperature,
+                humidity.
+            metadata (List of Strings): A list of metadata names to include in
+                the response. See "Filtering out attributes and metadata"
+                section for more detail. Example: accuracy.
+            response_format (AttrsFormat, str): Representation format of
+                response
+        Returns:
+            Dict
+        """
+        url = urljoin(self.base_url, f"v2/entities/{entity_id}/attrs")
+        headers = self.headers.copy()
+        params = {}
+        if entity_type:
+            params.update({"type": entity_type})
+        if attrs:
+            params.update({"attrs": ",".join(attrs)})
+        if metadata:
+            params.update({"metadata": ",".join(metadata)})
+        if response_format not in list(AttrsFormat):
+            raise ValueError(f"Value must be in {list(AttrsFormat)}")
+        params.update({"options": response_format})
+        try:
+            res = self.get(url=url, params=params, headers=headers)
+            if res.ok:
+                if response_format == AttrsFormat.NORMALIZED:
+                    return {
+                        key: ContextAttribute(**values)
+                        for key, values in res.json().items()
+                    }
+                return res.json()
+            res.raise_for_status()
+        except requests.RequestException as err:
+            msg = f"Could not load attributes from entity {entity_id} !"
+            self.log_error(err=err, msg=msg)
+            raise
+
+    def update_entity(self, entity: ContextEntity, append_strict: bool = False):
+        """
+        The request payload is an object representing the attributes to
+        append or update.
+
+        Note:
+            Update means overwriting the existing entity. If you want to
+            manipulate you should rather use patch_entity.
+
+        Args:
+            entity (ContextEntity):
+            append_strict: If `False` the entity attributes are updated (if they
+                previously exist) or appended (if they don't previously exist)
+                with the ones in the payload.
+                If `True` all the attributes in the payload not
+                previously existing in the entity are appended. In addition
+                to that, in case some of the attributes in the payload
+                already exist in the entity, an error is returned.
+                More precisely this means a strict append procedure.
+
+        Returns:
+            None
+        """
+        self.update_or_append_entity_attributes(
+            entity_id=entity.id,
+            entity_type=entity.type,
+            attrs=entity.get_properties(),
+            append_strict=append_strict,
+        )
+
+    def delete_entity(
+        self,
+        entity_id: str,
+        entity_type: str,
+        delete_devices: bool = False,
+        iota_client: IoTAClient = None,
+        iota_url: AnyHttpUrl = settings.IOTA_URL,
+    ) -> None:
+        """
+        Remove a entity from the context broker. No payload is required
+        or received.
+
+        Args:
+            entity_id:
+                Id of the entity to be deleted
+            entity_type:
+                several entities with the same entity id.
+            delete_devices:
+                If True, also delete all devices that reference this
+                entity (entity_id as entity_name)
+            iota_client:
+                Corresponding IoTA-Client used to access IoTA-Agent
+            iota_url:
+                URL of the corresponding IoT-Agent. This will autogenerate
+                an IoTA-Client, mirroring the information of the
+                ContextBrokerClient, e.g. FiwareHeader, and other headers
+
+        Returns:
+            None
+        """
+        url = urljoin(self.base_url, f"v2/entities/{entity_id}")
+        headers = self.headers.copy()
+        params = {"type": entity_type}
+
+        try:
+            res = self.delete(url=url, params=params, headers=headers)
+            if res.ok:
+                self.logger.info("Entity '%s' successfully deleted!", entity_id)
+            else:
+                res.raise_for_status()
+        except requests.RequestException as err:
+            msg = f"Could not delete entity {entity_id} !"
+            self.log_error(err=err, msg=msg)
+            raise
+
+        if delete_devices:
+            from filip.clients.ngsi_v2 import IoTAClient
+
+            if iota_client:
+                iota_client_local = deepcopy(iota_client)
+            else:
+                warnings.warn(
+                    "No IoTA-Client object provided! "
+                    "Will try to generate one. "
+                    "This usage is not recommended."
+                )
+
+                iota_client_local = IoTAClient(
+                    url=iota_url,
+                    fiware_header=self.fiware_headers,
+                    headers=self.headers,
+                )
+
+            for device in iota_client_local.get_device_list(entity_names=[entity_id]):
+                if device.entity_type == entity_type:
+                    iota_client_local.delete_device(device_id=device.device_id)
+
+            iota_client_local.close()
+
+    def delete_entities(self, entities: List[ContextEntity]) -> None:
+        """
+        Remove a list of entities from the context broker. This methode is
+        more efficient than to call delete_entity() for each entity
+
+        Args:
+            entities: List[ContextEntity]: List of entities to be deleted
+
+        Raises:
+            Exception, if one of the entities is not in the ContextBroker
+
+        Returns:
+            None
+        """
+
+        # update() delete, deletes all entities without attributes completely,
+        # and removes the attributes for the other
+        # The entities are sorted based on the fact if they have
+        # attributes.
+        entities_with_attributes: List[ContextEntity] = []
+        for entity in entities:
+            attribute_names = [
+                key
+                for key in entity.model_dump()
+                if key not in ContextEntity.model_fields
+            ]
+            if len(attribute_names) > 0:
+                entities_with_attributes.append(
+                    ContextEntity(id=entity.id, type=entity.type)
+                )
+
+        # Post update_delete for those without attribute only once,
+        # for the other post update_delete again but for the changed entity
+        # in the ContextBroker (only id and type left)
+        if len(entities) > 0:
+            self.update(entities=entities, action_type="delete")
+        if len(entities_with_attributes) > 0:
+            self.update(entities=entities_with_attributes, action_type="delete")
+
+    def update_or_append_entity_attributes(
+            self,
+            entity_id: str,
+            entity_type: str,
+            attrs: List[Union[NamedContextAttribute,
+                              Dict[str, ContextAttribute]]],
+            append_strict: bool = False,
+            forcedUpdate: bool = False):
+        """
+        The request payload is an object representing the attributes to
+        append or update. This corresponds to a 'POST' request if append is
+        set to 'False'
+
+        Note:
+            Be careful not to update attributes that are
+            provided via context registration, e.g. commands. Commands are
+            removed before sending the request. To avoid breaking things.
+
+        Args:
+            entity_id: Entity id to be updated
+            entity_type: Entity type, to avoid ambiguity in case there are
+                several entities with the same entity id.
+            attrs: List of attributes to update or to append
+            append_strict: If `False` the entity attributes are updated (if they
+                previously exist) or appended (if they don't previously exist)
+                with the ones in the payload.
+                If `True` all the attributes in the payload not
+                previously existing in the entity are appended. In addition
+                to that, in case some of the attributes in the payload
+                already exist in the entity, an error is returned.
+                More precisely this means a strict append procedure.
+            forcedUpdate: Update operation have to trigger any matching
+                subscription, no matter if there is an actual attribute
+                update or no instead of the default behavior, which is to
+                updated only if attribute is effectively updated.
+        Returns:
+            None
+
+        """
+        url = urljoin(self.base_url, f"v2/entities/{entity_id}/attrs")
+        headers = self.headers.copy()
+        params = {}
+        if entity_type:
+            params.update({'type': entity_type})
+        options = []
+        if append_strict:
+            options.append("append")
+        if forcedUpdate:
+            options.append("forcedUpdate")
+        if options:
+            params.update({'options': ",".join(options)})
+
+        entity = ContextEntity(id=entity_id, type=entity_type)
+        entity.add_attributes(attrs)
+        # exclude commands from the send data,
+        # as they live in the IoTA-agent
+        excluded_keys = {"id", "type"}
+        excluded_keys.update(
+            entity.get_commands(response_format=PropertyFormat.DICT).keys()
+        )
+        try:
+            res = self.post(
+                url=url,
+                headers=headers,
+                json=entity.model_dump(
+                    exclude=excluded_keys,
+                    exclude_none=True
+                ),
+                params=params,
+            )
+            if res.ok:
+                self.logger.info("Entity '%s' successfully " "updated!", entity.id)
+            else:
+                res.raise_for_status()
+        except requests.RequestException as err:
+            msg = f"Could not update or append attributes of entity" f" {entity.id} !"
+            self.log_error(err=err, msg=msg)
+            raise
+
+    def update_entity_key_value(self,
+                                entity: Union[ContextEntityKeyValues, dict],):
+        """
+        The entity are updated with a ContextEntityKeyValues object or a
+        dictionary contain the simplified entity data. This corresponds to a
+        'PATcH' request.
+        Only existing attribute can be updated!
+
+        Args:
+            entity: A ContextEntityKeyValues object or a dictionary contain
+            the simplified entity data
+
+        """
+        if isinstance(entity, dict):
+            entity = ContextEntityKeyValues(**entity)
+        url = urljoin(self.base_url, f'v2/entities/{entity.id}/attrs')
+        headers = self.headers.copy()
+        params = {"type": entity.type,
+                  "options": AttrsFormat.KEY_VALUES.value
+                  }
+        try:
+            res = self.patch(url=url,
+                             headers=headers,
+                             json=entity.model_dump(exclude={'id', 'type'},
+                                                    exclude_unset=True),
+                             params=params)
+            if res.ok:
+                self.logger.info("Entity '%s' successfully "
+                                 "updated!", entity.id)
+            else:
+                res.raise_for_status()
+        except requests.RequestException as err:
+            msg = f"Could not update attributes of entity" \
+                  f" {entity.id} !"
+            self.log_error(err=err, msg=msg)
+            raise
+
+    def update_entity_attributes_key_value(self,
+                                           entity_id: str,
+                                           attrs: dict,
+                                           entity_type: str = None,
+                                           ):
+        """
+        Update entity with attributes in keyValues form.
+        This corresponds to a 'PATcH' request.
+        Only existing attribute can be updated!
+
+        Args:
+            entity_id: Entity id to be updated
+            entity_type: Entity type, to avoid ambiguity in case there are
+                several entities with the same entity id.
+            attrs: a dictionary that contains the attribute values.
+            e.g. {
+                "temperature": 21.4,
+                "humidity": 50
+            }
+
+        Returns:
+
+        """
+        if entity_type:
+            pass
+        else:
+            _entity = self.get_entity(entity_id=entity_id)
+            entity_type = _entity.type
+
+        entity_dict = attrs.copy()
+        entity_dict.update({
+            "id": entity_id,
+            "type": entity_type
+        })
+        entity = ContextEntityKeyValues(**entity_dict)
+        self.update_entity_key_value(entity=entity)
+
+    def update_existing_entity_attributes(
+            self,
+            entity_id: str,
+            entity_type: str,
+            attrs: List[Union[NamedContextAttribute,
+                              Dict[str, ContextAttribute]]],
+            forcedUpdate: bool = False,
+            override_metadata: bool = False
+    ):
+        """
+        The entity attributes are updated with the ones in the payload.
+        In addition to that, if one or more attributes in the payload doesn't
+        exist in the entity, an error is returned. This corresponds to a
+        'PATcH' request.
+
+        Args:
+            entity_id: Entity id to be updated
+            entity_type: Entity type, to avoid ambiguity in case there are
+                several entities with the same entity id.
+            attrs: List of attributes to update or to append
+            forcedUpdate: Update operation have to trigger any matching
+                subscription, no matter if there is an actual attribute
+                update or no instead of the default behavior, which is to
+                updated only if attribute is effectively updated.
+            override_metadata:
+                Bool,replace the existing metadata with the one provided in
+                the request
+        Returns:
+            None
+
+        """
+        url = urljoin(self.base_url, f"v2/entities/{entity_id}/attrs")
+        headers = self.headers.copy()
+        params = {"type": entity_type}
+
+        entity = ContextEntity(id=entity_id, type=entity_type)
+        entity.add_attributes(attrs)
+
+        options = []
+        if override_metadata:
+            options.append("overrideMetadata")
+        if forcedUpdate:
+            options.append("forcedUpdate")
+        if options:
+            params.update({'options': ",".join(options)})
+
+        try:
+            res = self.patch(
+                url=url,
+                headers=headers,
+                json=entity.model_dump(
+                    exclude={"id", "type"},
+                    exclude_none=True
+                ),
+                params=params,
+            )
+            if res.ok:
+                self.logger.info("Entity '%s' successfully " "updated!", entity.id)
+            else:
+                res.raise_for_status()
+        except requests.RequestException as err:
+            msg = f"Could not update attributes of entity" f" {entity.id} !"
+            self.log_error(err=err, msg=msg)
+            raise
+
+    def override_entity(self, entity: ContextEntity):
+        """
+        The request payload is an object representing the attributes to
+        override the existing entity.
+
+        Note:
+            If you want to manipulate you should rather use patch_entity.
+
+        Args:
+            entity (ContextEntity):
+        Returns:
+            None
+        """
+        self.replace_entity_attributes(entity_id=entity.id,
+                                       entity_type=entity.type,
+                                       attrs=entity.get_properties())
+
+    def replace_entity_attributes(
+            self,
+            entity_id: str,
+            entity_type: str,
+            attrs: List[Union[NamedContextAttribute,
+                              Dict[str, ContextAttribute]]],
+            forcedUpdate: bool = False
+    ):
+        """
+        The attributes previously existing in the entity are removed and
+        replaced by the ones in the request. This corresponds to a 'PUT'
+        request.
+
+        Args:
+            entity_id: Entity id to be updated
+            entity_type: Entity type, to avoid ambiguity in case there are
+                several entities with the same entity id.
+            attrs: List of attributes to add to the entity
+            forcedUpdate: Update operation have to trigger any matching
+                subscription, no matter if there is an actual attribute
+                update or no instead of the default behavior, which is to
+                updated only if attribute is effectively updated.
+        Returns:
+            None
+        """
+        url = urljoin(self.base_url, f"v2/entities/{entity_id}/attrs")
+        headers = self.headers.copy()
+        params = {}
+        options = []
+        if forcedUpdate:
+            options.append("forcedUpdate")
+        if options:
+            params.update({'options': ",".join(options)})
+        if entity_type:
+            params.update({"type": entity_type})
+
+        entity = ContextEntity(id=entity_id, type=entity_type)
+        entity.add_attributes(attrs)
+
+        try:
+            res = self.put(
+                url=url,
+                headers=headers,
+                json=entity.model_dump(
+                    exclude={"id", "type"},
+                    exclude_none=True
+                ),
+                params=params,
+            )
+            if res.ok:
+                self.logger.info("Entity '%s' successfully " "updated!", entity.id)
+            else:
+                res.raise_for_status()
+        except requests.RequestException as err:
+            msg = f"Could not replace attribute of entity {entity.id} !"
+            self.log_error(err=err, msg=msg)
+            raise
+
+    # Attribute operations
+    def get_attribute(
+        self,
+        entity_id: str,
+        attr_name: str,
+        entity_type: str = None,
+        metadata: str = None,
+        response_format="",
+    ) -> ContextAttribute:
+        """
+        Retrieves a specified attribute from an entity.
+
+        Args:
+            entity_id: Id of the entity. Example: Bcn_Welt
+            attr_name: Name of the attribute to be retrieved.
+            entity_type (Optional): Type of the entity to retrieve
+            metadata (Optional): A list of metadata names to include in the
+                response. See "Filtering out attributes and metadata" section
+                for more detail.
+
+        Returns:
+            The content of the retrieved attribute as ContextAttribute
+
+        Raises:
+            Error
+
+        """
+        url = urljoin(self.base_url, f"v2/entities/{entity_id}/attrs/{attr_name}")
+        headers = self.headers.copy()
+        params = {}
+        if entity_type:
+            params.update({"type": entity_type})
+        if metadata:
+            params.update({"metadata": ",".join(metadata)})
+        try:
+            res = self.get(url=url, params=params, headers=headers)
+            if res.ok:
+                self.logger.debug("Received: %s", res.json())
+                return ContextAttribute(**res.json())
+            res.raise_for_status()
+        except requests.RequestException as err:
+            msg = (
+                f"Could not load attribute '{attr_name}' from entity" f"'{entity_id}' "
+            )
+            self.log_error(err=err, msg=msg)
+            raise
+
+    def update_entity_attribute(self,
+                                entity_id: str,
+                                attr: Union[ContextAttribute,
+                                            NamedContextAttribute],
+                                *,
+                                entity_type: str = None,
+                                attr_name: str = None,
+                                override_metadata: bool = True,
+                                forcedUpdate: bool = False):
+        """
+        Updates a specified attribute from an entity.
+
+        Args:
+            attr:
+                context attribute to update
+            entity_id:
+                Id of the entity. Example: Bcn_Welt
+            entity_type:
+                Entity type, to avoid ambiguity in case there are
+                several entities with the same entity id.
+            forcedUpdate: Update operation have to trigger any matching
+                subscription, no matter if there is an actual attribute
+                update or no instead of the default behavior, which is to
+                updated only if attribute is effectively updated.
+            attr_name:
+                Name of the attribute to be updated.
+            override_metadata:
+                Bool, if set to `True` (default) the metadata will be
+                overwritten. This is for backwards compatibility reasons.
+                If `False` the metadata values will be either updated if
+                already existing or append if not.
+                See also:
+                https://fiware-orion.readthedocs.io/en/master/user/metadata.html
+        """
+        headers = self.headers.copy()
+        if not isinstance(attr, NamedContextAttribute):
+            assert attr_name is not None, (
+                "Missing name for attribute. "
+                "attr_name must be present if"
+                "attr is of type ContextAttribute"
+            )
+        else:
+            assert attr_name is None, (
+                "Invalid argument attr_name. Do not set "
+                "attr_name if attr is of type "
+                "NamedContextAttribute"
+            )
+            attr_name = attr.name
+
+        url = urljoin(self.base_url, f"v2/entities/{entity_id}/attrs/{attr_name}")
+        params = {}
+        if entity_type:
+            params.update({"type": entity_type})
+        # set overrideMetadata option (we assure backwards compatibility here)
+        options = []
+        if override_metadata:
+            options.append("overrideMetadata")
+        if forcedUpdate:
+            options.append("forcedUpdate")
+        if options:
+            params.update({'options': ",".join(options)})
+        try:
+            res = self.put(
+                url=url,
+                headers=headers,
+                params=params,
+                json=attr.model_dump(
+                    exclude={"name"},
+                    exclude_none=True
+                ),
+            )
+            if res.ok:
+                self.logger.info(
+                    "Attribute '%s' of '%s' " "successfully updated!",
+                    attr_name,
+                    entity_id,
+                )
+            else:
+                res.raise_for_status()
+        except requests.RequestException as err:
+            msg = (
+                f"Could not update attribute '{attr_name}' of entity" f"'{entity_id}' "
+            )
+            self.log_error(err=err, msg=msg)
+            raise
+
+    def delete_entity_attribute(
+        self, entity_id: str, attr_name: str, entity_type: str = None
+    ) -> None:
+        """
+        Removes a specified attribute from an entity.
+
+        Args:
+            entity_id: Id of the entity.
+            attr_name: Name of the attribute to be retrieved.
+            entity_type: Entity type, to avoid ambiguity in case there are
+            several entities with the same entity id.
+        Raises:
+            Error
+
+        """
+        url = urljoin(self.base_url, f"v2/entities/{entity_id}/attrs/{attr_name}")
+        headers = self.headers.copy()
+        params = {}
+        if entity_type:
+            params.update({"type": entity_type})
+        try:
+            res = self.delete(url=url, headers=headers)
+            if res.ok:
+                self.logger.info(
+                    "Attribute '%s' of '%s' " "successfully deleted!",
+                    attr_name,
+                    entity_id,
+                )
+            else:
+                res.raise_for_status()
+        except requests.RequestException as err:
+            msg = (
+                f"Could not delete attribute '{attr_name}' of entity" f"'{entity_id}' "
+            )
+            self.log_error(err=err, msg=msg)
+            raise
+
+    # Attribute value operations
+    def get_attribute_value(
+        self, entity_id: str, attr_name: str, entity_type: str = None
+    ) -> Any:
+        """
+        This operation returns the value property with the value of the
+        attribute.
+
+        Args:
+            entity_id: Id of the entity. Example: Bcn_Welt
+            attr_name: Name of the attribute to be retrieved.
+                Example: temperature.
+            entity_type: Entity type, to avoid ambiguity in case there are
+                several entities with the same entity id.
+
+        Returns:
+
+        """
+        url = urljoin(self.base_url, f"v2/entities/{entity_id}/attrs/{attr_name}/value")
+        headers = self.headers.copy()
+        params = {}
+        if entity_type:
+            params.update({"type": entity_type})
+        try:
+            res = self.get(url=url, params=params, headers=headers)
+            if res.ok:
+                self.logger.debug("Received: %s", res.json())
+                return res.json()
+            res.raise_for_status()
+        except requests.RequestException as err:
+            msg = (
+                f"Could not load value of attribute '{attr_name}' from "
+                f"entity'{entity_id}' "
+            )
+            self.log_error(err=err, msg=msg)
+            raise
+
+    def update_attribute_value(self, *,
+                               entity_id: str,
+                               attr_name: str,
+                               value: Any,
+                               entity_type: str = None,
+                               forcedUpdate: bool = False
+                               ):
+        """
+        Updates the value of a specified attribute of an entity
+
+        Args:
+            value: update value
+            entity_id: Id of the entity. Example: Bcn_Welt
+            attr_name: Name of the attribute to be retrieved.
+                Example: temperature.
+            entity_type: Entity type, to avoid ambiguity in case there are
+                several entities with the same entity id.
+            forcedUpdate: Update operation have to trigger any matching
+                subscription, no matter if there is an actual attribute
+                update or no instead of the default behavior, which is to
+                updated only if attribute is effectively updated.
+        Returns:
+
+        """
+        url = urljoin(self.base_url, f"v2/entities/{entity_id}/attrs/{attr_name}/value")
+        headers = self.headers.copy()
+        params = {}
+        if entity_type:
+            params.update({'type': entity_type})
+        options = []
+        if forcedUpdate:
+            options.append("forcedUpdate")
+        if options:
+            params.update({'options': ",".join(options)})
+        try:
+            if not isinstance(value, (dict, list)):
+                headers.update({"Content-Type": "text/plain"})
+                if isinstance(value, str):
+                    value = f"{value}"
+                res = self.put(url=url, headers=headers, json=value, params=params)
+            else:
+                res = self.put(url=url, headers=headers, json=value, params=params)
+            if res.ok:
+                self.logger.info(
+                    "Attribute '%s' of '%s' " "successfully updated!",
+                    attr_name,
+                    entity_id,
+                )
+            else:
+                res.raise_for_status()
+        except requests.RequestException as err:
+            msg = (
+                f"Could not update value of attribute '{attr_name}' from "
+                f"entity '{entity_id}' "
+            )
+            self.log_error(err=err, msg=msg)
+            raise
+
+    # Types Operations
+    def get_entity_types(
+        self, *, limit: int = None, offset: int = None, options: str = None
+    ) -> List[Dict[str, Any]]:
+        """
+
+        Args:
+            limit: Limit the number of types to be retrieved.
+            offset: Skip a number of records.
+            options: Options dictionary. Allowed: count, values
+
+        Returns:
+
+        """
+        url = urljoin(self.base_url, "v2/types")
+        headers = self.headers.copy()
+        params = {}
+        if limit:
+            params.update({"limit": limit})
+        if offset:
+            params.update({"offset": offset})
+        if options:
+            params.update({"options": options})
+        try:
+            res = self.get(url=url, params=params, headers=headers)
+            if res.ok:
+                self.logger.debug("Received: %s", res.json())
+                return res.json()
+            res.raise_for_status()
+        except requests.RequestException as err:
+            msg = "Could not load entity types!"
+            self.log_error(err=err, msg=msg)
+            raise
+
+    def get_entity_type(self, entity_type: str) -> Dict[str, Any]:
+        """
+
+        Args:
+            entity_type: Entity Type. Example: Room
+
+        Returns:
+
+        """
+        url = urljoin(self.base_url, f"v2/types/{entity_type}")
+        headers = self.headers.copy()
+        params = {}
+        try:
+            res = self.get(url=url, params=params, headers=headers)
+            if res.ok:
+                self.logger.debug("Received: %s", res.json())
+                return res.json()
+            res.raise_for_status()
+        except requests.RequestException as err:
+            msg = f"Could not load entities of type" f"'{entity_type}' "
+            self.log_error(err=err, msg=msg)
+            raise
+
+    # SUBSCRIPTION API ENDPOINTS
+    def get_subscription_list(self, limit: PositiveInt = inf) -> List[Subscription]:
+        """
+        Returns a list of all the subscriptions present in the system.
+        Args:
+            limit: Limit the number of subscriptions to be retrieved
+        Returns:
+            list of subscriptions
+        """
+        url = urljoin(self.base_url, "v2/subscriptions/")
+        headers = self.headers.copy()
+        params = {}
+
+        # We always use the 'count' option to check weather pagination is
+        # required
+        params.update({"options": "count"})
+        try:
+            items = self.__pagination(
+                limit=limit, url=url, params=params, headers=headers
+            )
+            adapter = TypeAdapter(List[Subscription])
+            return adapter.validate_python(items)
+        except requests.RequestException as err:
+            msg = "Could not load subscriptions!"
+            self.log_error(err=err, msg=msg)
+            raise
+
+    def post_subscription(
+        self,
+        subscription: Subscription,
+        update: bool = False,
+        skip_initial_notification: bool = False,
+    ) -> str:
+        """
+        Creates a new subscription. The subscription is represented by a
+        Subscription object defined in filip.cb.models.
+
+        If the subscription already exists, the adding is prevented and the id
+        of the existing subscription is returned.
+
+        A subscription is deemed as already existing if there exists a
+        subscription with the exact same subject and notification fields. All
+        optional fields are not considered.
+
+        Args:
+            subscription: Subscription
+            update: True - If the subscription already exists, update it
+                    False- If the subscription already exists, throw warning
+            skip_initial_notification: True - Initial Notifications will be
+                sent to recipient containing the whole data. This is
+                deprecated and removed from version 3.0 of the context broker.
+                False - skip the initial notification
+        Returns:
+            str: Id of the (created) subscription
+
+        """
+        existing_subscriptions = self.get_subscription_list()
+
+        sub_dict = subscription.model_dump(include={'subject',
+                                                    'notification'})
+        for ex_sub in existing_subscriptions:
+            if self._subscription_dicts_are_equal(
+                    sub_dict,
+                    ex_sub.model_dump(include={'subject', 'notification'})
+            ):
+                self.logger.info("Subscription already exists")
+                if update:
+                    self.logger.info("Updated subscription")
+                    subscription.id = ex_sub.id
+                    self.update_subscription(subscription)
+                else:
+                    warnings.warn(
+                        f"Subscription existed already with the id" f" {ex_sub.id}"
+                    )
+                return ex_sub.id
+
+        params = {}
+        if skip_initial_notification:
+            version = self.get_version()["orion"]["version"]
+            if parse_version(version) <= parse_version("3.1"):
+                params.update({"options": "skipInitialNotification"})
+            else:
+                pass
+            warnings.warn(
+                f"Skip initial notifications is a deprecated "
+                f"feature of older versions <=3.1 of the context "
+                f"broker. The Context Broker that you requesting has "
+                f"version: {version}. For newer versions we "
+                f"automatically skip this option. Consider "
+                f"refactoring and updating your services",
+                DeprecationWarning,
+            )
+
+        url = urljoin(self.base_url, "v2/subscriptions")
+        headers = self.headers.copy()
+        headers.update({"Content-Type": "application/json"})
+        try:
+            res = self.post(
+                url=url,
+                headers=headers,
+                data=subscription.model_dump_json(exclude={"id"}, exclude_none=True),
+                params=params,
+            )
+            if res.ok:
+                self.logger.info("Subscription successfully created!")
+                return res.headers["Location"].split("/")[-1]
+            res.raise_for_status()
+        except requests.RequestException as err:
+            msg = "Could not send subscription!"
+            self.log_error(err=err, msg=msg)
+            raise
+
+    def get_subscription(self, subscription_id: str) -> Subscription:
+        """
+        Retrieves a subscription from
+        Args:
+            subscription_id: id of the subscription
+
+        Returns:
+
+        """
+        url = urljoin(self.base_url, f"v2/subscriptions/{subscription_id}")
+        headers = self.headers.copy()
+        try:
+            res = self.get(url=url, headers=headers)
+            if res.ok:
+                self.logger.debug("Received: %s", res.json())
+                return Subscription(**res.json())
+            res.raise_for_status()
+        except requests.RequestException as err:
+            msg = f"Could not load subscription {subscription_id}"
+            self.log_error(err=err, msg=msg)
+            raise
+
+    def update_subscription(
+        self, subscription: Subscription, skip_initial_notification: bool = False
+    ):
+        """
+        Only the fields included in the request are updated in the subscription.
+
+        Args:
+            subscription: Subscription to update
+            skip_initial_notification: True - Initial Notifications will be
+                sent to recipient containing the whole data. This is
+                deprecated and removed from version 3.0 of the context broker.
+                False - skip the initial notification
+
+        Returns:
+            None
+        """
+        params = {}
+        if skip_initial_notification:
+            version = self.get_version()["orion"]["version"]
+            if parse_version(version) <= parse_version("3.1"):
+                params.update({"options": "skipInitialNotification"})
+            else:
+                pass
+            warnings.warn(
+                f"Skip initial notifications is a deprecated "
+                f"feature of older versions <3.1 of the context "
+                f"broker. The Context Broker that you requesting has "
+                f"version: {version}. For newer versions we "
+                f"automatically skip this option. Consider "
+                f"refactoring and updating your services",
+                DeprecationWarning,
+            )
+
+        url = urljoin(self.base_url, f"v2/subscriptions/{subscription.id}")
+        headers = self.headers.copy()
+        headers.update({"Content-Type": "application/json"})
+        try:
+            res = self.patch(
+                url=url,
+                headers=headers,
+                data=subscription.model_dump_json(
+                    exclude={"id"},
+                    exclude_none=True
+                ),
+            )
+            if res.ok:
+                self.logger.info("Subscription successfully updated!")
+            else:
+                res.raise_for_status()
+        except requests.RequestException as err:
+            msg = f"Could not update subscription {subscription.id}"
+            self.log_error(err=err, msg=msg)
+            raise
+
+    def delete_subscription(self, subscription_id: str) -> None:
+        """
+        Deletes a subscription from a Context Broker
+        Args:
+            subscription_id: id of the subscription
+        """
+        url = urljoin(self.base_url, f"v2/subscriptions/{subscription_id}")
+        headers = self.headers.copy()
+        try:
+            res = self.delete(url=url, headers=headers)
+            if res.ok:
+                self.logger.info(
+                    f"Subscription '{subscription_id}' " f"successfully deleted!"
+                )
+            else:
+                res.raise_for_status()
+        except requests.RequestException as err:
+            msg = f"Could not delete subscription {subscription_id}"
+            self.log_error(err=err, msg=msg)
+            raise
+
+    # Registration API
+    def get_registration_list(self, *, limit: PositiveInt = None) -> List[Registration]:
+        """
+        Lists all the context provider registrations present in the system.
+
+        Args:
+            limit: Limit the number of registrations to be retrieved
+        Returns:
+
+        """
+        url = urljoin(self.base_url, "v2/registrations/")
+        headers = self.headers.copy()
+        params = {}
+
+        # We always use the 'count' option to check weather pagination is
+        # required
+        params.update({"options": "count"})
+        try:
+            items = self.__pagination(
+                limit=limit, url=url, params=params, headers=headers
+            )
+            adapter = TypeAdapter(List[Registration])
+            return adapter.validate_python(items)
+        except requests.RequestException as err:
+            msg = "Could not load registrations!"
+            self.log_error(err=err, msg=msg)
+            raise
+
+    def post_registration(self, registration: Registration):
+        """
+        Creates a new context provider registration. This is typically used
+        for binding context sources as providers of certain data. The
+        registration is represented by cb.models.Registration
+
+        Args:
+            registration (Registration):
+
+        Returns:
+
+        """
+        url = urljoin(self.base_url, "v2/registrations")
+        headers = self.headers.copy()
+        headers.update({"Content-Type": "application/json"})
+        try:
+            res = self.post(
+                url=url,
+                headers=headers,
+                data=registration.model_dump_json(exclude={"id"}, exclude_none=True),
+            )
+            if res.ok:
+                self.logger.info("Registration successfully created!")
+                return res.headers["Location"].split("/")[-1]
+            res.raise_for_status()
+        except requests.RequestException as err:
+            msg = f"Could not send registration {registration.id}!"
+            self.log_error(err=err, msg=msg)
+            raise
+
+    def get_registration(self, registration_id: str) -> Registration:
+        """
+        Retrieves a registration from context broker by id
+
+        Args:
+            registration_id: id of the registration
+
+        Returns:
+            Registration
+        """
+        url = urljoin(self.base_url, f"v2/registrations/{registration_id}")
+        headers = self.headers.copy()
+        try:
+            res = self.get(url=url, headers=headers)
+            if res.ok:
+                self.logger.debug("Received: %s", res.json())
+                return Registration(**res.json())
+            res.raise_for_status()
+        except requests.RequestException as err:
+            msg = f"Could not load registration {registration_id} !"
+            self.log_error(err=err, msg=msg)
+            raise
+
+    def update_registration(self, registration: Registration):
+        """
+        Only the fields included in the request are updated in the registration.
+
+        Args:
+            registration: Registration to update
+        Returns:
+
+        """
+        url = urljoin(self.base_url, f"v2/registrations/{registration.id}")
+        headers = self.headers.copy()
+        headers.update({"Content-Type": "application/json"})
+        try:
+            res = self.patch(
+                url=url,
+                headers=headers,
+                data=registration.model_dump_json(
+                    exclude={"id"},
+                    exclude_none=True
+                ),
+            )
+            if res.ok:
+                self.logger.info("Registration successfully updated!")
+            else:
+                res.raise_for_status()
+        except requests.RequestException as err:
+            msg = f"Could not update registration {registration.id} !"
+            self.log_error(err=err, msg=msg)
+            raise
+
+    def delete_registration(self, registration_id: str) -> None:
+        """
+        Deletes a subscription from a Context Broker
+        Args:
+            registration_id: id of the subscription
+        """
+        url = urljoin(self.base_url, f"v2/registrations/{registration_id}")
+        headers = self.headers.copy()
+        try:
+            res = self.delete(url=url, headers=headers)
+            if res.ok:
+                self.logger.info(
+                    "Registration '%s' " "successfully deleted!", registration_id
+                )
+            res.raise_for_status()
+        except requests.RequestException as err:
+            msg = f"Could not delete registration {registration_id} !"
+            self.log_error(err=err, msg=msg)
+            raise
+
+    # Batch operation API
+    def update(self,
+               *,
+               entities: List[ContextEntity],
+               action_type: Union[ActionType, str],
+               update_format: str = None,
+               forcedUpdate: bool = False,
+               override_metadata: bool = False,
+               ) -> None:
+        """
+        This operation allows to create, update and/or delete several entities
+        in a single batch operation.
+
+        This operation is split in as many individual operations as entities
+        in the entities vector, so the actionType is executed for each one of
+        them. Depending on the actionType, a mapping with regular non-batch
+        operations can be done:
+
+        append: maps to POST /v2/entities (if the entity does not already exist)
+        or POST /v2/entities/<id>/attrs (if the entity already exists).
+
+        appendStrict: maps to POST /v2/entities (if the entity does not
+        already exist) or POST /v2/entities/<id>/attrs?options=append (if the
+        entity already exists).
+
+        update: maps to PATCH /v2/entities/<id>/attrs.
+
+        delete: maps to DELETE /v2/entities/<id>/attrs/<attrName> on every
+            attribute included in the entity or to DELETE /v2/entities/<id> if
+            no attribute were included in the entity.
+
+        replace: maps to PUT /v2/entities/<id>/attrs.
+
+        Args:
+            entities: "an array of entities, each entity specified using the "
+                      "JSON entity representation format "
+            action_type (Update): "actionType, to specify the kind of update
+                    action to do: either append, appendStrict, update, delete,
+                    or replace. "
+            update_format (str): Optional 'keyValues'
+            forcedUpdate: Update operation have to trigger any matching
+                subscription, no matter if there is an actual attribute
+                update or no instead of the default behavior, which is to
+                updated only if attribute is effectively updated.
+            override_metadata:
+                Bool, replace the existing metadata with the one provided in
+                the request
+        Returns:
+
+        """
+
+        url = urljoin(self.base_url, "v2/op/update")
+        headers = self.headers.copy()
+        headers.update({"Content-Type": "application/json"})
+        params = {}
+        options = []
+        if override_metadata:
+            options.append("overrideMetadata")
+        if forcedUpdate:
+            options.append("forcedUpdate")
+        if options:
+            params.update({'options': ",".join(options)})
+        if update_format:
+            assert (
+                update_format == "keyValues"
+            ), "Only 'keyValues' is allowed as update format"
+            params.update({"options": "keyValues"})
+        update = Update(actionType=action_type, entities=entities)
+        try:
+            res = self.post(
+                url=url,
+                headers=headers,
+                params=params,
+                json=update.model_dump(by_alias=True),
+            )
+            if res.ok:
+                self.logger.info("Update operation '%s' succeeded!", action_type)
+            else:
+                res.raise_for_status()
+        except requests.RequestException as err:
+            msg = f"Update operation '{action_type}' failed!"
+            self.log_error(err=err, msg=msg)
+            raise
+
+    def query(
+        self,
+        *,
+        query: Query,
+        limit: PositiveInt = None,
+        order_by: str = None,
+        response_format: Union[AttrsFormat, str] = AttrsFormat.NORMALIZED,
+    ) -> List[Any]:
+        """
+        Generate api query
+        Args:
+            query (Query):
+            limit (PositiveInt):
+            order_by (str):
+            response_format (AttrsFormat, str):
+        Returns:
+            The response payload is an Array containing one object per matching
+            entity, or an empty array [] if no entities are found. The entities
+            follow the JSON entity representation format (described in the
+            section "JSON Entity Representation").
+        """
+        url = urljoin(self.base_url, "v2/op/query")
+        headers = self.headers.copy()
+        headers.update({"Content-Type": "application/json"})
+        params = {"options": "count"}
+
+        if response_format:
+            if response_format not in list(AttrsFormat):
+                raise ValueError(f"Value must be in {list(AttrsFormat)}")
+            params["options"] = ",".join([response_format, "count"])
+        try:
+            items = self.__pagination(
+                method=PaginationMethod.POST,
+                url=url,
+                headers=headers,
+                params=params,
+                data=query.model_dump_json(exclude_none=True),
+                limit=limit,
+            )
+            if response_format == AttrsFormat.NORMALIZED:
+                adapter = TypeAdapter(List[ContextEntity])
+                return adapter.validate_python(items)
+            if response_format == AttrsFormat.KEY_VALUES:
+                adapter = TypeAdapter(List[ContextEntityKeyValues])
+                return adapter.validate_python(items)
+            return items
+        except requests.RequestException as err:
+            msg = "Query operation failed!"
+            self.log_error(err=err, msg=msg)
+            raise
+
+    def notify(self, message: Message) -> None:
+        """
+        This operation is intended to consume a notification payload so that
+        all the entity data included by such notification is persisted,
+        overwriting if necessary. This operation is useful when one NGSIv2
+        endpoint is subscribed to another NGSIv2 endpoint (federation
+        scenarios). The request payload must be an NGSIv2 notification
+        payload. The behaviour must be exactly the same as 'update'
+        with 'action_type' equal to append.
+
+        Args:
+            message: Notification message
+
+        Returns:
+            None
+        """
+        url = urljoin(self.base_url, "v2/op/notify")
+        headers = self.headers.copy()
+        headers.update({"Content-Type": "application/json"})
+        params = {}
+        try:
+            res = self.post(
+                url=url,
+                headers=headers,
+                params=params,
+                data=message.model_dump_json(by_alias=True),
+            )
+            if res.ok:
+                self.logger.info("Notification message sent!")
+            else:
+                res.raise_for_status()
+        except requests.RequestException as err:
+            msg = (
+                f"Sending notifcation message failed! \n "
+                f"{message.model_dump_json(inent=2)}"
+            )
+            self.log_error(err=err, msg=msg)
+            raise
+
+    def post_command(
+        self,
+        *,
+        entity_id: str,
+        entity_type: str,
+        command: Union[Command, NamedCommand, Dict],
+        command_name: str = None,
+    ) -> None:
+        """
+        Post a command to a context entity this corresponds to 'PATCH' of the
+        specified command attribute.
+
+        Args:
+            entity_id: Entity identifier
+            command: Command
+            entity_type: Entity type
+            command_name: Name of the command in the entity
+
+        Returns:
+            None
+        """
+        if command_name:
+            assert isinstance(command, (Command, dict))
+            if isinstance(command, dict):
+                command = Command(**command)
+            command = {command_name: command.model_dump()}
+        else:
+            assert isinstance(command, (NamedCommand, dict))
+            if isinstance(command, dict):
+                command = NamedCommand(**command)
+
+        self.update_existing_entity_attributes(
+            entity_id=entity_id, entity_type=entity_type, attrs=[command]
+        )
+
+    def does_entity_exist(self, entity_id: str, entity_type: str) -> bool:
+        """
+        Test if an entity with given id and type is present in the CB
+
+        Args:
+            entity_id: Entity id
+            entity_type: Entity type
+
+        Returns:
+            bool; True if entity exists
+
+        Raises:
+            RequestException, if any error occurs (e.g: No Connection),
+            except that the entity is not found
+        """
+        url = urljoin(self.base_url, f"v2/entities/{entity_id}")
+        headers = self.headers.copy()
+        params = {"type": entity_type}
+
+        try:
+            res = self.get(url=url, params=params, headers=headers)
+            if res.ok:
+                return True
+            res.raise_for_status()
+        except requests.RequestException as err:
+            if err.response is None or not err.response.status_code == 404:
+                raise
+            return False
+
+    def patch_entity(self,
+                     entity: ContextEntity,
+                     old_entity: Optional[ContextEntity] = None,
+                     override_attr_metadata: bool = True) -> None:
+        """
+        Takes a given entity and updates the state in the CB to match it.
+        It is an extended equivalent to the HTTP method PATCH, which applies
+        partial modifications to a resource.
+
+        Args:
+            entity: Entity to update
+            old_entity: OPTIONAL, if given only the differences between the
+                       old_entity and entity are updated in the CB.
+                       Other changes made to the entity in CB, can be kept.
+                       If type or id was changed, the old_entity will be
+                       deleted.
+            override_attr_metadata:
+                Whether to override or append the attributes metadata.
+                `True` for overwrite or `False` for update/append
+
+        Returns:
+           None
+        """
+
+        new_entity = entity
+
+        if old_entity is None:
+            # If no old entity_was provided we use the current state to compare
+            # the entity to
+            if self.does_entity_exist(
+                entity_id=new_entity.id, entity_type=new_entity.type
+            ):
+                old_entity = self.get_entity(
+                    entity_id=new_entity.id, entity_type=new_entity.type
+                )
+            else:
+                # the entity is new, post and finish
+                self.post_entity(new_entity, update=False)
+                return
+
+        else:
+            # An old_entity was provided
+            # check if the old_entity (still) exists else recall methode
+            # and discard old_entity
+            if not self.does_entity_exist(
+                entity_id=old_entity.id, entity_type=old_entity.type
+            ):
+                self.patch_entity(
+                    new_entity, override_attr_metadata=override_attr_metadata
+                )
+                return
+
+            # if type or id was changed, the old_entity needs to be deleted
+            # and the new_entity created
+            # In this case we will lose the current state of the entity
+            if old_entity.id != new_entity.id or old_entity.type != new_entity.type:
+                self.delete_entity(entity_id=old_entity.id, entity_type=old_entity.type)
+
+                if not self.does_entity_exist(
+                    entity_id=new_entity.id, entity_type=new_entity.type
+                ):
+                    self.post_entity(entity=new_entity, update=False)
+                    return
+
+        # At this point we know that we need to patch only the attributes of
+        # the entity
+        # Check the differences between the attributes of old and new entity
+        # Delete the removed attributes, create the new ones,
+        # and update the existing if necessary
+        old_attributes = old_entity.get_attributes()
+        new_attributes = new_entity.get_attributes()
+
+        # Manage attributes that existed before
+        for old_attr in old_attributes:
+            # commands do not exist in the ContextEntity and are only
+            # registrations to the corresponding device. Operations as
+            # delete will fail as it does not technically exist
+            corresponding_new_attr = None
+            for new_attr in new_attributes:
+                if new_attr.name == old_attr.name:
+                    corresponding_new_attr = new_attr
+
+            if corresponding_new_attr is None:
+                # Attribute no longer exists, delete it
+                try:
+                    self.delete_entity_attribute(
+                        entity_id=new_entity.id,
+                        entity_type=new_entity.type,
+                        attr_name=old_attr.name,
+                    )
+                except requests.RequestException as err:
+                    # if the attribute is provided by a registration the
+                    # deletion will fail
+                    if not err.response.status_code == 404:
+                        raise
+            else:
+                # Check if attributed changed in any way, if yes update
+                # else do nothing and keep current state
+                if old_attr != corresponding_new_attr:
+                    try:
+                        self.update_entity_attribute(
+                            entity_id=new_entity.id,
+                            entity_type=new_entity.type,
+                            attr=corresponding_new_attr,
+                            override_metadata=override_attr_metadata,
+                        )
+                    except requests.RequestException as err:
+                        # if the attribute is provided by a registration the
+                        # update will fail
+                        if not err.response.status_code == 404:
+                            raise
+
+        # Create new attributes
+        update_entity = ContextEntity(id=entity.id, type=entity.type)
+        update_needed = False
+        for new_attr in new_attributes:
+            # commands do not exist in the ContextEntity and are only
+            # registrations to the corresponding device. Operations as
+            # delete will fail as it does not technically exists
+            attr_existed = False
+            for old_attr in old_attributes:
+                if new_attr.name == old_attr.name:
+                    attr_existed = True
+
+            if not attr_existed:
+                update_needed = True
+                update_entity.add_attributes([new_attr])
+
+        if update_needed:
+            self.update_entity(update_entity)
+
+    def _subscription_dicts_are_equal(self, first: dict, second: dict):
+        """
+        Check if two dictionaries and all sub-dictionaries are equal.
+        Logs a warning if the keys are not equal, but ignores the
+        comparison of such keys.
+
+        Args:
+            first dict: Dictionary of first subscription
+            second dict: Dictionary of second subscription
+
+        Returns:
+            True if equal, else False
+        """
+
+        def _value_is_not_none(value):
+            """
+            Recursive function to check if a value equals none.
+            If the value is a dict and any value of the dict is not none,
+            the value is not none.
+            If the value is a list and any item is not none, the value is not none.
+            If it's neither dict nore list, bool is used.
+            """
+            if isinstance(value, dict):
+                return any([_value_is_not_none(value=_v)
+                            for _v in value.values()])
+            if isinstance(value, list):
+                return any([_value_is_not_none(value=_v)for _v in value])
+            else:
+                return bool(value)
+        if first.keys() != second.keys():
+            warnings.warn(
+                "Subscriptions contain a different set of fields. "
+                "Only comparing to new fields of the new one."
+            )
+        for k, v in first.items():
+            ex_value = second.get(k, None)
+            if isinstance(v, dict) and isinstance(ex_value, dict):
+                equal = self._subscription_dicts_are_equal(v, ex_value)
+                if equal:
+                    continue
+                else:
+                    return False
+            if not _value_is_not_none(v) or not _value_is_not_none(ex_value):
+                warnings.warn(
+                    "Different field found:{"
+                    f"{k}: ({v}, {ex_value})"
+                    "}"
+                )
+            if v != ex_value:
+                self.logger.debug(f"Not equal fields for key {k}: ({v}, {ex_value})")
+                if not _value_is_not_none(v) and not _value_is_not_none(ex_value) or k == "timesSent":
+                    continue
+                return False
+        return True
+
+
+#
+#
+#    def check_duplicate_subscription(self, subscription_body, limit: int = 20):
+#        """
+#        Function compares the subject of the subscription body, on whether a subscription
+#        already exists for a device / entity.
+#        :param subscription_body: the body of the new subscripton
+#        :param limit: pagination parameter, to set the number of
+#        subscriptions bodies the get request should grab
+#        :return: exists, boolean -> True, if such a subscription allready
+#        exists
+#        """
+#        exists = False
+#        subscription_subject = json.loads(subscription_body)["subject"]
+#        # Exact keys depend on subscription body
+#        try:
+#            subscription_url = json.loads(subscription_body)[
+#            "notification"]["httpCustom"]["url"]
+#        except KeyError:
+#            subscription_url = json.loads(subscription_body)[
+#            "notification"]["http"]["url"]
+#
+#        # If the number of subscriptions is larger then the limit,
+#        paginations methods have to be used
+#        url = self.url + '/v2/subscriptions?limit=' + str(limit) +
+#        '&options=count'
+#        response = self.session.get(url, headers=self.get_header())
+#
+#        sub_count = float(response.headers["Fiware-Total-Count"])
+#        response = json.loads(response.text)
+#        if sub_count >= limit:
+#            response = self.get_pagination(url=url, headers=self.get_header(),
+#                                           limit=limit, count=sub_count)
+#            response = json.loads(response)
+#
+#        for existing_subscription in response:
+#            # check whether the exact same subscriptions already exists
+#            if existing_subscription["subject"] == subscription_subject:
+#                exists = True
+#                break
+#            try:
+#                existing_url = existing_subscription["notification"][
+#                "http"]["url"]
+#            except KeyError:
+#                existing_url = existing_subscription["notification"][
+#                "httpCustom"]["url"]
+#            # check whether both subscriptions notify to the same path
+#            if existing_url != subscription_url:
+#                continue
+#            else:
+#                # iterate over all entities included in the subscription object
+#                for entity in subscription_subject["entities"]:
+#                    if 'type' in entity.keys():
+#                        subscription_type = entity['type']
+#                    else:
+#                        subscription_type = entity['typePattern']
+#                    if 'id' in entity.keys():
+#                        subscription_id = entity['id']
+#                    else:
+#                        subscription_id = entity["idPattern"]
+#                    # iterate over all entities included in the exisiting
+#                    subscriptions
+#                    for existing_entity in existing_subscription["subject"][
+#                    "entities"]:
+#                        if "type" in entity.keys():
+#                            type_existing = entity["type"]
+#                        else:
+#                            type_existing = entity["typePattern"]
+#                        if "id" in entity.keys():
+#                            id_existing = entity["id"]
+#                        else:
+#                            id_existing = entity["idPattern"]
+#                        # as the ID field is non optional, it has to match
+#                        # check whether the type match
+#                        # if the type field is empty, they match all types
+#                        if (type_existing == subscription_type) or\
+#                                ('*' in subscription_type) or \
+#                                ('*' in type_existing)\
+#                                or (type_existing == "") or (
+#                                subscription_type == ""):
+#                            # check if on of the subscriptions is a pattern,
+#                            or if they both refer to the same id
+#                            # Get the attrs first, to avoid code duplication
+#                            # last thing to compare is the attributes
+#                            # Assumption -> position is the same as the
+#                            entities _list
+#                            # i == j
+#                            i = subscription_subject["entities"].index(entity)
+#                            j = existing_subscription["subject"][
+#                            "entities"].index(existing_entity)
+#                            try:
+#                                subscription_attrs = subscription_subject[
+#                                "condition"]["attrs"][i]
+#                            except (KeyError, IndexError):
+#                                subscription_attrs = []
+#                            try:
+#                                existing_attrs = existing_subscription[
+#                                "subject"]["condition"]["attrs"][j]
+#                            except (KeyError, IndexError):
+#                                existing_attrs = []
+#
+#                            if (".*" in subscription_id) or ('.*' in
+#                            id_existing) or (subscription_id == id_existing):
+#                                # Attributes have to match, or the have to
+#                                be an empty array
+#                                if (subscription_attrs == existing_attrs) or
+#                                (subscription_attrs == []) or (existing_attrs == []):
+#                                        exists = True
+#                            # if they do not match completely or subscribe
+#                            to all ids they have to match up to a certain position
+#                            elif ("*" in subscription_id) or ('*' in
+#                            id_existing):
+#                                    regex_existing = id_existing.find('*')
+#                                    regex_subscription =
+#                                    subscription_id.find('*')
+#                                    # slice the strings to compare
+#                                    if (id_existing[:regex_existing] in
+#                                    subscription_id) or (subscription_id[:regex_subscription] in id_existing) or \
+#                                            (id_existing[regex_existing:] in
+#                                            subscription_id) or (subscription_id[regex_subscription:] in id_existing):
+#                                            if (subscription_attrs ==
+#                                            existing_attrs) or (subscription_attrs == []) or (existing_attrs == []):
+#                                                exists = True
+#                                            else:
+#                                                continue
+#                                    else:
+#                                        continue
+#                            else:
+#                                continue
+#                        else:
+#                            continue
+#                    else:
+#                        continue
+#        return exists
+#
```

### Comparing `filip-0.3.0/filip/clients/ngsi_v2/client.py` & `filip-0.4.0/filip/clients/ngsi_v2/client.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,222 +1,222 @@
-"""
-Module for FIWARE api client
-"""
-import logging
-import json
-import errno
-from typing import Optional, Union, Dict
-from pathlib import Path
-from pydantic import BaseModel, AnyHttpUrl
-from requests.auth import HTTPBasicAuth, HTTPDigestAuth
-from requests import Session
-from filip.clients.base_http_client import BaseHttpClient
-from filip.config import settings
-from filip.models.base import FiwareHeader
-from filip.clients.ngsi_v2 import \
-    ContextBrokerClient, \
-    IoTAClient, \
-    QuantumLeapClient
-
-
-logger = logging.getLogger('client')
-
-
-class HttpClientConfig(BaseModel):
-    """
-    Config class for http client
-    """
-    cb_url: Optional[AnyHttpUrl] = settings.CB_URL
-    iota_url: Optional[AnyHttpUrl] = settings.IOTA_URL
-    ql_url: Optional[AnyHttpUrl] = settings.QL_URL
-    auth: Optional[Dict] = None
-
-
-class HttpClient(BaseHttpClient):
-    """
-    Master client. This client contains all implemented sub clients based on
-    the principal of composition. Hence, each sub client is accessible from
-    this client, but they share a general config and if provided a session.
-    """
-    def __init__(self,
-                 config: Union[str, Path, HttpClientConfig, Dict] = None,
-                 session: Session = None,
-                 fiware_header: FiwareHeader = None,
-                 **kwargs):
-        """
-        Constructor for master client
-        Args:
-            config (Union[str, Path, Dict]): Configuration object
-            session (request.Session): Session object
-            fiware_header (FiwareHeader): Fiware header
-            **kwargs: Optional arguments that ``request`` takes.
-        """
-        if config:
-            self.config = config
-        else:
-            self.config = HttpClientConfig()
-
-        super().__init__(session=session,
-                         fiware_header=fiware_header,
-                         **kwargs)
-
-        # initialize sub clients
-        self.cb = ContextBrokerClient(url=self.config.cb_url,
-                                      session=self.session,
-                                      fiware_header=self.fiware_headers,
-                                      **self.kwargs)
-
-        self.iota = IoTAClient(url=self.config.iota_url,
-                               session=self.session,
-                               fiware_header=self.fiware_headers,
-                               **self.kwargs)
-
-        self.timeseries = QuantumLeapClient(url=self.config.ql_url,
-                                            session=self.session,
-                                            fiware_header=self.fiware_headers,
-                                            **self.kwargs)
-
-        # from here on deprecated?
-        auth_types = {'basicauth': self.__http_basic_auth,
-                      'digestauth': self.__http_digest_auth}
-        # 'oauth2': self.__oauth2}
-
-        if self.config.auth:
-            assert self.config.auth['type'].lower() in auth_types.keys()
-            self.__get_secrets_file(path=self.config.auth['secret'])
-            auth_types[self.config.auth['type']]()
-
-        self.__secrets = {"username": None,
-                          "password": None,
-                          "client_id": None,
-                          "client_secret": None}
-
-    @property
-    def config(self):
-        """Return current config"""
-        return self._config
-
-    @config.setter
-    def config(self, config: HttpClientConfig):
-        """Set a new config"""
-        if isinstance(config, HttpClientConfig):
-            self._config = config
-        elif isinstance(config, (str, Path)):
-            with open(config) as f:
-                config_json = f.read()
-                self._config = HttpClientConfig.model_validate_json(config_json)
-        else:
-            self._config = HttpClientConfig.model_validate(config)
-
-    @property
-    def cert(self):
-        """Return session certificate"""
-        return self.session.cert
-
-    @property
-    def secrets(self):
-        """Returns secrets"""
-        return self.__secrets
-
-    @secrets.setter
-    def secrets(self, data: dict):
-        """Set new secrets"""
-        self.__secrets.update(data)
-
-    @secrets.deleter
-    def secrets(self):
-        """Delete secrets"""
-        self.__secrets = {}
-
-    def __get_secrets_file(self, path=None):
-        """
-        Reads credentials form secret file the path variable is pointing to.
-
-        Args:
-            path: location of secrets-file
-        Returns:
-             None
-        """
-        try:
-            with open(path, 'r') as filename:
-                logger.info("Reading credentials from: %s", path)
-                self.__secrets.update(json.load(filename))
-
-        except IOError as err:
-            if err.errno == errno.ENOENT:
-                logger.error("%s - does not exist", path)
-            elif err.errno == errno.EACCES:
-                logger.error("%s - cannot be read", path)
-            else:
-                logger.error("%s - some other error", path)
-
-    def __http_basic_auth(self):
-        """
-        Initiates a client using the basic authorization mechanism provided by
-        the requests package. The documentation of the package is located here:
-        https://requests.readthedocs.io/en/master/user/authentication/
-        The credentials must be provided via secret-file.
-        """
-        try:
-            self.session = Session()
-            self.session.auth = HTTPBasicAuth(self.__secrets['username'],
-                                              self.__secrets['password'])
-        except KeyError:
-            pass
-
-    def __http_digest_auth(self):
-        """
-        Initiates a client using the digest authorization mechanism provided by
-        the requests package. The documentation of the package is located here:
-        https://requests.readthedocs.io/en/master/user/authentication/
-        The credentials must be provided via secret-file.
-        """
-        try:
-            self.session = Session()
-            self.session.auth = HTTPDigestAuth(self.__secrets['username'],
-                                               self.__secrets['password'])
-        except KeyError:
-            pass
-
-    # def __oauth2(self):
-    #    """
-    #    Initiates a oauthclient according to the workflows defined by OAuth2.0.
-    #    We use requests-oauthlib for this implementation. The documentation
-    #    of the package is located here:
-    #    https://requests-oauthlib.readthedocs.io/en/latest/index.html
-    #    The information for workflow selection must be provided via
-    #    filip-config. The credentials must be provided via secrets-file.
-    #    :return: None
-    #    """
-    #    oauth2clients = {'authorization_code': None,
-    #                     'implicit': MobileApplicationClient,
-    #                     'resource_owner_password_credentials':
-    #                         LegacyApplicationClient,
-    #                     'client_credentials': BackendApplicationClient, }
-    #    try:
-    #        workflow = self.config['auth']['workflow']
-    #    except KeyError:
-    #        logger.warning(f"No workflow for OAuth2 defined! Default "
-    #                       f"workflow will used: Authorization Code Grant."
-    #                       f"Other oauth2-workflows available are: "
-    #                       f"{oauth2clients.keys()}")
-    #        workflow = 'authorization_code_grant'
-#
-    #    oauthclient = oauth2clients[workflow](client_id=self.__secrets[
-    #        'client_id'])
-    #    self.session = OAuth2Session(client_id=None,
-    #                                 client=oauthclient,
-    #                                 auto_refresh_url=self.__secrets[
-    #                                     'token_url'],
-    #                                 auto_refresh_kwargs={
-    #                                     self.__secrets['client_id'],
-    #                                     self.__secrets['client_secret']})
-#
-    #    self.__token = self.session.fetch_token(
-    #        token_url=self.__secrets['token_url'],
-    #        username=self.__secrets['username'],
-    #        password=self.__secrets['password'],
-    #        client_id=self.__secrets['client_id'],
-    #        client_secret=self.__secrets['client_secret'])
-
-    def __token_saver(self, token):
-        self.__token = token
+"""
+Module for FIWARE api client
+"""
+import logging
+import json
+import errno
+from typing import Optional, Union, Dict
+from pathlib import Path
+from pydantic import BaseModel, AnyHttpUrl
+from requests.auth import HTTPBasicAuth, HTTPDigestAuth
+from requests import Session
+from filip.clients.base_http_client import BaseHttpClient
+from filip.config import settings
+from filip.models.base import FiwareHeader
+from filip.clients.ngsi_v2 import \
+    ContextBrokerClient, \
+    IoTAClient, \
+    QuantumLeapClient
+
+
+logger = logging.getLogger('client')
+
+
+class HttpClientConfig(BaseModel):
+    """
+    Config class for http client
+    """
+    cb_url: Optional[AnyHttpUrl] = settings.CB_URL
+    iota_url: Optional[AnyHttpUrl] = settings.IOTA_URL
+    ql_url: Optional[AnyHttpUrl] = settings.QL_URL
+    auth: Optional[Dict] = None
+
+
+class HttpClient(BaseHttpClient):
+    """
+    Master client. This client contains all implemented sub clients based on
+    the principal of composition. Hence, each sub client is accessible from
+    this client, but they share a general config and if provided a session.
+    """
+    def __init__(self,
+                 config: Union[str, Path, HttpClientConfig, Dict] = None,
+                 session: Session = None,
+                 fiware_header: FiwareHeader = None,
+                 **kwargs):
+        """
+        Constructor for master client
+        Args:
+            config (Union[str, Path, Dict]): Configuration object
+            session (request.Session): Session object
+            fiware_header (FiwareHeader): Fiware header
+            **kwargs: Optional arguments that ``request`` takes.
+        """
+        if config:
+            self.config = config
+        else:
+            self.config = HttpClientConfig()
+
+        super().__init__(session=session,
+                         fiware_header=fiware_header,
+                         **kwargs)
+
+        # initialize sub clients
+        self.cb = ContextBrokerClient(url=self.config.cb_url,
+                                      session=self.session,
+                                      fiware_header=self.fiware_headers,
+                                      **self.kwargs)
+
+        self.iota = IoTAClient(url=self.config.iota_url,
+                               session=self.session,
+                               fiware_header=self.fiware_headers,
+                               **self.kwargs)
+
+        self.timeseries = QuantumLeapClient(url=self.config.ql_url,
+                                            session=self.session,
+                                            fiware_header=self.fiware_headers,
+                                            **self.kwargs)
+
+        # from here on deprecated?
+        auth_types = {'basicauth': self.__http_basic_auth,
+                      'digestauth': self.__http_digest_auth}
+        # 'oauth2': self.__oauth2}
+
+        if self.config.auth:
+            assert self.config.auth['type'].lower() in auth_types.keys()
+            self.__get_secrets_file(path=self.config.auth['secret'])
+            auth_types[self.config.auth['type']]()
+
+        self.__secrets = {"username": None,
+                          "password": None,
+                          "client_id": None,
+                          "client_secret": None}
+
+    @property
+    def config(self):
+        """Return current config"""
+        return self._config
+
+    @config.setter
+    def config(self, config: HttpClientConfig):
+        """Set a new config"""
+        if isinstance(config, HttpClientConfig):
+            self._config = config
+        elif isinstance(config, (str, Path)):
+            with open(config) as f:
+                config_json = f.read()
+                self._config = HttpClientConfig.model_validate_json(config_json)
+        else:
+            self._config = HttpClientConfig.model_validate(config)
+
+    @property
+    def cert(self):
+        """Return session certificate"""
+        return self.session.cert
+
+    @property
+    def secrets(self):
+        """Returns secrets"""
+        return self.__secrets
+
+    @secrets.setter
+    def secrets(self, data: dict):
+        """Set new secrets"""
+        self.__secrets.update(data)
+
+    @secrets.deleter
+    def secrets(self):
+        """Delete secrets"""
+        self.__secrets = {}
+
+    def __get_secrets_file(self, path=None):
+        """
+        Reads credentials form secret file the path variable is pointing to.
+
+        Args:
+            path: location of secrets-file
+        Returns:
+             None
+        """
+        try:
+            with open(path, 'r') as filename:
+                logger.info("Reading credentials from: %s", path)
+                self.__secrets.update(json.load(filename))
+
+        except IOError as err:
+            if err.errno == errno.ENOENT:
+                logger.error("%s - does not exist", path)
+            elif err.errno == errno.EACCES:
+                logger.error("%s - cannot be read", path)
+            else:
+                logger.error("%s - some other error", path)
+
+    def __http_basic_auth(self):
+        """
+        Initiates a client using the basic authorization mechanism provided by
+        the requests package. The documentation of the package is located here:
+        https://requests.readthedocs.io/en/master/user/authentication/
+        The credentials must be provided via secret-file.
+        """
+        try:
+            self.session = Session()
+            self.session.auth = HTTPBasicAuth(self.__secrets['username'],
+                                              self.__secrets['password'])
+        except KeyError:
+            pass
+
+    def __http_digest_auth(self):
+        """
+        Initiates a client using the digest authorization mechanism provided by
+        the requests package. The documentation of the package is located here:
+        https://requests.readthedocs.io/en/master/user/authentication/
+        The credentials must be provided via secret-file.
+        """
+        try:
+            self.session = Session()
+            self.session.auth = HTTPDigestAuth(self.__secrets['username'],
+                                               self.__secrets['password'])
+        except KeyError:
+            pass
+
+    # def __oauth2(self):
+    #    """
+    #    Initiates a oauthclient according to the workflows defined by OAuth2.0.
+    #    We use requests-oauthlib for this implementation. The documentation
+    #    of the package is located here:
+    #    https://requests-oauthlib.readthedocs.io/en/latest/index.html
+    #    The information for workflow selection must be provided via
+    #    filip-config. The credentials must be provided via secrets-file.
+    #    :return: None
+    #    """
+    #    oauth2clients = {'authorization_code': None,
+    #                     'implicit': MobileApplicationClient,
+    #                     'resource_owner_password_credentials':
+    #                         LegacyApplicationClient,
+    #                     'client_credentials': BackendApplicationClient, }
+    #    try:
+    #        workflow = self.config['auth']['workflow']
+    #    except KeyError:
+    #        logger.warning(f"No workflow for OAuth2 defined! Default "
+    #                       f"workflow will used: Authorization Code Grant."
+    #                       f"Other oauth2-workflows available are: "
+    #                       f"{oauth2clients.keys()}")
+    #        workflow = 'authorization_code_grant'
+#
+    #    oauthclient = oauth2clients[workflow](client_id=self.__secrets[
+    #        'client_id'])
+    #    self.session = OAuth2Session(client_id=None,
+    #                                 client=oauthclient,
+    #                                 auto_refresh_url=self.__secrets[
+    #                                     'token_url'],
+    #                                 auto_refresh_kwargs={
+    #                                     self.__secrets['client_id'],
+    #                                     self.__secrets['client_secret']})
+#
+    #    self.__token = self.session.fetch_token(
+    #        token_url=self.__secrets['token_url'],
+    #        username=self.__secrets['username'],
+    #        password=self.__secrets['password'],
+    #        client_id=self.__secrets['client_id'],
+    #        client_secret=self.__secrets['client_secret'])
+
+    def __token_saver(self, token):
+        self.__token = token
```

### Comparing `filip-0.3.0/filip/clients/ngsi_v2/iota.py` & `filip-0.4.0/filip/clients/ngsi_v2/iota.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,723 +1,722 @@
-"""
-IoT-Agent Module for API Client
-"""
-from __future__ import annotations
-
-import json
-from copy import deepcopy
-from typing import List, Dict, Set, TYPE_CHECKING, Union, Optional
-import warnings
-from urllib.parse import urljoin
-import requests
-from pydantic import AnyHttpUrl
-from pydantic.type_adapter import TypeAdapter
-from filip.config import settings
-from filip.clients.base_http_client import BaseHttpClient
-from filip.models.base import FiwareHeader
-from filip.models.ngsi_v2.iot import Device, ServiceGroup
-
-from filip.utils.filter import filter_device_list, filter_group_list
-
-if TYPE_CHECKING:
-    from filip.clients.ngsi_v2.cb import ContextBrokerClient
-
-
-class IoTAClient(BaseHttpClient):
-    """
-    Client for FIWARE IoT-Agents. The implementation follows the API
-    specifications from here:
-    https://iotagent-node-lib.readthedocs.io/en/latest/
-
-    Args:
-        url: Url of IoT-Agent
-        session (requests.Session):
-        fiware_header (FiwareHeader): fiware service and fiware service path
-        **kwargs (Optional): Optional arguments that ``request`` takes.
-    """
-
-    def __init__(self,
-                 url: str = None,
-                 *,
-                 session: requests.Session = None,
-                 fiware_header: FiwareHeader = None,
-                 **kwargs):
-        # set service url
-        url = url or settings.IOTA_URL
-        super().__init__(url=url,
-                         session=session,
-                         fiware_header=fiware_header,
-                         **kwargs)
-
-    # ABOUT API
-    def get_version(self) -> Dict:
-        """
-        Gets version of IoT Agent
-
-        Returns:
-            Dictionary with response
-        """
-        url = urljoin(self.base_url, 'iot/about')
-        try:
-            res = self.get(url=url, headers=self.headers)
-            if res.ok:
-                return res.json()
-            res.raise_for_status()
-        except requests.RequestException as err:
-            self.logger.error(err)
-        raise
-
-    # SERVICE GROUP API
-    def post_groups(self,
-                    service_groups: Union[ServiceGroup, List[ServiceGroup]],
-                    update: bool = False):
-        """
-        Creates a set of service groups for the given service and service_path.
-        The service_group and subservice information will taken from the
-        headers, overwriting any preexisting values.
-
-        Args:
-            service_groups (list of ServiceGroup): Service groups that will be
-            posted to the agent's API
-            update (bool): If service group already exists try to update its
-
-        Returns:
-            None
-        """
-        if not isinstance(service_groups, list):
-            service_groups = [service_groups]
-        for group in service_groups:
-            if group.service:
-                assert group.service == self.headers['fiware-service'], \
-                    "Service group service does not math fiware service"
-            if group.subservice:
-                assert group.subservice == self.headers['fiware-servicepath'], \
-                    "Service group subservice does not math fiware service path"
-
-        url = urljoin(self.base_url, 'iot/services')
-        headers = self.headers
-        data = {'services': [group.model_dump(exclude={'service', 'subservice'},
-                                              exclude_none=True,
-                                              exclude_unset=True) for
-                             group in service_groups]}
-        try:
-            res = self.post(url=url, headers=headers, json=data)
-            if res.ok:
-                self.logger.info("Services successfully posted")
-            elif res.status_code == 409:
-                self.logger.warning(res.text)
-                if len(service_groups) > 1:
-                    self.logger.info("Trying to split bulk operation into "
-                                     "single operations")
-                    for group in service_groups:
-                        self.post_group(service_group=group, update=update)
-                elif update is True:
-                    self.update_group(service_group=service_groups[0],
-                                      fields=None)
-                else:
-                    res.raise_for_status()
-            else:
-                res.raise_for_status()
-        except requests.RequestException as err:
-            self.log_error(err=err, msg=None)
-            raise
-
-    def post_group(self, service_group: ServiceGroup, update: bool = False):
-        """
-        Single service registration but using the bulk operation in background
-
-        Args:
-            service_group (ServiceGroup): Service that will be posted to the
-            agent's API
-            update (bool):
-
-        Returns:
-            None
-        """
-        return self.post_groups(service_groups=[service_group],
-                                update=update)
-
-    def get_group_list(self) -> List[ServiceGroup]:
-        r"""
-        Retrieves service_group groups from the database. If the servicepath
-        header has the wildcard expression, /\*, all the subservices for the
-        service_group are returned. The specific subservice parameters are
-        returned in any other case.
-
-        Returns:
-
-        """
-        url = urljoin(self.base_url, 'iot/services')
-        headers = self.headers
-        try:
-            res = self.get(url=url, headers=headers)
-            if res.ok:
-                ta = TypeAdapter(List[ServiceGroup])
-                return ta.validate_python(res.json()['services'])
-            res.raise_for_status()
-        except requests.RequestException as err:
-            self.log_error(err=err, msg=None)
-            raise
-
-    def get_group(self, *, resource: str, apikey: str) -> ServiceGroup:
-        """
-        Retrieves service_group groups from the database based on resource and
-        apikey
-        Args:
-            resource:
-            apikey:
-        Returns:
-
-        """
-        groups = self.get_group_list()
-        groups = filter_group_list(group_list=groups, resources=resource, apikeys=apikey)
-        if len(groups) == 1:
-            group = groups[0]
-            return group
-        elif len(groups) == 0:
-            raise KeyError(f"Service group with resource={resource} and apikey={apikey} was not found")
-        else:
-            raise NotImplementedError("There is a wierd error, try get_group_list() for debugging")
-
-    def update_groups(self, *,
-                      service_groups: Union[ServiceGroup, List[ServiceGroup]],
-                      add: False,
-                      fields: Union[Set[str], List[str]] = None) -> None:
-        """
-        Bulk operation for service group update.
-        Args:
-            fields:
-            service_groups:
-            add:
-
-        Returns:
-
-        """
-        if not isinstance(service_groups, list):
-            service_groups = [service_groups]
-        for group in service_groups:
-            self.update_group(service_group=group, fields=fields, add=add)
-
-    def update_group(self, *, service_group: ServiceGroup,
-                     fields: Union[Set[str], List[str]] = None,
-                     add: bool = True):
-        """
-        Modifies the information for a service group configuration, identified
-        by the resource and apikey query parameters. Takes a service group body
-        as the payload. The body does not have to be complete: for incomplete
-        bodies, just the existing attributes will be updated
-        
-        Args:
-            service_group (ServiceGroup): Service to update.
-            fields: Fields of the service_group to update. If 'None' all allowed
-            fields will be updated
-            add:
-        Returns:
-            None
-        """
-        if fields:
-            if isinstance(fields, list):
-                fields = set(fields)
-        else:
-            fields = None
-        url = urljoin(self.base_url, 'iot/services')
-        headers = self.headers
-        params = service_group.model_dump(include={'resource', 'apikey'})
-        try:
-            res = self.put(url=url,
-                           headers=headers,
-                           params=params,
-                           json=service_group.model_dump(
-                               include=fields,
-                               exclude={'service', 'subservice'},
-                               exclude_unset=True))
-            if res.ok:
-                self.logger.info("ServiceGroup updated!")
-            elif (res.status_code == 404) & (add is True):
-                self.post_group(service_group=service_group)
-            else:
-                res.raise_for_status()
-        except requests.RequestException as err:
-            self.log_error(err=err, msg=None)
-            raise
-
-    def delete_group(self, *, resource: str, apikey: str):
-        """
-        Deletes a service group in in the IoT-Agent
-        
-        Args:
-            resource:
-            apikey:
-
-        Returns:
-
-        """
-        url = urljoin(self.base_url, 'iot/services')
-        headers = self.headers
-        params = {'resource': resource,
-                  'apikey': apikey}
-        try:
-            res = self.delete(url=url, headers=headers, params=params)
-            if res.ok:
-                self.logger.info("ServiceGroup with resource: '%s' and "
-                                 "apikey: '%s' successfully deleted!",
-                                 resource, apikey)
-            else:
-                res.raise_for_status()
-        except requests.RequestException as err:
-            msg = f"Could not delete ServiceGroup with resource " \
-                  f"'{resource}' and apikey '{apikey}'!"
-            self.log_error(err=err, msg=msg)
-            raise
-
-    # DEVICE API
-    def post_devices(self, *, devices: Union[Device, List[Device]],
-                     update: bool = False) -> None:
-        """
-        Post a device from the device registry. No payload is required
-        or received.
-        If a device already exists in can be updated with update = True
-        Args:
-            devices (list of Devices):
-            update (bool):  Whether if the device is already existent it
-            should be updated
-        Returns:
-            None
-        """
-        if not isinstance(devices, list):
-            devices = [devices]
-        url = urljoin(self.base_url, 'iot/devices')
-        headers = self.headers
-        data = {"devices": [json.loads(device.model_dump_json(exclude_none=True)
-                                       ) for device in devices]}
-        try:
-            res = self.post(url=url, headers=headers, json=data)
-            if res.ok:
-                self.logger.info("Devices successfully posted!")
-            else:
-                res.raise_for_status()
-        except requests.RequestException as err:
-            if update:
-                return self.update_devices(devices=devices, add=False)
-            msg = "Could not update devices"
-            self.log_error(err=err, msg=msg)
-            raise
-
-    def post_device(self, *, device: Device, update: bool = False) -> None:
-        """
-        Post a device configuration to the IoT-Agent
-        
-        Args:
-            device: IoT device configuration to send
-            update: update device if configuration already exists
-
-        Returns:
-            None
-        """
-        return self.post_devices(devices=[device], update=update)
-
-    def get_device_list(self, *,
-                        limit: int = None,
-                        offset: int = None,
-                        device_ids: Union[str, List[str]] = None,
-                        entity_names: Union[str, List[str]] = None,
-                        entity_types: Union[str, List[str]] = None) -> List[Device]:
-        """
-        Returns a list of all the devices in the device registry with all
-        its data. The IoTAgent now only supports "limit" and "offset" as
-        request parameters.
-
-        Args:
-            limit:
-                if present, limits the number of devices returned in the
-                list. Must be a number between 1 and 1000.
-            offset:
-                if present, skip that number of devices from the original
-                query.
-            device_ids:
-                List of device_ids. If given, only devices with matching ids
-                will be returned
-            entity_names:
-                The entity_ids of the devices. If given, only the devices
-                with the specified entity_id will be returned
-            entity_types:
-                The entity_type of the device. If given, only the devices
-                with the specified entity_type will be returned
-
-        Returns:
-            List of matching devices
-        """
-        if limit:
-            if not 1 < limit < 1000:
-                self.logger.error("'limit' must be an integer between 1 and "
-                                  "1000!")
-                raise ValueError
-        url = urljoin(self.base_url, 'iot/devices')
-        headers = self.headers
-        params = {key: value for key, value in locals().items() if value is not
-                  None}
-        try:
-            res = self.get(url=url, headers=headers, params=params)
-            if res.ok:
-                ta = TypeAdapter(List[Device])
-                devices = ta.validate_python(res.json()['devices'])
-                # filter by device_ids, entity_names or entity_types
-                devices = filter_device_list(devices,
-                                             device_ids,
-                                             entity_names,
-                                             entity_types)
-                return devices
-            res.raise_for_status()
-        except requests.RequestException as err:
-            self.log_error(err=err, msg=None)
-            raise
-
-    def get_device(self, *, device_id: str) -> Device:
-        """
-        Returns all the information about a particular device.
-        
-        Args:
-            device_id:
-        Raises:
-            requests.RequestException, if device does not exist
-        Returns:
-            Device
-
-        """
-        url = urljoin(self.base_url, f'iot/devices/{device_id}')
-        headers = self.headers
-        try:
-            res = self.get(url=url, headers=headers)
-            if res.ok:
-                return Device.model_validate(res.json())
-            res.raise_for_status()
-        except requests.RequestException as err:
-            msg = f"Device {device_id} was not found"
-            self.log_error(err=err, msg=msg)
-            raise
-
-    def update_device(self, *, device: Device, add: bool = True) -> None:
-        """
-        Updates a device from the device registry.
-        Adds, removes attributes from the device entry and changes
-        attributes values.
-        It does not change device settings (endpoint,..) and only adds
-        attributes to the corresponding entity, their it does not
-        change any attribute value and does not delete removed attributes
-
-        Args:
-            device:
-            add (bool): If device not found add it
-        Returns:
-            None
-        """
-        url = urljoin(self.base_url, f'iot/devices/{device.device_id}')
-        headers = self.headers
-        try:
-            res = self.put(url=url, headers=headers, json=device.model_dump(
-                include={'attributes', 'lazy', 'commands', 'static_attributes'},
-                exclude_none=True))
-            if res.ok:
-                self.logger.info("Device '%s' successfully updated!",
-                                 device.device_id)
-            elif (res.status_code == 404) & (add is True):
-                self.post_device(device=device, update=False)
-            else:
-                res.raise_for_status()
-        except requests.RequestException as err:
-            msg = f"Could not update device '{device.device_id}'"
-            self.log_error(err=err, msg=msg)
-            raise
-
-    def update_devices(self, *, devices: Union[Device, List[Device]],
-                       add: False) -> None:
-        """
-        Bulk operation for device update.
-        Args:
-            devices:
-            add:
-
-        Returns:
-
-        """
-        if not isinstance(devices, list):
-            devices = [devices]
-        for device in devices:
-            self.update_device(device=device, add=add)
-
-    def delete_device(self, *, device_id: str,
-                      cb_url: AnyHttpUrl = settings.CB_URL,
-                      delete_entity: bool = False,
-                      force_entity_deletion: bool = False,
-                      cb_client: ContextBrokerClient = None,
-                      ) -> None:
-        """
-        Remove a device from the device registry. No payload is required
-        or received.
-        
-        Args:
-            device_id: str, ID of Device
-            delete_entity:  False -> Only delete the device entry,
-                                     the automatically created and linked
-                                     context-entity will continue to
-                                     exist in Fiware
-                            True -> Also delete the automatically
-                                    created and linked context-entity
-                                    If multiple devices are linked to this
-                                    entity, this operation is not executed and
-                                    an exception is raised
-            force_entity_deletion:
-                bool, if delete_entity is true and multiple devices are linked
-                to the linked entity, delete it and do not raise an error
-            cb_client (ContextBrokerClient):
-                Corresponding ContextBrokerClient object for entity manipulation
-            cb_url (AnyHttpUrl):
-                Url of the ContextBroker where the entity is found.
-                This will autogenerate an CB-Client, mirroring the information
-                of the IoTA-Client, e.g. FiwareHeader, and other headers
-                (not recommended!)
-
-        Returns:
-            None
-        """
-        url = urljoin(self.base_url, f'iot/devices/{device_id}', )
-        headers = self.headers
-
-        device = self.get_device(device_id=device_id)
-
-        try:
-            res = self.delete(url=url, headers=headers)
-            if res.ok:
-                self.logger.info("Device '%s' successfully deleted!", device_id)
-            else:
-                res.raise_for_status()
-        except requests.RequestException as err:
-            msg = f"Could not delete device {device_id}!"
-            self.log_error(err=err, msg=msg)
-            raise
-
-        if delete_entity:
-            # An entity can technically belong to multiple devices
-            # Only delete the entity if
-            devices = self.get_device_list(entity_names=[device.entity_name])
-
-            # Zero because we count the remaining devices
-            if len(devices) > 0 and not force_entity_deletion:
-                raise Exception(f"The corresponding entity to the device "
-                                f"{device_id} was not deleted because it is "
-                                f"linked to multiple devices. ")
-            else:
-                try:
-                    from filip.clients.ngsi_v2 import ContextBrokerClient
-
-                    if cb_client:
-                        cb_client_local = deepcopy(cb_client)
-                    else:
-                        warnings.warn("No `ContextBrokerClient` "
-                                      "object providesd! Will try to generate "
-                                      "one. This usage is not recommended.")
-
-                        cb_client_local = ContextBrokerClient(
-                            url=cb_url,
-                            fiware_header=self.fiware_headers,
-                            headers=headers)
-
-                    cb_client_local.delete_entity(
-                        entity_id=device.entity_name,
-                        entity_type=device.entity_type)
-
-                except requests.RequestException as err:
-                    # Do not throw an error
-                    # It is only important that the entity does not exist after
-                    # this methode, not if this methode actively deleted it
-                    pass
-
-                cb_client_local.close()
-
-    def patch_device(self,
-                     device: Device,
-                     patch_entity: bool = True,
-                     cb_client: ContextBrokerClient = None,
-                     cb_url: AnyHttpUrl = settings.CB_URL) -> None:
-        """
-        Updates a device state in Fiware, if the device does not exists it
-        is created, else its values are updated.
-        If the device settings (endpoint,..) were changed the device and
-        entity are deleted and re-added.
-
-        If patch_entity is true the corresponding entity in the ContextBroker is
-        also correctly updated. Else only new attributes are added there.
-
-        Args:
-            device (Device): Device to be posted to /updated in Fiware
-            patch_entity (bool): If true the corresponding entity is
-                completely synced
-            cb_client (ContextBrokerClient):
-                Corresponding ContextBrokerClient object for entity manipulation
-            cb_url (AnyHttpUrl):
-                Url of the ContextBroker where the entity is found.
-                This will autogenerate an CB-Client, mirroring the information
-                of the IoTA-Client, e.g. FiwareHeader, and other headers
-                (not recommended!)
-
-        Returns:
-            None
-        """
-        try:
-            live_device = self.get_device(device_id=device.device_id)
-        except requests.RequestException:
-            # device does not exist yet, post it
-            self.post_device(device=device)
-            return
-
-        # if the device settings were changed we need to delete the device
-        # and repost it
-        settings_dict = {"device_id", "service", "service_path",
-                         "entity_name", "entity_type",
-                         "timestamp", "apikey", "endpoint",
-                         "protocol", "transport",
-                         "expressionLanguage"}
-
-        live_settings = live_device.model_dump(include=settings_dict)
-        new_settings = device.model_dump(include=settings_dict)
-
-        if not live_settings == new_settings:
-            self.delete_device(device_id=device.device_id,
-                               delete_entity=True,
-                               force_entity_deletion=True,
-                               cb_client=cb_client)
-            self.post_device(device=device)
-            return
-
-        # We are at a state where the device exists, but only attributes were
-        # changed.
-        # we need to update the device, and the context entry separately,
-        # as update device only takes over a part of the changes to the
-        # ContextBroker.
-
-        # update device
-        self.update_device(device=device)
-
-        # update context entry
-        # 1. build context entity from information in device
-        # 2. patch it
-        from filip.models.ngsi_v2.context import \
-            ContextEntity, NamedContextAttribute
-
-        def build_context_entity_from_device(device: Device) -> ContextEntity:
-            from filip.models.base import DataType
-            entity = ContextEntity(id=device.entity_name,
-                                   type=device.entity_type)
-
-            for command in device.commands:
-                entity.add_attributes([
-                    # Command attribute will be registered by the device_update
-                    NamedContextAttribute(
-                        name=f"{command.name}_info",
-                        type=DataType.COMMAND_RESULT
-                    ),
-                    NamedContextAttribute(
-                        name=f"{command.name}_status",
-                        type=DataType.COMMAND_STATUS
-                    )
-                ])
-            for attribute in device.attributes:
-                entity.add_attributes([
-                    NamedContextAttribute(
-                        name=attribute.name,
-                        type=DataType.STRUCTUREDVALUE,
-                        metadata=attribute.metadata
-                    )
-                ])
-            for static_attribute in device.static_attributes:
-                entity.add_attributes([
-                    NamedContextAttribute(
-                        name=static_attribute.name,
-                        type=static_attribute.type,
-                        value=static_attribute.value,
-                        metadata=static_attribute.metadata
-                    )
-                ])
-            return entity
-
-        if patch_entity:
-            from filip.clients.ngsi_v2 import ContextBrokerClient
-            if cb_client:
-                cb_client_local = deepcopy(cb_client)
-            else:
-                warnings.warn("No `ContextBrokerClient` object provided! "
-                              "Will try to generate one. "
-                              "This usage is not recommended.")
-
-                cb_client_local = ContextBrokerClient(
-                    url=cb_url,
-                    fiware_header=self.fiware_headers,
-                    headers=self.headers)
-
-            cb_client_local.patch_entity(
-                entity=build_context_entity_from_device(device))
-            cb_client_local.close()
-
-    def does_device_exists(self, device_id: str) -> bool:
-        """
-        Test if a device with the given id exists in Fiware
-        Args:
-            device_id (str)
-        Returns:
-            bool
-        """
-        try:
-            self.get_device(device_id=device_id)
-            return True
-        except requests.RequestException as err:
-            if not err.response.status_code == 404:
-                raise
-            return False
-
-    # LOG API
-    def get_loglevel_of_agent(self):
-        """
-        Get current loglevel of agent
-        Returns:
-
-        """
-        url = urljoin(self.base_url, 'admin/log')
-        headers = self.headers.copy()
-        del headers['fiware-service']
-        del headers['fiware-servicepath']
-        try:
-            res = self.get(url=url, headers=headers)
-            if res.ok:
-                return res.json()['level']
-            res.raise_for_status()
-        except requests.RequestException as err:
-            self.log_error(err=err)
-            raise
-
-    def change_loglevel_of_agent(self, level: str):
-        """
-        Change current loglevel of agent
-        
-        Args:
-            level:
-
-        Returns:
-
-        """
-        level = level.upper()
-        if level not in ['INFO', 'ERROR', 'FATAL', 'DEBUG', 'WARNING']:
-            raise KeyError("Given log level is not supported")
-
-        url = urljoin(self.base_url, 'admin/log')
-        headers = self.headers.copy()
-        del headers['fiware-service']
-        del headers['fiware-servicepath']
-        try:
-            res = self.put(url=url, headers=headers, params=level)
-            if res.ok:
-                self.logger.info("Loglevel of agent at %s "
-                                 "changed to '%s'", self.base_url, level)
-            else:
-                res.raise_for_status()
-        except requests.RequestException as err:
-            self.log_error(err=err)
-            raise
+"""
+IoT-Agent Module for API Client
+"""
+from __future__ import annotations
+
+import json
+from copy import deepcopy
+from typing import List, Dict, Set, TYPE_CHECKING, Union, Optional
+import warnings
+from urllib.parse import urljoin
+import requests
+from pydantic import AnyHttpUrl
+from pydantic.type_adapter import TypeAdapter
+from filip.config import settings
+from filip.clients.base_http_client import BaseHttpClient
+from filip.models.base import FiwareHeader
+from filip.models.ngsi_v2.iot import Device, ServiceGroup
+
+from filip.utils.filter import filter_device_list, filter_group_list
+
+if TYPE_CHECKING:
+    from filip.clients.ngsi_v2.cb import ContextBrokerClient
+
+
+class IoTAClient(BaseHttpClient):
+    """
+    Client for FIWARE IoT-Agents. The implementation follows the API
+    specifications from here:
+    https://iotagent-node-lib.readthedocs.io/en/latest/
+
+    Args:
+        url: Url of IoT-Agent
+        session (requests.Session):
+        fiware_header (FiwareHeader): fiware service and fiware service path
+        **kwargs (Optional): Optional arguments that ``request`` takes.
+    """
+
+    def __init__(self,
+                 url: str = None,
+                 *,
+                 session: requests.Session = None,
+                 fiware_header: FiwareHeader = None,
+                 **kwargs):
+        # set service url
+        url = url or settings.IOTA_URL
+        super().__init__(url=url,
+                         session=session,
+                         fiware_header=fiware_header,
+                         **kwargs)
+
+    # ABOUT API
+    def get_version(self) -> Dict:
+        """
+        Gets version of IoT Agent
+
+        Returns:
+            Dictionary with response
+        """
+        url = urljoin(self.base_url, 'iot/about')
+        try:
+            res = self.get(url=url, headers=self.headers)
+            if res.ok:
+                return res.json()
+            res.raise_for_status()
+        except requests.RequestException as err:
+            self.logger.error(err)
+        raise
+
+    # SERVICE GROUP API
+    def post_groups(self,
+                    service_groups: Union[ServiceGroup, List[ServiceGroup]],
+                    update: bool = False):
+        """
+        Creates a set of service groups for the given service and service_path.
+        The service_group and subservice information will taken from the
+        headers, overwriting any preexisting values.
+
+        Args:
+            service_groups (list of ServiceGroup): Service groups that will be
+            posted to the agent's API
+            update (bool): If service group already exists try to update its
+
+        Returns:
+            None
+        """
+        if not isinstance(service_groups, list):
+            service_groups = [service_groups]
+        for group in service_groups:
+            if group.service:
+                assert group.service == self.headers['fiware-service'], \
+                    "Service group service does not math fiware service"
+            if group.subservice:
+                assert group.subservice == self.headers['fiware-servicepath'], \
+                    "Service group subservice does not math fiware service path"
+
+        url = urljoin(self.base_url, 'iot/services')
+        headers = self.headers
+        data = {'services': [group.model_dump(exclude={'service', 'subservice'},
+                                              exclude_none=True)
+                             for group in service_groups]}
+        try:
+            res = self.post(url=url, headers=headers, json=data)
+            if res.ok:
+                self.logger.info("Services successfully posted")
+            elif res.status_code == 409:
+                self.logger.warning(res.text)
+                if len(service_groups) > 1:
+                    self.logger.info("Trying to split bulk operation into "
+                                     "single operations")
+                    for group in service_groups:
+                        self.post_group(service_group=group, update=update)
+                elif update is True:
+                    self.update_group(service_group=service_groups[0],
+                                      fields=None)
+                else:
+                    res.raise_for_status()
+            else:
+                res.raise_for_status()
+        except requests.RequestException as err:
+            self.log_error(err=err, msg=None)
+            raise
+
+    def post_group(self, service_group: ServiceGroup, update: bool = False):
+        """
+        Single service registration but using the bulk operation in background
+
+        Args:
+            service_group (ServiceGroup): Service that will be posted to the
+            agent's API
+            update (bool):
+
+        Returns:
+            None
+        """
+        return self.post_groups(service_groups=[service_group],
+                                update=update)
+
+    def get_group_list(self) -> List[ServiceGroup]:
+        r"""
+        Retrieves service_group groups from the database. If the servicepath
+        header has the wildcard expression, /\*, all the subservices for the
+        service_group are returned. The specific subservice parameters are
+        returned in any other case.
+
+        Returns:
+
+        """
+        url = urljoin(self.base_url, 'iot/services')
+        headers = self.headers
+        try:
+            res = self.get(url=url, headers=headers)
+            if res.ok:
+                ta = TypeAdapter(List[ServiceGroup])
+                return ta.validate_python(res.json()['services'])
+            res.raise_for_status()
+        except requests.RequestException as err:
+            self.log_error(err=err, msg=None)
+            raise
+
+    def get_group(self, *, resource: str, apikey: str) -> ServiceGroup:
+        """
+        Retrieves service_group groups from the database based on resource and
+        apikey
+        Args:
+            resource:
+            apikey:
+        Returns:
+
+        """
+        groups = self.get_group_list()
+        groups = filter_group_list(group_list=groups, resources=resource, apikeys=apikey)
+        if len(groups) == 1:
+            group = groups[0]
+            return group
+        elif len(groups) == 0:
+            raise KeyError(f"Service group with resource={resource} and apikey={apikey} was not found")
+        else:
+            raise NotImplementedError("There is a wierd error, try get_group_list() for debugging")
+
+    def update_groups(self, *,
+                      service_groups: Union[ServiceGroup, List[ServiceGroup]],
+                      add: False,
+                      fields: Union[Set[str], List[str]] = None) -> None:
+        """
+        Bulk operation for service group update.
+        Args:
+            fields:
+            service_groups:
+            add:
+
+        Returns:
+
+        """
+        if not isinstance(service_groups, list):
+            service_groups = [service_groups]
+        for group in service_groups:
+            self.update_group(service_group=group, fields=fields, add=add)
+
+    def update_group(self, *, service_group: ServiceGroup,
+                     fields: Union[Set[str], List[str]] = None,
+                     add: bool = True):
+        """
+        Modifies the information for a service group configuration, identified
+        by the resource and apikey query parameters. Takes a service group body
+        as the payload. The body does not have to be complete: for incomplete
+        bodies, just the existing attributes will be updated
+        
+        Args:
+            service_group (ServiceGroup): Service to update.
+            fields: Fields of the service_group to update. If 'None' all allowed
+            fields will be updated
+            add:
+        Returns:
+            None
+        """
+        if fields:
+            if isinstance(fields, list):
+                fields = set(fields)
+        else:
+            fields = None
+        url = urljoin(self.base_url, 'iot/services')
+        headers = self.headers
+        params = service_group.model_dump(include={'resource', 'apikey'})
+        try:
+            res = self.put(url=url,
+                           headers=headers,
+                           params=params,
+                           json=service_group.model_dump(
+                               include=fields,
+                               exclude={'service', 'subservice'},
+                               exclude_none=True))
+            if res.ok:
+                self.logger.info("ServiceGroup updated!")
+            elif (res.status_code == 404) & (add is True):
+                self.post_group(service_group=service_group)
+            else:
+                res.raise_for_status()
+        except requests.RequestException as err:
+            self.log_error(err=err, msg=None)
+            raise
+
+    def delete_group(self, *, resource: str, apikey: str):
+        """
+        Deletes a service group in in the IoT-Agent
+        
+        Args:
+            resource:
+            apikey:
+
+        Returns:
+
+        """
+        url = urljoin(self.base_url, 'iot/services')
+        headers = self.headers
+        params = {'resource': resource,
+                  'apikey': apikey}
+        try:
+            res = self.delete(url=url, headers=headers, params=params)
+            if res.ok:
+                self.logger.info("ServiceGroup with resource: '%s' and "
+                                 "apikey: '%s' successfully deleted!",
+                                 resource, apikey)
+            else:
+                res.raise_for_status()
+        except requests.RequestException as err:
+            msg = f"Could not delete ServiceGroup with resource " \
+                  f"'{resource}' and apikey '{apikey}'!"
+            self.log_error(err=err, msg=msg)
+            raise
+
+    # DEVICE API
+    def post_devices(self, *, devices: Union[Device, List[Device]],
+                     update: bool = False) -> None:
+        """
+        Post a device from the device registry. No payload is required
+        or received.
+        If a device already exists in can be updated with update = True
+        Args:
+            devices (list of Devices):
+            update (bool):  Whether if the device is already existent it
+            should be updated
+        Returns:
+            None
+        """
+        if not isinstance(devices, list):
+            devices = [devices]
+        url = urljoin(self.base_url, 'iot/devices')
+        headers = self.headers
+        data = {"devices": [json.loads(device.model_dump_json(exclude_none=True)
+                                       ) for device in devices]}
+        try:
+            res = self.post(url=url, headers=headers, json=data)
+            if res.ok:
+                self.logger.info("Devices successfully posted!")
+            else:
+                res.raise_for_status()
+        except requests.RequestException as err:
+            if update:
+                return self.update_devices(devices=devices, add=False)
+            msg = "Could not post devices"
+            self.log_error(err=err, msg=msg)
+            raise
+
+    def post_device(self, *, device: Device, update: bool = False) -> None:
+        """
+        Post a device configuration to the IoT-Agent
+        
+        Args:
+            device: IoT device configuration to send
+            update: update device if configuration already exists
+
+        Returns:
+            None
+        """
+        return self.post_devices(devices=[device], update=update)
+
+    def get_device_list(self, *,
+                        limit: int = None,
+                        offset: int = None,
+                        device_ids: Union[str, List[str]] = None,
+                        entity_names: Union[str, List[str]] = None,
+                        entity_types: Union[str, List[str]] = None) -> List[Device]:
+        """
+        Returns a list of all the devices in the device registry with all
+        its data. The IoTAgent now only supports "limit" and "offset" as
+        request parameters.
+
+        Args:
+            limit:
+                if present, limits the number of devices returned in the
+                list. Must be a number between 1 and 1000.
+            offset:
+                if present, skip that number of devices from the original
+                query.
+            device_ids:
+                List of device_ids. If given, only devices with matching ids
+                will be returned
+            entity_names:
+                The entity_ids of the devices. If given, only the devices
+                with the specified entity_id will be returned
+            entity_types:
+                The entity_type of the device. If given, only the devices
+                with the specified entity_type will be returned
+
+        Returns:
+            List of matching devices
+        """
+        if limit:
+            if not 1 < limit < 1000:
+                self.logger.error("'limit' must be an integer between 1 and "
+                                  "1000!")
+                raise ValueError
+        url = urljoin(self.base_url, 'iot/devices')
+        headers = self.headers
+        params = {key: value for key, value in locals().items() if value is not
+                  None}
+        try:
+            res = self.get(url=url, headers=headers, params=params)
+            if res.ok:
+                ta = TypeAdapter(List[Device])
+                devices = ta.validate_python(res.json()['devices'])
+                # filter by device_ids, entity_names or entity_types
+                devices = filter_device_list(devices,
+                                             device_ids,
+                                             entity_names,
+                                             entity_types)
+                return devices
+            res.raise_for_status()
+        except requests.RequestException as err:
+            self.log_error(err=err, msg=None)
+            raise
+
+    def get_device(self, *, device_id: str) -> Device:
+        """
+        Returns all the information about a particular device.
+        
+        Args:
+            device_id:
+        Raises:
+            requests.RequestException, if device does not exist
+        Returns:
+            Device
+
+        """
+        url = urljoin(self.base_url, f'iot/devices/{device_id}')
+        headers = self.headers
+        try:
+            res = self.get(url=url, headers=headers)
+            if res.ok:
+                return Device.model_validate(res.json())
+            res.raise_for_status()
+        except requests.RequestException as err:
+            msg = f"Device {device_id} was not found"
+            self.log_error(err=err, msg=msg)
+            raise
+
+    def update_device(self, *, device: Device, add: bool = True) -> None:
+        """
+        Updates a device from the device registry.
+        Adds, removes attributes from the device entry and changes
+        attributes values.
+        It does not change device settings (endpoint,..) and only adds
+        attributes to the corresponding entity, their it does not
+        change any attribute value and does not delete removed attributes
+
+        Args:
+            device:
+            add (bool): If device not found add it
+        Returns:
+            None
+        """
+        url = urljoin(self.base_url, f'iot/devices/{device.device_id}')
+        headers = self.headers
+        try:
+            res = self.put(url=url, headers=headers, json=device.model_dump(
+                include={'attributes', 'lazy', 'commands', 'static_attributes'},
+                exclude_none=True))
+            if res.ok:
+                self.logger.info("Device '%s' successfully updated!",
+                                 device.device_id)
+            elif (res.status_code == 404) & (add is True):
+                self.post_device(device=device, update=False)
+            else:
+                res.raise_for_status()
+        except requests.RequestException as err:
+            msg = f"Could not update device '{device.device_id}'"
+            self.log_error(err=err, msg=msg)
+            raise
+
+    def update_devices(self, *, devices: Union[Device, List[Device]],
+                       add: False) -> None:
+        """
+        Bulk operation for device update.
+        Args:
+            devices:
+            add:
+
+        Returns:
+
+        """
+        if not isinstance(devices, list):
+            devices = [devices]
+        for device in devices:
+            self.update_device(device=device, add=add)
+
+    def delete_device(self, *, device_id: str,
+                      cb_url: AnyHttpUrl = settings.CB_URL,
+                      delete_entity: bool = False,
+                      force_entity_deletion: bool = False,
+                      cb_client: ContextBrokerClient = None,
+                      ) -> None:
+        """
+        Remove a device from the device registry. No payload is required
+        or received.
+        
+        Args:
+            device_id: str, ID of Device
+            delete_entity:  False -> Only delete the device entry,
+                                     the automatically created and linked
+                                     context-entity will continue to
+                                     exist in Fiware
+                            True -> Also delete the automatically
+                                    created and linked context-entity
+                                    If multiple devices are linked to this
+                                    entity, this operation is not executed and
+                                    an exception is raised
+            force_entity_deletion:
+                bool, if delete_entity is true and multiple devices are linked
+                to the linked entity, delete it and do not raise an error
+            cb_client (ContextBrokerClient):
+                Corresponding ContextBrokerClient object for entity manipulation
+            cb_url (AnyHttpUrl):
+                Url of the ContextBroker where the entity is found.
+                This will autogenerate an CB-Client, mirroring the information
+                of the IoTA-Client, e.g. FiwareHeader, and other headers
+                (not recommended!)
+
+        Returns:
+            None
+        """
+        url = urljoin(self.base_url, f'iot/devices/{device_id}', )
+        headers = self.headers
+
+        device = self.get_device(device_id=device_id)
+
+        try:
+            res = self.delete(url=url, headers=headers)
+            if res.ok:
+                self.logger.info("Device '%s' successfully deleted!", device_id)
+            else:
+                res.raise_for_status()
+        except requests.RequestException as err:
+            msg = f"Could not delete device {device_id}!"
+            self.log_error(err=err, msg=msg)
+            raise
+
+        if delete_entity:
+            # An entity can technically belong to multiple devices
+            # Only delete the entity if
+            devices = self.get_device_list(entity_names=[device.entity_name])
+
+            # Zero because we count the remaining devices
+            if len(devices) > 0 and not force_entity_deletion:
+                raise Exception(f"The corresponding entity to the device "
+                                f"{device_id} was not deleted because it is "
+                                f"linked to multiple devices. ")
+            else:
+                try:
+                    from filip.clients.ngsi_v2 import ContextBrokerClient
+
+                    if cb_client:
+                        cb_client_local = deepcopy(cb_client)
+                    else:
+                        warnings.warn("No `ContextBrokerClient` "
+                                      "object providesd! Will try to generate "
+                                      "one. This usage is not recommended.")
+
+                        cb_client_local = ContextBrokerClient(
+                            url=cb_url,
+                            fiware_header=self.fiware_headers,
+                            headers=headers)
+
+                    cb_client_local.delete_entity(
+                        entity_id=device.entity_name,
+                        entity_type=device.entity_type)
+
+                except requests.RequestException as err:
+                    # Do not throw an error
+                    # It is only important that the entity does not exist after
+                    # this methode, not if this methode actively deleted it
+                    pass
+
+                cb_client_local.close()
+
+    def patch_device(self,
+                     device: Device,
+                     patch_entity: bool = True,
+                     cb_client: ContextBrokerClient = None,
+                     cb_url: AnyHttpUrl = settings.CB_URL) -> None:
+        """
+        Updates a device state in Fiware, if the device does not exists it
+        is created, else its values are updated.
+        If the device settings (endpoint,..) were changed the device and
+        entity are deleted and re-added.
+
+        If patch_entity is true the corresponding entity in the ContextBroker is
+        also correctly updated. Else only new attributes are added there.
+
+        Args:
+            device (Device): Device to be posted to /updated in Fiware
+            patch_entity (bool): If true the corresponding entity is
+                completely synced
+            cb_client (ContextBrokerClient):
+                Corresponding ContextBrokerClient object for entity manipulation
+            cb_url (AnyHttpUrl):
+                Url of the ContextBroker where the entity is found.
+                This will autogenerate an CB-Client, mirroring the information
+                of the IoTA-Client, e.g. FiwareHeader, and other headers
+                (not recommended!)
+
+        Returns:
+            None
+        """
+        try:
+            live_device = self.get_device(device_id=device.device_id)
+        except requests.RequestException:
+            # device does not exist yet, post it
+            self.post_device(device=device)
+            return
+
+        # if the device settings were changed we need to delete the device
+        # and repost it
+        settings_dict = {"device_id", "service", "service_path",
+                         "entity_name", "entity_type",
+                         "timestamp", "apikey", "endpoint",
+                         "protocol", "transport",
+                         "expressionLanguage"}
+
+        live_settings = live_device.model_dump(include=settings_dict)
+        new_settings = device.model_dump(include=settings_dict)
+
+        if not live_settings == new_settings:
+            self.delete_device(device_id=device.device_id,
+                               delete_entity=True,
+                               force_entity_deletion=True,
+                               cb_client=cb_client)
+            self.post_device(device=device)
+            return
+
+        # We are at a state where the device exists, but only attributes were
+        # changed.
+        # we need to update the device, and the context entry separately,
+        # as update device only takes over a part of the changes to the
+        # ContextBroker.
+
+        # update device
+        self.update_device(device=device)
+
+        # update context entry
+        # 1. build context entity from information in device
+        # 2. patch it
+        from filip.models.ngsi_v2.context import \
+            ContextEntity, NamedContextAttribute
+
+        def build_context_entity_from_device(device: Device) -> ContextEntity:
+            from filip.models.base import DataType
+            entity = ContextEntity(id=device.entity_name,
+                                   type=device.entity_type)
+
+            for command in device.commands:
+                entity.add_attributes([
+                    # Command attribute will be registered by the device_update
+                    NamedContextAttribute(
+                        name=f"{command.name}_info",
+                        type=DataType.COMMAND_RESULT
+                    ),
+                    NamedContextAttribute(
+                        name=f"{command.name}_status",
+                        type=DataType.COMMAND_STATUS
+                    )
+                ])
+            for attribute in device.attributes:
+                entity.add_attributes([
+                    NamedContextAttribute(
+                        name=attribute.name,
+                        type=DataType.STRUCTUREDVALUE,
+                        metadata=attribute.metadata
+                    )
+                ])
+            for static_attribute in device.static_attributes:
+                entity.add_attributes([
+                    NamedContextAttribute(
+                        name=static_attribute.name,
+                        type=static_attribute.type,
+                        value=static_attribute.value,
+                        metadata=static_attribute.metadata
+                    )
+                ])
+            return entity
+
+        if patch_entity:
+            from filip.clients.ngsi_v2 import ContextBrokerClient
+            if cb_client:
+                cb_client_local = deepcopy(cb_client)
+            else:
+                warnings.warn("No `ContextBrokerClient` object provided! "
+                              "Will try to generate one. "
+                              "This usage is not recommended.")
+
+                cb_client_local = ContextBrokerClient(
+                    url=cb_url,
+                    fiware_header=self.fiware_headers,
+                    headers=self.headers)
+
+            cb_client_local.patch_entity(
+                entity=build_context_entity_from_device(device))
+            cb_client_local.close()
+
+    def does_device_exists(self, device_id: str) -> bool:
+        """
+        Test if a device with the given id exists in Fiware
+        Args:
+            device_id (str)
+        Returns:
+            bool
+        """
+        try:
+            self.get_device(device_id=device_id)
+            return True
+        except requests.RequestException as err:
+            if not err.response.status_code == 404:
+                raise
+            return False
+
+    # LOG API
+    def get_loglevel_of_agent(self):
+        """
+        Get current loglevel of agent
+        Returns:
+
+        """
+        url = urljoin(self.base_url, 'admin/log')
+        headers = self.headers.copy()
+        del headers['fiware-service']
+        del headers['fiware-servicepath']
+        try:
+            res = self.get(url=url, headers=headers)
+            if res.ok:
+                return res.json()['level']
+            res.raise_for_status()
+        except requests.RequestException as err:
+            self.log_error(err=err)
+            raise
+
+    def change_loglevel_of_agent(self, level: str):
+        """
+        Change current loglevel of agent
+        
+        Args:
+            level:
+
+        Returns:
+
+        """
+        level = level.upper()
+        if level not in ['INFO', 'ERROR', 'FATAL', 'DEBUG', 'WARNING']:
+            raise KeyError("Given log level is not supported")
+
+        url = urljoin(self.base_url, 'admin/log')
+        headers = self.headers.copy()
+        del headers['fiware-service']
+        del headers['fiware-servicepath']
+        try:
+            res = self.put(url=url, headers=headers, params=level)
+            if res.ok:
+                self.logger.info("Loglevel of agent at %s "
+                                 "changed to '%s'", self.base_url, level)
+            else:
+                res.raise_for_status()
+        except requests.RequestException as err:
+            self.log_error(err=err)
+            raise
```

### Comparing `filip-0.3.0/filip/clients/ngsi_v2/quantumleap.py` & `filip-0.4.0/filip/clients/ngsi_v2/quantumleap.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,1119 +1,1117 @@
-"""
-TimeSeries Module for QuantumLeap API Client
-"""
-import logging
-import time
-from math import inf
-from collections import deque
-from itertools import count
-from typing import Dict, List, Union, Deque, Optional
-from urllib.parse import urljoin
-import requests
-from pydantic import AnyHttpUrl
-from pydantic.type_adapter import TypeAdapter
-from filip import settings
-from filip.clients.base_http_client import BaseHttpClient
-from filip.models.base import FiwareHeader
-from filip.models.ngsi_v2.subscriptions import Message
-from filip.models.ngsi_v2.timeseries import \
-    AggrPeriod, \
-    AggrMethod, \
-    AggrScope, \
-    AttributeValues, \
-    TimeSeries, \
-    TimeSeriesHeader
-from filip.utils.validators import validate_http_url
-
-logger = logging.getLogger(__name__)
-
-
-class QuantumLeapClient(BaseHttpClient):
-    """
-    Implements functions to use the FIWARE's QuantumLeap, which subscribes to an
-    Orion Context Broker and stores the subscription data in a time series
-    database (CrateDB). Further Information:
-    https://smartsdk.github.io/ngsi-timeseries-api/#quantumleap
-    https://app.swaggerhub.com/apis/heikkilv/quantumleap-api/
-
-    Args:
-        url: url of the quantumleap service
-        session (Optional):
-        fiware_header:
-        **kwargs:
-    """
-
-    def __init__(self,
-                 url: str = None,
-                 *,
-                 session: requests.Session = None,
-                 fiware_header: FiwareHeader = None,
-                 **kwargs):
-        # set service url
-        url = url or settings.QL_URL
-        super().__init__(url=url,
-                         session=session,
-                         fiware_header=fiware_header,
-                         **kwargs)
-
-    # META API ENDPOINTS
-    def get_version(self) -> Dict:
-        """
-        Gets version of QuantumLeap-Service.
-
-        Returns:
-            Dictionary with response
-        """
-        url = urljoin(self.base_url, '/version')
-        try:
-            res = self.get(url=url)
-            if res.ok:
-                return res.json()
-            res.raise_for_status()
-        except requests.exceptions.RequestException as err:
-            self.logger.error(err)
-            raise
-
-    def get_health(self) -> Dict:
-        """
-        This endpoint is intended for administrators of QuantumLeap. Using the
-        information returned by this endpoint they can diagnose problems in the
-        service or its dependencies. This information is also useful for cloud
-        tools such as orchestrators and load balancers with rules based on
-        health-checks. Due to the lack of a standardized response format, we
-        base the implementation on the draft of
-        https://inadarei.github.io/rfc-healthcheck/
-
-        Returns:
-            Dictionary with response
-        """
-        url = urljoin(self.base_url, '/health')
-        try:
-            res = self.get(url=url)
-            if res.ok:
-                return res.json()
-            res.raise_for_status()
-        except requests.exceptions.RequestException as err:
-            self.logger.error(err)
-            raise
-
-    def post_config(self):
-        """
-        (To Be Implemented) Customize your persistence configuration to
-        better suit your needs.
-        """
-        raise NotImplementedError("Endpoint to be implemented..")
-
-    # INPUT API ENDPOINTS
-    def post_notification(self, notification: Message):
-        """
-        Notify QuantumLeap the arrival of a new NGSI notification.
-
-        Args:
-            notification: Notification Message Object
-        """
-        url = urljoin(self.base_url, '/v2/notify')
-        headers = self.headers.copy()
-        data = []
-        for entity in notification.data:
-            data.append(entity.model_dump(exclude_unset=True,
-                                          exclude_defaults=True,
-                                          exclude_none=True))
-        data_set = {
-            "data": data,
-            "subscriptionId": notification.subscriptionId
-        }
-
-        try:
-            res = self.post(
-                url=url,
-                headers=headers,
-                json=data_set)
-            if res.ok:
-                self.logger.debug(res.text)
-            else:
-                res.raise_for_status()
-        except requests.exceptions.RequestException as err:
-            msg = f"Could not post notification for subscription id " \
-                  f"{notification.subscriptionId}"
-            self.log_error(err=err, msg=msg)
-            raise
-
-    def post_subscription(self,
-                          cb_url: Union[AnyHttpUrl, str],
-                          ql_url: Union[AnyHttpUrl, str],
-                          entity_type: str = None,
-                          entity_id: str = None,
-                          id_pattern: str = None,
-                          attributes: str = None,
-                          observed_attributes: str = None,
-                          notified_attributes: str = None,
-                          throttling: int = None,
-                          time_index_attribute: str = None):
-        """
-        Subscribe QL to process Orion notifications of certain type.
-        This endpoint simplifies the creation of the subscription in orion
-        that will generate the notifications to be consumed by QuantumLeap in
-        order to save historical records. If you want an advanced specification
-        of the notifications, you can always create the subscription in orion
-        at your will. This endpoint just aims to simplify the common use case.
-
-        Args:
-            cb_url:
-                url of the context broker
-            ql_url:
-                The url where Orion can reach QuantumLeap. Do not include
-                specific paths.
-            entity_type (String):
-                The type of entities for which to create a
-                subscription, so as to persist historical data of entities of
-                this type.
-            entity_id (String):
-                Id of the entity to track. If specified, it
-                takes precedence over the idPattern parameter.
-            id_pattern (String): The pattern covering the entity ids for which
-                to subscribe. If not specified, QL will track all entities of
-                the specified type.
-            attributes (String): Comma-separated list of attribute names to
-                track.
-            observed_attributes (String): Comma-separated list of attribute
-                names to track.
-            notified_attributes (String): Comma-separated list of attribute
-                names to be used to restrict the data of which QL will keep a
-                history.
-            throttling (int): Minimal period of time in seconds which must
-                elapse between two consecutive notifications.
-            time_index_attribute (String): The name of a custom attribute to be
-                used as a
-            time index.
-        """
-        headers = self.headers.copy()
-        params = {}
-        url = urljoin(self.base_url, '/v2/subscribe')
-        validate_http_url(cb_url)
-        cb_url = urljoin(str(cb_url), '/v2')
-        params.update({'orionUrl': cb_url.encode('utf-8')})
-
-        validate_http_url(ql_url)
-        ql_url = urljoin(str(ql_url), '/v2')
-        params.update({'quantumleapUrl': ql_url.encode('utf-8')})
-
-        if entity_type:
-            params.update({'entityType': entity_type})
-        if entity_id:
-            params.update({'entityId': entity_id})
-        if id_pattern:
-            params.update({'idPattern': id_pattern})
-        if attributes:
-            params.update({'attributes': attributes})
-        if observed_attributes:
-            params.update({'observedAttributes': observed_attributes})
-        if notified_attributes:
-            params.update({'notifiedAttributes': notified_attributes})
-        if throttling or throttling == 0:
-            if throttling >= 0 and type(throttling) == int:
-                params.update({'throttling': throttling})
-            else:
-                raise TypeError("Throttling must be a positive integer or zero")
-        if time_index_attribute:
-            params.update({'timeIndexAttribute': time_index_attribute})
-
-        try:
-            res = self.post(url=url, headers=headers, params=params)
-            if res.ok:
-                msg = "Subscription created successfully!"
-                self.logger.info(msg)
-
-            res.raise_for_status()
-        except requests.exceptions.RequestException as err:
-            msg = "Could not create subscription."
-            self.log_error(err=err, msg=msg)
-            raise
-
-    def delete_entity(self, entity_id: str,
-                      entity_type: Optional[str] = None) -> str:
-        """
-        Given an entity (with type and id), delete all its historical records.
-
-        Args:
-            entity_id (String): Entity id is required.
-            entity_type (Optional[String]): Entity type if entity_id alone
-                can not uniquely define the entity.
-
-        Raises:
-            RequestException, if entity was not found
-            Exception, if deleting was not successful
-
-        Returns:
-            The entity_id of entity that is deleted.
-        """
-        url = urljoin(self.base_url, f'/v2/entities/{entity_id}')
-        headers = self.headers.copy()
-        if entity_type is not None:
-            params = {'type': entity_type}
-        else:
-            params = {}
-
-        # The deletion does not always resolves in a success even if an ok is
-        # returned.
-        # Try to delete multiple times with incrementing waits.
-        # If the entity is no longer found the methode returns with a success
-        # If the deletion attempt fails after the 10th try, raise an
-        # Exception: it could not be deleted
-        counter = 0
-        while counter < 10:
-            self.delete(url=url, headers=headers, params=params)
-            try:
-                self.get_entity_by_id(entity_id=entity_id,
-                                      entity_type=entity_type)
-            except requests.exceptions.RequestException as err:
-                self.logger.info("Entity id '%s' successfully deleted!",
-                                 entity_id)
-                return entity_id
-            time.sleep(counter * 5)
-            counter += 1
-
-        msg = f"Could not delete QL entity of id {entity_id}"
-        logger.error(msg=msg)
-        raise Exception(msg)
-
-    def delete_entity_type(self, entity_type: str) -> str:
-        """
-        Given an entity type, delete all the historical records of all
-        entities of such type.
-        Args:
-            entity_type (String): Type of entities data to be deleted.
-        Returns:
-            Entity type of the entities deleted.
-        """
-        url = urljoin(self.base_url, f'/v2/types/{entity_type}')
-        headers = self.headers.copy()
-        try:
-            res = self.delete(url=url, headers=headers)
-            if res.ok:
-                self.logger.info("Entities of type '%s' successfully deleted!",
-                                 entity_type)
-                return entity_type
-            res.raise_for_status()
-        except requests.exceptions.RequestException as err:
-            msg = f"Could not delete entities of type {entity_type}"
-            self.log_error(err=err, msg=msg)
-            raise
-
-    # QUERY API ENDPOINTS
-    def __query_builder(self,
-                        url,
-                        *,
-                        entity_id: str = None,
-                        options: str = None,
-                        entity_type: str = None,
-                        aggr_method: Union[str, AggrMethod] = None,
-                        aggr_period: Union[str, AggrPeriod] = None,
-                        from_date: str = None,
-                        to_date: str = None,
-                        last_n: int = None,
-                        limit: int = 10000,
-                        offset: int = 0,
-                        georel: str = None,
-                        geometry: str = None,
-                        coords: str = None,
-                        attrs: str = None,
-                        aggr_scope: Union[str, AggrScope] = None
-                        ) -> Deque[Dict]:
-        """
-        Private Function to call respective API endpoints, chops large
-        requests into multiple single requests and merges the
-        responses
-
-        Args:
-            url:
-            entity_id:
-            options:
-            entity_type:
-            aggr_method:
-            aggr_period:
-            from_date:
-            to_date:
-            last_n:
-            limit:
-                Maximum number of results to retrieve in a single response.
-            offset:
-                Offset to apply to the response results. For example, if the
-                query was to return 10 results and you use an offset of 1, the
-                response will return the last 9 values. Make sure you don't
-                give more offset than the number of results.
-            georel:
-            geometry:
-            coords:
-            attrs:
-            aggr_scope:
-
-        Returns:
-            Dict
-        """
-        params = {}
-        headers = self.headers.copy()
-        max_records_per_request = 10000
-        # create a double ending queue
-        res_q: Deque[Dict] = deque([])
-
-        if options:
-            params.update({'options': options})
-        if entity_type:
-            params.update({'type': entity_type})
-        if aggr_method:
-            aggr_method = AggrMethod(aggr_method)
-            params.update({'aggrMethod': aggr_method.value})
-        if aggr_period:
-            aggr_period = AggrPeriod(aggr_period)
-            params.update({'aggrPeriod': aggr_period.value})
-        if from_date:
-            params.update({'fromDate': from_date})
-        if to_date:
-            params.update({'toDate': to_date})
-        # These values are required for the integrated pagination mechanism
-        # maximum items per request
-        if limit is None:
-            limit = inf
-        if offset is None:
-            offset = 0
-        if georel:
-            params.update({'georel': georel})
-        if coords:
-            params.update({'coords': coords})
-        if geometry:
-            params.update({'geometry': geometry})
-        if attrs:
-            params.update({'attrs': attrs})
-        if aggr_scope:
-            aggr_scope = AggrScope(aggr_scope)
-            params.update({'aggr_scope': aggr_scope.value})
-        if entity_id:
-            params.update({'id': entity_id})
-
-        # This loop will chop large requests into smaller junks.
-        # The individual functions will then merge the final response models
-        for i in count(0, max_records_per_request):
-            try:
-                params['offset'] = offset + i
-
-                params['limit'] = min(limit - i, max_records_per_request)
-                if params['limit'] <= 0:
-                    break
-
-                if last_n:
-                    params['lastN'] = min(last_n - i, max_records_per_request)
-                    if params['lastN'] <= 0:
-                        break
-
-                res = self.get(url=url, params=params, headers=headers)
-
-                if res.ok:
-                    self.logger.debug('Received: %s', res.json())
-
-                    # revert append direction when using last_n
-                    if last_n:
-                        res_q.appendleft(res.json())
-                    else:
-                        res_q.append(res.json())
-                res.raise_for_status()
-
-            except requests.exceptions.RequestException as err:
-                if err.response.status_code == 404 and \
-                        err.response.json().get('error') == 'Not Found' and \
-                        len(res_q) > 0:
-                    break
-                else:
-                    msg = "Could not load entity data"
-                    self.log_error(err=err, msg=msg)
-                    raise
-
-        self.logger.info("Successfully retrieved entity data")
-        return res_q
-
-    # v2/entities
-    def get_entities(self, *,
-                     entity_type: str = None,
-                     from_date: str = None,
-                     to_date: str = None,
-                     limit: int = 10000,
-                     offset: int = None
-                     ) -> List[TimeSeriesHeader]:
-        """
-        Get list of all available entities and their context information
-        about EntityType and last update date.
-
-        Args:
-            entity_type (str): Comma-separated list of entity types whose data
-                are to be included in the response. Use only one (no comma)
-                when required. If used to resolve ambiguity for the given
-                entityId, make sure the given entityId exists for this
-                entityType.
-            from_date (str): The starting date and time (inclusive) from which
-                the context information is queried. Must be in ISO8601 format
-                (e.g., 2018-01-05T15:44:34)
-            to_date (str): The final date and time (inclusive) from which the
-                context information is queried. Must be in ISO8601 format
-                (e.g., 2018-01-05T15:44:34).
-            limit (int): Maximum number of results to be retrieved.
-                Default value : 10000
-            offset (int): Offset for the results.
-
-        Returns:
-            List of TimeSeriesHeader
-        """
-        url = urljoin(self.base_url, 'v2/entities')
-        res = self.__query_builder(url=url,
-                                   entity_type=entity_type,
-                                   from_date=from_date,
-                                   to_date=to_date,
-                                   limit=limit,
-                                   offset=offset)
-        ta = TypeAdapter(List[TimeSeriesHeader])
-        return ta.validate_python(res[0])
-
-    # /entities/{entityId}
-    def get_entity_by_id(self,
-                         entity_id: str,
-                         *,
-                         attrs: str = None,
-                         entity_type: str = None,
-                         aggr_method: Union[str, AggrMethod] = None,
-                         aggr_period: Union[str, AggrPeriod] = None,
-                         from_date: str = None,
-                         to_date: str = None,
-                         last_n: int = None,
-                         limit: int = 10000,
-                         offset: int = None,
-                         georel: str = None,
-                         geometry: str = None,
-                         coords: str = None,
-                         options: str = None
-                         ) -> TimeSeries:
-
-        """
-        History of N attributes of a given entity instance
-        For example, query max water level of the central tank throughout the
-        last year. Queries can get more
-        sophisticated with the use of filters and query attributes.
-
-        Args:
-            entity_id (String): Entity id is required.
-            attrs (String):
-                Comma-separated list of attribute names whose data are to be
-                included in the response. The attributes are retrieved in the
-                order specified by this parameter. If not specified, all
-                attributes are included in the response in arbitrary order.
-            entity_type (String): Comma-separated list of entity types whose
-                data are to be included in the response.
-            aggr_method (String):
-                The function to apply to the raw data filtered by the query
-                parameters. If not given, the returned data are the same raw
-                inserted data.
-
-                Allowed values: count, sum, avg, min, max
-            aggr_period (String):
-                If not defined, the aggregation will apply to all the values
-                contained in the search result. If defined, the aggregation
-                function will instead be applied N times, once for each
-                period, and all those results will be considered for the
-                response. For example, a query asking for the average
-                temperature of an attribute will typically return 1 value.
-                However, with an aggregationPeriod of day, you get the daily
-                average of the temperature instead (more than one value
-                assuming you had measurements across many days within the
-                scope of your search result). aggrPeriod must be accompanied
-                by an aggrMethod, and the aggrMethod will be applied to all
-                the numeric attributes specified in attrs; the rest of the
-                non-numerical attrs will be ignored. By default, the response
-                is grouped by entity_id. See aggrScope to create aggregation
-                across entities:
-
-                Allowed values: year, month, day, hour, minute, second
-
-            from_date (String):
-                The starting date and time (inclusive) from which the context
-                information is queried. Must be in ISO8601 format (e.g.,
-                2018-01-05T15:44:34)
-            to_date (String):
-                The final date and time (inclusive) from which the context
-                information is queried. Must be in ISO8601 format (e.g.,
-                2018-01-05T15:44:34)
-            last_n (int):
-                Used to request only the last N values that satisfy the
-                request conditions.
-            limit (int): Maximum number of results to be retrieved.
-                Default value : 10000
-            offset (int):
-                Offset to apply to the response results.
-            georel (String):
-                It specifies a spatial relationship between matching entities
-                and a reference shape (geometry). This parameter is used to
-                perform geographical queries with the same semantics as in the
-                FIWARE-NGSI v2 Specification. Full details can be found in the
-                Geographical Queries section of the specification:
-                https://fiware.github.io/specifications/ngsiv2/stable/.
-            geometry (String):
-                Required if georel is specified.  point, line, polygon, box
-            coords (String):
-                Optional but required if georel is specified. This parameter
-                defines the reference shape (geometry) in terms of WGS 84
-                coordinates and has the same semantics as in the
-                FIWARE-NGSI v2 Specification, except we only accept coordinates
-                in decimal degrees---e.g. 40.714,-74.006 is okay, but not
-                40 42' 51'',74 0' 21''. Full details can be found in the
-                Geographical Queries section of the specification:
-                https://fiware.github.io/specifications/ngsiv2/stable/.
-            options (String): Key value pair options.
-
-        Returns:
-            TimeSeries
-        """
-        url = urljoin(self.base_url, f'/v2/entities/{entity_id}')
-        res_q = self.__query_builder(url=url,
-                                     attrs=attrs,
-                                     options=options,
-                                     entity_type=entity_type,
-                                     aggr_method=aggr_method,
-                                     aggr_period=aggr_period,
-                                     from_date=from_date,
-                                     to_date=to_date,
-                                     last_n=last_n,
-                                     limit=limit,
-                                     offset=offset,
-                                     georel=georel,
-                                     geometry=geometry,
-                                     coords=coords)
-        # merge response chunks
-        res = TimeSeries.model_validate(res_q.popleft())
-        for item in res_q:
-            res.extend(TimeSeries.model_validate(item))
-
-        return res
-
-    # /entities/{entityId}/value
-    def get_entity_values_by_id(self,
-                                entity_id: str,
-                                *,
-                                attrs: str = None,
-                                entity_type: str = None,
-                                aggr_method: Union[str, AggrMethod] = None,
-                                aggr_period: Union[str, AggrPeriod] = None,
-                                from_date: str = None,
-                                to_date: str = None,
-                                last_n: int = None,
-                                limit: int = 10000,
-                                offset: int = None,
-                                georel: str = None,
-                                geometry: str = None,
-                                coords: str = None,
-                                options: str = None
-                                ) -> TimeSeries:
-        """
-        History of N attributes (values only) of a given entity instance
-        For example, query the average pressure, temperature and humidity (
-        values only, no metadata) of this
-        month in the weather station WS1.
-
-        Args:
-            entity_id (String): Entity id is required.
-            attrs (String): Comma-separated list of attribute names
-            entity_type (String): Comma-separated list of entity types whose
-                data are to be included in the response.
-            aggr_method (String): The function to apply to the raw data
-                filtered. count, sum, avg, min, max
-            aggr_period (String): year, month, day, hour, minute, second
-            from_date (String): Starting date and time inclusive.
-            to_date (String): Final date and time inclusive.
-            last_n (int): Request only the last N values.
-            limit (int): Maximum number of results to be retrieved.
-                Default value : 10000
-            offset (int): Offset for the results.
-            georel (String): Geographical pattern
-            geometry (String): Required if georel is specified.  point, line,
-                polygon, box
-            coords (String): Required if georel is specified.
-                e.g. 40.714,-74.006
-            options (String): Key value pair options.
-
-        Returns:
-            Response Model
-        """
-        url = urljoin(self.base_url, f'/v2/entities/{entity_id}/value')
-        res_q = self.__query_builder(url=url,
-                                     attrs=attrs,
-                                     options=options,
-                                     entity_type=entity_type,
-                                     aggr_method=aggr_method,
-                                     aggr_period=aggr_period,
-                                     from_date=from_date,
-                                     to_date=to_date,
-                                     last_n=last_n,
-                                     limit=limit,
-                                     offset=offset,
-                                     georel=georel,
-                                     geometry=geometry,
-                                     coords=coords)
-
-        # merge response chunks
-        res = TimeSeries(entityId=entity_id, **res_q.popleft())
-        for item in res_q:
-            res.extend(TimeSeries(entityId=entity_id, **item))
-
-        return res
-
-    # /entities/{entityId}/attrs/{attrName}
-    def get_entity_attr_by_id(self,
-                              entity_id: str,
-                              attr_name: str,
-                              *,
-                              entity_type: str = None,
-                              aggr_method: Union[str, AggrMethod] = None,
-                              aggr_period: Union[str, AggrPeriod] = None,
-                              from_date: str = None,
-                              to_date: str = None,
-                              last_n: int = None,
-                              limit: int = 10000,
-                              offset: int = None,
-                              georel: str = None,
-                              geometry: str = None,
-                              coords: str = None,
-                              options: str = None
-                              ) -> TimeSeries:
-        """
-        History of an attribute of a given entity instance
-        For example, query max water level of the central tank throughout the
-        last year. Queries can get more
-        sophisticated with the use of filters and query attributes.
-
-        Args:
-            entity_id (String): Entity id is required.
-            attr_name (String): The attribute name is required.
-            entity_type (String): Comma-separated list of entity types whose
-                data are to be included in the response.
-            aggr_method (String): The function to apply to the raw data
-                filtered. count, sum, avg, min, max
-            aggr_period (String): year, month, day, hour, minute, second
-            from_date (String): Starting date and time inclusive.
-            to_date (String): Final date and time inclusive.
-            last_n (int): Request only the last N values.
-            limit (int): Maximum number of results to be retrieved.
-                Default value : 10000
-            offset (int): Offset for the results.
-            georel (String): Geographical pattern
-            geometry (String): Required if georel is specified.  point, line,
-                polygon, box
-            coords (String): Required if georel is specified.
-                e.g. 40.714,-74.006
-            options (String): Key value pair options.
-
-        Returns:
-            Response Model
-        """
-        url = urljoin(self.base_url, f'/v2/entities/{entity_id}/attrs'
-                                     f'/{attr_name}')
-        req_q = self.__query_builder(url=url,
-                                     entity_id=entity_id,
-                                     options=options,
-                                     entity_type=entity_type,
-                                     aggr_method=aggr_method,
-                                     aggr_period=aggr_period,
-                                     from_date=from_date,
-                                     to_date=to_date,
-                                     last_n=last_n,
-                                     limit=limit,
-                                     offset=offset,
-                                     georel=georel,
-                                     geometry=geometry,
-                                     coords=coords)
-
-        # merge response chunks
-        first = req_q.popleft()
-        res = TimeSeries(entityId=entity_id,
-                         index=first.get('index'),
-                         attributes=[AttributeValues(**first)])
-        for item in req_q:
-            res.extend(TimeSeries(entityId=entity_id,
-                                  index=item.get('index'),
-                                  attributes=[AttributeValues(**item)]))
-
-        return res
-
-    # /entities/{entityId}/attrs/{attrName}/value
-    def get_entity_attr_values_by_id(self,
-                                     entity_id: str,
-                                     attr_name: str,
-                                     *,
-                                     entity_type: str = None,
-                                     aggr_method: Union[str, AggrMethod] = None,
-                                     aggr_period: Union[str, AggrPeriod] = None,
-                                     from_date: str = None,
-                                     to_date: str = None,
-                                     last_n: int = None,
-                                     limit: int = 10000,
-                                     offset: int = None,
-                                     georel: str = None,
-                                     geometry: str = None,
-                                     coords: str = None,
-                                     options: str = None
-                                     ) -> TimeSeries:
-        """
-        History of an attribute (values only) of a given entity instance
-        Similar to the previous, but focusing on the values regardless of the
-        metadata.
-
-        Args:
-            entity_id (String): Entity id is required.
-            attr_name (String): The attribute name is required.
-            entity_type (String): Comma-separated list of entity types whose
-                data are to be included in the response.
-            aggr_method (String): The function to apply to the raw data
-                filtered. count, sum, avg, min, max
-            aggr_period (String): year, month, day, hour, minute, second
-            from_date (String): Starting date and time inclusive.
-            to_date (String): Final date and time inclusive.
-            last_n (int): Request only the last N values.
-            limit (int): Maximum number of results to be retrieved.
-                Default value : 10000
-            offset (int): Offset for the results.
-            georel (String): Geographical pattern
-            geometry (String): Required if georel is specified.  point, line,
-                polygon, box
-            coords (String): Required if georel is specified.
-                e.g. 40.714,-74.006
-            options (String): Key value pair options.
-
-        Returns:
-            Response Model
-        """
-        url = urljoin(self.base_url, f'v2/entities/{entity_id}/attrs'
-                                     f'/{attr_name}/value')
-        res_q = self.__query_builder(url=url,
-                                     options=options,
-                                     entity_type=entity_type,
-                                     aggr_method=aggr_method,
-                                     aggr_period=aggr_period,
-                                     from_date=from_date,
-                                     to_date=to_date,
-                                     last_n=last_n,
-                                     limit=limit,
-                                     offset=offset,
-                                     georel=georel,
-                                     geometry=geometry,
-                                     coords=coords)
-        # merge response chunks
-        first = res_q.popleft()
-        res = TimeSeries(
-            entityId=entity_id,
-            index=first.get('index'),
-            attributes=[AttributeValues(attrName=attr_name,
-                                        values=first.get('values'))])
-        for item in res_q:
-            res.extend(
-                TimeSeries(
-                    entityId=entity_id,
-                    index=item.get('index'),
-                    attributes=[AttributeValues(attrName=attr_name,
-                                                values=item.get('values'))]))
-
-        return res
-
-    # /types/{entityType}
-    def get_entity_by_type(self,
-                           entity_type: str,
-                           *,
-                           attrs: str = None,
-                           entity_id: str = None,
-                           aggr_method: Union[str, AggrMethod] = None,
-                           aggr_period: Union[str, AggrPeriod] = None,
-                           from_date: str = None,
-                           to_date: str = None,
-                           last_n: int = None,
-                           limit: int = 10000,
-                           offset: int = None,
-                           georel: str = None,
-                           geometry: str = None,
-                           coords: str = None,
-                           options: str = None,
-                           aggr_scope: Union[str, AggrScope] = None
-                           ) -> List[TimeSeries]:
-        """
-        History of N attributes of N entities of the same type.
-        For example, query the average pressure, temperature and humidity of
-        this month in all the weather stations.
-        """
-        url = urljoin(self.base_url, f'/v2/types/{entity_type}')
-        res_q = self.__query_builder(url=url,
-                                     entity_id=entity_id,
-                                     attrs=attrs,
-                                     options=options,
-                                     aggr_method=aggr_method,
-                                     aggr_period=aggr_period,
-                                     from_date=from_date,
-                                     to_date=to_date,
-                                     last_n=last_n,
-                                     limit=limit,
-                                     offset=offset,
-                                     georel=georel,
-                                     geometry=geometry,
-                                     coords=coords,
-                                     aggr_scope=aggr_scope)
-
-        # merge chunks of response
-        res = [TimeSeries(entityType=entity_type, **item)
-               for item in res_q.popleft().get('entities')]
-
-        for chunk in res_q:
-            chunk = [TimeSeries(entityType=entity_type, **item)
-                     for item in chunk.get('entities')]
-            for new, old in zip(chunk, res):
-                old.extend(new)
-
-        return res
-
-    # /types/{entityType}/value
-    def get_entity_values_by_type(self,
-                                  entity_type: str,
-                                  *,
-                                  attrs: str = None,
-                                  entity_id: str = None,
-                                  aggr_method: Union[str, AggrMethod] = None,
-                                  aggr_period: Union[str, AggrPeriod] = None,
-                                  from_date: str = None,
-                                  to_date: str = None,
-                                  last_n: int = None,
-                                  limit: int = 10000,
-                                  offset: int = None,
-                                  georel: str = None,
-                                  geometry: str = None,
-                                  coords: str = None,
-                                  options: str = None,
-                                  aggr_scope: Union[str, AggrScope] = None
-                                  ) -> List[TimeSeries]:
-        """
-        History of N attributes (values only) of N entities of the same type.
-        For example, query the average pressure, temperature and humidity (
-        values only, no metadata) of this month in
-        all the weather stations.
-        """
-        url = urljoin(self.base_url, f'/v2/types/{entity_type}/value')
-        res_q = self.__query_builder(url=url,
-                                     entity_id=entity_id,
-                                     attrs=attrs,
-                                     options=options,
-                                     entity_type=entity_type,
-                                     aggr_method=aggr_method,
-                                     aggr_period=aggr_period,
-                                     from_date=from_date,
-                                     to_date=to_date,
-                                     last_n=last_n,
-                                     limit=limit,
-                                     offset=offset,
-                                     georel=georel,
-                                     geometry=geometry,
-                                     coords=coords,
-                                     aggr_scope=aggr_scope)
-        # merge chunks of response
-        res = [TimeSeries(entityType=entity_type, **item)
-               for item in res_q.popleft().get('values')]
-
-        for chunk in res_q:
-            chunk = [TimeSeries(entityType=entity_type, **item)
-                     for item in chunk.get('values')]
-            for new, old in zip(chunk, res):
-                old.extend(new)
-
-        return res
-
-    # /types/{entityType}/attrs/{attrName}
-    def get_entity_attr_by_type(self,
-                                entity_type: str,
-                                attr_name: str,
-                                *,
-                                entity_id: str = None,
-                                aggr_method: Union[str, AggrMethod] = None,
-                                aggr_period: Union[str, AggrPeriod] = None,
-                                from_date: str = None,
-                                to_date: str = None,
-                                last_n: int = None,
-                                limit: int = 10000,
-                                offset: int = None,
-                                georel: str = None,
-                                geometry: str = None,
-                                coords: str = None,
-                                options: str = None,
-                                aggr_scope: Union[str, AggrScope] = None
-                                ) -> List[TimeSeries]:
-        """
-        History of an attribute of N entities of the same type.
-        For example, query the pressure measurements of this month in all the
-        weather stations. Note in the response,
-        the index and values arrays are parallel. Also, when using
-        aggrMethod, the aggregation is done by-entity
-        instance. In this case, the index array is just the fromDate and
-        toDate values user specified in the request
-        (if any).
-
-        Args:
-            entity_type (String): Entity type is required.
-            attr_name (String): The attribute name is required.
-            entity_id (String): Comma-separated list of entity ids whose data
-                are to be included in the response.
-            aggr_method (String): The function to apply to the raw data
-                filtered. count, sum, avg, min, max
-            aggr_period (String): year, month, day, hour, minute, second
-            aggr_scope (str): Optional. (This parameter is not yet supported).
-                When the query results cover historical data for multiple
-                entities instances, you can define the aggregation method to be
-                applied for each entity instance [entity] or across
-                them [global]
-            from_date (String): Starting date and time inclusive.
-            to_date (String): Final date and time inclusive.
-            last_n (int): Request only the last N values.
-            limit (int): Maximum number of results to be retrieved.
-                Default value : 10000
-            offset (int): Offset for the results.
-            georel (String): Geographical pattern
-            geometry (String): Required if georel is specified.  point, line,
-                polygon, box
-            coords (String): Required if georel is specified.
-                e.g. 40.714,-74.006
-            options (String): Key value pair options.
-
-        Returns:
-            Response Model
-        """
-        url = urljoin(self.base_url, f'/v2/types/{entity_type}/attrs'
-                                     f'/{attr_name}')
-        res_q = self.__query_builder(url=url,
-                                     entity_id=entity_id,
-                                     options=options,
-                                     entity_type=entity_type,
-                                     aggr_method=aggr_method,
-                                     aggr_period=aggr_period,
-                                     from_date=from_date,
-                                     to_date=to_date,
-                                     last_n=last_n,
-                                     limit=limit,
-                                     offset=offset,
-                                     georel=georel,
-                                     geometry=geometry,
-                                     coords=coords,
-                                     aggr_scope=aggr_scope)
-
-        # merge chunks of response
-        first = res_q.popleft()
-        res = [TimeSeries(index=item.get('index'),
-                          entityType=entity_type,
-                          entityId=item.get('entityId'),
-                          attributes=[
-                              AttributeValues(
-                                  attrName=first.get('attrName'),
-                                  values=item.get('values'))])
-               for item in first.get('entities')]
-
-        for chunk in res_q:
-            chunk = [TimeSeries(index=item.get('index'),
-                                entityType=entity_type,
-                                entityId=item.get('entityId'),
-                                attributes=[
-                                    AttributeValues(
-                                        attrName=chunk.get('attrName'),
-                                        values=item.get('values'))])
-                     for item in chunk.get('entities')]
-            for new, old in zip(chunk, res):
-                old.extend(new)
-
-        return res
-
-    # /types/{entityType}/attrs/{attrName}/value
-    def get_entity_attr_values_by_type(self,
-                                       entity_type: str,
-                                       attr_name: str,
-                                       *,
-                                       entity_id: str = None,
-                                       aggr_method: Union[
-                                           str, AggrMethod] = None,
-                                       aggr_period: Union[
-                                           str, AggrPeriod] = None,
-                                       from_date: str = None,
-                                       to_date: str = None,
-                                       last_n: int = None,
-                                       limit: int = 10000,
-                                       offset: int = None,
-                                       georel: str = None,
-                                       geometry: str = None,
-                                       coords: str = None,
-                                       options: str = None,
-                                       aggr_scope: Union[str, AggrScope] = None
-                                       ) -> List[TimeSeries]:
-        """
-        History of an attribute (values only) of N entities of the same type.
-        For example, query the average pressure (values only, no metadata) of
-        this month in all the weather stations.
-
-        Args:
-            aggr_scope:
-            entity_type (String): Entity type is required.
-            attr_name (String): The attribute name is required.
-            entity_id (String): Comma-separated list of entity ids whose data
-                are to be included in the response.
-            aggr_method (String): The function to apply to the raw data
-                filtered. count, sum, avg, min, max
-            aggr_period (String): year, month, day, hour, minute, second
-            aggr_scope (String):
-            from_date (String): Starting date and time inclusive.
-            to_date (String): Final date and time inclusive.
-            last_n (int): Request only the last N values.
-            limit (int): Maximum number of results to be retrieved.
-                Default value : 10000
-            offset (int): Offset for the results.
-            georel (String): Geographical pattern
-            geometry (String): Required if georel is specified.  point, line,
-                polygon, box
-            coords (String): Required if georel is specified.
-                e.g. 40.714,-74.006
-            options (String): Key value pair options.
-
-        Returns:
-            Response Model
-        """
-        url = urljoin(self.base_url, f'/v2/types/{entity_type}/attrs/'
-                                     f'{attr_name}/value')
-        res_q = self.__query_builder(url=url,
-                                     entity_id=entity_id,
-                                     options=options,
-                                     entity_type=entity_type,
-                                     aggr_method=aggr_method,
-                                     aggr_period=aggr_period,
-                                     from_date=from_date,
-                                     to_date=to_date,
-                                     last_n=last_n,
-                                     limit=limit,
-                                     offset=offset,
-                                     georel=georel,
-                                     geometry=geometry,
-                                     coords=coords,
-                                     aggr_scope=aggr_scope)
-
-        # merge chunks of response
-        res = [TimeSeries(index=item.get('index'),
-                          entityType=entity_type,
-                          entityId=item.get('entityId'),
-                          attributes=[
-                              AttributeValues(attrName=attr_name,
-                                              values=item.get('values'))])
-               for item in res_q.popleft().get('values')]
-
-        for chunk in res_q:
-            chunk = [TimeSeries(index=item.get('index'),
-                                entityType=entity_type,
-                                entityId=item.get('entityId'),
-                                attributes=[
-                                    AttributeValues(attrName=attr_name,
-                                                    values=item.get('values'))])
-                     for item in chunk.get('values')]
-
-            for new, old in zip(chunk, res):
-                old.extend(new)
-
-        return res
+"""
+TimeSeries Module for QuantumLeap API Client
+"""
+import logging
+import time
+from math import inf
+from collections import deque
+from itertools import count
+from typing import Dict, List, Union, Deque, Optional
+from urllib.parse import urljoin
+import requests
+from pydantic import AnyHttpUrl
+from pydantic.type_adapter import TypeAdapter
+from filip import settings
+from filip.clients.base_http_client import BaseHttpClient
+from filip.models.base import FiwareHeader
+from filip.models.ngsi_v2.subscriptions import Message
+from filip.models.ngsi_v2.timeseries import \
+    AggrPeriod, \
+    AggrMethod, \
+    AggrScope, \
+    AttributeValues, \
+    TimeSeries, \
+    TimeSeriesHeader
+from filip.utils.validators import validate_http_url
+
+logger = logging.getLogger(__name__)
+
+
+class QuantumLeapClient(BaseHttpClient):
+    """
+    Implements functions to use the FIWARE's QuantumLeap, which subscribes to an
+    Orion Context Broker and stores the subscription data in a time series
+    database (CrateDB). Further Information:
+    https://smartsdk.github.io/ngsi-timeseries-api/#quantumleap
+    https://app.swaggerhub.com/apis/heikkilv/quantumleap-api/
+
+    Args:
+        url: url of the quantumleap service
+        session (Optional):
+        fiware_header:
+        **kwargs:
+    """
+
+    def __init__(self,
+                 url: str = None,
+                 *,
+                 session: requests.Session = None,
+                 fiware_header: FiwareHeader = None,
+                 **kwargs):
+        # set service url
+        url = url or settings.QL_URL
+        super().__init__(url=url,
+                         session=session,
+                         fiware_header=fiware_header,
+                         **kwargs)
+
+    # META API ENDPOINTS
+    def get_version(self) -> Dict:
+        """
+        Gets version of QuantumLeap-Service.
+
+        Returns:
+            Dictionary with response
+        """
+        url = urljoin(self.base_url, 'version')
+        try:
+            res = self.get(url=url, headers=self.headers)
+            if res.ok:
+                return res.json()
+            res.raise_for_status()
+        except requests.exceptions.RequestException as err:
+            self.logger.error(err)
+            raise
+
+    def get_health(self) -> Dict:
+        """
+        This endpoint is intended for administrators of QuantumLeap. Using the
+        information returned by this endpoint they can diagnose problems in the
+        service or its dependencies. This information is also useful for cloud
+        tools such as orchestrators and load balancers with rules based on
+        health-checks. Due to the lack of a standardized response format, we
+        base the implementation on the draft of
+        https://inadarei.github.io/rfc-healthcheck/
+
+        Returns:
+            Dictionary with response
+        """
+        url = urljoin(self.base_url, 'health')
+        try:
+            res = self.get(url=url, headers=self.headers)
+            if res.ok:
+                return res.json()
+            res.raise_for_status()
+        except requests.exceptions.RequestException as err:
+            self.logger.error(err)
+            raise
+
+    def post_config(self):
+        """
+        (To Be Implemented) Customize your persistence configuration to
+        better suit your needs.
+        """
+        raise NotImplementedError("Endpoint to be implemented..")
+
+    # INPUT API ENDPOINTS
+    def post_notification(self, notification: Message):
+        """
+        Notify QuantumLeap the arrival of a new NGSI notification.
+
+        Args:
+            notification: Notification Message Object
+        """
+        url = urljoin(self.base_url, 'v2/notify')
+        headers = self.headers.copy()
+        data = []
+        for entity in notification.data:
+            data.append(entity.model_dump(exclude_none=True))
+        data_set = {
+            "data": data,
+            "subscriptionId": notification.subscriptionId
+        }
+
+        try:
+            res = self.post(
+                url=url,
+                headers=headers,
+                json=data_set)
+            if res.ok:
+                self.logger.debug(res.text)
+            else:
+                res.raise_for_status()
+        except requests.exceptions.RequestException as err:
+            msg = f"Could not post notification for subscription id " \
+                  f"{notification.subscriptionId}"
+            self.log_error(err=err, msg=msg)
+            raise
+
+    def post_subscription(self,
+                          cb_url: Union[AnyHttpUrl, str],
+                          ql_url: Union[AnyHttpUrl, str],
+                          entity_type: str = None,
+                          entity_id: str = None,
+                          id_pattern: str = None,
+                          attributes: str = None,
+                          observed_attributes: str = None,
+                          notified_attributes: str = None,
+                          throttling: int = None,
+                          time_index_attribute: str = None):
+        """
+        Subscribe QL to process Orion notifications of certain type.
+        This endpoint simplifies the creation of the subscription in orion
+        that will generate the notifications to be consumed by QuantumLeap in
+        order to save historical records. If you want an advanced specification
+        of the notifications, you can always create the subscription in orion
+        at your will. This endpoint just aims to simplify the common use case.
+
+        Args:
+            cb_url:
+                url of the context broker
+            ql_url:
+                The url where Orion can reach QuantumLeap. Do not include
+                specific paths.
+            entity_type (String):
+                The type of entities for which to create a
+                subscription, so as to persist historical data of entities of
+                this type.
+            entity_id (String):
+                Id of the entity to track. If specified, it
+                takes precedence over the idPattern parameter.
+            id_pattern (String): The pattern covering the entity ids for which
+                to subscribe. If not specified, QL will track all entities of
+                the specified type.
+            attributes (String): Comma-separated list of attribute names to
+                track.
+            observed_attributes (String): Comma-separated list of attribute
+                names to track.
+            notified_attributes (String): Comma-separated list of attribute
+                names to be used to restrict the data of which QL will keep a
+                history.
+            throttling (int): Minimal period of time in seconds which must
+                elapse between two consecutive notifications.
+            time_index_attribute (String): The name of a custom attribute to be
+                used as a
+            time index.
+        """
+        headers = self.headers.copy()
+        params = {}
+        url = urljoin(self.base_url, 'v2/subscribe')
+        validate_http_url(cb_url)
+        cb_url = urljoin(str(cb_url), 'v2')
+        params.update({'orionUrl': cb_url.encode('utf-8')})
+
+        validate_http_url(ql_url)
+        ql_url = urljoin(str(ql_url), 'v2')
+        params.update({'quantumleapUrl': ql_url.encode('utf-8')})
+
+        if entity_type:
+            params.update({'entityType': entity_type})
+        if entity_id:
+            params.update({'entityId': entity_id})
+        if id_pattern:
+            params.update({'idPattern': id_pattern})
+        if attributes:
+            params.update({'attributes': attributes})
+        if observed_attributes:
+            params.update({'observedAttributes': observed_attributes})
+        if notified_attributes:
+            params.update({'notifiedAttributes': notified_attributes})
+        if throttling or throttling == 0:
+            if throttling >= 0 and type(throttling) == int:
+                params.update({'throttling': throttling})
+            else:
+                raise TypeError("Throttling must be a positive integer or zero")
+        if time_index_attribute:
+            params.update({'timeIndexAttribute': time_index_attribute})
+
+        try:
+            res = self.post(url=url, headers=headers, params=params)
+            if res.ok:
+                msg = "Subscription created successfully!"
+                self.logger.info(msg)
+
+            res.raise_for_status()
+        except requests.exceptions.RequestException as err:
+            msg = "Could not create subscription."
+            self.log_error(err=err, msg=msg)
+            raise
+
+    def delete_entity(self, entity_id: str,
+                      entity_type: Optional[str] = None) -> str:
+        """
+        Given an entity (with type and id), delete all its historical records.
+
+        Args:
+            entity_id (String): Entity id is required.
+            entity_type (Optional[String]): Entity type if entity_id alone
+                can not uniquely define the entity.
+
+        Raises:
+            RequestException, if entity was not found
+            Exception, if deleting was not successful
+
+        Returns:
+            The entity_id of entity that is deleted.
+        """
+        url = urljoin(self.base_url, f'v2/entities/{entity_id}')
+        headers = self.headers.copy()
+        if entity_type is not None:
+            params = {'type': entity_type}
+        else:
+            params = {}
+
+        # The deletion does not always resolves in a success even if an ok is
+        # returned.
+        # Try to delete multiple times with incrementing waits.
+        # If the entity is no longer found the methode returns with a success
+        # If the deletion attempt fails after the 10th try, raise an
+        # Exception: it could not be deleted
+        counter = 0
+        while counter < 10:
+            self.delete(url=url, headers=headers, params=params)
+            try:
+                self.get_entity_by_id(entity_id=entity_id,
+                                      entity_type=entity_type)
+            except requests.exceptions.RequestException as err:
+                self.logger.info("Entity id '%s' successfully deleted!",
+                                 entity_id)
+                return entity_id
+            time.sleep(counter * 5)
+            counter += 1
+
+        msg = f"Could not delete QL entity of id {entity_id}"
+        logger.error(msg=msg)
+        raise Exception(msg)
+
+    def delete_entity_type(self, entity_type: str) -> str:
+        """
+        Given an entity type, delete all the historical records of all
+        entities of such type.
+        Args:
+            entity_type (String): Type of entities data to be deleted.
+        Returns:
+            Entity type of the entities deleted.
+        """
+        url = urljoin(self.base_url, f'v2/types/{entity_type}')
+        headers = self.headers.copy()
+        try:
+            res = self.delete(url=url, headers=headers)
+            if res.ok:
+                self.logger.info("Entities of type '%s' successfully deleted!",
+                                 entity_type)
+                return entity_type
+            res.raise_for_status()
+        except requests.exceptions.RequestException as err:
+            msg = f"Could not delete entities of type {entity_type}"
+            self.log_error(err=err, msg=msg)
+            raise
+
+    # QUERY API ENDPOINTS
+    def __query_builder(self,
+                        url,
+                        *,
+                        entity_id: str = None,
+                        options: str = None,
+                        entity_type: str = None,
+                        aggr_method: Union[str, AggrMethod] = None,
+                        aggr_period: Union[str, AggrPeriod] = None,
+                        from_date: str = None,
+                        to_date: str = None,
+                        last_n: int = None,
+                        limit: int = 10000,
+                        offset: int = 0,
+                        georel: str = None,
+                        geometry: str = None,
+                        coords: str = None,
+                        attrs: str = None,
+                        aggr_scope: Union[str, AggrScope] = None
+                        ) -> Deque[Dict]:
+        """
+        Private Function to call respective API endpoints, chops large
+        requests into multiple single requests and merges the
+        responses
+
+        Args:
+            url:
+            entity_id:
+            options:
+            entity_type:
+            aggr_method:
+            aggr_period:
+            from_date:
+            to_date:
+            last_n:
+            limit:
+                Maximum number of results to retrieve in a single response.
+            offset:
+                Offset to apply to the response results. For example, if the
+                query was to return 10 results and you use an offset of 1, the
+                response will return the last 9 values. Make sure you don't
+                give more offset than the number of results.
+            georel:
+            geometry:
+            coords:
+            attrs:
+            aggr_scope:
+
+        Returns:
+            Dict
+        """
+        params = {}
+        headers = self.headers.copy()
+        max_records_per_request = 10000
+        # create a double ending queue
+        res_q: Deque[Dict] = deque([])
+
+        if options:
+            params.update({'options': options})
+        if entity_type:
+            params.update({'type': entity_type})
+        if aggr_method:
+            aggr_method = AggrMethod(aggr_method)
+            params.update({'aggrMethod': aggr_method.value})
+        if aggr_period:
+            aggr_period = AggrPeriod(aggr_period)
+            params.update({'aggrPeriod': aggr_period.value})
+        if from_date:
+            params.update({'fromDate': from_date})
+        if to_date:
+            params.update({'toDate': to_date})
+        # These values are required for the integrated pagination mechanism
+        # maximum items per request
+        if limit is None:
+            limit = inf
+        if offset is None:
+            offset = 0
+        if georel:
+            params.update({'georel': georel})
+        if coords:
+            params.update({'coords': coords})
+        if geometry:
+            params.update({'geometry': geometry})
+        if attrs:
+            params.update({'attrs': attrs})
+        if aggr_scope:
+            aggr_scope = AggrScope(aggr_scope)
+            params.update({'aggr_scope': aggr_scope.value})
+        if entity_id:
+            params.update({'id': entity_id})
+
+        # This loop will chop large requests into smaller junks.
+        # The individual functions will then merge the final response models
+        for i in count(0, max_records_per_request):
+            try:
+                params['offset'] = offset + i
+
+                params['limit'] = min(limit - i, max_records_per_request)
+                if params['limit'] <= 0:
+                    break
+
+                if last_n:
+                    params['lastN'] = min(last_n - i, max_records_per_request)
+                    if params['lastN'] <= 0:
+                        break
+
+                res = self.get(url=url, params=params, headers=headers)
+
+                if res.ok:
+                    self.logger.debug('Received: %s', res.json())
+
+                    # revert append direction when using last_n
+                    if last_n:
+                        res_q.appendleft(res.json())
+                    else:
+                        res_q.append(res.json())
+                res.raise_for_status()
+
+            except requests.exceptions.RequestException as err:
+                if err.response.status_code == 404 and \
+                        err.response.json().get('error') == 'Not Found' and \
+                        len(res_q) > 0:
+                    break
+                else:
+                    msg = "Could not load entity data"
+                    self.log_error(err=err, msg=msg)
+                    raise
+
+        self.logger.info("Successfully retrieved entity data")
+        return res_q
+
+    # v2/entities
+    def get_entities(self, *,
+                     entity_type: str = None,
+                     from_date: str = None,
+                     to_date: str = None,
+                     limit: int = 10000,
+                     offset: int = None
+                     ) -> List[TimeSeriesHeader]:
+        """
+        Get list of all available entities and their context information
+        about EntityType and last update date.
+
+        Args:
+            entity_type (str): Comma-separated list of entity types whose data
+                are to be included in the response. Use only one (no comma)
+                when required. If used to resolve ambiguity for the given
+                entityId, make sure the given entityId exists for this
+                entityType.
+            from_date (str): The starting date and time (inclusive) from which
+                the context information is queried. Must be in ISO8601 format
+                (e.g., 2018-01-05T15:44:34)
+            to_date (str): The final date and time (inclusive) from which the
+                context information is queried. Must be in ISO8601 format
+                (e.g., 2018-01-05T15:44:34).
+            limit (int): Maximum number of results to be retrieved.
+                Default value : 10000
+            offset (int): Offset for the results.
+
+        Returns:
+            List of TimeSeriesHeader
+        """
+        url = urljoin(self.base_url, 'v2/entities')
+        res = self.__query_builder(url=url,
+                                   entity_type=entity_type,
+                                   from_date=from_date,
+                                   to_date=to_date,
+                                   limit=limit,
+                                   offset=offset)
+        ta = TypeAdapter(List[TimeSeriesHeader])
+        return ta.validate_python(res[0])
+
+    # /entities/{entityId}
+    def get_entity_by_id(self,
+                         entity_id: str,
+                         *,
+                         attrs: str = None,
+                         entity_type: str = None,
+                         aggr_method: Union[str, AggrMethod] = None,
+                         aggr_period: Union[str, AggrPeriod] = None,
+                         from_date: str = None,
+                         to_date: str = None,
+                         last_n: int = None,
+                         limit: int = 10000,
+                         offset: int = None,
+                         georel: str = None,
+                         geometry: str = None,
+                         coords: str = None,
+                         options: str = None
+                         ) -> TimeSeries:
+
+        """
+        History of N attributes of a given entity instance
+        For example, query max water level of the central tank throughout the
+        last year. Queries can get more
+        sophisticated with the use of filters and query attributes.
+
+        Args:
+            entity_id (String): Entity id is required.
+            attrs (String):
+                Comma-separated list of attribute names whose data are to be
+                included in the response. The attributes are retrieved in the
+                order specified by this parameter. If not specified, all
+                attributes are included in the response in arbitrary order.
+            entity_type (String): Comma-separated list of entity types whose
+                data are to be included in the response.
+            aggr_method (String):
+                The function to apply to the raw data filtered by the query
+                parameters. If not given, the returned data are the same raw
+                inserted data.
+
+                Allowed values: count, sum, avg, min, max
+            aggr_period (String):
+                If not defined, the aggregation will apply to all the values
+                contained in the search result. If defined, the aggregation
+                function will instead be applied N times, once for each
+                period, and all those results will be considered for the
+                response. For example, a query asking for the average
+                temperature of an attribute will typically return 1 value.
+                However, with an aggregationPeriod of day, you get the daily
+                average of the temperature instead (more than one value
+                assuming you had measurements across many days within the
+                scope of your search result). aggrPeriod must be accompanied
+                by an aggrMethod, and the aggrMethod will be applied to all
+                the numeric attributes specified in attrs; the rest of the
+                non-numerical attrs will be ignored. By default, the response
+                is grouped by entity_id. See aggrScope to create aggregation
+                across entities:
+
+                Allowed values: year, month, day, hour, minute, second
+
+            from_date (String):
+                The starting date and time (inclusive) from which the context
+                information is queried. Must be in ISO8601 format (e.g.,
+                2018-01-05T15:44:34)
+            to_date (String):
+                The final date and time (inclusive) from which the context
+                information is queried. Must be in ISO8601 format (e.g.,
+                2018-01-05T15:44:34)
+            last_n (int):
+                Used to request only the last N values that satisfy the
+                request conditions.
+            limit (int): Maximum number of results to be retrieved.
+                Default value : 10000
+            offset (int):
+                Offset to apply to the response results.
+            georel (String):
+                It specifies a spatial relationship between matching entities
+                and a reference shape (geometry). This parameter is used to
+                perform geographical queries with the same semantics as in the
+                FIWARE-NGSI v2 Specification. Full details can be found in the
+                Geographical Queries section of the specification:
+                https://fiware.github.io/specifications/ngsiv2/stable/.
+            geometry (String):
+                Required if georel is specified.  point, line, polygon, box
+            coords (String):
+                Optional but required if georel is specified. This parameter
+                defines the reference shape (geometry) in terms of WGS 84
+                coordinates and has the same semantics as in the
+                FIWARE-NGSI v2 Specification, except we only accept coordinates
+                in decimal degrees---e.g. 40.714,-74.006 is okay, but not
+                40 42' 51'',74 0' 21''. Full details can be found in the
+                Geographical Queries section of the specification:
+                https://fiware.github.io/specifications/ngsiv2/stable/.
+            options (String): Key value pair options.
+
+        Returns:
+            TimeSeries
+        """
+        url = urljoin(self.base_url, f'v2/entities/{entity_id}')
+        res_q = self.__query_builder(url=url,
+                                     attrs=attrs,
+                                     options=options,
+                                     entity_type=entity_type,
+                                     aggr_method=aggr_method,
+                                     aggr_period=aggr_period,
+                                     from_date=from_date,
+                                     to_date=to_date,
+                                     last_n=last_n,
+                                     limit=limit,
+                                     offset=offset,
+                                     georel=georel,
+                                     geometry=geometry,
+                                     coords=coords)
+        # merge response chunks
+        res = TimeSeries.model_validate(res_q.popleft())
+        for item in res_q:
+            res.extend(TimeSeries.model_validate(item))
+
+        return res
+
+    # /entities/{entityId}/value
+    def get_entity_values_by_id(self,
+                                entity_id: str,
+                                *,
+                                attrs: str = None,
+                                entity_type: str = None,
+                                aggr_method: Union[str, AggrMethod] = None,
+                                aggr_period: Union[str, AggrPeriod] = None,
+                                from_date: str = None,
+                                to_date: str = None,
+                                last_n: int = None,
+                                limit: int = 10000,
+                                offset: int = None,
+                                georel: str = None,
+                                geometry: str = None,
+                                coords: str = None,
+                                options: str = None
+                                ) -> TimeSeries:
+        """
+        History of N attributes (values only) of a given entity instance
+        For example, query the average pressure, temperature and humidity (
+        values only, no metadata) of this
+        month in the weather station WS1.
+
+        Args:
+            entity_id (String): Entity id is required.
+            attrs (String): Comma-separated list of attribute names
+            entity_type (String): Comma-separated list of entity types whose
+                data are to be included in the response.
+            aggr_method (String): The function to apply to the raw data
+                filtered. count, sum, avg, min, max
+            aggr_period (String): year, month, day, hour, minute, second
+            from_date (String): Starting date and time inclusive.
+            to_date (String): Final date and time inclusive.
+            last_n (int): Request only the last N values.
+            limit (int): Maximum number of results to be retrieved.
+                Default value : 10000
+            offset (int): Offset for the results.
+            georel (String): Geographical pattern
+            geometry (String): Required if georel is specified.  point, line,
+                polygon, box
+            coords (String): Required if georel is specified.
+                e.g. 40.714,-74.006
+            options (String): Key value pair options.
+
+        Returns:
+            Response Model
+        """
+        url = urljoin(self.base_url, f'v2/entities/{entity_id}/value')
+        res_q = self.__query_builder(url=url,
+                                     attrs=attrs,
+                                     options=options,
+                                     entity_type=entity_type,
+                                     aggr_method=aggr_method,
+                                     aggr_period=aggr_period,
+                                     from_date=from_date,
+                                     to_date=to_date,
+                                     last_n=last_n,
+                                     limit=limit,
+                                     offset=offset,
+                                     georel=georel,
+                                     geometry=geometry,
+                                     coords=coords)
+
+        # merge response chunks
+        res = TimeSeries(entityId=entity_id, **res_q.popleft())
+        for item in res_q:
+            res.extend(TimeSeries(entityId=entity_id, **item))
+
+        return res
+
+    # /entities/{entityId}/attrs/{attrName}
+    def get_entity_attr_by_id(self,
+                              entity_id: str,
+                              attr_name: str,
+                              *,
+                              entity_type: str = None,
+                              aggr_method: Union[str, AggrMethod] = None,
+                              aggr_period: Union[str, AggrPeriod] = None,
+                              from_date: str = None,
+                              to_date: str = None,
+                              last_n: int = None,
+                              limit: int = 10000,
+                              offset: int = None,
+                              georel: str = None,
+                              geometry: str = None,
+                              coords: str = None,
+                              options: str = None
+                              ) -> TimeSeries:
+        """
+        History of an attribute of a given entity instance
+        For example, query max water level of the central tank throughout the
+        last year. Queries can get more
+        sophisticated with the use of filters and query attributes.
+
+        Args:
+            entity_id (String): Entity id is required.
+            attr_name (String): The attribute name is required.
+            entity_type (String): Comma-separated list of entity types whose
+                data are to be included in the response.
+            aggr_method (String): The function to apply to the raw data
+                filtered. count, sum, avg, min, max
+            aggr_period (String): year, month, day, hour, minute, second
+            from_date (String): Starting date and time inclusive.
+            to_date (String): Final date and time inclusive.
+            last_n (int): Request only the last N values.
+            limit (int): Maximum number of results to be retrieved.
+                Default value : 10000
+            offset (int): Offset for the results.
+            georel (String): Geographical pattern
+            geometry (String): Required if georel is specified.  point, line,
+                polygon, box
+            coords (String): Required if georel is specified.
+                e.g. 40.714,-74.006
+            options (String): Key value pair options.
+
+        Returns:
+            Response Model
+        """
+        url = urljoin(self.base_url, f'v2/entities/{entity_id}/attrs'
+                                     f'/{attr_name}')
+        req_q = self.__query_builder(url=url,
+                                     entity_id=entity_id,
+                                     options=options,
+                                     entity_type=entity_type,
+                                     aggr_method=aggr_method,
+                                     aggr_period=aggr_period,
+                                     from_date=from_date,
+                                     to_date=to_date,
+                                     last_n=last_n,
+                                     limit=limit,
+                                     offset=offset,
+                                     georel=georel,
+                                     geometry=geometry,
+                                     coords=coords)
+
+        # merge response chunks
+        first = req_q.popleft()
+        res = TimeSeries(entityId=entity_id,
+                         index=first.get('index'),
+                         attributes=[AttributeValues(**first)])
+        for item in req_q:
+            res.extend(TimeSeries(entityId=entity_id,
+                                  index=item.get('index'),
+                                  attributes=[AttributeValues(**item)]))
+
+        return res
+
+    # /entities/{entityId}/attrs/{attrName}/value
+    def get_entity_attr_values_by_id(self,
+                                     entity_id: str,
+                                     attr_name: str,
+                                     *,
+                                     entity_type: str = None,
+                                     aggr_method: Union[str, AggrMethod] = None,
+                                     aggr_period: Union[str, AggrPeriod] = None,
+                                     from_date: str = None,
+                                     to_date: str = None,
+                                     last_n: int = None,
+                                     limit: int = 10000,
+                                     offset: int = None,
+                                     georel: str = None,
+                                     geometry: str = None,
+                                     coords: str = None,
+                                     options: str = None
+                                     ) -> TimeSeries:
+        """
+        History of an attribute (values only) of a given entity instance
+        Similar to the previous, but focusing on the values regardless of the
+        metadata.
+
+        Args:
+            entity_id (String): Entity id is required.
+            attr_name (String): The attribute name is required.
+            entity_type (String): Comma-separated list of entity types whose
+                data are to be included in the response.
+            aggr_method (String): The function to apply to the raw data
+                filtered. count, sum, avg, min, max
+            aggr_period (String): year, month, day, hour, minute, second
+            from_date (String): Starting date and time inclusive.
+            to_date (String): Final date and time inclusive.
+            last_n (int): Request only the last N values.
+            limit (int): Maximum number of results to be retrieved.
+                Default value : 10000
+            offset (int): Offset for the results.
+            georel (String): Geographical pattern
+            geometry (String): Required if georel is specified.  point, line,
+                polygon, box
+            coords (String): Required if georel is specified.
+                e.g. 40.714,-74.006
+            options (String): Key value pair options.
+
+        Returns:
+            Response Model
+        """
+        url = urljoin(self.base_url, f'v2/entities/{entity_id}/attrs'
+                                     f'/{attr_name}/value')
+        res_q = self.__query_builder(url=url,
+                                     options=options,
+                                     entity_type=entity_type,
+                                     aggr_method=aggr_method,
+                                     aggr_period=aggr_period,
+                                     from_date=from_date,
+                                     to_date=to_date,
+                                     last_n=last_n,
+                                     limit=limit,
+                                     offset=offset,
+                                     georel=georel,
+                                     geometry=geometry,
+                                     coords=coords)
+        # merge response chunks
+        first = res_q.popleft()
+        res = TimeSeries(
+            entityId=entity_id,
+            index=first.get('index'),
+            attributes=[AttributeValues(attrName=attr_name,
+                                        values=first.get('values'))])
+        for item in res_q:
+            res.extend(
+                TimeSeries(
+                    entityId=entity_id,
+                    index=item.get('index'),
+                    attributes=[AttributeValues(attrName=attr_name,
+                                                values=item.get('values'))]))
+
+        return res
+
+    # /types/{entityType}
+    def get_entity_by_type(self,
+                           entity_type: str,
+                           *,
+                           attrs: str = None,
+                           entity_id: str = None,
+                           aggr_method: Union[str, AggrMethod] = None,
+                           aggr_period: Union[str, AggrPeriod] = None,
+                           from_date: str = None,
+                           to_date: str = None,
+                           last_n: int = None,
+                           limit: int = 10000,
+                           offset: int = None,
+                           georel: str = None,
+                           geometry: str = None,
+                           coords: str = None,
+                           options: str = None,
+                           aggr_scope: Union[str, AggrScope] = None
+                           ) -> List[TimeSeries]:
+        """
+        History of N attributes of N entities of the same type.
+        For example, query the average pressure, temperature and humidity of
+        this month in all the weather stations.
+        """
+        url = urljoin(self.base_url, f'v2/types/{entity_type}')
+        res_q = self.__query_builder(url=url,
+                                     entity_id=entity_id,
+                                     attrs=attrs,
+                                     options=options,
+                                     aggr_method=aggr_method,
+                                     aggr_period=aggr_period,
+                                     from_date=from_date,
+                                     to_date=to_date,
+                                     last_n=last_n,
+                                     limit=limit,
+                                     offset=offset,
+                                     georel=georel,
+                                     geometry=geometry,
+                                     coords=coords,
+                                     aggr_scope=aggr_scope)
+
+        # merge chunks of response
+        res = [TimeSeries(entityType=entity_type, **item)
+               for item in res_q.popleft().get('entities')]
+
+        for chunk in res_q:
+            chunk = [TimeSeries(entityType=entity_type, **item)
+                     for item in chunk.get('entities')]
+            for new, old in zip(chunk, res):
+                old.extend(new)
+
+        return res
+
+    # /types/{entityType}/value
+    def get_entity_values_by_type(self,
+                                  entity_type: str,
+                                  *,
+                                  attrs: str = None,
+                                  entity_id: str = None,
+                                  aggr_method: Union[str, AggrMethod] = None,
+                                  aggr_period: Union[str, AggrPeriod] = None,
+                                  from_date: str = None,
+                                  to_date: str = None,
+                                  last_n: int = None,
+                                  limit: int = 10000,
+                                  offset: int = None,
+                                  georel: str = None,
+                                  geometry: str = None,
+                                  coords: str = None,
+                                  options: str = None,
+                                  aggr_scope: Union[str, AggrScope] = None
+                                  ) -> List[TimeSeries]:
+        """
+        History of N attributes (values only) of N entities of the same type.
+        For example, query the average pressure, temperature and humidity (
+        values only, no metadata) of this month in
+        all the weather stations.
+        """
+        url = urljoin(self.base_url, f'v2/types/{entity_type}/value')
+        res_q = self.__query_builder(url=url,
+                                     entity_id=entity_id,
+                                     attrs=attrs,
+                                     options=options,
+                                     entity_type=entity_type,
+                                     aggr_method=aggr_method,
+                                     aggr_period=aggr_period,
+                                     from_date=from_date,
+                                     to_date=to_date,
+                                     last_n=last_n,
+                                     limit=limit,
+                                     offset=offset,
+                                     georel=georel,
+                                     geometry=geometry,
+                                     coords=coords,
+                                     aggr_scope=aggr_scope)
+        # merge chunks of response
+        res = [TimeSeries(entityType=entity_type, **item)
+               for item in res_q.popleft().get('values')]
+
+        for chunk in res_q:
+            chunk = [TimeSeries(entityType=entity_type, **item)
+                     for item in chunk.get('values')]
+            for new, old in zip(chunk, res):
+                old.extend(new)
+
+        return res
+
+    # /types/{entityType}/attrs/{attrName}
+    def get_entity_attr_by_type(self,
+                                entity_type: str,
+                                attr_name: str,
+                                *,
+                                entity_id: str = None,
+                                aggr_method: Union[str, AggrMethod] = None,
+                                aggr_period: Union[str, AggrPeriod] = None,
+                                from_date: str = None,
+                                to_date: str = None,
+                                last_n: int = None,
+                                limit: int = 10000,
+                                offset: int = None,
+                                georel: str = None,
+                                geometry: str = None,
+                                coords: str = None,
+                                options: str = None,
+                                aggr_scope: Union[str, AggrScope] = None
+                                ) -> List[TimeSeries]:
+        """
+        History of an attribute of N entities of the same type.
+        For example, query the pressure measurements of this month in all the
+        weather stations. Note in the response,
+        the index and values arrays are parallel. Also, when using
+        aggrMethod, the aggregation is done by-entity
+        instance. In this case, the index array is just the fromDate and
+        toDate values user specified in the request
+        (if any).
+
+        Args:
+            entity_type (String): Entity type is required.
+            attr_name (String): The attribute name is required.
+            entity_id (String): Comma-separated list of entity ids whose data
+                are to be included in the response.
+            aggr_method (String): The function to apply to the raw data
+                filtered. count, sum, avg, min, max
+            aggr_period (String): year, month, day, hour, minute, second
+            aggr_scope (str): Optional. (This parameter is not yet supported).
+                When the query results cover historical data for multiple
+                entities instances, you can define the aggregation method to be
+                applied for each entity instance [entity] or across
+                them [global]
+            from_date (String): Starting date and time inclusive.
+            to_date (String): Final date and time inclusive.
+            last_n (int): Request only the last N values.
+            limit (int): Maximum number of results to be retrieved.
+                Default value : 10000
+            offset (int): Offset for the results.
+            georel (String): Geographical pattern
+            geometry (String): Required if georel is specified.  point, line,
+                polygon, box
+            coords (String): Required if georel is specified.
+                e.g. 40.714,-74.006
+            options (String): Key value pair options.
+
+        Returns:
+            Response Model
+        """
+        url = urljoin(self.base_url, f'v2/types/{entity_type}/attrs'
+                                     f'/{attr_name}')
+        res_q = self.__query_builder(url=url,
+                                     entity_id=entity_id,
+                                     options=options,
+                                     entity_type=entity_type,
+                                     aggr_method=aggr_method,
+                                     aggr_period=aggr_period,
+                                     from_date=from_date,
+                                     to_date=to_date,
+                                     last_n=last_n,
+                                     limit=limit,
+                                     offset=offset,
+                                     georel=georel,
+                                     geometry=geometry,
+                                     coords=coords,
+                                     aggr_scope=aggr_scope)
+
+        # merge chunks of response
+        first = res_q.popleft()
+        res = [TimeSeries(index=item.get('index'),
+                          entityType=entity_type,
+                          entityId=item.get('entityId'),
+                          attributes=[
+                              AttributeValues(
+                                  attrName=first.get('attrName'),
+                                  values=item.get('values'))])
+               for item in first.get('entities')]
+
+        for chunk in res_q:
+            chunk = [TimeSeries(index=item.get('index'),
+                                entityType=entity_type,
+                                entityId=item.get('entityId'),
+                                attributes=[
+                                    AttributeValues(
+                                        attrName=chunk.get('attrName'),
+                                        values=item.get('values'))])
+                     for item in chunk.get('entities')]
+            for new, old in zip(chunk, res):
+                old.extend(new)
+
+        return res
+
+    # /types/{entityType}/attrs/{attrName}/value
+    def get_entity_attr_values_by_type(self,
+                                       entity_type: str,
+                                       attr_name: str,
+                                       *,
+                                       entity_id: str = None,
+                                       aggr_method: Union[
+                                           str, AggrMethod] = None,
+                                       aggr_period: Union[
+                                           str, AggrPeriod] = None,
+                                       from_date: str = None,
+                                       to_date: str = None,
+                                       last_n: int = None,
+                                       limit: int = 10000,
+                                       offset: int = None,
+                                       georel: str = None,
+                                       geometry: str = None,
+                                       coords: str = None,
+                                       options: str = None,
+                                       aggr_scope: Union[str, AggrScope] = None
+                                       ) -> List[TimeSeries]:
+        """
+        History of an attribute (values only) of N entities of the same type.
+        For example, query the average pressure (values only, no metadata) of
+        this month in all the weather stations.
+
+        Args:
+            aggr_scope:
+            entity_type (String): Entity type is required.
+            attr_name (String): The attribute name is required.
+            entity_id (String): Comma-separated list of entity ids whose data
+                are to be included in the response.
+            aggr_method (String): The function to apply to the raw data
+                filtered. count, sum, avg, min, max
+            aggr_period (String): year, month, day, hour, minute, second
+            aggr_scope (String):
+            from_date (String): Starting date and time inclusive.
+            to_date (String): Final date and time inclusive.
+            last_n (int): Request only the last N values.
+            limit (int): Maximum number of results to be retrieved.
+                Default value : 10000
+            offset (int): Offset for the results.
+            georel (String): Geographical pattern
+            geometry (String): Required if georel is specified.  point, line,
+                polygon, box
+            coords (String): Required if georel is specified.
+                e.g. 40.714,-74.006
+            options (String): Key value pair options.
+
+        Returns:
+            Response Model
+        """
+        url = urljoin(self.base_url, f'v2/types/{entity_type}/attrs/'
+                                     f'{attr_name}/value')
+        res_q = self.__query_builder(url=url,
+                                     entity_id=entity_id,
+                                     options=options,
+                                     entity_type=entity_type,
+                                     aggr_method=aggr_method,
+                                     aggr_period=aggr_period,
+                                     from_date=from_date,
+                                     to_date=to_date,
+                                     last_n=last_n,
+                                     limit=limit,
+                                     offset=offset,
+                                     georel=georel,
+                                     geometry=geometry,
+                                     coords=coords,
+                                     aggr_scope=aggr_scope)
+
+        # merge chunks of response
+        res = [TimeSeries(index=item.get('index'),
+                          entityType=entity_type,
+                          entityId=item.get('entityId'),
+                          attributes=[
+                              AttributeValues(attrName=attr_name,
+                                              values=item.get('values'))])
+               for item in res_q.popleft().get('values')]
+
+        for chunk in res_q:
+            chunk = [TimeSeries(index=item.get('index'),
+                                entityType=entity_type,
+                                entityId=item.get('entityId'),
+                                attributes=[
+                                    AttributeValues(attrName=attr_name,
+                                                    values=item.get('values'))])
+                     for item in chunk.get('values')]
+
+            for new, old in zip(chunk, res):
+                old.extend(new)
+
+        return res
```

### Comparing `filip-0.3.0/filip/config.py` & `filip-0.4.0/filip/config.py`

 * *Ordering differences only*

 * *Files 19% similar despite different names*

```diff
@@ -1,30 +1,30 @@
-"""
-Settings module to set url from .env.filip file. This can also seen as an
-example for other applications such as webapp that use the library. Using
-`*.env` belongs to best practices in containerized applications. Pydantic
-provides a convenient and clean way to manage environments.
-"""
-from pydantic import Field, AnyHttpUrl, AliasChoices
-from pydantic_settings import BaseSettings, SettingsConfigDict
-
-
-class Settings(BaseSettings):
-    """
-    Settings class that reads environment variables from a local `.env.filip`
-    file or environment variables. The `.env.filip` must be located in the
-    current working directory.
-    """
-    model_config = SettingsConfigDict(env_file='.env.filip', env_file_encoding='utf-8',
-                                      case_sensitive=False, extra="ignore")
-    CB_URL: AnyHttpUrl = Field(default="http://127.0.0.1:1026",
-                               validation_alias=AliasChoices(
-                                   'ORION_URL', 'CB_URL', 'CB_HOST',
-                                   'CONTEXTBROKER_URL', 'OCB_URL'))
-    IOTA_URL: AnyHttpUrl = Field(default="http://127.0.0.1:4041",
-                                 validation_alias='IOTA_URL')
-    QL_URL: AnyHttpUrl = Field(default="http://127.0.0.1:8668",
-                               validation_alias=AliasChoices('QUANTUMLEAP_URL', 'QL_URL'))
-
-
-# create settings object
-settings = Settings()
+"""
+Settings module to set url from .env.filip file. This can also seen as an
+example for other applications such as webapp that use the library. Using
+`*.env` belongs to best practices in containerized applications. Pydantic
+provides a convenient and clean way to manage environments.
+"""
+from pydantic import Field, AnyHttpUrl, AliasChoices
+from pydantic_settings import BaseSettings, SettingsConfigDict
+
+
+class Settings(BaseSettings):
+    """
+    Settings class that reads environment variables from a local `.env.filip`
+    file or environment variables. The `.env.filip` must be located in the
+    current working directory.
+    """
+    model_config = SettingsConfigDict(env_file='.env.filip', env_file_encoding='utf-8',
+                                      case_sensitive=False, extra="ignore")
+    CB_URL: AnyHttpUrl = Field(default="http://127.0.0.1:1026",
+                               validation_alias=AliasChoices(
+                                   'ORION_URL', 'CB_URL', 'CB_HOST',
+                                   'CONTEXTBROKER_URL', 'OCB_URL'))
+    IOTA_URL: AnyHttpUrl = Field(default="http://127.0.0.1:4041",
+                                 validation_alias='IOTA_URL')
+    QL_URL: AnyHttpUrl = Field(default="http://127.0.0.1:8668",
+                               validation_alias=AliasChoices('QUANTUMLEAP_URL', 'QL_URL'))
+
+
+# create settings object
+settings = Settings()
```

### Comparing `filip-0.3.0/filip/data/unece-units/units_of_measure.csv` & `filip-0.4.0/filip/data/unece-units/units_of_measure.csv`

 * *Ordering differences only*

 * *Files 5% similar despite different names*

```diff
@@ -1,2118 +1,2118 @@
-,Status,CommonCode,Name,Description,LevelAndCategory,Symbol,ConversionFactor
-0,X,05,lift,nan,3.9,nan,nan
-1,X,06,small spray,nan,3.9,nan,nan
-2,X,08,heat lot,nan,3.9,nan,nan
-3,nan,10,group,A unit of count defining the number of groups (group: set of items classified together).,3.9,nan,nan
-4,nan,11,outfit,A unit of count defining the number of outfits (outfit: a complete set of equipment / materials / objects used for a specific purpose).,3.9,nan,nan
-5,nan,13,ration,A unit of count defining the number of rations (ration: a single portion of provisions).,3.9,nan,nan
-6,nan,14,shot,"A unit of liquid measure, especially related to spirits.",3.9,nan,nan
-7,nan,15,"stick, military",A unit of count defining the number of military sticks (military stick: bombs or paratroops released in rapid succession from an aircraft).,3.9,nan,nan
-8,X,16,hundred fifteen kg drum,nan,3.3,nan,nan
-9,X,17,hundred lb drum,nan,3.3,nan,nan
-10,X,18,fiftyfive gallon (US) drum,nan,3.3,nan,nan
-11,X,19,tank truck,nan,3.4,nan,nan
-12,nan,20,twenty foot container,A unit of count defining the number of shipping containers that measure 20 foot in length.,3.4,nan,nan
-13,nan,21,forty foot container,A unit of count defining the number of shipping containers that measure 40 foot in length.,3.4,nan,nan
-14,nan,22,decilitre per gram,nan,1M,dl/g,10⁻¹ x m³/kg
-15,nan,23,gram per cubic centimetre,nan,1S,g/cm³,10³ kg/m³
-16,nan,24,theoretical pound,A unit of mass defining the expected mass of material expressed as the number of pounds.,3.1,nan,nan
-17,nan,25,gram per square centimetre,nan,1M,g/cm²,10 kg/m²
-18,X,26,actual ton,nan,3.1,nan,nan
-19,nan,27,theoretical ton,"A unit of mass defining the expected mass of material, expressed as the number of tons.",3.1,nan,nan
-20,nan,28,kilogram per square metre,nan,1,kg/m²,kg/m²
-21,X,29,pound per thousand square foot,nan,3.8,lb/kft²,nan
-22,X,30,horse power day per air dry metric ton,nan,3.5,nan,nan
-23,X,31,catch weight,nan,3.9,nan,nan
-24,X,32,kilogram per air dry metric ton,nan,3.5,nan,nan
-25,nan,33,kilopascal square metre per gram,nan,1M,kPa·m²/g,10⁶ m/s²
-26,nan,34,kilopascal per millimetre,nan,1M,kPa/mm,10⁶ kg/(m² x s²)
-27,nan,35,millilitre per square centimetre second,nan,1M,ml/(cm²·s),10⁻² m/s
-28,X,36,cubic foot per minute per square foot,Conversion factor required,1M,ft³/(min/ft²),nan
-29,nan,37,ounce per square foot,nan,2,oz/ft²,"0,305 151 7 kg/m²"
-30,nan,38,"ounce per square foot per 0,01inch",nan,3.9,oz/(ft²/cin),nan
-31,nan,40,millilitre per second,nan,1M,ml/s,10⁻⁶ m³/s
-32,nan,41,millilitre per minute,nan,1M,ml/min,"1,666 67 x 10⁻⁸ m³/s"
-33,X,43,super bulk bag,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-34,X,44,fivehundred kg bulk bag,nan,3.3,nan,nan
-35,X,45,threehundred kg bulk bag,nan,3.3,nan,nan
-36,X,46,fifty lb bulk bag,nan,3.3,nan,nan
-37,X,47,fifty lb bag,nan,3.3,nan,nan
-38,X,48,bulk car load,nan,3.4,nan,nan
-39,X,53,theoretical kilogram,nan,3.1,nan,nan
-40,X,54,theoretical tonne,nan,3.1,nan,nan
-41,nan,56,sitas,A unit of area for tin plate equal to a surface area of 100 square metres.,3.9,nan,nan
-42,nan,57,mesh,A unit of count defining the number of strands per inch as a measure of the fineness of a woven product.,3.9,nan,nan
-43,nan,58,net kilogram,A unit of mass defining the total number of kilograms after deductions.,3.1,nan,nan
-44,nan,59,part per million,A unit of proportion equal to 10⁻⁶.,3.7,ppm,1 x 10⁻⁶
-45,nan,60,percent weight,A unit of proportion equal to 10⁻².,3.7,nan,1 x 10⁻²
-46,nan,61,part per billion (US),A unit of proportion equal to 10⁻⁹.,3.7,ppb,1 x 10⁻⁹
-47,X,62,percent per 1000 hour,nan,3.7,nan,nan
-48,X,63,failure rate in time,nan,3.9,nan,nan
-49,D,64,"pound per square inch, gauge",nan,3.1,nan,"7,030 696 x 10² kg/m²"
-50,D,66,oersted,nan,3.5,Oe,"7,957 747 x 10 A/m"
-51,X,69,test specific scale,nan,3.9,nan,nan
-52,X,71,volt ampere per pound,nan,3.9,nan,nan
-53,X,72,watt per pound,nan,3.9,nan,nan
-54,X,73,ampere tum per centimetre,nan,3.9,nan,nan
-55,nan,74,millipascal,nan,1S,mPa,10⁻³ Pa
-56,D,76,gauss,nan,3.5,Gs,10⁻⁴ T
-57,nan,77,milli-inch,nan,2,mil,"25,4 x 10⁻⁶ m"
-58,D,78,kilogauss,nan,3.5,kGs,10⁻¹ T
-59,nan,80,pound per square inch absolute,nan,2,lb/in²,"7,030 696 x 10² kg/m²"
-60,nan,81,henry,nan,1,H,H
-61,D,84,kilopound-force per square inch,"A unit of pressure defining the number of kilopounds force per square inch.,Use kip per square inch (common code N20).",2,klbf/in²,"6,894 757 x 10⁶ Pa"
-62,nan,85,foot pound-force,nan,2,ft·lbf,"1,355 818 J"
-63,nan,87,pound per cubic foot,nan,2,lb/ft³,"1,601 846 x 10¹ kg/m³"
-64,nan,89,poise,nan,2,P,"0,1 Pa x s"
-65,X,90,Saybold universal second,nan,3.9,nan,nan
-66,nan,91,stokes,nan,2,St,10⁻⁴ m²/s
-67,X,92,calorie per cubic centimetre,nan,3.9,nan,nan
-68,X,93,calorie per gram,Use International Table (IT) calorie per gram (common code D75).,3.5,cal/g,"4,186 8 x 10³ J/kg"
-69,X,94,curl unit,nan,3.9,nan,nan
-70,X,95,twenty thousand gallon (US) tankcar,nan,3.4,nan,nan
-71,X,96,ten thousand gallon (US) tankcar,nan,3.4,nan,nan
-72,X,97,ten kg drum,nan,3.3,nan,nan
-73,X,98,fifteen kg drum,nan,3.3,nan,nan
-74,X,1A,car mile,nan,3.5,nan,nan
-75,X,1B,car count,nan,3.5,nan,nan
-76,X,1C,locomotive count,nan,3.5,nan,nan
-77,X,1D,caboose count,nan,3.5,nan,nan
-78,X,1E,empty car,nan,3.5,nan,nan
-79,X,1F,train mile,nan,3.5,nan,nan
-80,X,1G,fuel usage gallon (US),nan,3.5,nan,nan
-81,X,1H,caboose mile,nan,3.5,nan,nan
-82,nan,1I,fixed rate,A unit of quantity expressed as a predetermined or set rate for usage of a facility or service.,3.9,nan,nan
-83,X,1J,ton mile,nan,3.5,nan,nan
-84,X,1K,locomotive mile,nan,3.5,nan,nan
-85,X,1L,total car count,nan,3.5,nan,nan
-86,X,1M,total car mile,nan,3.5,nan,nan
-87,X,1X,quarter mile,nan,3.8,nan,nan
-88,nan,2A,radian per second,Refer ISO/TC12 SI Guide,1,rad/s,rad/s
-89,nan,2B,radian per second squared,Refer ISO/TC12 SI Guide,1,rad/s²,rad/s²
-90,nan,2C,roentgen,nan,2,R,"2,58 x 10⁻⁴ C/kg"
-91,nan,2G,volt AC,A unit of electric potential in relation to alternating current (AC).,3.1,V,V
-92,nan,2H,volt DC,A unit of electric potential in relation to direct current (DC).,3.1,V,V
-93,nan,2I,British thermal unit (international table) per hour,nan,2,BtuIT/h,"2,930 711x 10⁻¹ W"
-94,nan,2J,cubic centimetre per second,nan,1S,cm³/s,10⁻⁶ m³/s
-95,nan,2K,cubic foot per hour,nan,2,ft³/h,"7,865 79 x 10⁻⁶ m³/s"
-96,nan,2L,cubic foot per minute,nan,2,ft³/min,"4,719 474 x 10⁻⁴ m³/s"
-97,nan,2M,centimetre per second,nan,1S,cm/s,10⁻² m/s
-98,nan,2N,decibel,nan,1,dB,"0,115 129 3 Np"
-99,nan,2P,kilobyte,A unit of information equal to 10³ (1000) bytes.,3.6,kbyte,nan
-100,nan,2Q,kilobecquerel,nan,1S,kBq,10³ Bq
-101,nan,2R,kilocurie,nan,2S,kCi,"3,7 x 10¹³ Bq"
-102,nan,2U,megagram,nan,1S,Mg,10³ kg
-103,X,2V,megagram per hour,nan,3.8,Mg/h,nan
-104,X,2W,bin,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-105,nan,2X,metre per minute,nan,1M,m/min,"0,016 666 m/s"
-106,nan,2Y,milliroentgen,nan,2,mR,"2,58 x 10⁻⁷ C/kg"
-107,nan,2Z,millivolt,nan,1S,mV,10⁻³ V
-108,nan,3B,megajoule,nan,1S,MJ,10⁶ J
-109,nan,3C,manmonth,A unit of count defining the number of months for a person or persons to perform an undertaking.,3.9,nan,nan
-110,X,3E,pound per pound of product,nan,3.9,nan,nan
-111,X,3G,pound per piece of product,nan,3.9,nan,nan
-112,X,3H,kilogram per kilogram of product,nan,3.9,nan,nan
-113,X,3I,kilogram per piece of product,nan,3.9,nan,nan
-114,X,4A,bobbin,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-115,X,4B,cap,nan,3.9,nan,nan
-116,nan,4C,centistokes,nan,2,cSt,10⁻⁶ m²/s
-117,X,4E,twenty pack,nan,3.2,nan,nan
-118,nan,4G,microlitre,nan,1M,µl,10⁻⁹ m³
-119,nan,4H,micrometre (micron),nan,1S,µm,10⁻⁶ m
-120,nan,4K,milliampere,nan,1S,mA,10⁻³ A
-121,nan,4L,megabyte,A unit of information equal to 10⁶ (1000000) bytes.,3.6,Mbyte,nan
-122,nan,4M,milligram per hour,nan,1M,mg/h,"2,777 78 x 10⁻¹⁰ kg/s"
-123,nan,4N,megabecquerel,nan,1S,MBq,10⁶ Bq
-124,nan,4O,microfarad,nan,1S,µF,10⁻⁶ F
-125,nan,4P,newton per metre,nan,1,N/m,N/m
-126,nan,4Q,ounce inch,nan,2,oz·in,"7,200 778 x 10⁻⁴ kg x m"
-127,nan,4R,ounce foot,nan,2,oz·ft,"8,640 934 x 10⁻³ kg x m"
-128,nan,4T,picofarad,nan,1S,pF,10⁻¹² F
-129,nan,4U,pound per hour,nan,2,lb/h,"1,259 979 x 10⁻⁴ kg/s"
-130,nan,4W,ton (US) per hour,nan,2,ton (US) /h,"2,519 958 x 10⁻¹ kg/s"
-131,nan,4X,kilolitre per hour,nan,1M,kl/h,"2,777 78 x 10⁻⁴ m³/s"
-132,nan,5A,barrel (US) per minute,nan,2,barrel (US)/min,"2,649 79 x 10⁻³ m³/s"
-133,nan,5B,batch,A unit of count defining the number of batches (batch: quantity of material produced in one operation or number of animals or persons coming at once).,3.9,nan,nan
-134,X,5C,gallon(US) per thousand,nan,3.9,nan,nan
-135,nan,5E,MMSCF/day,A unit of volume equal to one million (1000000) cubic feet of gas per day.,3.9,nan,nan
-136,X,5F,pound per thousand,nan,3.9,nan,nan
-137,X,5G,pump,nan,3.9,nan,nan
-138,X,5H,stage,nan,3.9,nan,nan
-139,X,5I,standard cubic foot,Use standard (common code WSD),2,std,"4,672 m³"
-140,nan,5J,hydraulic horse power,A unit of power defining the hydraulic horse power delivered by a fluid pump depending on the viscosity of the fluid.,3.5,nan,nan
-141,X,5K,count per minute,nan,3.9,nan,nan
-142,X,5P,seismic level,nan,3.9,nan,nan
-143,X,5Q,seismic line,nan,3.9,nan,nan
-144,D,A1,15 °C calorie,nan,2,cal₁₅,"4,188 46  J"
-145,nan,A10,ampere square metre per joule second,nan,1,A·m²/(J·s),(A x s)/kg
-146,nan,A11,angstrom,nan,1,Å,10⁻¹⁰ m
-147,nan,A12,astronomical unit,nan,1,ua,"1,495 978 70 x 10¹¹ m"
-148,nan,A13,attojoule,nan,1S,aJ,10⁻¹⁸ J
-149,nan,A14,barn,nan,1,b,10⁻²⁸ m²
-150,nan,A15,barn per electronvolt,nan,1,b/eV,"6,241 51 x 10⁻¹⁰ m²/J"
-151,nan,A16,barn per steradian electronvolt,nan,1,b/(sr·eV),"6,241 51 x 10⁻¹⁰ m²/(sr xJ)"
-152,nan,A17,barn per steradian,nan,1,b/sr,1 x 10⁻²⁸ m²/sr
-153,nan,A18,becquerel per kilogram,nan,1,Bq/kg,"27,027 x 10⁻¹² Ci/kg"
-154,nan,A19,becquerel per cubic metre,nan,1,Bq/m³,Bq/m³
-155,nan,A2,ampere per centimetre,nan,1S,A/cm,10² A/m
-156,nan,A20,British thermal unit (international table) per second square foot degree Rankine,nan,2,BtuIT/(s·ft²·°R),"20 441,7 W/(m² x K)"
-157,nan,A21,British thermal unit (international table) per pound degree Rankine,nan,2,BtuIT/(lb·°R),"4 186,8 J/(kg x K)"
-158,nan,A22,British thermal unit (international table) per second foot degree Rankine,nan,2,BtuIT/(s·ft·°R),"6 230,64 W/(m x K)"
-159,nan,A23,British thermal unit (international table) per hour square foot degree Rankine,nan,2,BtuIT/(h·ft²·°R),"5,678 26 W/ (m² x K)"
-160,nan,A24,candela per square metre,nan,1,cd/m²,cd/m²
-161,D,A25,cheval vapeur,Synonym: metric horse power,2,CV,"7,354 988 x 10² W"
-162,nan,A26,coulomb metre,nan,1,C·m,A x s x m
-163,nan,A27,coulomb metre squared per volt,nan,1,C·m²/V,A² x  s⁴/kg
-164,nan,A28,coulomb per cubic centimetre,nan,1S,C/cm³,10⁶ C/m³
-165,nan,A29,coulomb per cubic metre,nan,1,C/m³,C/m³
-166,nan,A3,ampere per millimetre,nan,1S,A/mm,10³ A/m
-167,nan,A30,coulomb per cubic millimetre,nan,1S,C/mm³,10⁹ C/m³
-168,nan,A31,coulomb per kilogram second,nan,1,C/(kg·s),A/kg
-169,nan,A32,coulomb per mole,nan,1,C/mol,A x s/mol
-170,nan,A33,coulomb per square centimetre,nan,1S,C/cm²,10⁴ C/m²
-171,nan,A34,coulomb per square metre,nan,1,C/m²,C/m²
-172,nan,A35,coulomb per square millimetre,nan,1S,C/mm²,10⁶ C/m²
-173,nan,A36,cubic centimetre per mole,nan,1S,cm³/mol,10⁻⁶ m³/mol
-174,nan,A37,cubic decimetre per mole,nan,1S,dm³/mol,10⁻³ m³/mol
-175,nan,A38,cubic metre per coulomb,nan,1,m³/C,m³/A x s
-176,nan,A39,cubic metre per kilogram,nan,1,m³/kg,m³/kg
-177,nan,A4,ampere per square centimetre,nan,1S,A/cm²,10⁴ A/m²
-178,nan,A40,cubic metre per mole,nan,1,m³/mol,m³/mol
-179,nan,A41,ampere per square metre,nan,1,A/m²,A/m²
-180,nan,A42,curie per kilogram,nan,2,Ci/kg,"3,7 x 10¹⁰ Bq/kg"
-181,nan,A43,deadweight tonnage,"A unit of mass defining the difference between the weight of a ship when completely empty and its weight when completely loaded, expressed as the number of tons.",3.4,dwt,nan
-182,nan,A44,decalitre,nan,1M,dal,10⁻² m³
-183,nan,A45,decametre,nan,1M,dam,10 m
-184,nan,A47,decitex,A unit of yarn density. One decitex equals a mass of 1 gram per 10 kilometres of length.,3.5,dtex (g/10km),nan
-185,nan,A48,degree Rankine,Refer ISO 80000-5 (Quantities and units — Part 5: Thermodynamics),2,°R,5/9 x K
-186,nan,A49,denier,A unit of yarn density. One denier equals a mass of 1 gram per 9 kilometres of length.,3.5,den (g/9 km),nan
-187,nan,A5,ampere square metre,nan,1,A·m²,A x m²
-188,D,A50,dyne second per cubic centimetre,nan,2,dyn·s/cm³,10 Pa x s/m
-189,D,A51,dyne second per centimetre,nan,2,dyn·s/cm,10⁻³ N x s/m
-190,D,A52,dyne second per centimetre to the fifth power,nan,2,dyn·s/cm⁵,10⁵ Pa x s/m³
-191,nan,A53,electronvolt,nan,1,eV,"1,602 176 487 x 10⁻¹⁹ J"
-192,nan,A54,electronvolt per metre,nan,1,eV/m,"1,602 176 487 x 10⁻¹⁹ J/m"
-193,nan,A55,electronvolt square metre,nan,1,eV·m²,"1,602 176 487 x 10⁻¹⁹ J x m²"
-194,nan,A56,electronvolt square metre per kilogram,nan,1,eV·m²/kg,"1,602 176 487 x 10⁻¹⁹ J x m²/kg"
-195,D,A57,erg,nan,2,erg,10⁻⁷J
-196,D,A58,erg per centimetre,nan,2,erg/cm,10⁻⁵ J/m
-197,nan,A59,8-part cloud cover,"A unit of count defining the number of eighth-parts as a measure of the celestial dome cloud coverage.,Synonym: OKTA , OCTA",3.9,nan,nan
-198,nan,A6,ampere per square metre kelvin squared,nan,1,A/(m²·K²),A/(m² x K²)
-199,D,A60,erg per cubic centimetre,nan,2,erg/cm³,10⁻¹ J/m³
-200,D,A61,erg per gram,nan,2,erg/g,10⁻⁴ J/kg
-201,D,A62,erg per gram second,nan,2,erg/g·s,10⁻⁴ W/kg
-202,D,A63,erg per second,nan,2,erg/s,10⁻⁷ W
-203,D,A64,erg per second square centimetre,nan,2,erg/(s·cm²),10⁻³ W/m²
-204,D,A65,erg per square centimetre second,nan,2,erg/(cm²·s),10⁻³ W/m²
-205,D,A66,erg square centimetre,nan,2,erg·cm²,10⁻¹¹ J x m²
-206,D,A67,erg square centimetre per gram,nan,2,erg·cm²/g,10⁻⁸ J x m²/kg
-207,nan,A68,exajoule,nan,1S,EJ,10¹⁸ J
-208,nan,A69,farad per metre,nan,1,F/m,kg⁻¹ x m⁻³ x s⁴ x A²
-209,nan,A7,ampere per square millimetre,nan,1S,A/mm²,10⁶ A/m²
-210,nan,A70,femtojoule,nan,1S,fJ,10⁻¹⁵ J
-211,nan,A71,femtometre,nan,1S,fm,10⁻¹⁵ m
-212,nan,A73,foot per second squared,nan,2,ft/s²,"0,304 8 m/s²"
-213,nan,A74,foot pound-force per second,nan,2,ft·lbf/s,"1,355 818 W"
-214,nan,A75,freight ton,"A unit of information typically used for billing purposes, defined as either the number of metric tons or the number of cubic metres, whichever is the larger.",3.4,nan,nan
-215,nan,A76,gal,nan,1S,Gal,10⁻² m/s²
-216,D,A77,Gaussian CGS (Centimetre-Gram-Second system) unit of displacement,nan,3.5,nan,nan
-217,D,A78,Gaussian CGS (Centimetre-Gram-Second system) unit of electric current,nan,3.5,nan,nan
-218,D,A79,Gaussian CGS (Centimetre-Gram-Second system) unit of electric charge,nan,3.5,nan,nan
-219,nan,A8,ampere second,nan,1,A·s,C
-220,D,A80,Gaussian CGS (Centimetre-Gram-Second system) unit of electric field strength,nan,3.5,nan,nan
-221,D,A81,Gaussian CGS (Centimetre-Gram-Second system) unit of electric polarization,nan,3.5,nan,nan
-222,D,A82,Gaussian CGS (Centimetre-Gram-Second system) unit of electric potential,nan,3.5,nan,nan
-223,D,A83,Gaussian CGS (Centimetre-Gram-Second system) unit of magnetization,nan,3.5,nan,nan
-224,nan,A84,gigacoulomb per cubic metre,nan,1S,GC/m³,10⁹ C/m³
-225,nan,A85,gigaelectronvolt,nan,1S,GeV,10⁹ eV
-226,nan,A86,gigahertz,nan,1S,GHz,10⁹ Hz
-227,nan,A87,gigaohm,nan,1S,GΩ,10⁹ Ω
-228,nan,A88,gigaohm metre,nan,1S,GΩ·m,10⁹ Ω x m
-229,nan,A89,gigapascal,nan,1S,GPa,10⁹ Pa
-230,nan,A9,rate,A unit of quantity expressed as a rate for usage of a facility or service.,3.9,nan,nan
-231,nan,A90,gigawatt,nan,1S,GW,10⁹ W
-232,nan,A91,gon,Synonym: grade,2,gon,"1,570 796 x 10⁻² rad"
-233,nan,A93,gram per cubic metre,nan,1M,g/m³,10⁻³ kg/m³
-234,nan,A94,gram per mole,nan,1S,g/mol,10⁻³ kg/mol
-235,nan,A95,gray,nan,1,Gy,m²/s²
-236,nan,A96,gray per second,nan,1,Gy/s,m²/s³
-237,nan,A97,hectopascal,nan,1S,hPa,10² Pa
-238,nan,A98,henry per metre,nan,1,H/m,H/m
-239,nan,A99,bit,A unit of information equal to one binary digit.,3.6,bit,nan
-240,nan,AA,ball,A unit of count defining the number of balls (ball: object formed in the shape of sphere).,3.9,nan,nan
-241,nan,AB,bulk pack,A unit of count defining the number of items per bulk pack.,3.9,pk,nan
-242,nan,ACR,acre,nan,2,acre,"4 046,873 m²"
-243,nan,ACT,activity,A unit of count defining the number of activities (activity: a unit of work or action).,3.2,nan,nan
-244,nan,AD,byte,A unit of information equal to 8 bits.,3.6,byte,nan
-245,nan,AE,ampere per metre,nan,1,A/m,A/m
-246,nan,AH,additional minute,A unit of time defining the number of minutes in addition to the referenced minutes.,3.5,nan,nan
-247,nan,AI,average minute per call,A unit of count defining the number of minutes for the average interval of a call.,3.5,nan,nan
-248,X,AJ,cop,nan,3.9,nan,nan
-249,nan,AK,fathom,nan,2,fth,"1,828 8 m"
-250,nan,AL,access line,A unit of count defining the number of telephone access lines.,3.5,nan,nan
-251,X,AM,ampoule,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-252,nan,AMH,ampere hour,A unit of electric charge defining the amount of charge accumulated by a steady flow of one ampere for one hour.,1M,A·h,"3,6 x 10³ C"
-253,nan,AMP,ampere,nan,1,A,A
-254,nan,ANN,year,"Unit of time equal to 365,25 days.,Synonym: Julian year",2,y,"3,155 76 x 10⁷ s"
-255,X,AP,aluminium pound only,nan,3.1,nan,nan
-256,nan,APZ,troy ounce or apothecary ounce,nan,2,tr oz,"3,110 348 x 10⁻³ kg"
-257,nan,AQ,anti-hemophilic factor (AHF) unit,A unit of measure for blood potency (US).,3.9,nan,nan
-258,X,AR,suppository,nan,3.3,nan,nan
-259,D,ARE,are,Synonym: square decametre,2.0,a,10² m²
-260,nan,AS,assortment,A unit of count defining the number of assortments (assortment: set of items grouped in a mixed collection).,3.9,nan,nan
-261,nan,ASM,alcoholic strength by mass,A unit of mass defining the alcoholic strength of a liquid.,3.5,nan,nan
-262,nan,ASU,alcoholic strength by volume,"A unit of volume defining the alcoholic strength of a liquid (e.g. spirit, wine, beer, etc), often at a specific temperature.",3.5,nan,nan
-263,nan,ATM,standard atmosphere,nan,1,atm,1 013 25 Pa
-264,D,ATT,technical atmosphere,nan,2,at,"98 066,5 Pa"
-265,X,AV,capsule,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-266,X,AW,powder filled vial,nan,3.3,nan,nan
-267,nan,AWG,american wire gauge,A unit of distance used for measuring the diameter of small tubes or wires such as the outer diameter of hypotermic or suture needles.,2,AWG,nan
-268,nan,AY,assembly,A unit of count defining the number of assemblies (assembly: items that consist of component parts).,3.9,nan,nan
-269,nan,AZ,British thermal unit (international table) per pound,nan,2,BtuIT/lb,2 326 J/kg
-270,X,B0,Btu per cubic foot,nan,3.9,BTU/ft³,nan
-271,nan,B1,barrel (US) per day,nan,3.5,barrel (US)/d,"1,840 13 x 10⁻⁶ m³/s"
-272,nan,B10,bit per second,A unit of information equal to one binary digit per second.,3.6,bit/s,nan
-273,nan,B11,joule per kilogram kelvin,nan,1,J/(kg·K),J/(kg x K)
-274,nan,B12,joule per metre,nan,1,J/m,J/m
-275,nan,B13,joule per square metre,Synonym: joule per metre squared,1,J/m²,J/m²
-276,nan,B14,joule per metre to the fourth power,nan,1,J/m⁴,J/m⁴
-277,nan,B15,joule per mole,nan,1,J/mol,J/mol
-278,nan,B16,joule per mole kelvin,nan,1,J/(mol·K),J/(mol x K)
-279,nan,B17,credit,A unit of count defining the number of entries made to the credit side of an account.,3.9,nan,nan
-280,nan,B18,joule second,nan,1,J·s,J x s
-281,nan,B19,digit,A unit of information defining the quantity of numerals used to form a number.,3.7,nan,nan
-282,X,B2,bunk,nan,3.9,nan,nan
-283,nan,B20,joule square metre per kilogram,nan,1,J·m²/kg,J x m²/kg
-284,nan,B21,kelvin per watt,nan,1,K/W,K/W
-285,nan,B22,kiloampere,nan,1S,kA,10³ A
-286,nan,B23,kiloampere per square metre,nan,1S,kA/m²,10³ A/m²
-287,nan,B24,kiloampere per metre,nan,1S,kA/m,10³ A/m
-288,nan,B25,kilobecquerel per kilogram,nan,1S,kBq/kg,10³ Bq/kg
-289,nan,B26,kilocoulomb,nan,1S,kC,10³ C
-290,nan,B27,kilocoulomb per cubic metre,nan,1S,kC/m³,10³ C/m³
-291,nan,B28,kilocoulomb per square metre,nan,1S,kC/m²,10³ C/m²
-292,nan,B29,kiloelectronvolt,nan,1S,keV,10³ eV
-293,nan,B3,batting pound,A unit of mass defining the number of pounds of wadded fibre.,3.1,nan,nan
-294,nan,B30,gibibit,A unit of information equal to 2³⁰ bits (binary digits).,3.6,Gibit,nan
-295,nan,B31,kilogram metre per second,nan,1,kg·m/s,kg x m/s
-296,nan,B32,kilogram metre squared,nan,1,kg·m²,kg x m²
-297,nan,B33,kilogram metre squared per second,nan,1,kg·m²/s,kg x m²/s
-298,nan,B34,kilogram per cubic decimetre,nan,1S,kg/dm³,10³ kg/m³
-299,nan,B35,kilogram per litre,nan,1S,kg/l or kg/L,10³ kg/m³
-300,D,B36,calorie (thermochemical) per gram,nan,2,calth/g,4 184 J/kg
-301,D,B37,kilogram-force,nan,2,kgf,"9,806 65 N"
-302,D,B38,kilogram-force metre,nan,2,kgf·m,"9,806 65 N x m"
-303,D,B39,kilogram-force metre per second,nan,2,kgf·m/s,"9,806 65 W"
-304,nan,B4,"barrel, imperial",A unit of volume used to measure beer.  One beer barrel equals 36 imperial gallons.,3.5,nan,nan
-305,D,B40,kilogram-force per square metre,nan,2,kgf/m²,"9,806 65 Pa"
-306,nan,B41,kilojoule per kelvin,nan,1S,kJ/K,10³ J/K
-307,nan,B42,kilojoule per kilogram,nan,1S,kJ/kg,10³ J/kg
-308,nan,B43,kilojoule per kilogram kelvin,nan,1S,kJ/(kg·K),10³ J/(kg x K)
-309,nan,B44,kilojoule per mole,nan,1S,kJ/mol,10³ J/mol
-310,nan,B45,kilomole,nan,1S,kmol,10³ mol
-311,nan,B46,kilomole per cubic metre,nan,1S,kmol/m³,10³ mol/m³
-312,nan,B47,kilonewton,nan,1S,kN,10³ N
-313,nan,B48,kilonewton metre,nan,1S,kN·m,10³ N x m
-314,nan,B49,kiloohm,nan,1S,kΩ,10³ Ω
-315,X,B5,billet,nan,3.9,nan,nan
-316,nan,B50,kiloohm metre,nan,1S,kΩ·m,10³ Ω x m
-317,D,B51,kilopond,Synonym: kilogram-force,2,kp,"9,806 65 N"
-318,nan,B52,kilosecond,nan,1S,ks,10³ s
-319,nan,B53,kilosiemens,nan,1S,kS,10³ S
-320,nan,B54,kilosiemens per metre,nan,1S,kS/m,10³ S/m
-321,nan,B55,kilovolt per metre,nan,1S,kV/m,10³ V/m
-322,nan,B56,kiloweber per metre,nan,1S,kWb/m,10³ Wb/m
-323,nan,B57,light year,A unit of length defining the distance that light travels in a vacuum in one year.,2,ly,"9,460 73 x 10¹⁵ m"
-324,nan,B58,litre per mole,nan,1M,l/mol,10⁻³ m³/mol
-325,nan,B59,lumen hour,nan,1S,lm·h,"3,6 x 10³ s x cd x sr"
-326,X,B6,bun,nan,3.9,nan,nan
-327,nan,B60,lumen per square metre,nan,1,lm/m²,cd x sr/m²
-328,nan,B61,lumen per watt,nan,1,lm/W,cd x sr/W
-329,nan,B62,lumen second,nan,1,lm·s,s x cd x sr
-330,nan,B63,lux hour,nan,1S,lx·h,"3,6 x 10³ s x cd x sr / m²"
-331,nan,B64,lux second,nan,1,lx·s,s x cd x sr / m²
-332,D,B65,maxwell,nan,3.5,Mx,10⁻⁸ Wb
-333,nan,B66,megaampere per square metre,nan,1S,MA/m²,10⁶ A/m²
-334,nan,B67,megabecquerel per kilogram,nan,1S,MBq/kg,10⁶ Bq/kg
-335,nan,B68,gigabit,A unit of information equal to 10⁹ bits (binary digits).,3.6,Gbit,nan
-336,nan,B69,megacoulomb per cubic metre,nan,1S,MC/m³,10⁶ C/m³
-337,nan,B7,cycle,A unit of count defining the number of cycles (cycle: a recurrent period of definite duration).,3.9,nan,nan
-338,nan,B70,megacoulomb per square metre,nan,1S,MC/m²,10⁶ C/m²
-339,nan,B71,megaelectronvolt,nan,1S,MeV,10⁶ eV
-340,nan,B72,megagram per cubic metre,nan,1S,Mg/m³,10³ kg/m³
-341,nan,B73,meganewton,nan,1S,MN,10⁶ N
-342,nan,B74,meganewton metre,nan,1S,MN·m,10⁶ N x m
-343,nan,B75,megaohm,nan,1S,MΩ,10⁶ Ω
-344,nan,B76,megaohm metre,nan,1S,MΩ·m,10⁶ Ω x m
-345,nan,B77,megasiemens per metre,nan,1S,MS/m,10⁶ S/m
-346,nan,B78,megavolt,nan,1S,MV,10⁶ V
-347,nan,B79,megavolt per metre,nan,1S,MV/m,10⁶ V/m
-348,nan,B8,joule per cubic metre,nan,1,J/m³,J/m³
-349,nan,B80,gigabit per second,A unit of information equal to 10⁹ bits (binary digits) per second.,3.6,Gbit/s,nan
-350,nan,B81,reciprocal metre squared reciprocal second,nan,1,m⁻²/s,m⁻²/s
-351,nan,B82,inch per linear foot,A unit of length defining the number of inches per linear foot.,3.1,nan,nan
-352,nan,B83,metre to the fourth power,nan,1,m⁴,m⁴
-353,nan,B84,microampere,nan,1S,µA,10⁻⁶ A
-354,nan,B85,microbar,nan,1S,µbar,10⁻¹ Pa
-355,nan,B86,microcoulomb,nan,1S,µC,10⁻⁶ C
-356,nan,B87,microcoulomb per cubic metre,nan,1S,µC/m³,10⁻⁶ C/m³
-357,nan,B88,microcoulomb per square metre,nan,1S,µC/m²,10⁻⁶ C/m²
-358,nan,B89,microfarad per metre,nan,1S,µF/m,10⁻⁶ F/m
-359,X,B9,batt,nan,3.9,nan,nan
-360,nan,B90,microhenry,nan,1S,µH,10⁻⁶ H
-361,nan,B91,microhenry per metre,nan,1S,µH/m,10⁻⁶ H/m
-362,nan,B92,micronewton,nan,1S,µN,10⁻⁶ N
-363,nan,B93,micronewton metre,nan,1S,µN·m,10⁻⁶ N x m
-364,nan,B94,microohm,nan,1S,µΩ,10⁻⁶ Ω
-365,nan,B95,microohm metre,nan,1S,µΩ·m,10⁻⁶ Ω x m
-366,nan,B96,micropascal,nan,1S,µPa,10⁻⁶ Pa
-367,nan,B97,microradian,nan,1S,µrad,10⁻⁶ rad
-368,nan,B98,microsecond,nan,1S,µs,10⁻⁶ s
-369,nan,B99,microsiemens,nan,1S,µS,10⁻⁶ S
-370,nan,BAR,bar [unit of pressure],nan,1,bar,10⁵ Pa
-371,nan,BB,base box,"A unit of area of 112 sheets of tin mil products (tin plate, tin free steel or black plate) 14 by 20 inches, or 31,360 square inches.",3.5,nan,nan
-372,X,BD,board,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-373,X,BE,bundle,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-374,nan,BFT,board foot,A unit of volume defining the number of cords (cord: a stack of firewood of 128 cubic feet).,3.5,fbm,nan
-375,X,BG,bag,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-376,X,BH,brush,nan,3.9,nan,nan
-377,nan,BHP,brake horse power,nan,2,BHP,"7,457 x 10² W"
-378,nan,BIL,billion (EUR),Synonym: trillion (US),3.7,nan,10¹²
-379,X,BJ,bucket,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-380,X,BK,basket,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-381,X,BL,bale,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-382,nan,BLD,dry barrel (US),nan,2,bbl (US),"1,156 27 x 10⁻¹ m³"
-383,nan,BLL,barrel (US),nan,2,barrel (US),"158,987 3 x 10⁻³ m³"
-384,X,BO,bottle,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-385,nan,BP,hundred board foot,A unit of volume equal to one hundred board foot.,3.5,nan,nan
-386,nan,BPM,beats per minute,The number of beats per minute.,3.1,BPM,1.667 x 10-2 /s
-387,nan,BQL,becquerel,nan,1,Bq,"27,027 x 10⁻¹² Ci"
-388,X,BR,bar [unit of packaging],"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-389,X,BT,bolt,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-390,nan,BTU,British thermal unit (international table),nan,2,BtuIT,"1,055 056 x 10³ J"
-391,nan,BUA,bushel (US),nan,2,bu (US),"3,523 907 x 10⁻² m³"
-392,nan,BUI,bushel (UK),nan,2,bushel (UK),"3,636 872 x 10⁻² m³"
-393,X,BW,base weight,nan,3.9,nan,nan
-394,X,BX,box,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-395,X,BZ,million BTUs,nan,3.8,nan,nan
-396,nan,C0,call,A unit of count defining the number of calls (call: communication session or visitation).,3.5,nan,nan
-397,X,C1,composite product pound (total weight),nan,3.9,nan,nan
-398,nan,C10,millifarad,nan,1S,mF,10⁻³ F
-399,nan,C11,milligal,nan,1M,mGal,10⁻⁵ m/s²
-400,nan,C12,milligram per metre,nan,1S,mg/m,10⁻⁶ kg/m
-401,nan,C13,milligray,nan,1S,mGy,10⁻³ Gy
-402,nan,C14,millihenry,nan,1S,mH,10⁻³ H
-403,nan,C15,millijoule,nan,1S,mJ,10⁻³ J
-404,nan,C16,millimetre per second,nan,1S,mm/s,10⁻³ m/s
-405,nan,C17,millimetre squared per second,nan,1S,mm²/s,10⁻⁶ m²/s
-406,nan,C18,millimole,nan,1S,mmol,10⁻³ mol
-407,nan,C19,mole per kilogram,nan,1,mol/kg,mol/kg
-408,X,C2,carset,nan,3.5,nan,nan
-409,nan,C20,millinewton,nan,1S,mN,10⁻³ N
-410,nan,C21,kibibit,A unit of information equal to 2¹⁰ (1024) bits (binary digits).,3.6,Kibit,nan
-411,nan,C22,millinewton per metre,nan,1S,mN/m,10⁻³ N/m
-412,nan,C23,milliohm metre,nan,1S,mΩ·m,10⁻³ Ω x m
-413,nan,C24,millipascal second,nan,1S,mPa·s,10⁻³ Pa x s
-414,nan,C25,milliradian,nan,1S,mrad,10⁻³ rad
-415,nan,C26,millisecond,nan,1S,ms,10⁻³ s
-416,nan,C27,millisiemens,nan,1S,mS,10⁻³ S
-417,nan,C28,millisievert,nan,1S,mSv,10⁻³ Sv
-418,nan,C29,millitesla,nan,1S,mT,10⁻³ T
-419,nan,C3,microvolt per metre,nan,1S,µV/m,10⁻⁶ V/m
-420,nan,C30,millivolt per metre,nan,1S,mV/m,10⁻³ V/m
-421,nan,C31,milliwatt,nan,1S,mW,10⁻³ W
-422,nan,C32,milliwatt per square metre,nan,1S,mW/m²,10⁻³ W/m²
-423,nan,C33,milliweber,nan,1S,mWb,10⁻³ Wb
-424,nan,C34,mole,nan,1,mol,mol
-425,nan,C35,mole per cubic decimetre,nan,1S,mol/dm³,10³ mol/m³
-426,nan,C36,mole per cubic metre,nan,1,mol/m³,mol/m³
-427,nan,C37,kilobit,A unit of information equal to 10³ (1000) bits (binary digits).,3.6,kbit,nan
-428,nan,C38,mole per litre,nan,1,mol/l,10³ mol/m³
-429,nan,C39,nanoampere,nan,1S,nA,10⁻⁹ A
-430,X,C4,carload,nan,3.5,nan,nan
-431,nan,C40,nanocoulomb,nan,1S,nC,10⁻⁹ C
-432,nan,C41,nanofarad,nan,1S,nF,10⁻⁹ F
-433,nan,C42,nanofarad per metre,nan,1S,nF/m,10⁻⁹ F/m
-434,nan,C43,nanohenry,nan,1S,nH,10⁻⁹ H
-435,nan,C44,nanohenry per metre,nan,1S,nH/m,10⁻⁹ H/m
-436,nan,C45,nanometre,nan,1S,nm,10⁻⁹ m
-437,nan,C46,nanoohm metre,nan,1S,nΩ·m,10⁻⁹ Ω·x m
-438,nan,C47,nanosecond,nan,1S,ns,10⁻⁹ s
-439,nan,C48,nanotesla,nan,1S,nT,10⁻⁹ T
-440,nan,C49,nanowatt,nan,1S,nW,10⁻⁹ W
-441,X,C5,cost,nan,3.9,nan,nan
-442,nan,C50,neper,nan,1,Np,Np
-443,nan,C51,neper per second,nan,1,Np/s,Np/s
-444,nan,C52,picometre,nan,1S,pm,10⁻¹² m
-445,nan,C53,newton metre second,nan,1,N·m·s,N x m x s
-446,nan,C54,newton metre squared per kilogram squared,nan,1,N·m²/kg²,N x m²/kg²
-447,nan,C55,newton per square metre,nan,1S,N/m²,Pa
-448,nan,C56,newton per square millimetre,nan,1S,N/mm²,10⁶ Pa
-449,nan,C57,newton second,nan,1,N·s,N x s
-450,nan,C58,newton second per metre,nan,1,N·s/m,N x s/m
-451,nan,C59,octave,A unit used in music to describe the ratio in frequency between notes.,1,nan,nan
-452,X,C6,cell,nan,3.9,nan,nan
-453,nan,C60,ohm centimetre,nan,1S,Ω·cm,10⁻² Ω x m 
-454,nan,C61,ohm metre,nan,1,Ω·m,Ω x m
-455,nan,C62,one,Synonym: unit,1,1,1
-456,nan,C63,parsec,nan,1,pc,"3,085 678 x 10¹⁶ m"
-457,nan,C64,pascal per kelvin,nan,1,Pa/K,Pa/K
-458,nan,C65,pascal second,nan,1,Pa·s,Pa x s
-459,nan,C66,pascal second per cubic metre,nan,1,Pa·s/m³,Pa x s/m³
-460,nan,C67,pascal second per metre,nan,1,Pa· s/m,Pa x s/m
-461,nan,C68,petajoule,nan,1S,PJ,10¹⁵ J
-462,nan,C69,phon,A unit of subjective sound loudness. A sound has loudness p phons if it seems to the listener to be equal in loudness to the sound of a pure tone of frequency 1 kilohertz and strength p decibels.,1,nan,nan
-463,nan,C7,centipoise,nan,2,cP,10⁻³ Pa x s
-464,nan,C70,picoampere,nan,1S,pA,10⁻¹² A
-465,nan,C71,picocoulomb,nan,1S,pC,10⁻¹² C
-466,nan,C72,picofarad per metre,nan,1S,pF/m,10⁻¹² F/m
-467,nan,C73,picohenry,nan,1S,pH,10⁻¹² H
-468,nan,C74,kilobit per second,A unit of information equal to 10³ (1000) bits (binary digits) per second.,3.6,kbit/s,10³ bit/s
-469,nan,C75,picowatt,nan,1S,pW,10⁻¹² W
-470,nan,C76,picowatt per square metre,nan,1S,pW/m²,10⁻¹² W/m²
-471,X,C77,pound gage,nan,3.1,nan,nan
-472,nan,C78,pound-force,nan,2,lbf,"4,448 222 N"
-473,nan,C79,kilovolt ampere hour,A unit of accumulated energy of 1000 volt amperes over a period of one hour.,3.1,kVAh,nan
-474,nan,C8,millicoulomb per kilogram,nan,1S,mC/kg,10⁻³ C/kg
-475,nan,C80,rad,nan,2,rad,10⁻² Gy
-476,nan,C81,radian,nan,1,rad,rad
-477,nan,C82,radian square metre per mole,nan,1,rad·m²/mol,rad x m²/mol
-478,nan,C83,radian square metre per kilogram,nan,1,rad·m²/kg,rad x m²/kg
-479,nan,C84,radian per metre,nan,1,rad/m,rad/m
-480,nan,C85,reciprocal angstrom,nan,1,Å⁻¹,10¹⁰ m⁻¹
-481,nan,C86,reciprocal cubic metre,nan,1,m⁻³,m⁻³
-482,nan,C87,reciprocal cubic metre per second,Synonym: reciprocal second per cubic metre,1,m⁻³/s,m⁻³/s
-483,nan,C88,reciprocal electron volt per cubic metre,nan,1,eV⁻¹/m³,"6,241 46 x 10¹⁸ J⁻¹/m³"
-484,nan,C89,reciprocal henry,nan,1,H⁻¹,H⁻¹
-485,nan,C9,coil group,A unit of count defining the number of coil groups (coil group: groups of items arranged by lengths of those items placed in a joined sequence of concentric circles).,3.9,nan,nan
-486,nan,C90,reciprocal joule per cubic metre,nan,1,J⁻¹/m³,J⁻¹/m³
-487,nan,C91,reciprocal kelvin or kelvin to the power minus one,nan,1,K⁻¹,K⁻¹
-488,nan,C92,reciprocal metre,nan,1,m⁻¹,m⁻¹
-489,nan,C93,reciprocal square metre,Synonym: reciprocal metre squared,1,m⁻²,m⁻²
-490,nan,C94,reciprocal minute,nan,1S,min⁻¹,"1,666 667 x 10⁻² s"
-491,nan,C95,reciprocal mole,nan,1,mol⁻¹,mol⁻¹
-492,nan,C96,reciprocal pascal or pascal to the power minus one,nan,1,Pa⁻¹,Pa⁻¹
-493,nan,C97,reciprocal second,nan,1,s⁻¹,s⁻¹
-494,X,C98,reciprocal second per cubic metre,nan,1,s⁻¹/m³,s⁻¹/m³
-495,nan,C99,reciprocal second per metre squared,nan,1,s⁻¹/m²,s⁻¹/m²
-496,X,CA,can,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-497,nan,CCT,carrying capacity in metric ton,"A unit of mass defining the carrying capacity, expressed as the number of metric tons.",3.4,nan,nan
-498,nan,CDL,candela,nan,1,cd,cd
-499,nan,CEL,degree Celsius,Refer ISO 80000-5 (Quantities and units — Part 5: Thermodynamics),1,°C,1 x K
-500,nan,CEN,hundred,A unit of count defining the number of units in multiples of 100.,3.7,nan,100
-501,nan,CG,card,A unit of count defining the number of units of card (card: thick stiff paper or cardboard).,3.9,nan,nan
-502,nan,CGM,centigram,nan,1M,cg,10⁻⁵ kg
-503,X,CH,container,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.4,nan,nan
-504,X,CJ,cone,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.9,nan,nan
-505,X,CK,connector,nan,3.9,nan,nan
-506,nan,CKG,coulomb per kilogram,nan,1,C/kg,A x s/kg
-507,X,CL,coil,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-508,nan,CLF,hundred leave,"A unit of count defining the number of leaves, expressed in units of one hundred leaves.",3.8,nan,nan
-509,nan,CLT,centilitre,nan,1S,cl,10⁻⁵ m³
-510,nan,CMK,square centimetre,nan,1S,cm²,10⁻⁴ m²
-511,nan,CMQ,cubic centimetre,nan,1S,cm³,10⁻⁶ m³
-512,nan,CMT,centimetre,nan,"1S,3.5",cm,10⁻² m
-513,nan,CNP,hundred pack,A unit of count defining the number of hundred-packs (hundred-pack: set of one hundred items packaged together).,"3.2,3.8",nan,nan
-514,nan,CNT,cental (UK),A unit of mass equal to one hundred weight (US).,3.5,nan,"45,359 237 kg"
-515,X,CO,carboy,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-516,nan,COU,coulomb,nan,1,C,A x s
-517,X,CQ,cartridge,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.9,nan,nan
-518,X,CR,crate,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-519,X,CS,case,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-520,X,CT,carton,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-521,nan,CTG,content gram,A unit of mass defining the number of grams of a named item in a product.,3.1,nan,nan
-522,nan,CTM,metric carat,nan,3.5,nan,200 mg
-523,nan,CTN,content ton (metric),A unit of mass defining the number of metric tons of a named item in a product.,3.1,nan,nan
-524,X,CU,cup,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-525,nan,CUR,curie,nan,2,Ci,"3,7 x 10¹⁰ Bq"
-526,X,CV,cover,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-527,nan,CWA,hundred pound (cwt) / hundred weight (US),nan,2,cwt (US),"45,359 2 kg"
-528,nan,CWI,hundred weight (UK),nan,2,cwt (UK),"50,802 35 kg"
-529,X,CY,cylinder,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-530,X,CZ,combo,nan,3.9,nan,nan
-531,nan,D03,kilowatt hour per hour,A unit of accumulated energy of a thousand watts over a period of one hour.,3.1,kW·h/h,nan
-532,nan,D04,lot [unit of weight],A unit of weight equal to about 1/2 ounce or 15 grams.,3.2,nan,nan
-533,nan,D1,reciprocal second per steradian,nan,1,s⁻¹/sr,s⁻¹/sr
-534,nan,D10,siemens per metre,nan,1,S/m,S/m
-535,nan,D11,mebibit,A unit of information equal to 2²⁰ (1048576) bits (binary digits).,3.6,Mibit,nan
-536,nan,D12,siemens square metre per mole,nan,1,S·m²/mol,S x m²/mol
-537,nan,D13,sievert,nan,1,Sv,m²/s²
-538,X,D14,thousand linear yard,nan,3.8,nan,nan
-539,nan,D15,sone,A unit of subjective sound loudness. One sone is the loudness of a pure tone of frequency one kilohertz and strength 40 decibels.,1,nan,nan
-540,nan,D16,square centimetre per erg,nan,2,cm²/erg,10³ m²/J
-541,nan,D17,square centimetre per steradian erg,nan,2,cm²/(sr·erg),10³ m²/(sr x J)
-542,nan,D18,metre kelvin,nan,1,m·K,m x K
-543,nan,D19,square metre kelvin per watt,nan,1,m²·K/W,m² x K/W
-544,nan,D2,reciprocal second per steradian metre squared,nan,1,s⁻¹/(sr·m²),s⁻¹/(sr x m²)
-545,nan,D20,square metre per joule,nan,1,m²/J,m²/J
-546,nan,D21,square metre per kilogram,nan,1,m²/kg,m²/kg
-547,nan,D22,square metre per mole,nan,1,m²/mol,m²/mol
-548,nan,D23,pen gram (protein),A unit of count defining the number of grams of amino acid prescribed for parenteral/enteral therapy.,3.9,nan,nan
-549,nan,D24,square metre per steradian,nan,1,m²/sr,m²/sr
-550,nan,D25,square metre per steradian joule,nan,1,m²/(sr·J),m²/(sr x J)
-551,nan,D26,square metre per volt second,nan,1,m²/(V·s),m²/(V x s)
-552,nan,D27,steradian,nan,1,sr,sr
-553,X,D28,syphon,nan,3.9,nan,nan
-554,nan,D29,terahertz,nan,1S,THz,10¹² Hz
-555,nan,D30,terajoule,nan,1S,TJ,10¹² J
-556,nan,D31,terawatt,nan,1S,TW,10¹² W
-557,nan,D32,terawatt hour,nan,1S,TW·h,"3,6 x 10¹⁵ J"
-558,nan,D33,tesla,nan,1,T,T
-559,nan,D34,tex,A unit of yarn density. One decitex equals a mass of 1 gram per 1 kilometre of length.,3.5,tex (g/km),10⁻⁶ kg/m
-560,D,D35,calorie (thermochemical),nan,2,calth,"4,184 J"
-561,nan,D36,megabit,A unit of information equal to 10⁶ (1000000) bits (binary digits).,3.6,Mbit,nan
-562,D,D37,calorie (thermochemical) per gram kelvin,nan,2,calth/(g·K),"4,184 x 10³ J/(kg x K)"
-563,D,D38,calorie (thermochemical) per second centimetre kelvin,nan,2,calth/(s·cm·K),"418,4 W/(m x K)"
-564,D,D39,calorie (thermochemical) per second square centimetre kelvin,nan,2,calth/(s·cm²·K),"4,184 x10⁴ W/(m² x K)"
-565,X,D40,thousand litre,nan,3.8,nan,m³
-566,nan,D41,tonne per cubic metre,nan,1S,t/m³,10³ kg/m³
-567,nan,D42,tropical year,nan,2,y (tropical),"3,155 692 5 x 10⁷ s"
-568,nan,D43,unified atomic mass unit,nan,1,u,"1,660 538 782 x 10⁻²⁷ kg"
-569,nan,D44,var,The name of the unit is an acronym for volt-ampere-reactive.,1,var,V x A
-570,nan,D45,volt squared per kelvin squared,nan,1,V²/K²,V²/K²
-571,nan,D46,volt - ampere,nan,1,V·A,W
-572,nan,D47,volt per centimetre,nan,1S,V/cm,V/m x 10²
-573,nan,D48,volt per kelvin,nan,1,V/K,V/K
-574,nan,D49,millivolt per kelvin,nan,1S,mV/K,10⁻³ V/K
-575,nan,D5,kilogram per square centimetre,nan,2,kg/cm²,10⁴ kg/m²
-576,nan,D50,volt per metre,nan,1,V/m,V/m
-577,nan,D51,volt per millimetre,nan,1S,V/mm,10³ V/m
-578,nan,D52,watt per kelvin,nan,1,W/K,W/K
-579,nan,D53,watt per metre kelvin,nan,1,W/(m·K),W/(m x K)
-580,nan,D54,watt per square metre,nan,1,W/m²,W/m²
-581,nan,D55,watt per square metre kelvin,nan,1,W/(m²·K),W/(m² x K)
-582,nan,D56,watt per square metre kelvin to the fourth power,nan,1,W/(m²·K⁴),W/(m² x K⁴)
-583,nan,D57,watt per steradian,nan,1,W/sr,W/sr
-584,nan,D58,watt per steradian square metre,nan,1,W/(sr·m²),W/(sr x m²)
-585,nan,D59,weber per metre,nan,1,Wb/m,Wb/m
-586,nan,D6,roentgen per second,nan,2,R/s,"2,58 x 10⁻⁴ C/(kg x s)"
-587,nan,D60,weber per millimetre,nan,1S,Wb/mm,10³ Wb/m
-588,nan,D61,minute [unit of angle],nan,1,',"2,908 882 x 10⁻⁴ rad"
-589,nan,D62,second [unit of angle],nan,1,"""","4,848 137 x 10⁻⁶ rad"
-590,nan,D63,book,A unit of count defining the number of books (book: set of items bound together or written document of a material whole).,3.9,nan,nan
-591,X,D64,block,nan,3.9,nan,nan
-592,nan,D65,round,A unit of count defining the number of rounds (round: A circular or cylindrical object).,3.9,nan,nan
-593,X,D66,cassette,nan,3.9,nan,nan
-594,X,D67,dollar per hour,nan,3.9,nan,nan
-595,nan,D68,number of words,A unit of count defining the number of words.,3.7,nan,nan
-596,nan,D69,inch to the fourth power,nan,2,in⁴,"41,623 14 x 10⁻⁸ m⁴"
-597,X,D7,sandwich,nan,3.9,nan,nan
-598,D,D70,calorie (international table),nan,2,calIT,"4,186 8 J"
-599,D,D71,calorie (international table) per second centimetre kelvin,nan,2,calIT/(s·cm·K),"418,68 W/(m x K)"
-600,D,D72,calorie (international table) per second square centimetre kelvin,nan,2,calIT/(s·cm²·K),"4,186 8 x 10⁴ W/(m² x K)"
-601,nan,D73,joule square metre,nan,1,J·m²,J x m²
-602,nan,D74,kilogram per mole,nan,1,kg/mol,kg/mol
-603,D,D75,calorie (international table) per gram,nan,2,calIT/g,"4 186,8 J/kg"
-604,D,D76,calorie (international table) per gram kelvin,nan,2,calIT/(g·K),"4 186,8 J/(kg x K)"
-605,nan,D77,megacoulomb,nan,1S,MC,10⁶ C
-606,nan,D78,megajoule per second,A unit of accumulated energy equal to one million joules per second.,3.1,MJ/s,nan
-607,X,D79,beam,nan,3.3,nan,nan
-608,X,D8,draize score,nan,3.7,nan,nan
-609,nan,D80,microwatt,nan,1S,µW,10⁻⁶ W
-610,nan,D81,microtesla,nan,1S,µT,10⁻⁶ T
-611,nan,D82,microvolt,nan,1S,µV,10⁻⁶ V
-612,nan,D83,millinewton metre,nan,1S,mN·m,10⁻³ N x m
-613,nan,D85,microwatt per square metre,nan,1S,µW/m²,10⁻⁶ W/m²
-614,nan,D86,millicoulomb,nan,1S,mC,10⁻³ C
-615,nan,D87,millimole per kilogram,nan,1S,mmol/kg,10⁻³ mol/kg
-616,nan,D88,millicoulomb per cubic metre,nan,1S,mC/m³,10⁻³ C/m³
-617,nan,D89,millicoulomb per square metre,nan,1S,mC/m²,10⁻³ C/m²
-618,D,D9,dyne per square centimetre,nan,"2,3.9",dyn/cm²,10⁻¹ Pa
-619,X,D90,cubic metre (net),nan,3.1,nan,nan
-620,nan,D91,rem,nan,2,rem,10⁻² Sv
-621,X,D92,band,nan,3.9,nan,nan
-622,nan,D93,second per cubic metre,nan,1,s/m³,s/m³
-623,nan,D94,second per cubic metre radian,nan,1,s/(rad·m³),s/(rad x m³)
-624,nan,D95,joule per gram,nan,1S,J/g,J/(10⁻³ x kg)
-625,X,D96,pound gross,nan,3.1,nan,nan
-626,X,D97,pallet/unit load,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.4,nan,nan
-627,X,D98,mass pound,nan,3.1,nan,nan
-628,X,D99,sleeve,nan,3.3,nan,nan
-629,nan,DAA,decare,nan,1M,daa,10³ m²
-630,nan,DAD,ten day,A unit of time defining the number of days in multiples of 10.,3.2,nan,nan
-631,nan,DAY,day,nan,1,d,86 400 s
-632,nan,DB,dry pound,"A unit of mass defining the number of pounds of a product, disregarding the water content of the product.",3.1,nan,nan
-633,X,DC,disk (disc),nan,3.9,nan,nan
-634,nan,DD,degree [unit of angle],nan,1,°,"1,745 329 x 10⁻² rad"
-635,X,DE,deal,nan,3.9,nan,nan
-636,nan,DEC,decade,A unit of count defining the number of decades (decade: quantity equal to 10 or time equal to 10 years).,3.8,nan,nan
-637,nan,DG,decigram,nan,1M,dg,10⁻⁴ kg
-638,X,DI,dispenser,nan,3.3,nan,nan
-639,nan,DJ,decagram,nan,1M,dag,10⁻² kg
-640,nan,DLT,decilitre,nan,1M,dl,10⁻⁴ m³
-641,nan,DMA,cubic decametre,nan,1S,dam³,10³ m³
-642,nan,DMK,square decimetre,nan,1S,dm²,10⁻² m²
-643,nan,DMO,standard kilolitre,"A unit of volume defining the number of kilolitres of a product at a temperature of 15 degrees Celsius, especially in relation to hydrocarbon oils.",3.1,nan,nan
-644,nan,DMQ,cubic decimetre,nan,1S,dm³,10⁻³ m³
-645,nan,DMT,decimetre,nan,1M,dm,10⁻¹ m
-646,nan,DN,decinewton metre,nan,1S,dN·m,10⁻¹ N x m
-647,nan,DPC,dozen piece,"A unit of count defining the number of pieces in multiples of 12 (piece: a single item, article or exemplar).",3.2,nan,nan
-648,nan,DPR,dozen pair,A unit of count defining the number of pairs in multiples of 12 (pair: item described by two's).,3.2,nan,nan
-649,nan,DPT,displacement tonnage,"A unit of mass defining the volume of sea water a ship displaces, expressed as the number of tons.",3.4,nan,nan
-650,X,DQ,data record,nan,3.6,nan,nan
-651,X,DR,drum,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-652,nan,DRA,dram (US),"Synonym: drachm (UK), troy dram",3.5,nan,"3,887 935 g"
-653,nan,DRI,dram (UK),Synonym: avoirdupois dram,3.5,nan,"1,771 745 g"
-654,nan,DRL,dozen roll,"A unit of count defining the number of rolls, expressed in twelve roll units.",3.2,nan,nan
-655,X,DRM,drachm (UK),nan,3.5,nan,"3,887 935 g"
-656,X,DS,display,nan,3.9,nan,nan
-657,nan,DT,dry ton,"A unit of mass defining the number of tons of a product, disregarding the water content of the product.",3.1,nan,nan
-658,nan,DTN,decitonne,"Synonym: centner, metric 100 kg; quintal, metric 100 kg","1M,3.5",dt or dtn,10² kg
-659,D,DU,dyne,nan,2,dyn,10⁻⁵ N
-660,nan,DWT,pennyweight,nan,3.5,nan,"1,555 174 g"
-661,D,DX,dyne per centimetre,nan,2,dyn/cm,10⁻³ N/m
-662,X,DY,directory book,nan,3.9,nan,nan
-663,nan,DZN,dozen,A unit of count defining the number of units in multiples of 12.,3.7,DOZ,12
-664,nan,DZP,dozen pack,A unit of count defining the number of packs in multiples of 12 (pack: standard packaging unit).,3.2,nan,nan
-665,nan,E01,newton per square centimetre,A measure of pressure expressed in newtons per square centimetre.,1M,N/cm²,10⁴ Pa
-666,nan,E07,megawatt hour per hour,A unit of accumulated energy of a million watts over a period of one hour.,3.1,MW·h/h,nan
-667,nan,E08,megawatt per hertz,A unit of energy expressed as the load change in million watts that will cause a frequency shift of one hertz.,3.1,MW/Hz,nan
-668,nan,E09,milliampere hour,A unit of power load delivered at the rate of one thousandth of an ampere over a period of one hour.,1M,mA·h,"3,6 C"
-669,nan,E10,degree day,A unit of measure used in meteorology and engineering to measure the demand for heating or cooling over a given period of days.,3.5,deg da,nan
-670,D,E11,gigacalorie,A unit of heat energy equal to one thousand million calories.,3.5,nan,10⁹ cal
-671,nan,E12,mille,A unit of count defining the number of cigarettes in units of 1000.,3.9,nan,nan
-672,nan,E14,kilocalorie (international table),A unit of heat energy equal to one thousand calories.,2,kcalIT,"4,186 8 x 10³ J"
-673,nan,E15,kilocalorie (thermochemical) per hour,A unit of energy equal to one thousand calories per hour.,2,kcalth/h,"1,162 22 W"
-674,nan,E16,million Btu(IT) per hour,A unit of power equal to one million British thermal units per hour.,3.1,BtuIT/h,"293 071,1 W"
-675,nan,E17,cubic foot per second,A unit of volume equal to one cubic foot passing a given point in a period of one second.,3.1,ft³/s,"2,831 685 x 10⁻² m³/s"
-676,nan,E18,tonne per hour,A unit of weight or mass equal to one tonne per hour.,2,t/h,"2,777 78 x 10⁻¹ kg/s"
-677,nan,E19,ping,A unit of area equal to 3.3 square metres.,3.1,nan,"3,305 m²"
-678,X,E2,belt,nan,3.9,nan,nan
-679,nan,E20,megabit per second,A unit of information equal to 10⁶ (1000000) bits (binary digits) per second.,3.6,Mbit/s,nan
-680,nan,E21,shares,A unit of count defining the number of shares (share: a total or portion of the parts into which a business entity’s capital is divided).,3.7,nan,nan
-681,nan,E22,TEU,A unit of count defining the number of twenty-foot equivalent units (TEUs) as a measure of containerized cargo capacity.,3.4,nan,nan
-682,nan,E23,tyre,"A unit of count defining the number of tyres (a solid or air-filled covering placed around a wheel rim to form a soft contact with the road, absorb shock and provide traction).",3.7,nan,nan
-683,nan,E25,active unit,A unit of count defining the number of active units within a substance.,3.9,nan,nan
-684,nan,E27,dose,A unit of count defining the number of doses (dose: a definite quantity of a medicine or drug).,3.9,nan,nan
-685,nan,E28,air dry ton,"A unit of mass defining the number of tons of a product, disregarding the water content of the product.",3.1,nan,nan
-686,X,E3,trailer,nan,3.4,nan,nan
-687,nan,E30,strand,"A unit of count defining the number of strands (strand: long, thin, flexible, single thread, strip of fibre, constituent filament or multiples of the same, twisted together).",3.7,nan,nan
-688,nan,E31,square metre per litre,A unit of count defining the number of square metres per litre.,3.1,m²/l,nan
-689,nan,E32,litre per hour,A unit of count defining the number of litres per hour.,3.1,l/h,"2,777 78 x 10⁻⁷ m³/s"
-690,nan,E33,foot per thousand,A unit of count defining the number of feet per thousand units.,3.1,nan,"3,048 x 10⁻⁴ m"
-691,nan,E34,gigabyte,A unit of information equal to 10⁹ bytes.,3.6,Gbyte,nan
-692,nan,E35,terabyte,A unit of information equal to 10¹² bytes.,3.6,Tbyte,nan
-693,nan,E36,petabyte,A unit of information equal to 10¹⁵ bytes.,3.6,Pbyte,nan
-694,nan,E37,pixel,A unit of count defining the number of pixels (pixel: picture element).,3.6,nan,nan
-695,nan,E38,megapixel,A unit of count equal to 10⁶ (1000000) pixels (picture elements).,3.6,nan,nan
-696,nan,E39,dots per inch,A unit of information defining the number of dots per linear inch as a measure of the resolution or sharpness of a graphic image.,3.6,dpi,nan
-697,nan,E4,gross kilogram,A unit of mass defining the total number of kilograms before deductions.,3.1,nan,nan
-698,nan,E40,part per hundred thousand,A unit of proportion equal to 10⁻⁵.,3.7,ppht,1 x 10⁻⁵
-699,nan,E41,kilogram-force per square millimetre,A unit of pressure defining the number of kilograms force per square millimetre.,2,kgf/mm²,"9,806 65 x 10⁶ Pa"
-700,nan,E42,kilogram-force per square centimetre,A unit of pressure defining the number of kilograms force per square centimetre.,2,kgf/cm²,"9,806 65 x 10⁴ Pa"
-701,nan,E43,joule per square centimetre,A unit of energy defining the number of joules per square centimetre.,1M,J/cm²,10⁴ J/m²
-702,nan,E44,kilogram-force metre per square centimetre,A unit of torsion defining the torque kilogram-force metre per square centimetre.,3.5,kgf·m/cm²,nan
-703,nan,E45,milliohm,nan,1S,mΩ,10⁻³ Ω
-704,nan,E46,kilowatt hour per cubic metre,A unit of energy consumption expressed as kilowatt hour per cubic metre.,3.1,kW·h/m³,"3,6 x 10⁶ J/m³"
-705,nan,E47,kilowatt hour per kelvin,A unit of energy consumption expressed as kilowatt hour per kelvin.,3.1,kW·h/K,"3,6 x 10⁶ J/K"
-706,nan,E48,service unit,A unit of count defining the number of service units (service unit: defined period / property / facility / utility of supply).,3.5,nan,nan
-707,nan,E49,working day,A unit of count defining the number of working days (working day: a day on which work is ordinarily performed).,3.5,nan,nan
-708,X,E5,metric long ton,Use ton (UK) or long ton (US) (common code LTN),3.1,nan,nan
-709,nan,E50,accounting unit,A unit of count defining the number of accounting units.,3.5,nan,nan
-710,nan,E51,job,A unit of count defining the number of jobs.,3.5,nan,nan
-711,nan,E52,run foot,A unit of count defining the number feet per run.,3.5,nan,nan
-712,nan,E53,test,A unit of count defining the number of tests.,3.5,nan,nan
-713,nan,E54,trip,A unit of count defining the number of trips.,3.5,nan,nan
-714,nan,E55,use,A unit of count defining the number of times an object is used.,3.5,nan,nan
-715,nan,E56,well,A unit of count defining the number of wells.,3.5,nan,nan
-716,nan,E57,zone,A unit of count defining the number of zones.,3.5,nan,nan
-717,nan,E58,exabit per second,A unit of information equal to 10¹⁸ bits (binary digits) per second.,3.6,Ebit/s,nan
-718,nan,E59,exbibyte,A unit of information equal to 2⁶⁰ bytes.,3.6,Eibyte,nan
-719,nan,E60,pebibyte,A unit of information equal to 2⁵⁰ bytes.,3.6,Pibyte,nan
-720,nan,E61,tebibyte,A unit of information equal to 2⁴⁰ bytes.,3.6,Tibyte,nan
-721,nan,E62,gibibyte,A unit of information equal to 2³⁰ bytes.,3.6,Gibyte,nan
-722,nan,E63,mebibyte,A unit of information equal to 2²⁰ bytes.,3.6,Mibyte,nan
-723,nan,E64,kibibyte,A unit of information equal to 2¹⁰ bytes.,3.6,Kibyte,nan
-724,nan,E65,exbibit per metre,A unit of information equal to 2⁶⁰ bits (binary digits) per metre.,3.6,Eibit/m,nan
-725,nan,E66,exbibit per square metre,A unit of information equal to 2⁶⁰ bits (binary digits) per square metre.,3.6,Eibit/m²,nan
-726,nan,E67,exbibit per cubic metre,A unit of information equal to 2⁶⁰ bits (binary digits) per cubic metre.,3.6,Eibit/m³,nan
-727,nan,E68,gigabyte per second,A unit of information equal to 10⁹ bytes per second.,3.6,Gbyte/s,nan
-728,nan,E69,gibibit per metre,A unit of information equal to 2³⁰ bits (binary digits) per metre.,3.6,Gibit/m,nan
-729,nan,E70,gibibit per square metre,A unit of information equal to 2³⁰ bits (binary digits) per square metre.,3.6,Gibit/m²,nan
-730,nan,E71,gibibit per cubic metre,A unit of information equal to 2³⁰ bits (binary digits) per cubic metre.,3.6,Gibit/m³,nan
-731,nan,E72,kibibit per metre,A unit of information equal to 2¹⁰ bits (binary digits) per metre.,3.6,Kibit/m,nan
-732,nan,E73,kibibit per square metre,A unit of information equal to 2¹⁰ bits (binary digits) per square metre.,3.6,Kibit/m²,nan
-733,nan,E74,kibibit per cubic metre,A unit of information equal to 2¹⁰ bits (binary digits) per cubic metre.,3.6,Kibit/m³,nan
-734,nan,E75,mebibit per metre,A unit of information equal to 2²⁰ bits (binary digits) per metre.,3.6,Mibit/m,nan
-735,nan,E76,mebibit per square metre,A unit of information equal to 2²⁰ bits (binary digits) per square metre.,3.6,Mibit/m²,nan
-736,nan,E77,mebibit per cubic metre,A unit of information equal to 2²⁰ bits (binary digits) per cubic metre.,3.6,Mibit/m³,nan
-737,nan,E78,petabit,A unit of information equal to 10¹⁵ bits (binary digits).,3.6,Pbit,nan
-738,nan,E79,petabit per second,A unit of information equal to 10¹⁵ bits (binary digits) per second.,3.6,Pbit/s,nan
-739,nan,E80,pebibit per metre,A unit of information equal to 2⁵⁰ bits (binary digits) per metre.,3.6,Pibit/m,nan
-740,nan,E81,pebibit per square metre,A unit of information equal to 2⁵⁰ bits (binary digits) per square metre.,3.6,Pibit/m²,nan
-741,nan,E82,pebibit per cubic metre,A unit of information equal to 2⁵⁰ bits (binary digits) per cubic metre.,3.6,Pibit/m³,nan
-742,nan,E83,terabit,A unit of information equal to 10¹² bits (binary digits).,3.6,Tbit,nan
-743,nan,E84,terabit per second,A unit of information equal to 10¹² bits (binary digits) per second.,3.6,Tbit/s,nan
-744,nan,E85,tebibit per metre,A unit of information equal to 2⁴⁰ bits (binary digits) per metre.,3.6,Tibit/m,nan
-745,nan,E86,tebibit per cubic metre,A unit of information equal to 2⁴⁰ bits (binary digits) per cubic metre.,3.6,Tibit/m³,nan
-746,nan,E87,tebibit per square metre,A unit of information equal to 2⁴⁰ bits (binary digits) per square metre.,3.6,Tibit/m²,nan
-747,nan,E88,bit per metre,A unit of information equal to 1 bit (binary digit) per metre.,3.6,bit/m,nan
-748,nan,E89,bit per square metre,A unit of information equal to 1 bit (binary digit) per square metre.,3.6,bit/m²,nan
-749,nan,E90,reciprocal centimetre,nan,3.1,cm⁻¹,10² m⁻¹
-750,nan,E91,reciprocal day,nan,3.1,d⁻¹,"1,157 41 × 10⁻⁵ s⁻¹"
-751,nan,E92,cubic decimetre per hour,nan,1S,dm³/h,"2,777 78 × 10⁻⁷ m³ x s⁻¹"
-752,nan,E93,kilogram per hour,nan,1S,kg/h,"2,777 78 × 10⁻⁴ kg x s⁻¹"
-753,nan,E94,kilomole per second,nan,1S,kmol/s,10³ s⁻¹ x mol
-754,nan,E95,mole per second,nan,1S,mol/s,s⁻¹ x mol
-755,nan,E96,degree per second,nan,1M,°/s,"1,745 329 x 10⁻² rad x s⁻¹"
-756,nan,E97,millimetre per degree Celcius metre,nan,1M,mm/(°C·m),10⁻³ K⁻¹
-757,nan,E98,degree Celsius per kelvin,nan,1M,°C/K,1.0
-758,nan,E99,hectopascal per bar,nan,1M,hPa/bar,10⁻³
-759,nan,EA,each,A unit of count defining the number of items regarded as separate units.,3.2,nan,nan
-760,nan,EB,electronic mail box,A unit of count defining the number of electronic mail boxes.,3.9,nan,nan
-761,X,EC,each per month,nan,3.9,nan,nan
-762,X,EP,eleven pack,nan,3.2,nan,nan
-763,nan,EQ,equivalent gallon,A unit of volume defining the number of gallons of product produced from concentrate.,3.1,nan,nan
-764,X,EV,envelope,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.9,nan,nan
-765,nan,F01,bit per cubic metre,A unit of information equal to 1 bit (binary digit) per cubic metre.,3.6,bit/m³,nan
-766,nan,F02,kelvin per kelvin,nan,1M,K/K,1.0
-767,nan,F03,kilopascal per bar,nan,1M,kPa/bar,10⁻²
-768,nan,F04,millibar per bar,nan,1M,mbar/bar,10⁻³
-769,nan,F05,megapascal per bar,nan,1M,MPa/bar,10¹
-770,nan,F06,poise per bar,nan,2,P/bar,10⁻⁶ s
-771,nan,F07,pascal per bar,nan,1M,Pa/bar,10⁻⁵
-772,nan,F08,milliampere per inch,nan,2,mA/in,"3,937 007 874 015 75 x 10⁻² A x m⁻¹"
-773,X,F1,thousand cubic foot per day,nan,3.8,nan,nan
-774,nan,F10,kelvin per hour,nan,1M,K/h,"2,777 78 × 10⁻⁴ s⁻¹ x K"
-775,nan,F11,kelvin per minute,nan,1M,K/min,"1,666 67 × 10⁻² s⁻¹ x K"
-776,nan,F12,kelvin per second,nan,1M,K/s,s⁻¹ x K
-777,nan,F13,slug,A unit of mass. One slug is the mass accelerated at 1 foot per second per second by a force of 1 pound.,2,slug,"1,459 390 x 10¹ kg"
-778,nan,F14,gram per kelvin,nan,1M,g/K,10⁻³ kg x K⁻¹
-779,nan,F15,kilogram per kelvin,nan,1M,kg/K,kg x K⁻¹
-780,nan,F16,milligram per kelvin,nan,1M,mg/K,10⁻⁶ kg x K⁻¹
-781,nan,F17,pound-force per foot,nan,2,lbf/ft,"1,459 39 × 10¹ kg x s⁻²"
-782,nan,F18,kilogram square centimetre,nan,1M,kg·cm²,10⁻⁴ kg m²
-783,nan,F19,kilogram square millimetre,nan,1M,kg·mm²,10⁻⁶ kg m²
-784,nan,F20,pound inch squared,nan,2,lb·in²,"2,926 397 x 10⁻⁴ kg x m²"
-785,nan,F21,pound-force inch,nan,2,lbf·in,"1,129 85 × 10⁻¹ kg x m² x s⁻²"
-786,nan,F22,pound-force foot per ampere,nan,2,lbf·ft/A,"1,355 82 kg x m² x s⁻² x A⁻¹"
-787,nan,F23,gram per cubic decimetre,nan,1M,g/dm³,kg x m⁻³
-788,nan,F24,kilogram per kilomol,nan,1M,kg/kmol,10⁻³ kg x mol⁻¹
-789,nan,F25,gram per hertz,nan,1M,g/Hz,10⁻³ kg x s
-790,nan,F26,gram per day,nan,1M,g/d,"1,157 41 × 10⁻⁸ kg x s⁻¹"
-791,nan,F27,gram per hour,nan,1M,g/h,"2,777 78 × 10⁻⁷ kg x s⁻¹"
-792,nan,F28,gram per minute,nan,1M,g/min,"1,666 67 × 10⁻⁵ kg x s⁻¹"
-793,nan,F29,gram per second,nan,1M,g/s,10⁻³ kg x s⁻¹
-794,nan,F30,kilogram per day,nan,1M,kg/d,"1,157 41 × 10⁻⁵ kg x s⁻¹"
-795,nan,F31,kilogram per minute,nan,1M,kg/min,"1,666 67 × 10⁻² kg x s⁻¹"
-796,nan,F32,milligram per day,nan,1M,mg/d,"1,157 41 × 10⁻¹¹ kg x s⁻¹"
-797,nan,F33,milligram per minute,nan,1M,mg/min,"1,666 67 × 10⁻⁸ kg x s⁻¹"
-798,nan,F34,milligram per second,nan,1M,mg/s,10⁻⁶ kg x s⁻¹
-799,nan,F35,gram per day kelvin,nan,1M,g/(d·K),"1,157 41 × 10⁻⁸ kg x s⁻¹ x K⁻¹"
-800,nan,F36,gram per hour kelvin,nan,1M,g/(h·K),"2,777 78 × 10⁻⁷ kg x s⁻¹ x K⁻¹"
-801,nan,F37,gram per minute kelvin,nan,1M,g/(min·K),"1,666 67 × 10⁻⁵ kg x s⁻¹ x K⁻¹"
-802,nan,F38,gram per second kelvin,nan,1M,g/(s·K),10⁻³ kg x s⁻¹ x K⁻¹
-803,nan,F39,kilogram per day kelvin,nan,1M,kg/(d·K),"1,157 41 × 10⁻⁵ kg x s⁻¹ x K⁻¹"
-804,nan,F40,kilogram per hour kelvin,nan,1M,kg/(h·K),"2,777 78 × 10⁻⁴ kg x s⁻¹ x K⁻¹"
-805,nan,F41,kilogram per minute kelvin,nan,1M,kg/(min·K),"1,666 67 × 10⁻²kg x s⁻¹ x K⁻¹"
-806,nan,F42,kilogram per second kelvin,nan,1M,kg/(s·K),kg x s⁻¹ x K⁻¹
-807,nan,F43,milligram per day kelvin,nan,1M,mg/(d·K),"1,157 41 × 10⁻¹¹ kg x s⁻¹ x K⁻¹"
-808,nan,F44,milligram per hour kelvin,nan,1M,mg/(h·K),"2,777 78 × 10⁻¹⁰ kg x s⁻¹ x K⁻¹"
-809,nan,F45,milligram per minute kelvin,nan,1M,mg/(min·K),"1,666 67 × 10⁻⁸ kg x s⁻¹ x K⁻¹"
-810,nan,F46,milligram per second kelvin,nan,1M,mg/(s·K),10⁻⁶ kg x s⁻¹ x K⁻¹
-811,nan,F47,newton per millimetre,nan,1M,N/mm,10³ kg x s⁻²
-812,nan,F48,pound-force per inch,nan,2,lbf/in,"1,751 27 × 10² kg x s⁻²"
-813,nan,F49,rod [unit of distance],A unit of distance equal to 5.5 yards (16 feet 6 inches).,2,rd (US),"5,029 210 m"
-814,nan,F50,micrometre per kelvin,nan,1M,µm/K,10⁻⁶ m x K⁻¹
-815,nan,F51,centimetre per kelvin,nan,1M,cm/K,10⁻² m x K⁻¹
-816,nan,F52,metre per kelvin,nan,1M,m/K,m x K⁻¹
-817,nan,F53,millimetre per kelvin,nan,1M,mm/K,10⁻³ m x K⁻¹
-818,nan,F54,milliohm per metre,nan,1M,mΩ/m,10⁻³ Ω/m
-819,nan,F55,ohm per mile (statute mile),nan,2,Ω/mi,"6,213 71 × 10⁻⁴  Ω/m"
-820,nan,F56,ohm per kilometre,nan,1M,Ω/km,10⁻³ Ω/m
-821,nan,F57,milliampere per pound-force per square inch,nan,2,mA/(lbf/in²),"1,450 38 × 10⁻⁷ kg⁻¹ x m x s² x A"
-822,nan,F58,reciprocal bar,nan,1M,1/bar,bar⁻¹
-823,nan,F59,milliampere per bar,nan,1M,mA/bar,10⁻⁸ kg⁻¹ x m x s² x A
-824,nan,F60,degree Celsius per bar,nan,1M,°C/bar,10⁻⁵ kg⁻¹ x m x s² x K
-825,nan,F61,kelvin per bar,nan,1M,K/bar,10⁻⁵ kg⁻¹ x m x s² x K
-826,nan,F62,gram per day bar,nan,1M,g/(d·bar),"1,157 41 × 10⁻¹³ m x s"
-827,nan,F63,gram per hour bar,nan,1M,g/(h·bar),"2,777 78 × 10⁻¹² m x s"
-828,nan,F64,gram per minute bar,nan,1M,g/(min·bar),"1,666 67 × 10⁻¹⁰ m x s"
-829,nan,F65,gram per second bar,nan,1M,g/(s·bar),10⁻⁸ m x s
-830,nan,F66,kilogram per day bar,nan,1M,kg/(d·bar),"1,157 41 × 10⁻¹⁰ m x s"
-831,nan,F67,kilogram per hour bar,nan,1M,kg/(h·bar),"2,777 78 × 10⁻⁹ m x s"
-832,nan,F68,kilogram per minute bar,nan,1M,kg/(min·bar),"1,666 67 × 10⁻⁷ m x s"
-833,nan,F69,kilogram per second bar,nan,1M,kg/(s·bar),10⁻⁵ m x s
-834,nan,F70,milligram per day bar,nan,1M,mg/(d·bar),"1,157 41 × 10⁻¹⁶ m x s"
-835,nan,F71,milligram per hour bar,nan,1M,mg/(h·bar),"2,777 78 × 10⁻¹⁵ m x s"
-836,nan,F72,milligram per minute bar,nan,1M,mg/(min·bar),"1,666 67 × 10⁻¹³ m x s"
-837,nan,F73,milligram per second bar,nan,1M,mg/(s·bar),10⁻¹¹ m x s
-838,nan,F74,gram per bar,nan,1M,g/bar,10⁻⁸ m x s²
-839,nan,F75,milligram per bar,nan,1M,mg/bar,10⁻¹¹ m x s²
-840,nan,F76,milliampere per millimetre,nan,1M,mA/mm,m⁻¹ x A
-841,nan,F77,pascal second per kelvin,nan,1M,Pa.s/K,kg x m⁻¹ x s⁻¹ x K⁻¹
-842,nan,F78,inch of water,nan,2,inH₂O,"2,490 89 × 10² kg x m⁻¹ x s⁻²"
-843,nan,F79,inch of mercury,nan,2,inHg,"3,386 39 × 10³ kg x m⁻¹ x s⁻²"
-844,nan,F80,water horse power,A unit of power defining the amount of power required to move a given volume of water against acceleration of gravity to a specified elevation (pressure head).,2,nan,"7,460 43 x 10² W"
-845,nan,F81,bar per kelvin,nan,1M,bar/K,10⁵ kg x m⁻¹ x s⁻² x K⁻¹
-846,nan,F82,hectopascal per kelvin,nan,1M,hPa/K,10² kg x m⁻¹ x s⁻² x K⁻¹
-847,nan,F83,kilopascal per kelvin,nan,1M,kPa/K,10³ kg x m⁻¹ x s⁻² x K⁻¹
-848,nan,F84,millibar per kelvin,nan,1M,mbar/K,10² kg x m⁻¹ x s⁻² x K⁻¹
-849,nan,F85,megapascal per kelvin,nan,1M,MPa/K,10⁶ kg x m⁻¹ x s⁻² x K⁻¹
-850,nan,F86,poise per kelvin,nan,2,P/K,10⁻¹ kg x m⁻¹ x s⁻¹ x K⁻¹
-851,nan,F87,volt per litre minute,nan,1M,V/(l·min),"1,666 67 × 10¹ kg x m⁻¹ x s⁻⁴ x A⁻¹"
-852,nan,F88,newton centimetre,nan,1M,N·cm,10⁻² kg x m² x s⁻²
-853,nan,F89,newton metre per degree,nan,1M,Nm/°,"57,295 788 kg x m² x s⁻² x rad⁻¹"
-854,X,F9,fibre per cubic centimetre of air,nan,3.9,nan,nan
-855,nan,F90,newton metre per ampere,nan,1M,N·m/A,kg x m² x s⁻² x A⁻¹
-856,nan,F91,bar litre per second,nan,1M,bar·l/s,10² kg x m² x s⁻³
-857,nan,F92,bar cubic metre per second,nan,1M,bar·m³/s,10⁵ kg x m² x s⁻³
-858,nan,F93,hectopascal litre per second,nan,1M,hPa·l/s,10⁻¹ kg x m² x s⁻³
-859,nan,F94,hectopascal cubic metre per second,nan,1M,hPa·m³/s,10² kg x m² x s⁻³
-860,nan,F95,millibar litre per second,nan,1M,mbar·l/s,10⁻¹ kg x m² x s⁻³
-861,nan,F96,millibar cubic metre per second,nan,1M,mbar·m³/s,10² kg x m² x s⁻³
-862,nan,F97,megapascal litre per second,nan,1M,MPa·l/s,10³ kg x m² x s⁻³
-863,nan,F98,megapascal cubic metre per second,nan,1M,MPa·m³/s,10⁶ kg x m² x s⁻³
-864,nan,F99,pascal litre per second,nan,1M,Pa·l/s,10⁻³ kg x m² x s⁻³
-865,nan,FAH,degree Fahrenheit,Refer ISO 80000-5 (Quantities and units — Part 5: Thermodynamics),2,°F,5/9 x K
-866,nan,FAR,farad,nan,1,F,F
-867,X,FB,field,nan,3.9,nan,nan
-868,nan,FBM,fibre metre,A unit of length defining the number of metres of individual fibre.,3.1,nan,nan
-869,nan,FC,thousand cubic foot,A unit of volume equal to one thousand cubic foot.,3.8,kft³,nan
-870,X,FD,million particle per cubic foot,nan,3.9,nan,nan
-871,X,FE,track foot,nan,3.5,nan,nan
-872,nan,FF,hundred cubic metre,A unit of volume equal to one hundred cubic metres.,3.8,nan,nan
-873,X,FG,transdermal patch,nan,3.9,nan,nan
-874,nan,FH,micromole,nan,1S,µmol,10⁻⁶ mol
-875,nan,FIT,failures in time,A unit of count defining the number of failures that can be expected over a specified time interval. Failure rates of semiconductor components are often specified as FIT (failures in time unit) where 1 FIT = 10⁻⁹ /h.,3.8,FIT,"2,777 78 × 10⁻¹³ s⁻¹"
-876,nan,FL,flake ton,A unit of mass defining the number of tons of a flaked substance (flake: a small flattish fragment).,3.1,nan,nan
-877,X,FM,million cubic foot,nan,3.8,Mft³,nan
-878,nan,FOT,foot,nan,2,ft,"0,304 8 m"
-879,nan,FP,pound per square foot,nan,2,lb/ft²,"4,882 428 kg/m²"
-880,nan,FR,foot per minute,nan,2,ft/min,"5,08 x 10⁻³ m/s"
-881,nan,FS,foot per second,nan,2,ft/s,"0,304 8 m/s"
-882,nan,FTK,square foot,nan,2,ft²,"9,290 304 x 10⁻² m²"
-883,nan,FTQ,cubic foot,nan,2,ft³,"2,831 685 x 10⁻² m³"
-884,nan,G01,pascal cubic metre per second,nan,1M,Pa·m³/s,kg x m² x s⁻³
-885,nan,G04,centimetre per bar,nan,1M,cm/bar,10⁻⁷ kg⁻¹ x m² x s²
-886,nan,G05,metre per bar,nan,1M,m/bar,10⁻⁵ kg⁻¹ x m² x s²
-887,nan,G06,millimetre per bar,nan,1M,mm/bar,10⁻⁸ kg⁻¹ x m² x s²
-888,nan,G08,square inch per second,nan,2,in²/s,"6,451 6 × 10⁻⁴ m² x s⁻¹"
-889,nan,G09,square metre per second kelvin,nan,1M,m²/(s·K),m² x s⁻¹ x K⁻¹
-890,nan,G10,stokes per kelvin,nan,2,St/K,10⁻⁴ m² x s⁻¹ x K⁻¹
-891,nan,G11,gram per cubic centimetre bar,nan,1M,g/(cm³·bar),10⁻² m⁻² x s²
-892,nan,G12,gram per cubic decimetre bar,nan,1M,g/(dm³·bar),10⁻⁵ m⁻² x s²
-893,nan,G13,gram per litre bar,nan,1M,g/(l·bar),10⁻⁵ m⁻² x s²
-894,nan,G14,gram per cubic metre bar,nan,1M,g/(m³·bar),10⁻⁸ m⁻² x s²
-895,nan,G15,gram per millilitre bar,nan,1M,g/(ml·bar),10⁻² m⁻² x s²
-896,nan,G16,kilogram per cubic centimetre bar,nan,1M,kg/(cm³·bar),10¹ m⁻² x s²
-897,nan,G17,kilogram per litre bar,nan,1M,kg/(l·bar),10⁻² m⁻² x s²
-898,nan,G18,kilogram per cubic metre bar,nan,1M,kg/(m³·bar),10⁻⁵ m⁻² x s²
-899,nan,G19,newton metre per kilogram,nan,1M,N·m/kg,m² x s⁻²
-900,nan,G2,US gallon per minute,nan,2,gal (US) /min,"6,309 020 x 10⁻⁵ m³/s"
-901,nan,G20,pound-force foot per pound,nan,2,lbf·ft/lb,"2,989 07 m² x s⁻²"
-902,nan,G21,cup [unit of volume],nan,2,cup (US),"2,365 882 x 10⁻⁴ m³"
-903,nan,G23,peck,nan,2,pk (US),"8,809 768 x 10⁻³ m³"
-904,nan,G24,tablespoon (US),nan,2,tablespoon (US),"1,478 676 x 10⁻⁵ m³"
-905,nan,G25,teaspoon (US),nan,2,teaspoon (US),"4,928 922 x 10⁻⁶ m³"
-906,nan,G26,stere,nan,1M,st,m³
-907,nan,G27,cubic centimetre per kelvin,nan,1M,cm³/K,10⁻⁶ m³ x K⁻¹
-908,nan,G28,litre per kelvin,nan,1M,l/K,10⁻³ m³ x K⁻¹
-909,nan,G29,cubic metre per kelvin,nan,1M,m³/K,m³ x K⁻¹
-910,nan,G3,Imperial gallon per minute,nan,2,gal (UK) /min,"7,576 82 x 10⁻⁵ m³/s"
-911,nan,G30,millilitre per kelvin,nan,1M,ml/K,10⁻⁶ m³ x K⁻¹
-912,nan,G31,kilogram per cubic centimetre,nan,1M,kg/cm³,10⁶ kg x m⁻³
-913,nan,G32,ounce (avoirdupois) per cubic yard,nan,2,oz/yd³,"3,707 98 × 10⁻² kg x m⁻³"
-914,nan,G33,gram per cubic centimetre kelvin,nan,1M,g/(cm³·K),10³ kg x m⁻³ x K⁻¹
-915,nan,G34,gram per cubic decimetre kelvin,nan,1M,g/(dm³·K),kg x m⁻³ x K⁻¹
-916,nan,G35,gram per litre kelvin,nan,1M,g/(l·K),kg x m⁻³ x K⁻¹
-917,nan,G36,gram per cubic metre kelvin,nan,1M,g/(m³·K),10⁻³ kg x m⁻³ x K⁻¹
-918,nan,G37,gram per millilitre kelvin,nan,1M,g/(ml·K),10³ kg x m⁻³ x K⁻¹
-919,nan,G38,kilogram per cubic centimetre kelvin,nan,1M,kg/(cm³·K),10⁶ kg x m⁻³ x K⁻¹
-920,nan,G39,kilogram per litre kelvin,nan,1M,kg/(l·K),10³ kg x m⁻³ x K⁻¹
-921,nan,G40,kilogram per cubic metre kelvin,nan,1M,kg/(m³·K),kg x m⁻³ x K⁻¹
-922,nan,G41,square metre per second bar,nan,1M,m²/(s·bar),10⁻⁵ kg⁻¹ x m³ x s
-923,nan,G42,microsiemens per centimetre,nan,1M,µS/cm,10⁻⁴ S/m
-924,nan,G43,microsiemens per metre,nan,1M,µS/m,10⁻⁶ S/m
-925,nan,G44,nanosiemens per centimetre,nan,1M,nS/cm,10⁻⁷ S/m
-926,nan,G45,nanosiemens per metre,nan,1M,nS/m,10⁻⁹ S/m
-927,nan,G46,stokes per bar,nan,2,St/bar,10⁻⁹ kg⁻¹ x m³ x s
-928,nan,G47,cubic centimetre per day,nan,1M,cm³/d,"1,157 41 × 10⁻¹¹ m³ x s⁻¹"
-929,nan,G48,cubic centimetre per hour,nan,1M,cm³/h,"2,777 78 × 10⁻¹⁰ m³ x s⁻¹"
-930,nan,G49,cubic centimetre per minute,nan,1M,cm³/min,"1,666 67 × 10⁻⁸ m³ x s⁻¹"
-931,nan,G50,gallon (US) per hour,nan,2,gal/h,"1,051 5 × 10⁻⁶ m³ x s⁻¹"
-932,nan,G51,litre per second,nan,1M,l/s,10⁻³ m³ x s⁻¹
-933,nan,G52,cubic metre per day,nan,1M,m³/d,"1,157 41 × 10⁻⁵ m³ x s⁻¹"
-934,nan,G53,cubic metre per minute,nan,1M,m³/min,"1,666 67 × 10⁻² m³ x s⁻¹"
-935,nan,G54,millilitre per day,nan,1M,ml/d,"1,157 41 × 10⁻¹¹ m³ x s⁻¹"
-936,nan,G55,millilitre per hour,nan,1M,ml/h,"2,777 78 × 10⁻¹⁰ m³ x s⁻¹"
-937,nan,G56,cubic inch per hour,nan,2,in³/h,"4,551 96 × 10⁻⁹ m³ x s⁻¹"
-938,nan,G57,cubic inch per minute,nan,2,in³/min,"2,731 18 × 10⁻⁷ m³ x s⁻¹"
-939,nan,G58,cubic inch per second,nan,2,in³/s,"1,638 71 × 10⁻⁵ m³ x s⁻¹"
-940,nan,G59,milliampere per litre minute,nan,1M,mA/(l·min),"1,666 67 × 10⁻² m⁻³ x s⁻¹ x A"
-941,nan,G60,volt per bar,nan,1M,V/bar,10⁻⁵ m³ x s⁻¹ x A⁻¹
-942,nan,G61,cubic centimetre per day kelvin,nan,1M,cm³/(d·K),"1,157 41 × 10⁻¹¹ m³ x s⁻¹ x K⁻¹"
-943,nan,G62,cubic centimetre per hour kelvin,nan,1M,cm³/(h·K),"2,777 78 × 10⁻¹⁰ m³ x s⁻¹ x K⁻¹"
-944,nan,G63,cubic centimetre per minute kelvin,nan,1M,cm³/(min·K),"1,666 67 × 10⁻⁸ m³ x s⁻¹ x K⁻¹"
-945,nan,G64,cubic centimetre per second kelvin,nan,1M,cm³/(s·K),10⁻⁶ m³ x s⁻¹ x K⁻¹
-946,nan,G65,litre per day kelvin,nan,1M,l/(d·K),"1,157 41 × 10⁻⁸ m³ x s⁻¹ x K⁻¹"
-947,nan,G66,litre per hour kelvin,nan,1M,l/(h·K),"2,777 78 × 10⁻⁷ m³ x s⁻¹ x K⁻¹"
-948,nan,G67,litre per minute kelvin,nan,1M,l/(min·K),"1,666 67 × 10⁻⁵ m³ x s⁻¹ x K⁻¹"
-949,nan,G68,litre per second kelvin,nan,1M,l/(s·K),10⁻³ m³ x s⁻¹ x K⁻¹
-950,nan,G69,cubic metre per day kelvin,nan,1M,m³/(d·K),"1,157 41 × 10⁻⁵ m³ x s⁻¹ x K⁻¹"
-951,X,G7,microfiche sheet,nan,3.9,nan,nan
-952,nan,G70,cubic metre per hour kelvin,nan,1M,m³/(h·K),"2,777 78 × 10⁻⁴ m³ x s⁻¹ x K⁻¹"
-953,nan,G71,cubic metre per minute kelvin,nan,1M,m³/(min·K),"1,666 67 × 10⁻² m³ x s⁻¹ x K⁻¹"
-954,nan,G72,cubic metre per second kelvin,nan,1M,m³/(s·K),m³ x s⁻¹ x K⁻¹
-955,nan,G73,millilitre per day kelvin,nan,1M,ml/(d·K),"1,157 41 × 10⁻¹¹ m³ x s⁻¹ x K⁻¹"
-956,nan,G74,millilitre per hour kelvin,nan,1M,ml/(h·K),"2,777 78 × 10⁻¹⁰ m³ x s⁻¹ x K⁻¹"
-957,nan,G75,millilitre per minute kelvin,nan,1M,ml/(min·K),"1,666 67 × 10⁻⁸ m³ x s⁻¹ x K⁻¹"
-958,nan,G76,millilitre per second kelvin,nan,1M,ml/(s·K),10⁻⁶ m³ x s⁻¹ x K⁻¹
-959,nan,G77,millimetre to the fourth power,nan,1M,mm⁴,10⁻¹² m⁴
-960,nan,G78,cubic centimetre per day bar,nan,1M,cm³/(d·bar),"1,157 41 × 10⁻¹⁶ kg⁻¹ x m⁴ x s"
-961,nan,G79,cubic centimetre per hour bar,nan,1M,cm³/(h·bar),"2,777 78 × 10⁻¹⁵ kg⁻¹ x m⁴ x s"
-962,nan,G80,cubic centimetre per minute bar,nan,1M,cm³/(min·bar),"1,666 67 × 10⁻¹³ kg⁻¹ x m⁴ x s"
-963,nan,G81,cubic centimetre per second bar,nan,1M,cm³/(s·bar),10⁻¹¹ kg⁻¹ x m⁴ x s
-964,nan,G82,litre per day bar,nan,1M,l/(d·bar),"1,157 41 × 10⁻¹³ kg⁻¹ x m⁴ x s"
-965,nan,G83,litre per hour bar,nan,1M,l/(h·bar),"2,777 78 × 10⁻¹² kg⁻¹ x m⁴ x s"
-966,nan,G84,litre per minute bar,nan,1M,l/(min·bar),"1,666 67 × 10⁻¹⁰ kg⁻¹ x m⁴ x s"
-967,nan,G85,litre per second bar,nan,1M,l/(s·bar),10⁻⁸ kg⁻¹ x m⁴ x s
-968,nan,G86,cubic metre per day bar,nan,1M,m³/(d·bar),"1,157 41 × 10⁻¹⁰ kg⁻¹ x m⁴ x s"
-969,nan,G87,cubic metre per hour bar,nan,1M,m³/(h·bar),"2,777 78 × 10⁻⁹ kg⁻¹ x m⁴ x s"
-970,nan,G88,cubic metre per minute bar,nan,1M,m³/(min·bar),"1,666 67 × 10⁻⁷ kg⁻¹ x m⁴ x s"
-971,nan,G89,cubic metre per second bar,nan,1M,m³/(s·bar),10⁻⁵ kg⁻¹ x m⁴ x s
-972,nan,G90,millilitre per day bar,nan,1M,ml/(d·bar),"1,157 41 x 10⁻¹⁶ x kg⁻¹ x m⁴ x s"
-973,nan,G91,millilitre per hour bar,nan,1M,ml/(h·bar),"2,777 78 x 10⁻¹⁵ x kg⁻¹ x m⁴ x s"
-974,nan,G92,millilitre per minute bar,nan,1M,ml/(min·bar),"1,666 67 × 10⁻¹³ x kg⁻¹ x m⁴ x s"
-975,nan,G93,millilitre per second bar,nan,1M,ml/(s·bar),10⁻¹¹ kg⁻¹ x m⁴ x s
-976,nan,G94,cubic centimetre per bar,nan,1M,cm³/bar,10⁻¹¹ kg⁻¹ x m⁴ x s²
-977,nan,G95,litre per bar,nan,1M,l/bar,10⁻⁸ kg⁻¹ x m⁴ x s²
-978,nan,G96,cubic metre per bar,nan,1M,m³/bar,10⁻⁵ kg⁻¹ x m⁴ x s²
-979,nan,G97,millilitre per bar,nan,1M,ml/bar,10⁻¹¹ kg⁻¹ x m⁴ x s²
-980,nan,G98,microhenry per kiloohm,nan,1M,µH/kΩ,10⁻⁹ s
-981,nan,G99,microhenry per ohm,nan,1M,µH/Ω,10⁻⁶ s
-982,nan,GB,gallon (US) per day,nan,3.5,gal (US)/d,"4,381 264 x 10⁻⁸ m³/s"
-983,nan,GBQ,gigabecquerel,nan,1M,GBq,10⁹ Bq
-984,X,GC,gram per 100 gram,nan,3.7,nan,nan
-985,X,GD,gross barrel,nan,3.1,nan,nan
-986,nan,GDW,"gram, dry weight","A unit of mass defining the number of grams of a product, disregarding the water content of the product.",3.1,nan,nan
-987,nan,GE,pound per gallon (US),nan,2,lb/gal (US),"1,198 264 x 10² kg/m³"
-988,nan,GF,gram per metre (gram per 100 centimetres),nan,1M,g/m,10⁻³ kg/m
-989,nan,GFI,gram of fissile isotope,A unit of mass defining the number of grams of a fissile isotope (fissile isotope: an isotope whose nucleus is able to be split when irradiated with low energy neutrons).,3.1,gi F/S,nan
-990,nan,GGR,great gross,A unit of count defining the number of units in multiples of 1728 (12 x 12 x 12).,3.7,nan,1728
-991,X,GH,half gallon (US),nan,3.8,nan,nan
-992,nan,GIA,gill (US),nan,3.5,gi (US),"1,182 941 x 10⁻⁴ m³"
-993,nan,GIC,"gram, including container","A unit of mass defining the number of grams of a product, including its container.",3.1,nan,nan
-994,nan,GII,gill (UK),nan,3.5,gi (UK),"1,420 653 x 10⁻⁴ m³"
-995,nan,GIP,"gram, including inner packaging","A unit of mass defining the number of grams of a product, including its inner packaging materials.",3.1,nan,nan
-996,nan,GJ,gram per millilitre,nan,1S,g/ml,10³ kg/m³
-997,X,GK,gram per kilogram,nan,3.7,nan,nan
-998,nan,GL,gram per litre,nan,1S,g/l,kg/m³
-999,nan,GLD,dry gallon (US),nan,2,dry gal (US),"4,404 884 x 10⁻³ m³"
-1000,nan,GLI,gallon (UK),nan,2,gal (UK),"4,546 092 x 10⁻³ m³"
-1001,nan,GLL,gallon (US),nan,2,gal (US),"3,785 412 x 10⁻³ m³"
-1002,nan,GM,gram per square metre,nan,1M,g/m²,10⁻³ kg/m²
-1003,X,GN,gross gallon,nan,3.1,nan,nan
-1004,nan,GO,milligram per square metre,nan,1,mg/m²,10⁻⁶ kg/m²
-1005,nan,GP,milligram per cubic metre,nan,1M,mg/m³,10⁻⁶ kg/m³
-1006,nan,GQ,microgram per cubic metre,nan,1M,µg/m³,10⁻⁹ kg/m³
-1007,nan,GRM,gram,nan,1S,g,10⁻³ kg
-1008,nan,GRN,grain,nan,2,gr,"64,798 91 x 10⁻⁶ kg"
-1009,nan,GRO,gross,A unit of count defining the number of units in multiples of 144 (12 x 12).,3.7,gr,144
-1010,D,GRT,gross register ton,"A unit of mass equal to the total cubic footage before deductions, where 1 register ton is equal to 100 cubic feet. Refer International Convention on tonnage measurement of ships.",3.4,nan,nan
-1011,D,GT,gross ton,"A unit of mass equal to 2240 pounds. Refer International Convention on Tonnage measurement of Ships.,Synonym: ton (UK) or long ton (US) (common code LTN)","3.1,3.4",nan,nan
-1012,nan,GV,gigajoule,nan,1S,GJ,10⁹ J
-1013,X,GW,gallon per thousand cubic foot,nan,3.5,nan,nan
-1014,nan,GWH,gigawatt hour,nan,1S,GW·h,"3,6 x 10¹² J"
-1015,X,GY,gross yard,nan,3.1,nan,nan
-1016,X,GZ,gage system,nan,3.9,nan,nan
-1017,nan,H03,henry per kiloohm,nan,1M,H/kΩ,10⁻³ s
-1018,nan,H04,henry per ohm,nan,1M,H/Ω,s
-1019,nan,H05,millihenry per kiloohm,nan,1M,mH/kΩ,10⁻⁶ s
-1020,nan,H06,millihenry per ohm,nan,1M,mH/Ω,10⁻³ s
-1021,nan,H07,pascal second per bar,nan,1M,Pa·s/bar,10⁻⁵ s
-1022,nan,H08,microbecquerel,nan,1M,µBq,10⁻⁶ Bq
-1023,nan,H09,reciprocal year,nan,1M,1/y,"3,168 81 x 10⁻⁸ s⁻¹"
-1024,X,H1,half page – electronic,nan,3.9,nan,nan
-1025,nan,H10,reciprocal hour,nan,1M,1/h,"2,777 78 × 10⁻⁴ s⁻¹"
-1026,nan,H11,reciprocal month,nan,1M,1/mo,"3,802 57 × 10⁻⁷ s⁻¹"
-1027,nan,H12,degree Celsius per hour,nan,1M,°C/h,"2,777 78 x 10⁻⁴ s⁻¹ K"
-1028,nan,H13,degree Celsius per minute,nan,1M,°C/min,"1,666 67 x 10⁻² s⁻¹ K"
-1029,nan,H14,degree Celsius per second,nan,1M,°C/s,s⁻¹ K
-1030,nan,H15,square centimetre per gram,nan,1M,cm²/g,10⁻¹ kg⁻¹ x m²
-1031,nan,H16,square decametre,Synonym: are,1S,dam²,10² m²
-1032,nan,H18,square hectometre,Synonym: hectare,1S,hm²,10⁴ m²
-1033,nan,H19,cubic hectometre,nan,1S,hm³,10⁶ m³
-1034,X,H2,half litre,nan,3.8,nan,nan
-1035,nan,H20,cubic kilometre,nan,1S,km³,10⁹ m³
-1036,nan,H21,blank,A unit of count defining the number of blanks.,3.2,nan,nan
-1037,nan,H22,volt square inch per pound-force,nan,2.0,V/(lbf/in²),"1,450 377 439 8 × 10⁻⁴ m³ x s⁻¹ x A⁻¹"
-1038,nan,H23,volt per inch,nan,2.0,V/in,"3,937 007 874 × 10¹ m x kg x s⁻³ x A⁻¹"
-1039,nan,H24,volt per microsecond,nan,1S,V/µs,10⁶ V/s
-1040,nan,H25,percent per kelvin,"A unit of proportion, equal to 0.01, in relation to the SI base unit Kelvin.",3.7,%/K,10⁻² K⁻¹
-1041,nan,H26,ohm per metre,nan,1M,Ω/m,Ω/m
-1042,nan,H27,degree per metre,nan,2,°/m,"1,745 329 x 10⁻² rad/m"
-1043,nan,H28,microfarad per kilometre,nan,1S,µF/km,10⁻⁹ F/m
-1044,nan,H29,microgram per litre,nan,1M,µg/l,10⁻⁶ m⁻³ x kg
-1045,nan,H30,square micrometre (square micron),nan,1S,µm²,10⁻¹² m²
-1046,nan,H31,ampere per kilogram,nan,1.0,A/kg,A x kg⁻¹
-1047,nan,H32,ampere squared second,nan,1.0,A²·s,A² x s
-1048,nan,H33,farad per kilometre,nan,1S,F/km,10⁻³ F/m
-1049,nan,H34,hertz metre,nan,2,Hz·m,Hz x m
-1050,nan,H35,kelvin metre per watt,nan,1.0,K·m/W,K x m⁻¹ x kg⁻¹ x s³
-1051,nan,H36,megaohm per kilometre,nan,1M,MΩ/km,10³ Ω/m
-1052,nan,H37,megaohm per metre,nan,1M,MΩ/m,10⁶ Ω/m
-1053,nan,H38,megaampere,nan,1S,MA,10⁶ A
-1054,nan,H39,megahertz kilometre,nan,2,MHz·km,10⁹ Hz x m
-1055,nan,H40,newton per ampere,nan,1.0,N/A,kg x m x s⁻² x A⁻¹
-1056,nan,H41,"newton metre watt to the power minus 0,5",nan,2.0,N·m·W⁻⁰‧⁵,kg x m² x s⁻² x W⁻⁰‧⁵
-1057,nan,H42,pascal per metre,nan,1M,Pa/m,m⁻² kg x s⁻²
-1058,nan,H43,siemens per centimetre,nan,1S,S/cm,10² S/m
-1059,nan,H44,teraohm,nan,1S,TΩ,10¹² Ω
-1060,nan,H45,volt second per metre,nan,1.0,V·s/m,m x kg x s⁻² x A⁻¹
-1061,nan,H46,volt per second,nan,1S,V/s,m² x kg x s⁻⁴ x A⁻¹
-1062,nan,H47,watt per cubic metre,nan,1.0,W/m³,m⁻¹ x kg x s⁻³
-1063,nan,H48,attofarad,nan,1S,aF,10⁻¹⁸ m⁻² x kg⁻¹ x s⁴ x A²
-1064,nan,H49,centimetre per hour,nan,1M,cm/h,"0,277 777 778 × 10⁻⁶ m x s⁻¹"
-1065,nan,H50,reciprocal cubic centimetre,nan,1M,cm⁻³,10⁶ m⁻³
-1066,nan,H51,decibel per kilometre,nan,1.0,dB/km,10⁻⁴ B/m
-1067,nan,H52,decibel per metre,nan,1.0,dB/m,10⁻¹ B/m
-1068,nan,H53,kilogram per bar,nan,1M,kg/bar,10⁻⁵ m x s²
-1069,nan,H54,kilogram per cubic decimetre kelvin,nan,1M,(kg/dm³)/K,10³ m⁻³ x kg x K⁻¹
-1070,nan,H55,kilogram per cubic decimetre bar,nan,1M,(kg/dm³)/bar,10⁻² m⁻² x s²
-1071,nan,H56,kilogram per square metre second,nan,1.0,kg/(m²·s),kg m⁻² x s⁻¹
-1072,nan,H57,inch per two pi radiant,nan,2.0,in/revolution,"2,54 x 10⁻² m/(2 x π x rad)"
-1073,nan,H58,metre per volt second,nan,1.0,m/(V·s),m⁻¹ x kg⁻¹ x s² x A
-1074,nan,H59,square metre per newton,nan,1.0,m²/N,m x kg⁻¹ x s²
-1075,nan,H60,cubic metre per cubic metre,nan,1M,m³/m³,1.0
-1076,nan,H61,millisiemens per centimetre,nan,1S,mS/cm,10⁻¹ S/m
-1077,nan,H62,millivolt per minute,nan,1M,mV/min,"1,666 666 667 × 10⁻⁵ m² x kg x s⁻⁴ x A⁻¹"
-1078,nan,H63,milligram per square centimetre,nan,1S,mg/cm²,10⁻² m⁻² x kg
-1079,nan,H64,milligram per gram,nan,1S,mg/g,10⁻³ 1
-1080,nan,H65,millilitre per cubic metre,nan,1M,ml/m³,10⁻⁶ 1
-1081,nan,H66,millimetre per year,nan,2.0,mm/y,"3,15576 × 10⁴ m x s⁻¹"
-1082,nan,H67,millimetre per hour,nan,2.0,mm/h,"0,277 777 778 × 10⁻⁷ m x s⁻¹"
-1083,nan,H68,millimole per gram,nan,1M,mmol/g,mol x kg⁻¹
-1084,nan,H69,picopascal per kilometre,nan,1M,pPa/km,10⁻¹⁵ m⁻² x kg x s⁻²
-1085,nan,H70,picosecond,nan,1.0,ps,10⁻¹² s
-1086,nan,H71,percent per month,"A unit of proportion, equal to 0.01, in relation to a month.",3.7,%/mo,nan
-1087,nan,H72,percent per hectobar,"A unit of proportion, equal to 0.01, in relation to 100-fold of the unit bar.",3.7,%/hbar,nan
-1088,nan,H73,percent per decakelvin,"A unit of proportion, equal to 0.01, in relation to 10-fold of the SI base unit Kelvin.",3.7,%/daK,10⁻³ K⁻¹
-1089,nan,H74,watt per metre,nan,1M,W/m,W m⁻¹
-1090,nan,H75,decapascal,nan,1M,daPa,10¹ Pa
-1091,nan,H76,gram per millimetre,nan,1M,g/mm,10¹ kg x m⁻¹
-1092,nan,H77,module width,A unit of measure used to describe the breadth of electronic assemblies as an installation standard or mounting dimension.,3,MW,nan
-1093,D,H78,conventional centimetre of water,nan,2,cm H₂O,"9,806 65 × 10¹ Pa"
-1094,nan,H79,French gauge,"A unit of distance used for measuring the diameter of small tubes such as urological instruments and catheters.,Synonym: French, Charrière, Charrière gauge",2,Fg,"0,333 333 333 × 10⁻³ m"
-1095,nan,H80,rack unit,A unit of measure used to describe the height in rack units of equipment intended for mounting in a 19-inch rack or a 23-inch rack. One rack unit is 1.75 inches (44.45 mm) high.,3,U or RU,"4,445 × 10⁻² m"
-1096,nan,H81,millimetre per minute,nan,1M,mm/min,"1,666 666 667 × 10⁻⁵ m x s⁻¹"
-1097,nan,H82,big point,A unit of length defining the number of big points (big point: Adobe software(US) defines the big point to be exactly 1/72 inch (0.013 888 9 inch or 0.352 777 8 millimeters)),3.5,bp,"0,352 777 8 × 10⁻³ m"
-1098,nan,H83,litre per kilogram,nan,1M,l/kg,10⁻³ m³ x kg⁻¹
-1099,nan,H84,gram millimetre,nan,1M,g·mm,10⁻⁶ kg x m
-1100,nan,H85,reciprocal week,nan,1M,1/wk,"1,647 989 452 868 × 10⁻⁶ s⁻¹"
-1101,nan,H87,piece,"A unit of count defining the number of pieces (piece: a single item, article or exemplar).",3.8,nan,nan
-1102,nan,H88,megaohm kilometre,nan,1S,MΩ·km,10⁹ Ω x m
-1103,nan,H89,percent per ohm,"A unit of proportion, equal to 0.01, in relation to the SI derived unit ohm.",3.7,%/Ω,10⁻² Ω⁻¹
-1104,nan,H90,percent per degree,"A unit of proportion, equal to 0.01, in relation to an angle of one degree.",3.7,%/°,"0,572 957 8 rad⁻¹"
-1105,nan,H91,percent per ten thousand,"A unit of proportion, equal to 0.01, in relation to multiples of ten thousand.",3.7,%/10000,10⁻⁶
-1106,nan,H92,percent per one hundred thousand,"A unit of proportion, equal to 0.01, in relation to multiples of one hundred thousand.",3.7,%/100000,10⁻⁷
-1107,nan,H93,percent per hundred,"A unit of proportion, equal to 0.01, in relation to multiples of one hundred.",3.7,%/100,10⁻⁴
-1108,nan,H94,percent per thousand,"A unit of proportion, equal to 0.01, in relation to multiples of one thousand.",3.7,%/1000,10⁻⁵
-1109,nan,H95,percent per volt,"A unit of proportion, equal to 0.01, in relation to the SI derived unit volt.",3.7,%/V,10⁻² V⁻¹
-1110,nan,H96,percent per bar,"A unit of proportion, equal to 0.01, in relation to an atmospheric pressure of one bar.",3.7,%/bar,10⁻⁷ Pa⁻¹
-1111,nan,H98,percent per inch,"A unit of proportion, equal to 0.01, in relation to an inch.",3.7,%/in,"0,393 700 8 m⁻¹"
-1112,nan,H99,percent per metre,"A unit of proportion, equal to 0.01, in relation to a metre.",3.7,%/m,10⁻² m⁻¹
-1113,nan,HA,hank,"A unit of length, typically for yarn.",3.9,nan,nan
-1114,D,HAR,hectare,Synonym: square hectometre,2.0,ha,10⁴ m²
-1115,nan,HBA,hectobar,nan,1M,hbar,10⁷ Pa
-1116,nan,HBX,hundred boxes,A unit of count defining the number of boxes in multiples of one hundred box units.,3.2,nan,nan
-1117,nan,HC,hundred count,A unit of count defining the number of units counted in multiples of 100.,3.7,nan,nan
-1118,X,HD,half dozen,nan,3.7,nan,6
-1119,nan,HDW,"hundred kilogram, dry weight","A unit of mass defining the number of hundred kilograms of a product, disregarding the water content of the product.",3.1,nan,nan
-1120,X,HE,hundredth of a carat,nan,3.5,nan,nan
-1121,nan,HEA,head,A unit of count defining the number of heads (head: a person or animal considered as one of a number).,3.5,nan,nan
-1122,X,HF,hundred foot,nan,3.8,nan,nan
-1123,nan,HGM,hectogram,nan,1M,hg,10⁻¹ kg
-1124,nan,HH,hundred cubic foot,A unit of volume equal to one hundred cubic foot.,3.8,nan,nan
-1125,X,HI,hundred sheet,nan,3.8,nan,nan
-1126,nan,HIU,hundred international unit,A unit of count defining the number of international units in multiples of 100.,3.7,nan,nan
-1127,D,HJ,metric horse power,nan,2,metric hp,"735,498 75 W"
-1128,X,HK,hundred kilogram,nan,3.8,nan,nan
-1129,nan,HKM,"hundred kilogram, net mass","A unit of mass defining the number of hundred kilograms of a product, after deductions.",3.1,nan,nan
-1130,X,HL,hundred foot (linear),nan,3.8,nan,nan
-1131,nan,HLT,hectolitre,nan,1S,hl,10⁻¹ m³
-1132,nan,HM,mile per hour (statute mile),nan,2,mile/h,"0,447 04 m/s"
-1133,nan,HMQ,million cubic metre,A unit of volume equal to one million cubic metres.,3.8,Mm³,nan
-1134,nan,HMT,hectometre,nan,1M,hm,10² m
-1135,D,HN,conventional millimetre of mercury,nan,2,mm Hg,"133,322 4 Pa"
-1136,X,HO,hundred troy ounce,nan,3.8,nan,nan
-1137,D,HP,conventional millimetre of water,nan,2,mm H₂O,"9,806 65 Pa"
-1138,nan,HPA,hectolitre of pure alcohol,A unit of volume equal to one hundred litres of pure alcohol.,3.1,nan,nan
-1139,X,HS,hundred square foot,nan,3.8,nan,nan
-1140,X,HT,half hour,nan,3.8,nan,nan
-1141,nan,HTZ,hertz,nan,1,Hz,Hz
-1142,nan,HUR,hour,nan,1,h,3 600 s
-1143,X,HY,hundred yard,nan,3.8,nan,nan
-1144,nan,IA,inch pound (pound inch),nan,2,in·lb,"1,152 12 x 10⁻² kg x m"
-1145,X,IC,count per inch,nan,3.9,nan,nan
-1146,nan,IE,person,A unit of count defining the number of persons.,3.9,nan,nan
-1147,X,IF,inches of water,Use inch of water (common code F78),3.1,nan,nan
-1148,X,II,column inch,nan,3.9,nan,nan
-1149,X,IL,inch per minute,nan,3.5,nan,nan
-1150,X,IM,impression,nan,3.9,nan,nan
-1151,nan,INH,inch,nan,2,in,"25,4 x 10⁻³ m"
-1152,nan,INK,square inch,nan,2,in²,"6,451 6 x 10⁻⁴ m²"
-1153,nan,INQ,cubic inch,Synonym: inch cubed,2,in³,"16,387 064 x 10⁻⁶ m³"
-1154,X,IP,insurance policy,nan,3.9,nan,nan
-1155,nan,ISD,international sugar degree,"A unit of measure defining the sugar content of a solution, expressed in degrees.",3.5,nan,nan
-1156,X,IT,count per centimetre,nan,3.9,nan,nan
-1157,nan,IU,inch per second,nan,2,in/s,"0,025 4 m/s"
-1158,nan,IUG,international unit per gram,A unit of count defining the number of international units per gram.,3.7,nan,nan
-1159,nan,IV,inch per second squared,nan,2,in/s²,"0,025 4 m/s²"
-1160,nan,J10,percent per millimetre,"A unit of proportion, equal to 0.01, in relation to a millimetre.",3.7,%/mm,10 m⁻¹
-1161,nan,J12,per mille per psi,A unit of pressure equal to one thousandth of a psi (pound-force per square inch).,3.7,‰/psi,"1,450 377 x 10⁻⁷ Pa⁻¹"
-1162,nan,J13,degree API,A unit of relative density as a measure of how heavy or light a petroleum liquid is compared to water (API: American Petroleum Institute).,3.5,°API,nan
-1163,nan,J14,degree Baume (origin scale),A traditional unit of relative density for liquids. Named after Antoine Baumé.,3.5,°Bé,nan
-1164,nan,J15,degree Baume (US heavy),A unit of relative density for liquids heavier than water.,3.5,°Bé (US heavy),nan
-1165,nan,J16,degree Baume (US light),A unit of relative density for liquids lighter than water.,3.5,°Bé (US light),nan
-1166,nan,J17,degree Balling,"A unit of density as a measure of sugar content, especially of beer wort. Named after Karl Balling.",3.5,°Balling,nan
-1167,nan,J18,degree Brix,A unit of proportion used in measuring the dissolved sugar-to-water mass ratio of a liquid. Named after Adolf Brix.,3.5,°Bx,nan
-1168,nan,J19,degree Fahrenheit hour square foot per British thermal unit (thermochemical),nan,2,°F·h·ft²/Btuth,"0,176 228 m² x K/W"
-1169,nan,J2,joule per kilogram,nan,1,J/kg,J/kg
-1170,nan,J20,degree Fahrenheit per kelvin,nan,2,°F/K,"0,555 555 6"
-1171,nan,J21,degree Fahrenheit per bar,nan,2,°F/bar,"0,555 555 6 x 10⁻⁵ K/Pa"
-1172,nan,J22,degree Fahrenheit hour square foot per British thermal unit (international table),nan,2,°F·h·ft²/BtuIT,"0,176 110 2 m² x K/W"
-1173,nan,J23,degree Fahrenheit per hour,nan,2,°F/h,"1,543 210 x 10⁻⁴ K/s"
-1174,nan,J24,degree Fahrenheit per minute,nan,2,°F/min,"9,259 259 x 10⁻³  K/s"
-1175,nan,J25,degree Fahrenheit per second,nan,2,°F/s,"0,555 555 6 K/s"
-1176,nan,J26,reciprocal degree Fahrenheit,nan,2,1/°F,"1,8 1/K"
-1177,nan,J27,degree Oechsle,"A unit of density as a measure of sugar content of must, the unfermented liqueur from which wine is made. Named after Ferdinand Oechsle.",3.5,°Oechsle,nan
-1178,nan,J28,degree Rankine per hour,nan,2,°R/h,"1,543 210 x 10⁻⁴ K/s"
-1179,nan,J29,degree Rankine per minute,nan,2,°R/min,"9,259 259 x 10⁻³  K/s"
-1180,nan,J30,degree Rankine per second,nan,2,°R/s,"0,555 555 6 K/s"
-1181,nan,J31,degree Twaddell,A unit of density for liquids that are heavier than water.  1 degree Twaddle represents a difference in specific gravity of 0.005.,3.5,°Tw,nan
-1182,nan,J32,micropoise,nan,2,µP,10⁻⁶ Pa x s
-1183,nan,J33,microgram per kilogram,nan,1S,µg/kg,10⁻⁹
-1184,nan,J34,microgram per cubic metre kelvin,nan,2,(µg/m³)/K,10⁻⁹ (kg/m³)/K
-1185,nan,J35,microgram per cubic metre bar,nan,2,(µg/m³)/bar,10⁻¹⁴ (kg/m³)/Pa
-1186,nan,J36,microlitre per litre,nan,1S,µl/l,10⁻⁶
-1187,nan,J38,baud,A unit of signal transmission speed equal to one signalling event per second.,3.6,Bd,nan
-1188,nan,J39,British thermal unit (mean),nan,2,Btu,"1,055 87 x 10³ J"
-1189,nan,J40,British thermal unit (international table) foot per hour square foot degree Fahrenheit,nan,2,BtuIT·ft/(h·ft²·°F),"1,730 735 W/(m x K)"
-1190,nan,J41,British thermal unit (international table) inch per hour square foot degree Fahrenheit,nan,2,BtuIT·in/(h·ft²·°F),"0,144 227 9 W/(m x K)"
-1191,nan,J42,British thermal unit (international table) inch per second square foot degree Fahrenheit,nan,2,BtuIT·in/(s·ft²·°F),"5,192 204 x 10² W/(m x K)"
-1192,nan,J43,British thermal unit (international table) per pound degree Fahrenheit,nan,2,BtuIT/(lb·°F),"4,186 8 x 10³ J/(kg x K)"
-1193,nan,J44,British thermal unit (international table) per minute,nan,2,BtuIT/min,"17,584 266 W"
-1194,nan,J45,British thermal unit (international table) per second,nan,2,BtuIT/s,"1,055 056 x 10³ W"
-1195,nan,J46,British thermal unit (thermochemical) foot per hour square foot degree Fahrenheit,nan,2,Btuth·ft/(h·ft²·°F),"1,729 577 W/(m x K)"
-1196,nan,J47,British thermal unit (thermochemical) per hour,nan,2,Btuth/h,"0,292 875 1 W"
-1197,nan,J48,British thermal unit (thermochemical) inch per hour square foot degree Fahrenheit,nan,2,Btuth·in/(h·ft²·°F),"0,144 131 4 W/(m x K)"
-1198,nan,J49,British thermal unit (thermochemical) inch per second square foot degree Fahrenheit,nan,2,Btuth·in/(s·ft²·°F),"5,188 732 x 10² W/(m x K)"
-1199,nan,J50,British thermal unit (thermochemical) per pound degree Fahrenheit,nan,2,Btuth/(lb·°F),"4,184 x 10³ J/(kg x K)"
-1200,nan,J51,British thermal unit (thermochemical) per minute,nan,2,Btuth/min,"17,572 50 W"
-1201,nan,J52,British thermal unit (thermochemical) per second,nan,2,Btuth/s,"1,054 350 x 10³ W"
-1202,nan,J53,coulomb square metre per kilogram,nan,2,C·m²/kg,C x m²/kg
-1203,nan,J54,megabaud,A unit of signal transmission speed equal to 10⁶ (1000000) signaling events per second.,3.6,MBd,10⁶ Bd
-1204,nan,J55,watt second,nan,1S,W·s,W x s
-1205,nan,J56,bar per bar,nan,2,bar/bar,1
-1206,nan,J57,barrel (UK petroleum),nan,2,bbl (UK liq.),"0,159 113 15 m³"
-1207,nan,J58,barrel (UK petroleum) per minute,nan,2,bbl (UK liq.)/min,"2,651 886 m³/s"
-1208,nan,J59,barrel (UK petroleum) per day,nan,2,bbl (UK liq.)/d,"1,841 587 4 x 10⁻⁶ m³/s"
-1209,nan,J60,barrel (UK petroleum) per hour,nan,2,bbl (UK liq.)/h,"4,419 810 x 10⁻⁵ m³/s"
-1210,nan,J61,barrel (UK petroleum) per second,nan,2,bbl (UK liq.)/s,"0,159 113 15 m³/s"
-1211,nan,J62,barrel (US petroleum) per hour,nan,2,bbl (US)/h,"4,416 314 x 10⁻⁵ m³/s"
-1212,nan,J63,barrel (US petroleum) per second,nan,2,bbl (US)/s,"0,158 987 3 m³/s"
-1213,nan,J64,bushel (UK) per day,nan,2,bu (UK)/d,"4,209 343 x 10⁻⁷ m³/s"
-1214,nan,J65,bushel (UK) per hour,nan,2,bu (UK)/h,"1,010 242 x 10⁻⁵ m³/s"
-1215,nan,J66,bushel (UK) per minute,nan,2,bu (UK)/min,"6,061 453 x 10⁻⁴ m³/s"
-1216,nan,J67,bushel (UK) per second,nan,2,bu (UK)/s,"3,636 872 x 10⁻² m³/s"
-1217,nan,J68,bushel (US dry) per day,nan,2,bu (US dry)/d,"4,078 596 x 10⁻⁷ m³/s"
-1218,nan,J69,bushel (US dry) per hour,nan,2,bu (US dry)/h,"9,788 631 x 10⁻⁶ m³/s"
-1219,nan,J70,bushel (US dry) per minute,nan,2,bu (US dry)/min,"5,873 178 x 10⁻⁴ m³/s"
-1220,nan,J71,bushel (US dry) per second,nan,2,bu (US dry)/s,"3,523 907 x 10⁻² m³/s"
-1221,nan,J72,centinewton metre,nan,1S,cN·m,10⁻² N x m
-1222,nan,J73,centipoise per kelvin,nan,2,cP/K,10⁻³  Pa x s/K
-1223,nan,J74,centipoise per bar,nan,2,cP/bar,10⁻⁸ s
-1224,nan,J75,calorie (mean),nan,2,cal,"4,190 02 J"
-1225,nan,J76,calorie (international table) per gram degree Celsius,nan,2,calIT/(g·°C),"4,186 8 x 10³ J/(kg x K)"
-1226,nan,J78,calorie (thermochemical) per centimetre second degree Celsius,nan,2,calth/(cm·s·°C),"4,184 x 10² W/(m x K)"
-1227,nan,J79,calorie (thermochemical) per gram degree Celsius,nan,2,calth/(g·°C),"4,184 x 10³ J/(kg x K)"
-1228,nan,J81,calorie (thermochemical) per minute,nan,2,calth/min,"6,973 333 x 10⁻² W"
-1229,nan,J82,calorie (thermochemical) per second,nan,2,calth/s,"4,184 W"
-1230,nan,J83,clo,nan,2,clo,"0,155 m² x K/W"
-1231,nan,J84,centimetre per second kelvin,nan,2,(cm/s)/K,10⁻² (m/s)/K
-1232,nan,J85,centimetre per second bar,nan,2,(cm/s)/bar,10⁻⁷ (m/s)/Pa
-1233,nan,J87,cubic centimetre per cubic metre,nan,1S,cm³/m³,10⁻⁶
-1234,D,J89,centimetre of mercury,nan,2,cm Hg,"1,333 224 x 10³ Pa"
-1235,nan,J90,cubic decimetre per day,nan,1S,dm³/d,"1,157 41 x 10⁻⁸ m³/s"
-1236,nan,J91,cubic decimetre per cubic metre,nan,1S,dm³/m³,10⁻³
-1237,nan,J92,cubic decimetre per minute,nan,1S,dm³/min,"1,666 67 x 10⁻⁵ m³/s"
-1238,nan,J93,cubic decimetre per second,nan,1S,dm³/s,10⁻³ m³/s
-1239,D,J94,dyne centimetre,nan,2,dyn·cm,10⁻⁷ N x m
-1240,nan,J95,ounce (UK fluid) per day,nan,2,fl oz (UK)/d,"3,288 549 x 10⁻¹⁰ m³/s"
-1241,nan,J96,ounce (UK fluid) per hour,nan,2,fl oz (UK)/h,"7,892 517 x 10⁻⁹ m³/s"
-1242,nan,J97,ounce (UK fluid) per minute,nan,2,fl oz (UK)/min,"4,735 51 x 10⁻⁷ m³/s"
-1243,nan,J98,ounce (UK fluid) per second,nan,2,fl oz (UK)/s,"2,841 306 x 10⁻⁵ m³/s"
-1244,nan,J99,ounce (US fluid) per day,nan,2,fl oz (US)/d,"3,422 862 x 10⁻¹⁰ m³/s"
-1245,X,JB,jumbo,nan,3.4,nan,nan
-1246,nan,JE,joule per kelvin,nan,1,J/K,J/K
-1247,X,JG,jug,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-1248,nan,JK,megajoule per kilogram,nan,1S,MJ/kg,10⁶ J/kg
-1249,nan,JM,megajoule per cubic metre,nan,1M,MJ/m³,10⁶ J/m³
-1250,nan,JNT,pipeline joint,A count of the number of pipeline joints.,3.5,nan,nan
-1251,X,JO,joint,nan,3.9,nan,nan
-1252,nan,JOU,joule,nan,1,J,J
-1253,nan,JPS,hundred metre,A unit of count defining the number of 100 metre lengths.,3.1,nan,nan
-1254,X,JR,jar,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-1255,nan,JWL,number of jewels,A unit of count defining the number of jewels (jewel: precious stone).,3.7,nan,nan
-1256,nan,K1,kilowatt demand,A unit of measure defining the power load measured at predetermined intervals.,3.5,nan,nan
-1257,nan,K10,ounce (US fluid) per hour,nan,2,fl oz (US)/h,"8,214 869 x 10⁻⁹ m³/s"
-1258,nan,K11,ounce (US fluid) per minute,nan,2,fl oz (US)/min,"4,928 922 x 10⁻⁷ m³/s"
-1259,nan,K12,ounce (US fluid) per second,nan,2,fl oz (US)/s,"2,957 353 x 10⁻⁵ m³/s"
-1260,nan,K13,foot per degree Fahrenheit,nan,2,ft/°F,"0,548 64 m/K"
-1261,nan,K14,foot per hour,nan,2,ft/h,"8,466 667 x 10⁻⁵m/s"
-1262,nan,K15,foot pound-force per hour,nan,2,ft·lbf/h,"3,766 161 x 10⁻⁴ W"
-1263,nan,K16,foot pound-force per minute,nan,2,ft·lbf/min,"2,259 697 x 10⁻² W"
-1264,nan,K17,foot per psi,nan,2,ft/psi,"4,420 750 x 10⁻⁵ m/Pa"
-1265,nan,K18,foot per second degree Fahrenheit,nan,2,(ft/s)/°F,"0,548 64  (m/s)/K"
-1266,nan,K19,foot per second psi,nan,2,(ft/s)/psi,"4,420 750 x 10⁻⁵ (m/s)/Pa"
-1267,nan,K2,kilovolt ampere reactive demand,A unit of measure defining the reactive power demand equal to one kilovolt ampere of reactive power.,3.5,nan,nan
-1268,nan,K20,reciprocal cubic foot,nan,2,1/ft³,"35,314 66 m⁻³"
-1269,nan,K21,cubic foot per degree Fahrenheit,nan,2,ft³/°F,"5,097 033 x 10⁻² m³/K"
-1270,nan,K22,cubic foot per day,nan,2,ft³/d,"3,277 413 x 10⁻⁷ m³/s"
-1271,nan,K23,cubic foot per psi,nan,2,ft³/psi,"4,107 012 x 10⁻⁶ m³/Pa"
-1272,D,K24,foot of water,nan,2,ft H₂O,"2,989 067 x 10³  Pa"
-1273,D,K25,foot of mercury,nan,2,ft Hg,"4,063 666 x 10⁴ Pa"
-1274,nan,K26,gallon (UK) per day,nan,2,gal (UK)/d,"5,261 678 x 10⁻⁸ m³/s"
-1275,nan,K27,gallon (UK) per hour,nan,2,gal (UK)/h,"1,262 803 x 10⁻⁶ m³/s"
-1276,nan,K28,gallon (UK) per second,nan,2,gal (UK)/s,"4,546 09 x 10⁻³ m³/s"
-1277,nan,K3,kilovolt ampere reactive hour,A unit of measure defining the accumulated reactive energy equal to one kilovolt ampere of reactive power per hour.,3.5,kvar·h,nan
-1278,nan,K30,gallon (US liquid) per second,nan,2,gal (US liq.)/s,"3,785 412 x 10⁻³ m³/s"
-1279,nan,K31,gram-force per square centimetre,nan,2,gf/cm²,"98,066 5 Pa"
-1280,nan,K32,gill (UK) per day,nan,2,gi (UK)/d,"1,644 274 x 10⁻⁵ m³/s"
-1281,nan,K33,gill (UK) per hour,nan,2,gi (UK)/h,"3,946 258 x 10⁻⁸ m³/s"
-1282,nan,K34,gill (UK) per minute,nan,2,gi (UK)/min,"0,023 677 55 m³/s"
-1283,nan,K35,gill (UK) per second,nan,2,gi (UK)/s,"1,420 653 x 10⁻⁴ m³/s"
-1284,nan,K36,gill (US) per day,nan,2,gi (US)/d,"1,369 145 x 10⁻⁹ m³/s"
-1285,nan,K37,gill (US) per hour,nan,2,gi (US)/h,"3,285 947 x 10⁻⁸ m³/s"
-1286,nan,K38,gill (US) per minute,nan,2,gi (US)/min,"1,971 568 x 10⁻⁶ m³/s"
-1287,nan,K39,gill (US) per second,nan,2,gi (US)/s,"1,182 941 x 10⁻⁴ m³/s"
-1288,nan,K40,standard acceleration of free fall,nan,2,gn,"9,806 65 m/s²"
-1289,nan,K41,grain per gallon (US),nan,2,gr/gal (US),"1,711 806 x 10⁻² kg/m³"
-1290,nan,K42,horsepower (boiler),nan,2,boiler hp,"9,809 50 x 10³ W"
-1291,nan,K43,horsepower (electric),nan,2,electric hp,746 W
-1292,nan,K45,inch per degree Fahrenheit,nan,2,in/°F,"4,572 x 10⁻² m/K"
-1293,nan,K46,inch per psi,nan,2,in/psi,"3,683 959 x 10⁻⁶ m/Pa"
-1294,nan,K47,inch per second degree Fahrenheit,nan,2,(in/s)/°F,"4,572 x 10⁻² (m/s)/K"
-1295,nan,K48,inch per second psi,nan,2,(in/s)/psi,"3,683 959 x 10⁻⁶ (m/s)/Pa"
-1296,nan,K49,reciprocal cubic inch,nan,2,1/in³,"6,102 375 9 x 10⁴ m⁻³"
-1297,D,K5,kilovolt ampere (reactive),Use kilovar (common code KVR),1S,kvar,10³ V x A
-1298,nan,K50,kilobaud,A unit of signal transmission speed equal to 10³ (1000) signaling events per second.,3.6,kBd,10³ Bd
-1299,nan,K51,kilocalorie (mean),nan,2,kcal,"4,190 02 x 10³ J"
-1300,nan,K52,kilocalorie (international table) per hour metre degree Celsius,nan,2,kcal/(m·h·°C),"1,163 J/(m x s x K)"
-1301,nan,K53,kilocalorie (thermochemical),nan,2,kcalth,"4,184 x 10³ J"
-1302,nan,K54,kilocalorie (thermochemical) per minute,nan,2,kcalth/min,"69,733 33 W"
-1303,nan,K55,kilocalorie (thermochemical) per second,nan,2,kcalth/s,"4,184 x 10³ W"
-1304,nan,K58,kilomole per hour,nan,1S,kmol/h,"2,777 78 x 10⁻¹ mol/s"
-1305,nan,K59,kilomole per cubic metre kelvin,nan,2,(kmol/m³)/K,10³ (mol/m³)/K
-1306,nan,K6,kilolitre,nan,1M,kl,m³
-1307,nan,K60,kilomole per cubic metre bar,nan,2,(kmol/m³)/bar,10⁻² (mol/m³)/Pa
-1308,nan,K61,kilomole per minute,nan,1S,kmol/min,"16,666 7 mol/s"
-1309,nan,K62,litre per litre,nan,1S,l/l,1
-1310,nan,K63,reciprocal litre,nan,2,1/l,10³ m⁻³
-1311,nan,K64,pound (avoirdupois) per degree Fahrenheit,nan,2,lb/°F,"0,816 466 3 kg/K"
-1312,nan,K65,pound (avoirdupois) square foot,nan,2,lb·ft²,"4,214 011 x 10⁻² kg x m²"
-1313,nan,K66,pound (avoirdupois) per day,nan,2,lb/d,"5,249 912 x 10⁻⁶ kg/s"
-1314,nan,K67,pound per foot hour,nan,2,lb/(ft·h),"4,133 789 x 10⁻⁴ Pa x s"
-1315,nan,K68,pound per foot second,nan,2,lb/(ft·s),"1,488 164 Pa x s"
-1316,nan,K69,pound (avoirdupois) per cubic foot degree Fahrenheit,nan,2,(lb/ft³)/°F,"28,833 23 (kg/m³)/K"
-1317,nan,K70,pound (avoirdupois) per cubic foot psi,nan,2,(lb/ft³)/psi,"2,323 282 x 10⁻³"
-1318,nan,K71,pound (avoirdupois) per gallon (UK),nan,2,lb/gal (UK),"99,776 37 kg/m³"
-1319,nan,K73,pound (avoirdupois) per hour degree Fahrenheit,nan,2,(lb/h)/°F,"2,267 962 x 10⁻⁴ (kg/s)/K"
-1320,nan,K74,pound (avoirdupois) per hour psi,nan,2,(lb/h)/psi,"1,827 445 x 10⁻⁸ (kg/s)/Pa"
-1321,nan,K75,pound (avoirdupois) per cubic inch degree Fahrenheit,nan,2,(lb/in³)/°F,"4,982 384 x 10⁴ (kg/m³)/K"
-1322,nan,K76,pound (avoirdupois) per cubic inch psi,nan,2,(lb/in³)/psi,"4,014 632 (kg/m³)/Pa"
-1323,nan,K77,pound (avoirdupois) per psi,nan,2,lb/psi,"6,578 802 x 10⁻⁵ kg/Pa"
-1324,nan,K78,pound (avoirdupois) per minute,nan,2,lb/min,"7,559 873 x 10⁻³ kg/s"
-1325,nan,K79,pound (avoirdupois) per minute degree Fahrenheit,nan,2,lb/(min·°F),"1,360 777  x 10⁻² (kg/s)/K"
-1326,nan,K80,pound (avoirdupois) per minute psi,nan,2,(lb/min)/psi,"1,096 467 x 10⁻⁶ (kg/s)/Pa"
-1327,nan,K81,pound (avoirdupois) per second,nan,2,lb/s,"0,453 592 4 kg/s"
-1328,nan,K82,pound (avoirdupois) per second degree Fahrenheit,nan,2,(lb/s)/°F,"0,816 466 3 (kg/s)/K"
-1329,nan,K83,pound (avoirdupois) per second psi,nan,2,(lb/s)/psi,"6,578 802 x 10⁻⁵ (kg/s)/Pa"
-1330,nan,K84,pound per cubic yard,nan,2,lb/yd³,"0,593 276 4 kg/m³"
-1331,nan,K85,pound-force per square foot,nan,2,lbf/ft²,"47,880 26 Pa"
-1332,nan,K86,pound-force per square inch degree Fahrenheit,nan,2,psi/°F,"1,241 056 x 10⁴ Pa/K"
-1333,nan,K87,psi cubic inch per second,nan,2,psi·in³/s,"0,112 985 Pa x m³/s"
-1334,nan,K88,psi litre per second,nan,2,psi·l/s,"6,894 757 Pa x m³/s"
-1335,nan,K89,psi cubic metre per second,nan,2,psi·m³/s,"6,894 757  x 10³ Pa x m³/s"
-1336,nan,K90,psi cubic yard per second,nan,2,psi·yd³/s,"5,271 420 x 10³ Pa x m³/s"
-1337,nan,K91,pound-force second per square foot,nan,2,lbf·s/ft²,"47,880 26 Pa x s"
-1338,nan,K92,pound-force second per square inch,nan,2,lbf·s/in²,"6,894 757  x 10³ Pa x s"
-1339,nan,K93,reciprocal psi,nan,2,1/psi,"1,450 377 x 10⁻⁴ Pa⁻¹"
-1340,nan,K94,quart (UK liquid) per day,nan,2,qt (UK liq.)/d,"1,315 420 x 10⁻⁸ m³/s"
-1341,nan,K95,quart (UK liquid) per hour,nan,2,qt (UK liq.)/h,"3,157 008 x 10⁻⁷ m³/s"
-1342,nan,K96,quart (UK liquid) per minute,nan,2,qt (UK liq.)/min,"1,894 205 x 10⁻⁵ m³/s"
-1343,nan,K97,quart (UK liquid) per second,nan,2,qt (UK liq.)/s,"1,136 523 x 10⁻³ m³/s"
-1344,nan,K98,quart (US liquid) per day,nan,2,qt (US liq.)/d,"1,095 316 x 10⁻⁸ m³/s"
-1345,nan,K99,quart (US liquid) per hour,nan,2,qt (US liq.)/h,"2,628 758 x 10⁻⁷ m³/s"
-1346,nan,KA,cake,"A unit of count defining the number of cakes (cake: object shaped into a flat, compact mass).",3.9,nan,nan
-1347,nan,KAT,katal,A unit of catalytic activity defining the catalytic activity of enzymes and other catalysts.,1M,kat,s⁻¹ x mol
-1348,nan,KB,kilocharacter,A unit of information equal to 10³ (1000) characters.,3.9,nan,nan
-1349,nan,KBA,kilobar,nan,1M,kbar,10⁸ Pa
-1350,nan,KCC,kilogram of choline chloride,A unit of mass equal to one thousand grams of choline chloride.,3.1,kg C₅ H₁₄ClNO,nan
-1351,X,KD,kilogram decimal,nan,3.9,nan,nan
-1352,nan,KDW,kilogram drained net weight,"A unit of mass defining the net number of kilograms of a product, disregarding the liquid content of the product.",3.1,kg/net eda,nan
-1353,nan,KEL,kelvin,Refer ISO 80000-5 (Quantities and units — Part 5: Thermodynamics),1,K,K
-1354,X,KF,kilopacket,nan,3.9,nan,nan
-1355,X,KG,keg,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-1356,nan,KGM,kilogram,A unit of mass equal to one thousand grams.,1,kg,kg
-1357,nan,KGS,kilogram per second,nan,1,kg/s,kg/s
-1358,nan,KHY,kilogram of hydrogen peroxide,A unit of mass equal to one thousand grams of hydrogen peroxide.,3.1,kg H₂O₂,nan
-1359,nan,KHZ,kilohertz,nan,1S,kHz,10³ Hz
-1360,nan,KI,kilogram per millimetre width,nan,3.1,nan,10³ kg/m
-1361,nan,KIC,"kilogram, including container","A unit of mass defining the number of kilograms of a product, including its container.",3.1,nan,nan
-1362,nan,KIP,"kilogram, including inner packaging","A unit of mass defining the number of kilograms of a product, including its inner packaging materials.",3.1,nan,nan
-1363,nan,KJ,kilosegment,A unit of information equal to 10³ (1000) segments.,3.6,nan,nan
-1364,nan,KJO,kilojoule,nan,1S,kJ,10³ J
-1365,nan,KL,kilogram per metre,nan,1,kg/m,kg/m
-1366,nan,KLK,lactic dry material percentage,A unit of proportion defining the percentage of dry lactic material in a product.,3.5,nan,nan
-1367,nan,KLX,kilolux,A unit of illuminance equal to one thousand lux.,1M,klx,10³ cd x sr / m²
-1368,nan,KMA,kilogram of methylamine,A unit of mass equal to one thousand grams of methylamine.,3.1,kg met.am.,nan
-1369,nan,KMH,kilometre per hour,nan,1S,km/h,"0,277 778 m/s"
-1370,nan,KMK,square kilometre,nan,1S,km²,10⁶ m²
-1371,nan,KMQ,kilogram per cubic metre,A unit of weight expressed in kilograms of a substance that fills a volume of one cubic metre.,1,kg/m³,kg/m³
-1372,nan,KMT,kilometre,nan,1S,km,10³ m
-1373,nan,KNI,kilogram of nitrogen,A unit of mass equal to one thousand grams of nitrogen.,3.1,kg N,nan
-1374,nan,KNM,kilonewton per square metre,Pressure expressed in kN/m2.,1S,kN/m2,103pascal
-1375,nan,KNS,kilogram named substance,A unit of mass equal to one kilogram of a named substance.,3.1,nan,nan
-1376,nan,KNT,knot,nan,1,kn,"0,514 444 m/s"
-1377,nan,KO,milliequivalence caustic potash per gram of product,A unit of count defining the number of milligrams of potassium hydroxide per gram of product as a measure of the concentration of potassium hydroxide in the product.,3.9,nan,nan
-1378,nan,KPA,kilopascal,nan,1S,kPa,10³ Pa
-1379,nan,KPH,kilogram of potassium hydroxide (caustic potash),A unit of mass equal to one thousand grams of potassium hydroxide (caustic potash).,3.1,kg KOH,nan
-1380,nan,KPO,kilogram of potassium oxide,A unit of mass equal to one thousand grams of potassium oxide.,3.1,kg K₂O,nan
-1381,nan,KPP,kilogram of phosphorus pentoxide (phosphoric anhydride),A unit of mass equal to one thousand grams of phosphorus pentoxide phosphoric anhydride.,3.1,nan,nan
-1382,nan,KR,kiloroentgen,nan,2,kR,"2,58 x 10⁻¹ C/kg"
-1383,X,KS,thousand pound per square inch,nan,3.8,nan,nan
-1384,nan,KSD,kilogram of substance 90 % dry,A unit of mass equal to one thousand grams of a named substance that is 90% dry.,3.1,kg 90 % sdt,nan
-1385,nan,KSH,kilogram of sodium hydroxide (caustic soda),A unit of mass equal to one thousand grams of sodium hydroxide (caustic soda).,3.1,kg NaOH,nan
-1386,nan,KT,kit,"A unit of count defining the number of kits (kit: tub, barrel or pail).",3.2,nan,nan
-1387,X,KTM,kilometre,nan,1S,km,10³ m
-1388,nan,KTN,kilotonne,nan,1M,kt,10⁶ kg
-1389,nan,KUR,kilogram of uranium,A unit of mass equal to one thousand grams of uranium.,3.1,kg U,nan
-1390,nan,KVA,kilovolt - ampere,nan,1S,kV·A,10³ V x A
-1391,nan,KVR,kilovar,nan,1S,kvar,10³ V x A
-1392,nan,KVT,kilovolt,nan,1S,kV,10³ V
-1393,nan,KW,kilogram per millimetre,nan,1M,kg/mm,10³ kg/m
-1394,nan,KWH,kilowatt hour,nan,1S,kW·h,"3,6 x 10⁶ J"
-1395,+,KWY,kilowatt year,killowatt year,2,kW/year,nan
-1396,¦,KWN,Kilowatt hour per normalized cubic metre,Kilowatt hour per normalized cubic metre (temperature 0°C and pressure 1013.25 millibars ).,2,nan,nan
-1397,nan,KWO,kilogram of tungsten trioxide,A unit of mass equal to one thousand grams of tungsten trioxide.,3.1,kg WO₃,nan
-1398,¦,KWS,Kilowatt hour per standard cubic metre,Kilowatt hour per standard cubic metre (temperature 15°C and pressure 1013.25 millibars).,2,nan,nan
-1399,nan,KWT,kilowatt,nan,1S,kW,10³ W
-1400,nan,KX,millilitre per kilogram,nan,1M,ml/kg,10⁻⁶ m³/kg
-1401,nan,L10,quart (US liquid) per minute,nan,2,qt (US liq.)/min,"1,577 255 x 10⁻⁵ m³/s"
-1402,nan,L11,quart (US liquid) per second,nan,2,qt (US liq.)/s,"9,463 529 x 10⁻⁴ m³/s"
-1403,nan,L12,metre per second kelvin,nan,2,(m/s)/K,(m/s)/K
-1404,nan,L13,metre per second bar,nan,2,(m/s)/bar,10⁻⁵ (m/s)/Pa
-1405,nan,L14,square metre hour degree Celsius per kilocalorie (international table),nan,2,m²·h·°C/kcal,"0,859 845 2 m² x s x K/J"
-1406,nan,L15,millipascal second per kelvin,nan,2,mPa·s/K,10⁻³ Pa x s/K
-1407,nan,L16,millipascal second per bar,nan,2,mPa·s/bar,10⁻⁸ s
-1408,nan,L17,milligram per cubic metre kelvin,nan,2,(mg/m³)/K,10⁻⁶ (kg/m³)/K
-1409,nan,L18,milligram per cubic metre bar,nan,2,(mg/m³)/bar,10⁻¹¹ (kg/m³)/Pa
-1410,nan,L19,millilitre per litre,nan,1S,ml/l,10⁻³
-1411,nan,L2,litre per minute,nan,1M,l/min,"1,666 67 x 10⁻⁵ m³/s"
-1412,nan,L20,reciprocal cubic millimetre,nan,1S,1/mm³,10⁹ m⁻³
-1413,nan,L21,cubic millimetre per cubic metre,nan,1S,mm³/m³,10⁹
-1414,nan,L23,mole per hour,nan,1S,mol/h,"2,777 78 x 10⁻⁴ mol/s"
-1415,nan,L24,mole per kilogram kelvin,nan,2,(mol/kg)/K,(mol/kg)/K
-1416,nan,L25,mole per kilogram bar,nan,2,(mol/kg)/bar,10⁻⁵ (mol/kg)/Pa
-1417,nan,L26,mole per litre kelvin,nan,2,(mol/l)/K,10³ (mol/m³)/K
-1418,nan,L27,mole per litre bar,nan,2,(mol/l)/bar,10⁻² (mol/m³)/Pa
-1419,nan,L28,mole per cubic metre kelvin,nan,2,(mol/m³)/K,(mol/m³)/K
-1420,nan,L29,mole per cubic metre bar,nan,2,(mol/m³)/bar,10⁻⁵ (mol/m³)/Pa
-1421,nan,L30,mole per minute,nan,1S,mol/min,"1,666 67 x 10⁻² mol/s"
-1422,nan,L31,milliroentgen aequivalent men,nan,2,mrem,10⁻⁵ Sv
-1423,nan,L32,nanogram per kilogram,nan,1S,ng/kg,10⁻¹²
-1424,nan,L33,ounce (avoirdupois) per day,nan,2,oz/d,"3,281 194 x 10⁻⁷kg/s"
-1425,nan,L34,ounce (avoirdupois) per hour,nan,2,oz/h,"7,874 867 x 10⁻⁶ kg/s"
-1426,nan,L35,ounce (avoirdupois) per minute,nan,2,oz/min,"4,724 92 x 10⁻⁴ kg/s"
-1427,nan,L36,ounce (avoirdupois) per second,nan,2,oz/s,"2,834 952 x 10⁻² kg/s"
-1428,nan,L37,ounce (avoirdupois) per gallon (UK),nan,2,oz/gal (UK),"6,236 023 kg/m³"
-1429,nan,L38,ounce (avoirdupois) per gallon (US),nan,2,oz/gal (US),"7,489 152 kg/m³"
-1430,nan,L39,ounce (avoirdupois) per cubic inch,nan,2,oz/in³,"1,729 994 x 10³ kg/m³"
-1431,nan,L40,ounce (avoirdupois)-force,nan,2,ozf,"0,278 013 9 N"
-1432,nan,L41,ounce (avoirdupois)-force inch,nan,2,ozf·in,"7,061 552 x 10⁻³ N x m"
-1433,nan,L42,picosiemens per metre,nan,2,pS/m,10⁻¹² S/m
-1434,nan,L43,peck (UK),nan,2,pk (UK),"9,092 181 x 10⁻³ m³"
-1435,nan,L44,peck (UK) per day,nan,2,pk (UK)/d,"1,052 336 x 10⁻⁷ m³/s"
-1436,nan,L45,peck (UK) per hour,nan,2,pk (UK)/h,"2,525 606 x 10⁻⁶ m³/s"
-1437,nan,L46,peck (UK) per minute,nan,2,pk (UK)/min,"1,515 363 5 x 10⁻⁴ m³/s"
-1438,nan,L47,peck (UK) per second,nan,2,pk (UK)/s,"9,092 181 x 10⁻³ m³/s"
-1439,nan,L48,peck (US dry) per day,nan,2,pk (US dry)/d,"1,019 649 x 10⁻⁷ m³/s"
-1440,nan,L49,peck (US dry) per hour,nan,2,pk (US dry)/h,"2,447 158 x 10⁻⁶ m³/s"
-1441,nan,L50,peck (US dry) per minute,nan,2,pk (US dry)/min,"1,468 295 x 10⁻⁴ m³/s"
-1442,nan,L51,peck (US dry) per second,nan,2,pk (US dry)/s,"8,809 768 x 10⁻³ m³/s"
-1443,nan,L52,psi per psi,nan,2,psi/psi,1.0
-1444,nan,L53,pint (UK) per day,nan,2,pt (UK)/d,"6,577 098 x 10⁻⁹ m³/s"
-1445,nan,L54,pint (UK) per hour,nan,2,pt (UK)/h,"1,578 504 x 10⁻⁷ m³/s"
-1446,nan,L55,pint (UK) per minute,nan,2,pt (UK)/min,"9,471 022 x 10⁻⁶ m³/s"
-1447,nan,L56,pint (UK) per second,nan,2,pt (UK)/s,"5,682 613 x 10⁻⁴ m³/s"
-1448,nan,L57,pint (US liquid) per day,nan,2,pt (US liq.)/d,"5,476 580 x 10⁻⁹ m³/s"
-1449,nan,L58,pint (US liquid) per hour,nan,2,pt (US liq.)/h,"1,314 379 x 10⁻⁷ m³/s"
-1450,nan,L59,pint (US liquid) per minute,nan,2,pt (US liq.)/min,"7,886 275 x 10⁻⁶ m³/s"
-1451,nan,L60,pint (US liquid) per second,nan,2,pt (US liq.)/s,"4,731 765 x 10⁻⁴ m³/s"
-1452,X,L61,pint (US dry),Use dry pint (common code PTD),2,pt (US dry),"5,506 105 x 10⁻⁴ m³"
-1453,X,L62,quart (US dry),Use dry quart (US) (common code QTD),2,qt (US dry),"1,101 221 x 10⁻³ m³"
-1454,nan,L63,slug per day,nan,2,slug/d,"1,689 109 x 10⁻⁴ kg/s"
-1455,nan,L64,slug per foot second,nan,2,slug/(ft·s),"47,880 26 Pa x s"
-1456,nan,L65,slug per cubic foot,nan,2,slug/ft³,"5,153 788 x 10² kg/m³"
-1457,nan,L66,slug per hour,nan,2,slug/h,"4,053 861 x 10⁻³ kg/s"
-1458,nan,L67,slug per minute,nan,2,slug/min,"0,243 231 7 kg/s"
-1459,nan,L68,slug per second,nan,2,slug/s,"14,593 90 kg/s"
-1460,nan,L69,tonne per kelvin,nan,2,t/K,10³ kg/K
-1461,nan,L70,tonne per bar,nan,2,t/bar,10⁻² kg/Pa
-1462,nan,L71,tonne per day,nan,2,t/d,"1,157 41 x 10⁻² kg/s"
-1463,nan,L72,tonne per day kelvin,nan,2,(t/d)/K,"1,157 41 x 10⁻² (kg/s)/K"
-1464,nan,L73,tonne per day bar,nan,2,(t/d)/bar,"1,157 41 x 10⁻⁷ (kg/s)/Pa"
-1465,nan,L74,tonne per hour kelvin,nan,2,(t/h)/K,"2,777 78 x 10⁻¹ (kg/s)/K"
-1466,nan,L75,tonne per hour bar,nan,2,(t/h)/bar,"2,777 78 x 10⁻⁶ (kg/s)/Pa"
-1467,nan,L76,tonne per cubic metre kelvin,nan,2,(t/m³)/K,10³ (kg/m³)/K
-1468,nan,L77,tonne per cubic metre bar,nan,2,(t/m³)/bar,10⁻² (kg/m³)/Pa
-1469,nan,L78,tonne per minute,nan,2,t/min,"16,666 7 kg/s"
-1470,nan,L79,tonne per minute kelvin,nan,2,(t/min)/K,"16,666 7 (kg/s)/K"
-1471,nan,L80,tonne per minute bar,nan,2,(t/min)/bar,"1,666 67 x 10⁻⁴ (kg/s)/Pa"
-1472,nan,L81,tonne per second,nan,2,t/s,10³ kg/s
-1473,nan,L82,tonne per second kelvin,nan,2,(t/s)/K,10³ (kg/s)/K
-1474,nan,L83,tonne per second bar,nan,2,(t/s)/bar,10⁻² (kg/s)/Pa
-1475,nan,L84,ton (UK shipping),nan,2,British shipping ton,"1,189 3 m³"
-1476,nan,L85,ton long per day,nan,2,ton (UK)/d,"1,175 980 x 10⁻² kg/s"
-1477,nan,L86,ton (US shipping),nan,2,(US) shipping ton,"1,132 6 m³"
-1478,nan,L87,ton short per degree Fahrenheit,nan,2,ton (US)/°F,"1,632 932 x 10³ kg/K"
-1479,nan,L88,ton short per day,nan,2,ton (US)/d,"1,049 982 x 10⁻² kg/s"
-1480,nan,L89,ton short per hour degree Fahrenheit,nan,2,ton (US)/(h·°F),"0,453 592 2 kg/s x K"
-1481,nan,L90,ton short per hour psi,nan,2,(ton (US)/h)/psi,"3,654 889 x 10⁻⁵ (kg/s)/Pa"
-1482,nan,L91,ton short per psi,nan,2,ton (US)/psi,"0,131 576"
-1483,nan,L92,ton (UK long) per cubic yard,nan,2,ton.l/yd³ (UK),"1,328 939 x 10³ kg/m³"
-1484,nan,L93,ton (US short) per cubic yard,nan,2,ton.s/yd³ (US),"1,186 553 x 10³ kg/m³"
-1485,nan,L94,ton-force (US short),nan,2,ton.sh-force,"8,896 443 x 10³ N"
-1486,nan,L95,common year,nan,2,y (365 days),"3,153 6 x 10⁷ s"
-1487,nan,L96,sidereal year,nan,2,y (sidereal),"3,155 815 x 10⁷ s"
-1488,nan,L98,yard per degree Fahrenheit,nan,2,yd/°F,"1,645 92 m/K"
-1489,nan,L99,yard per psi,nan,2,yd/psi,"1,326 225 x 10⁻⁴ m/Pa"
-1490,nan,LA,pound per cubic inch,nan,2,lb/in³,"2,767 990 x 10⁴ kg/m³"
-1491,nan,LAC,lactose excess percentage,A unit of proportion defining the percentage of lactose in a product that exceeds a defined percentage level.,3.5,nan,nan
-1492,nan,LBR,pound,nan,2,lb,"0,453 592 37 kg"
-1493,nan,LBT,troy pound (US),nan,3.5,nan,"373,241 7 g"
-1494,X,LC,linear centimetre,nan,3.1,nan,nan
-1495,nan,LD,litre per day,nan,1M,l/d,"1,157 41 x 10⁻⁸ m³/s"
-1496,X,LE,lite,nan,3.9,nan,nan
-1497,nan,LEF,leaf,A unit of count defining the number of leaves.,3.5,nan,nan
-1498,nan,LF,linear foot,A unit of count defining the number of feet (12-inch) in length of a uniform width object.,3.1,nan,nan
-1499,nan,LH,labour hour,A unit of time defining the number of labour hours.,3.1,nan,nan
-1500,X,LI,linear inch,nan,3.1,nan,nan
-1501,X,LJ,large spray,nan,3.9,nan,nan
-1502,nan,LK,link,A unit of distance equal to 0.01 chain.,3.9,nan,nan
-1503,nan,LM,linear metre,A unit of count defining the number of metres in length of a uniform width object.,3.1,nan,nan
-1504,nan,LN,length,A unit of distance defining the linear extent of an item measured from end to end.,3.9,nan,nan
-1505,nan,LO,lot [unit of procurement],A unit of count defining the number of lots (lot: a collection of associated items).,3.9,nan,nan
-1506,nan,LP,liquid pound,A unit of mass defining the number of pounds of a liquid substance.,3.1,nan,nan
-1507,nan,LPA,litre of pure alcohol,A unit of volume equal to one litre of pure alcohol.,3.1,nan,nan
-1508,nan,LR,layer,A unit of count defining the number of layers.,3.9,nan,nan
-1509,nan,LS,lump sum,A unit of count defining the number of whole or a complete monetary amounts.,3.9,nan,nan
-1510,nan,LTN,ton (UK) or long ton (US),Synonym: gross ton (2240 lb),2,ton (UK),"1,016 047 x 10³ kg"
-1511,nan,LTR,litre,nan,1,l,10⁻³ m³
-1512,nan,LUB,"metric ton, lubricating oil",A unit of mass defining the number of metric tons of lubricating oil.,3.1,nan,nan
-1513,nan,LUM,lumen,nan,1,lm,cd x sr
-1514,nan,LUX,lux,nan,1,lx,cd x sr / m²
-1515,X,LX,linear yard per pound,nan,3.1,nan,nan
-1516,nan,LY,linear yard,A unit of count defining the number of 36-inch units in length of a uniform width object.,3.1,nan,nan
-1517,X,M0,magnetic tape,nan,3.6,nan,nan
-1518,nan,M1,milligram per litre,nan,1M,mg/l,10⁻³ kg/m³
-1519,nan,M10,reciprocal cubic yard,nan,2,1/yd³,"1,307 951 m⁻³"
-1520,nan,M11,cubic yard per degree Fahrenheit,nan,2,yd³/°F,"1,376 199 m³/K"
-1521,nan,M12,cubic yard per day,nan,2,yd³/d,"8,849 015 x 10⁻⁶ m³/s"
-1522,nan,M13,cubic yard per hour,nan,2,yd³/h,"2,123 764 x 10⁻⁴ m³/s"
-1523,nan,M14,cubic yard per psi,nan,2,yd³/psi,"1,108 893 x 10⁻⁴ m³/Pa"
-1524,nan,M15,cubic yard per minute,nan,2,yd³/min,"1,274 258 x 10⁻² m³/s"
-1525,nan,M16,cubic yard per second,nan,2,yd³/s,"0,764 554 9 m³/s"
-1526,nan,M17,kilohertz metre,nan,2,kHz·m,10³ Hz x m
-1527,nan,M18,gigahertz metre,nan,2,GHz·m,10⁹ Hz x m
-1528,nan,M19,Beaufort,"An empirical measure for describing wind speed based mainly on observed sea conditions. The Beaufort scale indicates the wind speed by numbers that typically range from 0 for calm, to 12 for hurricane.",3,Bft,nan
-1529,nan,M20,reciprocal megakelvin or megakelvin to the power minus one,nan,2,1/MK,10⁻⁶ K⁻¹
-1530,nan,M21,reciprocal kilovolt - ampere reciprocal hour,nan,2,1/kVAh,"2,777 778 x 10⁻⁷ (V x A x s)⁻¹"
-1531,nan,M22,millilitre per square centimetre minute,nan,2,(ml/min)/cm²,"2,777 778 x 10⁻⁶  (m³/s)/m²"
-1532,nan,M23,newton per centimetre,nan,1M,N/cm,10² N/m
-1533,nan,M24,ohm kilometre,nan,1M,Ω·km,10³ Ω x m
-1534,nan,M25,percent per degree Celsius,"A unit of proportion, equal to 0.01, in relation to a temperature of one degree.",3.7,%/°C,10⁻² °C⁻¹
-1535,nan,M26,gigaohm per metre,nan,2,GΩ/m,10⁹ Ω/m
-1536,nan,M27,megahertz metre,nan,2,MHz·m,10⁶ Hz x m
-1537,nan,M29,kilogram per kilogram,nan,1S,kg/kg,1
-1538,nan,M30,reciprocal volt - ampere reciprocal second,nan,1S,1/(V·A·s),(V x A x s)⁻¹
-1539,nan,M31,kilogram per kilometre,nan,1S,kg/km,10⁻³ kg/m
-1540,nan,M32,pascal second per litre,nan,2,Pa·s/l,10³ Pa x s/m³
-1541,nan,M33,millimole per litre,nan,1S,mmol/l,mol/m³
-1542,nan,M34,newton metre per square metre,nan,1S,N·m/m²,N x m/m²
-1543,nan,M35,millivolt - ampere,nan,1S,mV·A,10⁻³ V x A
-1544,nan,M36,30-day month,"A unit of count defining the number of months expressed in multiples of 30 days, one day equals 24 hours.",3.7,mo (30 days),"2,592 000 x 10⁶ s"
-1545,nan,M37,actual/360,"A unit of count defining the number of years expressed in multiples of 360 days, one day equals 24 hours.",3.7,y (360 days),"3,110 400 0 x 10⁷ s"
-1546,nan,M38,kilometre per second squared,1000-fold of the SI base unit metre divided by the power of the SI base unit second by exponent 2.,1M,km/s²,10³ m/s²
-1547,nan,M39,centimetre per second squared,"0,01-fold of the SI base unit metre divided by the power of the SI base unit second by exponent 2.",1M,cm/s²,10⁻² m/s²
-1548,nan,M4,monetary value,A unit of measure expressed as a monetary amount.,3.9,nan,nan
-1549,nan,M40,yard per second squared,Unit of the length according to the Anglo-American and Imperial system of units divided by the power of the SI base unit second by exponent 2.,2,yd/s²,"9,144 x 10⁻¹ m/s²"
-1550,nan,M41,millimetre per second squared,"0,001-fold of the SI base unit metre divided by the power of the SI base unit second by exponent 2.",1M,mm/s²,10⁻³ m/s²
-1551,nan,M42,mile (statute mile) per second squared,Unit of the length according to the Imperial system of units divided by the power of the SI base unit second by exponent 2.,2,mi/s²,"1,609 344 x 10³ m/s²"
-1552,nan,M43,mil,"Unit to indicate an angle at military zone, equal to the 6400th part of the full circle of the 360° or 2·p·rad.",2,mil,"9,817 477  x 10⁻⁴ rad"
-1553,nan,M44,revolution,Unit to identify an angle of the full circle of 360° or 2·p·rad (Refer ISO/TC12 SI Guide).,2,rev,"6,283 185 rad"
-1554,nan,M45,degree [unit of angle] per second squared,360 part of a full circle divided by the power of the SI base unit second and the exponent 2.,1M,°/s²,"1,745 329 x 10⁻² rad / s"
-1555,nan,M46,revolution per minute,Unit of the angular velocity.,2.0,r/min,"0,104 719 8 rad/s"
-1556,nan,M47,circular mil,"Unit of an area, of which the size is given by a diameter of length of 1 mm (0,001 in) based on the formula: area = p·(diameter/2)².",2,cmil,"5,067 075 x 10⁻¹⁰ m²"
-1557,nan,M48,square mile (based on U.S. survey foot),"Unit of the area, which is mainly common in the agriculture and forestry.",2,mi² (US survey),"2,589 998 x 10⁶ m²"
-1558,nan,M49,chain (based on U.S. survey foot),Unit of the length according the Anglo-American system of units.,2,ch (US survey) ,"2,011684 x 10 m"
-1559,nan,M5,microcurie,nan,2S,µCi,"3,7 x 10⁴ Bq"
-1560,nan,M50,furlong,Unit commonly used in Great Britain at rural distances: 1 furlong = 40 rods = 10 chains (UK) = 1/8 mile = 1/10 furlong = 220 yards = 660 foot.,2,fur,"2,011 68 x 10² m"
-1561,nan,M51,foot (U.S. survey),"Unit commonly used in the United States for ordnance survey.,",2,ft (US survey) ,"3,048 006 x 10⁻¹ m"
-1562,nan,M52,mile (based on U.S. survey foot),Unit commonly used in the United States for ordnance survey.,2,mi (US survey) ,"1,609347 x 10³ m"
-1563,nan,M53,metre per pascal,SI base unit metre divided by the derived SI unit pascal.,1M,m/Pa,kg⁻¹ x m² x s²
-1564,nan,M55,metre per radiant,Unit of the translation factor for implementation from rotation to linear movement.,1S,m/rad,m/rad
-1565,nan,M56,shake,Unit for a very short period.,2,shake,10⁻⁸ s
-1566,nan,M57,mile per minute,Unit of velocity from the Imperial system of units.,2,mi/min,"26,822 4 m/s"
-1567,nan,M58,mile per second,Unit of the velocity from the Imperial system of units.,2,mi/s,"1,609 344 x 10³ m/s"
-1568,nan,M59,metre per second pascal,SI base unit meter divided by the product of SI base unit second and the derived SI unit pascal.,1S,(m/s)/Pa,m² x kg⁻¹ x s
-1569,nan,M60,metre per hour,SI base unit metre divided by the unit hour.,2,m/h,"2,777 78 x 10⁻⁴ m/s"
-1570,nan,M61,inch per year,Unit of the length according to the Anglo-American and Imperial system of units divided by the unit common year with 365 days.,2,in/y,"8,048 774 x 10⁻¹⁰ m/s"
-1571,nan,M62,kilometre per second,1000-fold of the SI base unit metre divided by the SI base unit second.,2,km/s,10³ m/s
-1572,nan,M63,inch per minute,Unit inch according to the Anglo-American and Imperial system of units divided by the unit minute.,2,in/min,"4,233 333 x 10⁻⁴ m/s"
-1573,nan,M64,yard per second,Unit yard according to the Anglo-American and Imperial system of units divided by the SI base unit second.,2,yd/s,"9,144 x 10⁻¹ m/s"
-1574,nan,M65,yard per minute,Unit yard according to the Anglo-American and Imperial system of units divided by the unit minute.,2,yd/min,"1,524 x 10⁻² m/s"
-1575,nan,M66,yard per hour,Unit yard according to the Anglo-American and Imperial system of units divided by the unit hour.,2,yd/h,"2,54 x 10⁻⁴ m/s"
-1576,nan,M67,acre-foot (based on U.S. survey foot),"Unit of the volume, which is used in the United States to measure/gauge the capacity of reservoirs.",2,acre-ft (US survey),"1,233 489 x 10³ m³"
-1577,nan,M68,cord (128 ft3),Traditional unit of the volume of stacked firewood which has been measured with a cord.,2,cord,"3,624 556 m³"
-1578,nan,M69,cubic mile (UK statute),Unit of volume according to the Imperial system of units.,2,mi³,"4,168 182 x 10⁹ m³"
-1579,nan,M7,micro-inch,nan,2,µin,"25,4 x 10⁻⁹ m"
-1580,nan,M70,"ton, register",Traditional unit of the cargo capacity.,2,RT,"2,831 685 m³"
-1581,nan,M71,cubic metre per pascal,Power of the SI base unit meter by exponent 3 divided by the derived SI base unit pascal.,1S,m³/Pa,kg⁻¹ x m⁴ x s²
-1582,nan,M72,bel,Logarithmic relationship to base 10.,1M,B,B
-1583,nan,M73,kilogram per cubic metre pascal,SI base unit kilogram divided by the product of the power of the SI base unit metre with exponent 3 and the derived SI unit pascal.,1M,(kg/m³)/Pa,m⁻² x s²
-1584,nan,M74,kilogram per pascal,SI base unit kilogram divided by the derived SI unit pascal.,2.0,kg/Pa,m x s²
-1585,nan,M75,kilopound-force,1000-fold of the unit of the force pound-force (lbf) according to the Anglo-American system of units with the relationship.,2,kip,"4,448 222 x 10³ N"
-1586,nan,M76,poundal,"Non SI-conforming unit of the power, which corresponds to a mass of a pound multiplied with the acceleration of a foot per square second.",2,pdl,"1,382 550 x 10⁻¹ N"
-1587,nan,M77,kilogram metre per second squared,Product of the SI base unit kilogram and the SI base unit metre divided by the power of the SI base unit second by exponent 2.,2,kg·m/s²,(kg x m)/s²
-1588,nan,M78,pond,"0,001-fold of the unit of the weight, defined as a mass of 1 kg which finds out about a weight strength from 1 kp by the gravitational force at sea level which corresponds to a strength of 9,806 65 newton.",2,p,"9,806 65 x 10⁻³ N"
-1589,nan,M79,square foot per hour,Power of the unit foot according to the Anglo-American and Imperial system of units by exponent 2 divided by the unit of time hour.,2,ft²/h,"2,580 64 x 10⁻⁵ m²/s"
-1590,nan,M80,stokes per pascal,CGS (Centimetre-Gram-Second system) unit stokes divided by the derived SI unit pascal.,2,St/Pa,10⁻⁴ kg⁻¹ x m³ x s
-1591,nan,M81,square centimetre per second,"0,000 1-fold of the power of the SI base unit metre by exponent 2 divided by the SI base unit second.",2,cm²/s,10⁻⁴ m²/s
-1592,nan,M82,square metre per second pascal,Power of the SI base unit metre with the exponent 2 divided by the SI base unit second and the derived SI unit pascal.,1.0,(m²/s)/Pa,kg⁻¹ x m³ x s
-1593,nan,M83,denier,Traditional unit for the indication of the linear mass of textile fibers and yarns.,2.0,den,"1,111 111 x 10⁻⁷ kg/m"
-1594,nan,M84,pound per yard,Unit for linear mass according to avoirdupois system of units.,2,lb/yd,"4,960 546 x 10⁻¹ kg/m"
-1595,nan,M85,"ton, assay",Non SI-conforming unit of the mass used in the mineralogy to determine the concentration of precious metals in ore according to the mass of the precious metal in milligrams in a sample of the mass of an assay sound (number of troy ounces in a short ton (1 000 lb)).,2,nan,"2,916 667 x 10⁻² kg"
-1596,nan,M86,pfund,Outdated unit of the mass used in Germany.,2,pfd,"0,5 kg"
-1597,nan,M87,kilogram per second pascal,SI base unit kilogram divided by the product of the SI base unit second and the derived SI unit pascal.,1S,(kg/s)/Pa,m x s
-1598,nan,M88,tonne per month,Unit tonne divided by the unit month.,2,t/mo,"3,802 570 537 68 x 10⁻⁴ kg/s"
-1599,nan,M89,tonne per year,Unit tonne divided by the unit year with 365 days.,2,t/y,"3,168 808 781 x 10⁻⁵ kg/s"
-1600,nan,M9,million Btu per 1000 cubic foot,nan,3.9,MBTU/kft³,nan
-1601,nan,M90,kilopound per hour,1000-fold of the unit of the mass avoirdupois pound according to the avoirdupois unit system divided by the unit hour.,2,klb/h,"0,125 997 889 kg/s"
-1602,nan,M91,pound per pound,Proportion of the mass consisting of the avoirdupois pound according to the avoirdupois unit system divided by the avoirdupois pound according to the avoirdupois unit system.,2.0,lb/lb,1.0
-1603,nan,M92,pound-force foot,Product of the unit pound-force according to the Anglo-American system of units and the unit foot according to the Anglo-American and the Imperial system of units.,2,lbf·ft,"1,355 818 N x m"
-1604,nan,M93,newton metre per radian,Product of the derived SI unit newton and the SI base unit metre divided by the unit radian.,1M,N·m/rad,m² x kg x s⁻² x rad⁻¹
-1605,nan,M94,kilogram metre,Unit of imbalance as a product of the SI base unit kilogram and the SI base unit metre.,1S,kg·m,kg x m
-1606,nan,M95,poundal foot,Product of the non SI-conforming unit of the force poundal and the unit foot according to the Anglo-American and Imperial system of units .,2,pdl·ft,"4,214 011 x 10⁻² N x m"
-1607,nan,M96,poundal inch,Product of the non SI-conforming unit of the force poundal and the unit inch according to the Anglo-American and Imperial system of units .,2,pdl·in,"3,511 677 10⁻³ N x m"
-1608,nan,M97,dyne metre,CGS (Centimetre-Gram-Second system) unit of the rotational moment.,2,dyn·m,10⁻⁵ N x m
-1609,nan,M98,kilogram centimetre per second,"Product of the SI base unit kilogram and the 0,01-fold of the SI base unit metre divided by the SI base unit second.",1M,kg·(cm/s),10⁻² kg x m/s
-1610,nan,M99,gram centimetre per second,"Product of the 0,001-fold of the SI base unit kilogram and the 0,01-fold of the SI base unit metre divided by the SI base unit second.",1M,g·(cm/s),10⁻⁵ kg x m/s
-1611,X,MA,machine per unit,nan,3.9,nan,nan
-1612,nan,MAH,megavolt ampere reactive hour,A unit of electrical reactive power defining the total amount of reactive power across a power system.,3.1,Mvar·h,nan
-1613,nan,MAL,megalitre,nan,1M,Ml,10³ m³
-1614,nan,MAM,megametre,nan,2,Mm,10⁶ m
-1615,nan,MAR,megavar,A unit of electrical reactive power represented by a current of one thousand amperes flowing due a potential difference of one thousand volts where the sine of the phase angle between them is 1.,1M,Mvar,nan
-1616,nan,MAW,megawatt,A unit of power defining the rate of energy transferred or consumed when a current of 1000 amperes flows due to a potential of 1000 volts at unity power factor.,1S,MW,10⁶ W
-1617,nan,MBE,thousand standard brick equivalent,A unit of count defining the number of one thousand brick equivalent units.,3.5,nan,nan
-1618,nan,MBF,thousand board foot,A unit of volume equal to one thousand board foot.,3.5,nan,nan
-1619,nan,MBR,millibar,nan,1S,mbar,10² Pa
-1620,nan,MC,microgram,nan,1S,µg,10⁻⁹ kg
-1621,nan,MCU,millicurie,nan,2S,mCi,"3,7 x 10⁷ Bq"
-1622,nan,MD,air dry metric ton,"A unit of count defining the number of metric tons of a product, disregarding the water content of the product.",3.1,nan,nan
-1623,X,MF,milligram per square foot per side,nan,3.1,nan,nan
-1624,nan,MGM,milligram,nan,1S,mg,10⁻⁶ kg
-1625,nan,MHZ,megahertz,nan,1S,MHz,10⁶ Hz
-1626,nan,MIK,square mile (statute mile),nan,2,mi²,"2,589 988 km²"
-1627,nan,MIL,thousand,nan,3.7,nan,10³
-1628,nan,MIN,minute [unit of time],nan,1,min,60 s
-1629,nan,MIO,million,nan,3.7,nan,10⁶
-1630,nan,MIU,million international unit,A unit of count defining the number of international units in multiples of 10⁶.,3.7,nan,nan
-1631,X,MK,milligram per square inch,nan,3.5,mg/in²,nan
-1632,nan,MLD,milliard,Synonym: billion (US),3.7,nan,10⁹
-1633,nan,MLT,millilitre,nan,1S,ml,10⁻⁶ m³
-1634,nan,MMK,square millimetre,nan,1S,mm²,10⁻⁶ m²
-1635,nan,MMQ,cubic millimetre,nan,1S,mm³,10⁻⁹ m³
-1636,nan,MMT,millimetre,nan,1S,mm,10⁻³ m
-1637,nan,MND,"kilogram, dry weight","A unit of mass defining the number of kilograms of a product, disregarding the water content of the product.",3.1,nan,nan
-1638,nan,MON,month,"Unit of time equal to 1/12 of a year of 365,25 days.",2,mo,"2,629 800 x 10⁶ s"
-1639,nan,MPA,megapascal,nan,1S,MPa,10⁶ Pa
-1640,X,MQ,thousand metre,nan,3.8,nan,10³m
-1641,nan,MQH,cubic metre per hour,nan,1M,m³/h,"2,777 78 x 10⁻⁴ m³/s"
-1642,nan,MQS,cubic metre per second,nan,1,m³/s,m³/s
-1643,nan,MSK,metre per second squared,nan,1,m/s²,m/s²
-1644,X,MT,mat,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-1645,nan,MTK,square metre,nan,1,m²,m²
-1646,nan,MTQ,cubic metre,Synonym: metre cubed,1,m³,m³
-1647,nan,MTR,metre,nan,1,m,m
-1648,nan,MTS,metre per second,nan,1,m/s,m/s
-1649,X,MV,number of mults,nan,3.7,nan,nan
-1650,nan,MVA,megavolt - ampere,nan,1S,MV·A,10⁶ V x A
-1651,nan,MWH,megawatt hour (1000 kW.h),A unit of power defining the total amount of bulk energy transferred or consumed.,1S,MW·h,"3,6 x 10⁹ J"
-1652,nan,N1,pen calorie,A unit of count defining the number of calories prescribed daily for parenteral/enteral therapy.,3.9,nan,nan
-1653,nan,N10,pound foot per second,Product of the avoirdupois pound according to the avoirdupois unit system and the unit foot according to the Anglo-American and Imperial system of units divided by the SI base unit second.,2.0,lb·(ft/s),"1,382 550 x 10⁻¹ kg x m/s"
-1654,nan,N11,pound inch per second,Product of the avoirdupois pound according to the avoirdupois unit system and the unit inch according to the Anglo-American and Imperial system of units divided by the SI base unit second.,2.0,lb·(in/s),"1,152 125 x 10⁻² kg x m/s"
-1655,nan,N12,Pferdestaerke,"Obsolete unit of the power relating to DIN 1301-3:1979: 1 PS = 735,498 75 W.",2,PS,"7,354 988 x 10² W"
-1656,nan,N13,centimetre of mercury (0 ºC),"Non SI-conforming unit of pressure, at which a value of 1 cmHg meets the static pressure, which is generated by a mercury at a temperature of 0 °C with a height of 1 centimetre .",2,cmHg (0 ºC),"1,333 22 x 10³ Pa"
-1657,nan,N14,centimetre of water (4 ºC),"Non SI-conforming unit of pressure, at which a value of 1 cmH2O meets the static pressure, which is generated by a head of water at a temperature of 4 °C with a height of 1 centimetre .",2,cmH₂O (4 °C),"9,806 38 x 10 Pa"
-1658,nan,N15,foot of water (39.2 ºF),"Non SI-conforming unit of pressure according to the Anglo-American and Imperial system for units, whereas the value of 1 ftH2O is equivalent to the static pressure, which is generated by a head of water at a temperature 39,2°F with a height of 1 foot .",2,"ftH₂O (39,2 ºF)","2,988 98 x 10³  Pa"
-1659,nan,N16,inch of mercury (32 ºF),"Non SI-conforming unit of pressure according to the Anglo-American and Imperial system for units, whereas the value of 1 inHg meets the static pressure, which is generated by a mercury at a temperature of 32°F with a height of 1 inch.",2,inHG (32 ºF),"3,386 38 x 10³  Pa"
-1660,nan,N17,inch of mercury (60 ºF),"Non SI-conforming unit of pressure according to the Anglo-American and Imperial system for units, whereas the value of 1 inHg meets the static pressure, which is generated by a mercury at a temperature of 60°F with a height of 1 inch.",2,inHg (60 ºF),"3,376 85 x 10³  Pa"
-1661,nan,N18,inch of water (39.2 ºF),"Non SI-conforming unit of pressure according to the Anglo-American and Imperial system for units, whereas the value of 1 inH2O meets the static pressure, which is generated by a head of water at a temperature of 39,2°F with a height of 1 inch .",2,"inH₂O (39,2 ºF)","2,490 82 × 10² Pa"
-1662,nan,N19,inch of water (60 ºF),"Non SI-conforming unit of pressure according to the Anglo-American and Imperial system for units, whereas the value of 1 inH2O meets the static pressure, which is generated by a head of water at a temperature of 60°F with a height of 1 inch .",2,inH₂O (60 ºF),"2,488 4 × 10² Pa"
-1663,X,N2,number of lines,nan,3.9,nan,nan
-1664,nan,N20,kip per square inch,Non SI-conforming unit of the pressure according to the Anglo-American system of units as the 1000-fold of the unit of the force pound-force divided by the power of the unit inch by exponent 2.,2,ksi,"6,894 757 x 10⁶ Pa"
-1665,nan,N21,poundal per square foot,"Non SI-conforming unit of pressure by the Imperial system of units according to NIST: 1 pdl/ft² = 1,488 164 Pa.",2,pdl/ft²,"1,488 164 Pa"
-1666,nan,N22,ounce (avoirdupois) per square inch,Unit of the surface specific mass (avoirdupois ounce according to the avoirdupois system of units according to the surface square inch according to the Anglo-American and Imperial system of units).,2,oz/in²,"4,394 185 x 10 kg/m²"
-1667,nan,N23,conventional metre of water,"Not SI-conforming unit of pressure, whereas a value of 1 mH2O is equivalent to the static pressure, which is produced by one metre high water column .",2,mH₂O,"9,806 65 x 10³ Pa"
-1668,nan,N24,gram per square millimetre,"0,001-fold of the SI base unit kilogram divided by the 0.000 001-fold of the power of the SI base unit meter by exponent 2.",2,g/mm²,10³ kg/m²
-1669,nan,N25,pound per square yard,Unit for areal-related mass as a unit pound according to the avoirdupois unit system divided by the power of the unit yard according to the Anglo-American and Imperial system of units with exponent 2.,2,lb/yd²,"5,424 919 x 10⁻¹ kg/m²"
-1670,nan,N26,poundal per square inch,Non SI-conforming unit of the pressure according to the Imperial system of units (poundal by square inch).,2,pdl/in²,"2,142 957 × 10² Pa"
-1671,nan,N27,foot to the fourth power,"Power of the unit foot according to the Anglo-American and Imperial system of units by exponent 4 according to NIST: 1 ft4 = 8,630 975 m4.",2,ft⁴,"8,630 975 x 10⁻³ m⁴"
-1672,nan,N28,cubic decimetre per kilogram,"0,001 fold of the power of the SI base unit meter by exponent 3 divided by the SI based unit kilogram.",1M,dm³/kg,10⁻³ m³ x kg⁻¹
-1673,nan,N29,cubic foot per pound,Power of the unit foot according to the Anglo-American and Imperial system of units by exponent 3 divided by the unit avoirdupois pound according to the avoirdupois unit system.,2.0,ft³/lb,"6,242 796 x 10⁻² m³/kg"
-1674,nan,N3,print point,nan,3.5,nan,"0,013 8 in (approx)"
-1675,nan,N30,cubic inch per pound,Power of the unit inch according to the Anglo-American and Imperial system of units by exponent 3 divided by the avoirdupois pound according to the avoirdupois unit system .,2.0,in³/lb,"3,612 728 x 10⁻⁵ m³/kg"
-1676,nan,N31,kilonewton per metre,1000-fold of the derived SI unit newton divided by the SI base unit metre.,1M,kN/m,10³ N/m
-1677,nan,N32,poundal per inch,Non SI-conforming unit of the surface tension according to the Imperial unit system as quotient poundal by inch.,2.0,pdl/in,"5,443 110 N/m"
-1678,nan,N33,pound-force per yard,Unit of force per unit length based on the Anglo-American system of units.,2.0,lbf/yd,"4,864 635 N/m"
-1679,nan,N34,poundal second per square foot,Non SI-conforming unit of viscosity.,2.0,(pdl/ft²)·s,"1,488 164 Pa x s"
-1680,nan,N35,poise per pascal,CGS (Centimetre-Gram-Second system) unit poise divided by the derived SI unit pascal.,2,P/Pa,"0,1 s"
-1681,nan,N36,newton second per square metre,Unit of the dynamic viscosity as a product of unit of the pressure (newton by square metre) multiplied with the SI base unit second.,1S,(N/m²)·s,Pa x s
-1682,nan,N37,kilogram per metre second,Unit of the dynamic viscosity as a quotient SI base unit kilogram divided by the SI base unit metre and by the SI base unit second.,1.0,kg/(m·s),Pa x s
-1683,nan,N38,kilogram per metre minute,Unit of the dynamic viscosity as a quotient SI base unit kilogram divided by the SI base unit metre and by the unit minute.,1.0,kg/(m·min),"1,666 67 × 10⁻² Pa x s"
-1684,nan,N39,kilogram per metre day,Unit of the dynamic viscosity as a quotient SI base unit kilogram divided by the SI base unit metre and by the unit day.,1M,kg/(m·d),"1,157 41 × 10⁻⁵ Pa x s"
-1685,nan,N40,kilogram per metre hour,Unit of the dynamic viscosity as a quotient SI base unit kilogram divided by the SI base unit metre and by the unit hour.,1M,kg/(m·h),"2,777 78 × 10⁻⁴ Pa x s"
-1686,nan,N41,gram per centimetre second,"Unit of the dynamic viscosity as a quotient of the 0,001-fold of the SI base unit kilogram divided by the 0,01-fold of the SI base unit metre and SI base unit second.",1M,g/(cm·s),"0,1 Pa x s"
-1687,nan,N42,poundal second per square inch,Non SI-conforming unit of dynamic viscosity according to the Imperial system of units as product unit of the pressure (poundal by square inch) multiplied by the SI base unit second.,2.0,(pdl/in²)·s,"2,142 957 x 10² Pa x s"
-1688,nan,N43,pound per foot minute,Unit of the dynamic viscosity according to the Anglo-American unit system.,2.0,lb/(ft·min),"2,480 273 x 10⁻²  Pa x s"
-1689,nan,N44,pound per foot day,Unit of the dynamic viscosity according to the Anglo-American unit system.,2.0,lb/(ft·d),"1,722 412 x 10⁻⁵ Pa x s"
-1690,nan,N45,cubic metre per second pascal,Power of the SI base unit meter by exponent 3 divided by the product of the SI base unit second and the derived SI base unit pascal.,1S,(m³/s)/Pa,kg⁻¹ x m⁴ x s
-1691,nan,N46,foot poundal,Unit of the work (force-path).,2,ft·pdl,"4,214 011 x 10⁻² J"
-1692,nan,N47,inch poundal,Unit of work (force multiplied by path) according to the Imperial system of units as a product unit inch multiplied by poundal.,2.0,in·pdl,"3,511 677 x 10⁻³ J"
-1693,nan,N48,watt per square centimetre,"Derived SI unit watt divided by the power of the 0,01-fold the SI base unit metre by exponent 2.",2.0,W/cm²,10⁴ W/m²
-1694,nan,N49,watt per square inch,Derived SI unit watt divided by the power of the unit inch according to the Anglo-American and Imperial system of units by exponent 2.,2.0,W/in²,"1,550 003 x 10³ W/m²"
-1695,nan,N50,British thermal unit (international table) per square foot hour,Unit of the surface heat flux according to the Imperial system of units.,2.0,BtuIT/(ft²·h),"3,154 591 W/m²"
-1696,nan,N51,British thermal unit (thermochemical) per square foot hour,Unit of the surface heat flux according to the Imperial system of units.,2.0,Btuth/(ft²·h),"3,152 481 W/m²"
-1697,nan,N52,British thermal unit (thermochemical) per square foot minute,Unit of the surface heat flux according to the Imperial system of units.,2.0,Btuth/(ft²·min) ,"1,891 489 x 10² W/m²"
-1698,nan,N53,British thermal unit (international table) per square foot second,Unit of the surface heat flux according to the Imperial system of units.,2.0,BtuIT/(ft²·s),"1,135 653 x 10⁴ W/m²"
-1699,nan,N54,British thermal unit (thermochemical) per square foot second,Unit of the surface heat flux according to the Imperial system of units.,2.0,Btuth/(ft²·s),"1,134 893 x 10⁴ W/m²"
-1700,nan,N55,British thermal unit (international table) per square inch second,Unit of the surface heat flux according to the Imperial system of units.,2.0,BtuIT/(in²·s),"1,634 246 x 10⁶ W/m²"
-1701,nan,N56,calorie (thermochemical) per square centimetre minute,Unit of the surface heat flux according to the Imperial system of units.,2.0,calth/(cm²·min),"6,973 333 x 10² W/m²"
-1702,nan,N57,calorie (thermochemical) per square centimetre second,Unit of the surface heat flux according to the Imperial system of units.,2.0,calth/(cm²·s),"4,184 x 10⁴ W/m²"
-1703,nan,N58,British thermal unit (international table) per cubic foot,Unit of the energy density according to the Imperial system of units.,2.0,BtuIT/ft³,"3,725 895 x10⁴ J/m³"
-1704,nan,N59,British thermal unit (thermochemical) per cubic foot,Unit of the energy density according to the Imperial system of units.,2.0,Btuth/ft³,"3,723 403 x10⁴ J/m³"
-1705,nan,N60,British thermal unit (international table) per degree Fahrenheit,Unit of the heat capacity according to the Imperial system of units.,2.0,BtuIT/ºF,"1,899 101 x 10³ J/K"
-1706,nan,N61,British thermal unit (thermochemical) per degree Fahrenheit,Unit of the heat capacity according to the Imperial system of units.,2.0,Btuth/ºF,"1,897 830 x 10³ J/K"
-1707,nan,N62,British thermal unit (international table) per degree Rankine,Unit of the heat capacity according to the Imperial system of units.,2.0,BtuIT/ºR,"1,899 101 x 10³ J/K"
-1708,nan,N63,British thermal unit (thermochemical) per degree Rankine,Unit of the heat capacity according to the Imperial system of units.,2.0,Btuth/ºR,"1,897 830 x 10³ J/K"
-1709,nan,N64,British thermal unit (thermochemical) per pound degree Rankine,Unit of the heat capacity (British thermal unit according to the international table according to the Rankine degree) according to the Imperial system of units divided by the unit avoirdupois pound according to the avoirdupois system of units.,2,(Btuth/°R)/lb,"4,184 x 10³ J/(kg x K)"
-1710,nan,N65,kilocalorie (international table) per gram kelvin,"Unit of the mass-related heat capacity as quotient 1000-fold of the calorie (international table) divided by the product of the 0,001-fold of the SI base units kilogram and kelvin.",2,(kcalIT/K)/g,"4,186 8 x 10⁶ J/(kg x K)"
-1711,nan,N66,British thermal unit (39 ºF),Unit of heat energy according to the Imperial system of units in a reference temperature of 39 °F.,2,Btu (39 ºF) ,"1,059 67  x 10³ J"
-1712,nan,N67,British thermal unit (59 ºF),Unit of heat energy according to the Imperial system of units in a reference temperature of 59 °F.,2,Btu (59 ºF),"1,054 80  x 10³ J"
-1713,nan,N68,British thermal unit (60 ºF),Unit of head energy according to the Imperial system of units at a reference temperature of 60 °F.,2,Btu (60 ºF) ,"1,054 68  x 10³ J"
-1714,nan,N69,calorie (20 ºC),"Unit for quantity of heat, which is to be required for 1 g air free water at a constant pressure from 101,325 kPa, to warm up the pressure of standard atmosphere at sea level, from 19,5 °C on 20,5 °C.",2,cal₂₀,"4,181 90"
-1715,nan,N70,quad (1015 BtuIT),Unit of heat energy according to the imperial system of units.,2,quad,"1,055 056 × 10¹⁸ J"
-1716,nan,N71,therm (EC),"Unit of heat energy in commercial use, within the EU defined: 1 thm (EC) = 100 000 BtuIT.",2,thm (EC),"1,055 06 × 10⁸ J"
-1717,nan,N72,therm (U.S.),Unit of heat energy in commercial use.,2,thm (US),"1,054 804 × 10⁸ J"
-1718,nan,N73,British thermal unit (thermochemical) per pound,Unit of the heat energy according to the Imperial system of units divided the unit avoirdupois pound according to the avoirdupois system of units.,2,Btuth/lb,"2,324 444 x 10³ J/kg"
-1719,nan,N74,British thermal unit (international table) per hour square foot degree Fahrenheit,Unit of the heat transition coefficient according to the Imperial system of units.,2,BtuIT/(h·ft²·ºF),"5,678 263 W/(m² x K)"
-1720,nan,N75,British thermal unit (thermochemical) per hour square foot degree Fahrenheit,Unit of the heat transition coefficient according to the imperial system of units.,2,Btuth/(h·ft²·ºF),"5,674 466 W/(m² x K)"
-1721,nan,N76,British thermal unit (international table) per second square foot degree Fahrenheit,Unit of the heat transition coefficient according to the imperial system of units.,2,BtuIT/(s·ft²·ºF),"2,044 175 x 10⁴ W/(m² x K)"
-1722,nan,N77,British thermal unit (thermochemical) per second square foot degree Fahrenheit,Unit of the heat transition coefficient according to the imperial system of units.,2,Btuth/(s·ft²·ºF) ,"2,042 808 x 10⁴ W/(m² x K)"
-1723,nan,N78,kilowatt per square metre kelvin,1000-fold of the derived SI unit watt divided by the product of the power of the SI base unit metre by exponent 2 and the SI base unit kelvin.,1M,kW/(m²·K),10³ W/(m² x K)
-1724,nan,N79,kelvin per pascal,SI base unit kelvin divided by the derived SI unit pascal.,1S,K/Pa,kg⁻¹ x m x s² x K
-1725,nan,N80,watt per metre degree Celsius,Derived SI unit watt divided by the product of the SI base unit metre and the unit for temperature degree Celsius.,1M,W/(m·°C),W/(m x K)
-1726,nan,N81,kilowatt per metre kelvin,1000-fold of the derived SI unit watt divided by the product of the SI base unit metre and the SI base unit kelvin.,1M,kW/(m·K),10³ W/(m x K)
-1727,nan,N82,kilowatt per metre degree Celsius,1000-fold of the derived SI unit watt divided by the product of the SI base unit metre and the unit for temperature degree Celsius.,1M,kW/(m·°C),10³ W/(m x K)
-1728,nan,N83,metre per degree Celcius metre,SI base unit metre divided by the product of the unit degree Celsius and the SI base unit metre.,2.0,m/(°C·m),K⁻¹
-1729,nan,N84,degree Fahrenheit hour per British thermal unit (international table),Non SI-conforming unit of the thermal resistance according to the Imperial system of units.,2.0,ºF/(BtuIT/h),"1,895 634 K/W"
-1730,nan,N85,degree Fahrenheit hour per British thermal unit (thermochemical),Non SI-conforming unit of the thermal resistance according to the Imperial system of units.,2.0,ºF/(Btuth/h),"1,896 903 K/W"
-1731,nan,N86,degree Fahrenheit second per British thermal unit (international table),Non SI-conforming unit of the thermal resistance according to the Imperial system of units.,2.0,ºF/(BtuIT/s),"5,265 651 x 10⁻⁴ K/W"
-1732,nan,N87,degree Fahrenheit second per British thermal unit (thermochemical),Non SI-conforming unit of the thermal resistance according to the Imperial system of units.,2.0,ºF/(Btuth/s),"5,269 175 x 10⁻⁴ K/W"
-1733,nan,N88,degree Fahrenheit hour square foot per British thermal unit (international table) inch,Unit of specific thermal resistance according to the Imperial system of units.,2.0,ºF·h·ft²/(BtuIT·in),"6,933 472 K x m/W"
-1734,nan,N89,degree Fahrenheit hour square foot per British thermal unit (thermochemical) inch,Unit of specific thermal resistance according to the Imperial system of units.,2.0,ºF·h·ft²/(Btuth·in),"6,938 112 K x m/W"
-1735,nan,N90,kilofarad,1000-fold of the derived SI unit farad.,1M,kF,10³ F
-1736,nan,N91,reciprocal joule,Reciprocal of the derived SI unit joule.,1.0,1/J,1/J
-1737,nan,N92,picosiemens,"0,000 000 000 001-fold of the derived SI unit siemens.",1M,pS,10⁻¹² S
-1738,nan,N93,ampere per pascal,SI base unit ampere divided by the derived SI unit pascal.,1M,A/Pa,kg⁻¹ x m x s² x A
-1739,nan,N94,franklin,"CGS (Centimetre-Gram-Second system) unit of the electrical charge, where the charge amounts to exactly 1 Fr where the force of 1 dyn on an equal load is performed at a distance of 1 cm.",2.0,Fr,"3,335 641 x 10⁻¹⁰ C"
-1740,nan,N95,ampere minute,A unit of electric charge defining the amount of charge accumulated by a steady flow of one ampere for one minute..,1M,A·min,60 C
-1741,nan,N96,biot,CGS (Centimetre-Gram-Second system) unit of the electric power which is defined by a force of 2 dyn per cm between two parallel conductors of infinite length with negligible cross-section in the distance of 1 cm.,2.0,Bi,10¹ A
-1742,nan,N97,gilbert,"CGS (Centimetre-Gram-Second system) unit of the magnetomotive force, which is defined by the work to increase the magnetic potential of a positive common pol with 1 erg.",2.0,Gi,"7,957 747 x 10⁻¹ A"
-1743,nan,N98,volt per pascal,Derived SI unit volt divided by the derived SI unit pascal.,1M,V/Pa,m³ x s⁻¹ x A⁻¹
-1744,nan,N99,picovolt,"0,000 000 000 001-fold of the derived SI unit volt.",1M,pV,10⁻¹² V
-1745,nan,NA,milligram per kilogram,nan,1S,mg/kg,10⁻⁶  1
-1746,nan,NAR,number of articles,A unit of count defining the number of articles (article: item).,3.7,nan,nan
-1747,X,NB,barge,nan,3.4,nan,nan
-1748,X,NBB,number of bobbins,nan,3.7,nan,nan
-1749,X,NC,car,nan,3.5,nan,nan
-1750,nan,NCL,number of cells,"A unit of count defining the number of cells (cell: an enclosed or circumscribed space, cavity, or volume).",3.7,nan,nan
-1751,X,ND,net barrel,nan,3.1,nan,nan
-1752,X,NE,net litre,nan,3.1,nan,nan
-1753,nan,NEW,newton,nan,1,N,(kg x m)/s²
-1754,nan,NF,message,A unit of count defining the number of messages.,3.9,nan,nan
-1755,X,NG,net gallon (us),nan,3.1,nan,nan
-1756,X,NH,message hour,nan,3.5,nan,nan
-1757,X,NI,net imperial gallon,nan,3.1,nan,nan
-1758,nan,NIL,nil,A unit of count defining the number of instances of nothing.,3.8,(),nan
-1759,nan,NIU,number of international units,A unit of count defining the number of international units.,3.7,nan,nan
-1760,X,NJ,number of screens,nan,3.7,nan,nan
-1761,nan,NL,load,A unit of volume defining the number of loads (load: a quantity of items carried or processed at one time).,3.4,nan,nan
-1762,¦,NM3,Normalised cubic metre,Normalised cubic metre (temperature 0°C and pressure 1013.25 millibars ),2,nan,m3
-1763,nan,NMI,nautical mile,nan,1,n mile,1 852 m
-1764,nan,NMP,number of packs,A unit of count defining the number of packs (pack: a collection of objects packaged together).,3.7,nan,nan
-1765,X,NN,train,nan,3.5,nan,nan
-1766,X,NPL,number of parcels,nan,3.7,nan,nan
-1767,D,NPR,number of pairs,A unit of count defining the number of pairs (pair: item described by two's).,3.7,nan,use pair
-1768,nan,NPT,number of parts,A unit of count defining the number of parts (part: component of a larger entity).,3.7,nan,nan
-1769,D,NQ,mho,nan,2,nan,S
-1770,D,NR,micromho,nan,2,nan,10⁻⁶ S
-1771,X,NRL,number of rolls,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.7,nan,nan
-1772,nan,NT,net ton,"A unit of mass equal to 2000 pounds, see ton (US).  Refer International Convention on tonnage measurement of Ships.",3.4,nan,nan
-1773,D,NTT,net register ton,"A unit of mass equal to the total cubic footage after deductions, where 1 register ton is equal to 100 cubic feet. Refer International Convention on tonnage measurement of Ships.",3.4,nan,nan
-1774,nan,NU,newton metre,nan,1,N·m,N x m
-1775,X,NV,vehicle,nan,3.4,nan,nan
-1776,nan,NX,part per thousand,"A unit of proportion equal to 10⁻³. ,Synonym: per mille",3.7,‰,1 x 10⁻³
-1777,X,NY,pound per air dry metric ton,nan,3.5,nan,nan
-1778,nan,OA,panel,"A unit of count defining the number of panels (panel: a distinct, usually rectangular, section of a surface).",3.9,nan,nan
-1779,nan,ODE,ozone depletion equivalent,"A unit of mass defining the ozone depletion potential in kilograms of a product relative to the calculated depletion for the reference substance, Trichlorofluoromethane (CFC-11).",3.1,nan,nan
-1780,nan,ODG,ODS Grams,"A unit of measure calculated by multiplying the mass of the substance in grams and the ozone-depleting potential for the substance.,",3.1,nan,nan
-1781,nan,ODK,ODS Kilograms,A unit of measure calculated by multiplying the mass of the substance in kilograms and the ozone-depleting potential for the substance.,3.1,nan,nan
-1782,nan,ODM,ODS Milligrams,A unit of measure calculated by multiplying the mass of the substance in milligrams and the ozone-depleting potential for the substance.,3.1,nan,nan
-1783,nan,OHM,ohm,nan,1,Ω,Ω
-1784,nan,ON,ounce per square yard,nan,2,oz/yd²,"3,390 575 x 10⁻² kg/m²"
-1785,nan,ONZ,ounce (avoirdupois),nan,2,oz,"2,834 952 x 10⁻² kg"
-1786,X,OP,two pack,nan,3.2,nan,nan
-1787,nan,OPM,oscillations per minute,The number of oscillations per minute.,2,o/min,1.667 x 10-2 /s
-1788,nan,OT,overtime hour,A unit of time defining the number of overtime hours.,3.1,nan,nan
-1789,D,OZ,ounce av,A unit of measure equal to 1/16 of a pound or about 28.3495 grams (av = avoirdupois). Use ounce (common code ONZ).,3.1,nan,nan
-1790,nan,OZA,fluid ounce (US),nan,2,fl oz (US),"2,957 353 x 10⁻⁵ m³"
-1791,nan,OZI,fluid ounce (UK),nan,2,fl oz (UK),"2,841 306 x 10⁻⁵ m³"
-1792,X,P0,page - electronic,nan,3.9,nan,nan
-1793,nan,P1,percent,A unit of proportion equal to 0.01.,3.7,% or pct,1 x 10⁻²
-1794,nan,P10,coulomb per metre,Derived SI unit coulomb divided by the SI base unit metre.,1.0,C/m,m⁻¹ x s x A
-1795,nan,P11,kiloweber,1000 fold of the derived SI unit weber.,1M,kWb,10³ Wb
-1796,nan,P12,gamma,Unit of magnetic flow density.,2.0,γ,10⁻⁹ T
-1797,nan,P13,kilotesla,1000-fold of the derived SI unit tesla.,1M,kT,10³ T
-1798,nan,P14,joule per second,Quotient of the derived SI unit joule divided by the SI base unit second.,1.0,J/s,W
-1799,nan,P15,joule per minute,Quotient from the derived SI unit joule divided by the unit minute.,1M,J/min,"1,666 67 × 10⁻² W"
-1800,nan,P16,joule per hour,Quotient from the derived SI unit joule divided by the unit hour.,1M,J/h,"2,777 78 × 10⁻⁴ W"
-1801,nan,P17,joule per day,Quotient from the derived SI unit joule divided by the unit day.,1M,J/d,"1,157 41 × 10⁻⁵ W"
-1802,nan,P18,kilojoule per second,Quotient from the 1000-fold of the derived SI unit joule divided by the SI base unit second.,1M,kJ/s,10³ W
-1803,nan,P19,kilojoule per minute,Quotient from the 1000-fold of the derived SI unit joule divided by the unit minute.,1M,kJ/min,"1,666 67 × 10 W"
-1804,nan,P2,pound per foot,nan,2,lb/ft,"1,488 164 kg/m"
-1805,nan,P20,kilojoule per hour,Quotient from the 1000-fold of the derived SI unit joule divided by the unit hour.,1M,kJ/h,"2,777 78 x 10⁻¹ W"
-1806,nan,P21,kilojoule per day,Quotient from the 1000-fold of the derived SI unit joule divided by the unit day.,1M,kJ/d,"1,157 41 x 10⁻² W"
-1807,nan,P22,nanoohm,"0,000 000 001-fold of the derived SI unit ohm.",1M,nΩ,10⁻⁹ Ω
-1808,nan,P23,ohm circular-mil per foot,Unit of resistivity.,2.0,Ω·cmil/ft ,"1,662 426 x 10⁻⁹ Ω x m"
-1809,nan,P24,kilohenry,1000-fold of the derived SI unit henry.,1M,kH,10³ H
-1810,nan,P25,lumen per square foot,Derived SI unit lumen divided by the power of the unit foot according to the Anglo-American and Imperial system of units by exponent 2.,2.0,lm/ft²,"1,076 391 x 10¹ cd x sr / m²"
-1811,nan,P26,phot,"CGS (Centimetre-Gram-Second system) unit of luminance, defined as lumen by square centimetre.",2.0,ph,10⁴ cd x sr / m²
-1812,nan,P27,footcandle,"Non SI conform traditional unit, defined as density of light which impinges on a surface which has a distance of one foot from a light source, which shines with an intensity of an international candle.",2.0,ftc,"1,076 391 x 10¹ cd x sr / m²"
-1813,nan,P28,candela per square inch,SI base unit candela divided by the power of unit inch according to the Anglo-American and Imperial system of units by exponent 2.,2.0,cd/in²,"1,550 003 x 10³ cd/m²"
-1814,nan,P29,footlambert,"Unit of the luminance according to the Anglo-American system of units, defined as emitted or reflected luminance of a lm/ft².",2.0,ftL,"3,426 259 cd/m²"
-1815,X,P3,three pack,nan,3.2,nan,nan
-1816,nan,P30,lambert,"CGS (Centimetre-Gram-Second system) unit of luminance, defined as the emitted or reflected luminance by one lumen per square centimetre.",2.0,Lb,"3,183 099 x 10³ cd/m²"
-1817,nan,P31,stilb,"CGS (Centimetre-Gram-Second system) unit of luminance, defined as emitted or reflected luminance by one lumen per square centimetre.",2.0,sb,10⁴ cd/m²
-1818,nan,P32,candela per square foot,Base unit SI candela divided by the power of the unit foot according to the Anglo-American and Imperial system of units by exponent 2.,2.0,cd/ft²,"1,076 391 x 10 cd/m²"
-1819,nan,P33,kilocandela,1000-fold of the SI base unit candela.,1M,kcd,10³ cd
-1820,nan,P34,millicandela,"0,001-fold of the SI base unit candela.",1M,mcd,10⁻³ cd
-1821,nan,P35,Hefner-Kerze,"Obsolete, non-legal unit of the power in Germany relating to DIN 1301-3:1979: 1 HK = 0,903 cd.",2.0,HK,"0,903 cd"
-1822,nan,P36,international candle,"Obsolete, non-legal unit of the power in Germany relating to DIN 1301-3:1979: 1 HK = 1,019 cd.",2.0,IK,"1,019 cd"
-1823,nan,P37,British thermal unit (international table) per square foot,Unit of the areal-related energy transmission according to the Imperial system of units.,2.0,BtuIT/ft²,"1,135 653 x 10⁴ J/m²"
-1824,nan,P38,British thermal unit (thermochemical) per square foot,Unit of the areal-related energy transmission according to the Imperial system of units.,2.0,Btuth/ft²,"1,134 893 x 10⁴ J/m²"
-1825,nan,P39,calorie (thermochemical) per square centimetre,Unit of the areal-related energy transmission according to the Imperial system of units.,2.0,calth/cm²,"4,184 x 10⁴ J/m²"
-1826,X,P4,four pack,nan,3.2,nan,nan
-1827,nan,P40,langley,CGS (Centimetre-Gram-Second system) unit of the areal-related energy transmission (as a measure of the incident quantity of heat of solar radiation on the earth's surface).,2.0,Ly,"4,184 x 10⁴ J/m²"
-1828,nan,P41,decade (logarithmic),"1 Dec := log2 10 ˜ 3,32 according to the logarithm for frequency range between f1 and f2, when f2/f1 = 10.",2,dec,dec
-1829,nan,P42,pascal squared second,Unit of the set as a product of the power of derived SI unit pascal with exponent 2 and the SI base unit second.,1.0,Pa²·s,m⁻² x kg² x s⁻³
-1830,nan,P43,bel per metre,Unit bel divided by the SI base unit metre.,1M,B/m,B/m
-1831,nan,P44,pound mole,Non SI-conforming unit of quantity of a substance relating that one pound mole of a chemical composition corresponds to the same number of pounds as the molecular weight of one molecule of this composition in atomic mass units.,2.0,lbmol,"453,592 4 mol"
-1832,nan,P45,pound mole per second,Non SI-conforming unit of the power of the amount of substance non-SI compliant unit of the molar flux relating that a pound mole of a chemical composition the same number of pound corresponds like the molecular weight of a molecule of this composition in atomic mass units.,2.0,lbmol/s,"4,535 924 x 10² mol/s"
-1833,nan,P46,pound mole per minute,Non SI-conforming unit of the power of the amount of substance non-SI compliant unit of the molar flux relating that a pound mole of a chemical composition the same number of pound corresponds like the molecular weight of a molecule of this composition in atomic mass units.,2.0,lbmol/h,"7,559 873 mol/s"
-1834,nan,P47,kilomole per kilogram,1000-fold of the SI base unit mol divided by the SI base unit kilogram.,1M,kmol/kg,10³ mol/kg
-1835,nan,P48,pound mole per pound,Non SI-conforming unit of the material molar flux divided by the avoirdupois pound for mass according to the avoirdupois unit system.,2.0,lbmol/lb,10³ mol/kg
-1836,nan,P49,newton square metre per ampere,Product of the derived SI unit newton and the power of SI base unit metre with exponent 2 divided by the SI base unit ampere.,1S,N·m²/A,m³ x kg x s⁻²  x A⁻¹
-1837,nan,P5,five pack,A unit of count defining the number of five-packs (five-pack: set of five items packaged together).,3.2,nan,nan
-1838,nan,P50,weber metre,Product of the derived SI unit weber and SI base unit metre.,1S,Wb·m,m³ x kg x s⁻²  x A⁻¹
-1839,nan,P51,mol per kilogram pascal,SI base unit mol divided by the product of the SI base unit kilogram and the derived SI unit pascal.,1S,(mol/kg)/Pa,m x kg⁻² x s² x mol
-1840,nan,P52,mol per cubic metre pascal,SI base unit mol divided by the product of the power from the SI base unit metre with exponent 3 and the derived SI unit pascal.,1S,(mol/m³)/Pa,m⁻² x kg⁻¹ x s² x mol
-1841,nan,P53,unit pole,CGS (Centimetre-Gram-Second system) unit for magnetic flux of a magnetic pole (according to the interaction of identical poles of 1 dyn at a distance of a cm).,2.0,unit pole ,"1,256 637 x 10⁻⁷ Wb"
-1842,nan,P54,milligray per second,"0,001-fold of the derived SI unit gray divided by the SI base unit second.",1M,mGy/s,10⁻³ Gy/s
-1843,nan,P55,microgray per second,"0,000 001-fold of the derived SI unit gray divided by the SI base unit second.",1M,µGy/s,10⁻⁶ Gy/s
-1844,nan,P56,nanogray per second,"0,000 000 001-fold of the derived SI unit gray divided by the SI base unit second.",1M,nGy/s,10⁻⁹ Gy/s
-1845,nan,P57,gray per minute,SI derived unit gray divided by the unit minute.,1M,Gy/min,"1,666 67 × 10⁻² Gy/s"
-1846,nan,P58,milligray per minute,"0,001-fold of the derived SI unit gray divided by the unit minute.",1M,mGy/min,"1,666 67 × 10⁻⁵ Gy/s"
-1847,nan,P59,microgray per minute,"0,000 001-fold of the derived SI unit gray divided by the unit minute.",1M,µGy/min,"1,666 67 × 10⁻⁸ Gy/s"
-1848,X,P6,six pack,nan,3.2,nan,nan
-1849,nan,P60,nanogray per minute,"0,000 000 001-fold of the derived SI unit gray divided by the unit minute.",1M,nGy/min,"1,666 67 × 10⁻¹¹ Gy/s"
-1850,nan,P61,gray per hour,SI derived unit gray divided by the unit hour.,1M,Gy/h,"2,777 78 × 10⁻⁴ Gy/s"
-1851,nan,P62,milligray per hour,"0,001-fold of the derived SI unit gray divided by the unit hour.",1M,mGy/h,"2,777 78 × 10⁻⁷ Gy/s"
-1852,nan,P63,microgray per hour,"0,000 001-fold of the derived SI unit gray divided by the unit hour.",1M,µGy/h,"2,777 78 × 10⁻¹⁰ Gy/s"
-1853,nan,P64,nanogray per hour,"0,000 000 001-fold of the derived SI unit gray divided by the unit hour.",1M,nGy/h,"2,777 78 × 10⁻¹³ Gy/s"
-1854,nan,P65,sievert per second,Derived SI unit sievert divided by the SI base unit second.,2.0,Sv/s,Sv/s
-1855,nan,P66,millisievert per second,"0,001-fold of the derived SI unit sievert divided by the SI base unit second.",2.0,mSv/s,10⁻³ Sv/s
-1856,nan,P67,microsievert per second,"0,000 001-fold of the derived SI unit sievert divided by the SI base unit second.",2.0,µSv/s,10⁻⁶ Sv/s
-1857,nan,P68,nanosievert per second,"0,000 000 001-fold of the derived SI unit sievert divided by the SI base unit second.",2.0,nSv/s,10⁻⁹ Sv/s
-1858,nan,P69,rem per second,"Unit for the equivalent tin rate relating to DIN 1301-3:1979: 1 rem/s = 0,01 J/(kg·s) = 1 Sv/s.",2.0,rem/s,10⁻² Sv/s
-1859,X,P7,seven pack,nan,3.2,nan,nan
-1860,nan,P70,sievert per hour,Derived SI unit sievert divided by the unit hour.,2.0,Sv/h,"2,777 78 × 10⁻⁴ Sv/s"
-1861,nan,P71,millisievert per hour,"0,001-fold of the derived SI unit sievert divided by the unit hour.",2.0,mSv/h,"0,277 777 778 × 10⁻⁷ Sv/s"
-1862,nan,P72,microsievert per hour,"0,000 001-fold of the derived SI unit sievert divided by the unit hour.",2.0,µSv/h,"0,277 777 778 × 10⁻¹⁰ Sv/s"
-1863,nan,P73,nanosievert per hour,"0,000 000 001-fold of the derived SI unit sievert divided by the unit hour.",2.0,nSv/h,"0,277 777 778 × 10⁻¹³ Sv/s"
-1864,nan,P74,sievert per minute,Derived SI unit sievert divided by the unit minute.,2.0,Sv/min,"0,016 666 Sv/s"
-1865,nan,P75,millisievert per minute,"0,001-fold of the derived SI unit sievert divided by the unit minute.",2.0,mSv/min,"1,666 666 667 × 10⁻⁵ Sv/s"
-1866,nan,P76,microsievert per minute,"0,000 001-fold of the derived SI unit sievert divided by the unit minute.",2.0,µSv/min,"1,666 666 667 × 10⁻⁸ Sv/s"
-1867,nan,P77,nanosievert per minute,"0,000 000 001-fold of the derived SI unit sievert divided by the unit minute.",2.0,nSv/min,"1,666 666 667 × 10⁻¹¹ Sv/s"
-1868,nan,P78,reciprocal square inch,Complement of the power of the unit inch according to the Anglo-American and Imperial system of units by exponent 2.,2.0,1/in²,"1,550 003 x 10³ m⁻²"
-1869,nan,P79,pascal square metre per kilogram,"Unit of the burst index as derived unit for pressure pascal related to the substance, represented as a quotient from the SI base unit kilogram divided by the power of the SI base unit metre by exponent 2.",1.0,Pa/(kg/m²),m/s²
-1870,X,P8,eight pack,nan,3.2,nan,nan
-1871,nan,P80,millipascal per metre,"0,001-fold of the derived SI unit pascal divided by the SI base unit metre.",1M,mPa/m,10⁻³ kg/(m² x s²)
-1872,nan,P81,kilopascal per metre,1000-fold of the derived SI unit pascal divided by the SI base unit metre.,1M,kPa/m,10³ kg/(m² x s²)
-1873,nan,P82,hectopascal per metre,100-fold of the derived SI unit pascal divided by the SI base unit metre.,1M,hPa/m,10² kg/(m² x s²)
-1874,nan,P83,standard atmosphere per metre,Outdated unit of the pressure divided by the SI base unit metre.,2.0,Atm/m,"1,013 25 x 10⁵ kg/(m² x s²)"
-1875,nan,P84,technical atmosphere per metre,Obsolete and non-legal unit of the pressure which is generated by a 10 metre water column divided by the SI base unit metre.,2.0,at/m,"9,806 65 x 10⁴  kg/(m² x s²)"
-1876,nan,P85,torr per metre,CGS (Centimetre-Gram-Second system) unit of the pressure divided by the SI base unit metre.,2.0,Torr/m,"1,333 224 x 10² kg/(m² x s²)"
-1877,nan,P86,psi per inch,Compound unit for pressure (pound-force according to the Anglo-American unit system divided by the power of the unit inch according to the Anglo-American and Imperial system of units with the exponent 2) divided by the unit inch according to the Anglo-American and Imperial system of units .,2.0,psi/in,"2,714 471 x 10⁵ kg/(m² x s²)"
-1878,nan,P87,cubic metre per second square metre,Unit of volume flow cubic meters by second related to the transmission surface in square metres.,1M,(m³/s)/m²,m/s
-1879,nan,P88,rhe,Non SI-conforming unit of fluidity of dynamic viscosity.,3.5,rhe,10 m x kg⁻¹ x s
-1880,nan,P89,pound-force foot per inch,Unit for length-related rotational moment according to the Anglo-American and Imperial system of units.,3.5,lbf·ft/in,"53,378 66 m x kg / s²"
-1881,X,P9,nine pack,nan,3.2,nan,nan
-1882,nan,P90,pound-force inch per inch,Unit for length-related rotational moment according to the Anglo-American and Imperial system of units.,3.5,lbf·in/in,"4,448 222 m x kg / s²"
-1883,nan,P91,perm (0 ºC),"Traditional unit for the ability of a material to allow the transition of the steam, defined at a temperature of 0 °C as steam transmittance, where the mass of one grain steam penetrates an area of one foot squared at a pressure from one inch mercury per hour.",3.5,perm (0 ºC) ,"5,721 35 x 10⁻¹¹ kg/(m² x Pa x s)"
-1884,nan,P92,perm (23 ºC),"Traditional unit for the ability of a material to allow the transition of the steam, defined at a temperature of 23 °C as steam transmittance at which the mass of one grain of steam penetrates an area of one square foot at a pressure of one inch mercury per hour.",3.5,perm (23 ºC) ,"5,745 25 x 10⁻¹¹ kg/(m² x Pa x s)"
-1885,nan,P93,byte per second,Unit byte divided by the SI base unit second.,3.6,byte/s,byte/s
-1886,nan,P94,kilobyte per second,1000-fold of the unit byte divided by the SI base unit second.,3.6,kbyte/s,10³ byte/s
-1887,nan,P95,megabyte per second,1 000 000-fold of the unit byte divided by the SI base unit second.,3.6,Mbyte/s,10⁶ byte/s
-1888,nan,P96,reciprocal volt,Reciprocal of the derived SI unit volt.,3.5,1/V,m⁻² x kg⁻¹ x s³ x A
-1889,nan,P97,reciprocal radian,Reciprocal of the unit radian.,3.5,1/rad,1/rad
-1890,nan,P98,pascal to the power sum of stoichiometric numbers,"Unit of the equilibrium constant on the basis of the pressure(ISO 80000-9:2009, 9-35.a).",3.5,PaΣνB,nan
-1891,nan,P99,mole per cubiv metre to the power sum of stoichiometric numbers,"Unit of the equilibrium constant on the basis of the concentration (ISO 80000-9:2009, 9-36.a).",3.5,(mol/m³)∑νB,nan
-1892,X,PA,packet,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-1893,nan,PAL,pascal,nan,1,Pa,Pa
-1894,X,PB,pair inch,nan,3.8,nan,nan
-1895,nan,PD,pad,A unit of count defining the number of pads (pad: block of paper sheets fastened together at one end).,3.9,nan,nan
-1896,X,PE,pound equivalent,nan,3.1,nan,nan
-1897,X,PF,pallet (lift),"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-1898,nan,PFL,proof litre,"A unit of volume equal to one litre of proof spirits, or the alcohol equivalent thereof. Used for measuring the strength of distilled alcoholic liquors, expressed as a percentage of the alcohol content of a standard mixture at a specific temperature.",3.1,nan,nan
-1899,X,PG,plate,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-1900,nan,PGL,proof gallon,"A unit of volume equal to one gallon of proof spirits, or the alcohol equivalent thereof. Used for measuring the strength of distilled alcoholic liquors, expressed as a percentage of the alcohol content of a standard mixture at a specific temperature.",3.1,nan,nan
-1901,nan,PI,pitch,A unit of count defining the number of characters that fit in a horizontal inch.,3.5,nan,nan
-1902,X,PK,pack,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).,Synonym: package",3.3,nan,nan
-1903,X,PL,pail,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-1904,nan,PLA,degree Plato,"A unit of proportion defining the sugar content of a product, especially in relation to beer.",3.5,°P,nan
-1905,X,PM,pound percentage,nan,3.1,nan,nan
-1906,X,PN,pound net,nan,3.1,nan,nan
-1907,nan,PO,pound per inch of length,nan,2,lb/in,"1,785 797 x 10¹ kg/m"
-1908,nan,PQ,page per inch,"A unit of quantity defining the degree of thickness of a bound publication, expressed as the number of pages per inch of thickness.",3.5,ppi,nan
-1909,nan,PR,pair,A unit of count defining the number of pairs (pair: item described by two's).,3.7,nan,2
-1910,nan,PS,pound-force per square inch,nan,2,lbf/in²,"6,894 757 x 10³ Pa"
-1911,D,PT,pint (US),Use liquid pint (common code PTL),2,pt (US),"4, 731 76 x 10⁻⁴ m³"
-1912,nan,PTD,dry pint (US),nan,2,dry pt (US),"5,506 105 x 10⁻⁴ m³"
-1913,nan,PTI,pint (UK),nan,2,pt (UK),"5, 682 61 x 10⁻⁴ m³"
-1914,nan,PTL,liquid pint (US),nan,2,liq pt (US),"4, 731 765 x 10⁻⁴ m³"
-1915,nan,PTN,portion,"A quantity of allowance of food allotted to, or enough for, one person.",3.5,PTN,nan
-1916,X,PU,tray / tray pack,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-1917,X,PV,half pint (US),nan,3.8,nan,nan
-1918,X,PW,pound per inch of width,nan,3.1,nan,nan
-1919,X,PY,peck dry (US),nan,3.5,nan,nan
-1920,X,PZ,peck dry (UK),nan,3.5,nan,nan
-1921,nan,Q10,joule per tesla,Unit of the magnetic dipole moment of the molecule as derived SI unit joule divided by the derived SI unit tesla.,3.5,J/T,m² x A
-1922,nan,Q11,erlang,Unit of the market value according to the feature of a single feature as a statistical measurement of the existing utilization.,3.6,E,1 E
-1923,nan,Q12,octet,Synonym for byte: 1 octet = 8 bit = 1 byte.,3.6,o,8 bit
-1924,nan,Q13,octet per second,Unit octet divided by the SI base unit second.,3.6,o/s,8 bit/s
-1925,nan,Q14,shannon,"Logarithmic unit for information equal to the content of decision of a sentence of two mutually exclusive events, expressed as a logarithm to base 2.",3.6,Sh,nan
-1926,nan,Q15,hartley,"Logarithmic unit for information equal to the content of decision of a sentence of ten mutually exclusive events, expressed as a logarithm to base 10.",3.6,Hart,nan
-1927,nan,Q16,natural unit of information,"Logarithmic unit for information equal to the content of decision of a sentence of ,718 281 828 459 mutually exclusive events, expressed as a logarithm to base Euler value e.",3.6,nat,nat
-1928,nan,Q17,shannon per second,"Time related logarithmic unit for information equal to the content of decision of a sentence of two mutually exclusive events, expressed as a logarithm to base 2.",3.6,Sh/s,Sh/s
-1929,nan,Q18,hartley per second,"Time related logarithmic unit for information equal to the content of decision of a sentence of ten mutually exclusive events, expressed as a logarithm to base 10.",3.6,Hart/s,Hart/s
-1930,nan,Q19,natural unit of information per second,"Time related logarithmic unit for information equal to the content of decision of a sentence of 2,718 281 828 459 mutually exclusive events, expressed as a logarithm to base of the Euler value e.",3.6,nat/s,nat/s
-1931,nan,Q20,second per kilogramm,"Unit of the Einstein transition probability for spontaneous or inducing emissions and absorption according to ISO 80000-7:2008, expressed as SI base unit second divided by the SI base unit kilogram.",3.5,s/kg,kg⁻¹ x s
-1932,nan,Q21,watt square metre,"Unit of the first radiation constants c1 = 2·p·h·c0², the value of which is 3,741 771 18·10?¹6-fold   that of the comparative value of the product of the derived SI unit watt multiplied with the power of the SI base unit metre with the exponent 2.",3.5,W·m²,m⁴ x kg x s⁻³
-1933,nan,Q22,second per radian cubic metre,Unit of the density of states as an expression of angular frequency as complement of the product of hertz and radiant and the power of SI base unit metre by exponent 3 .,3.5,1/(Hz·rad·m³),m⁻³ x s x rad⁻¹
-1934,nan,Q23,weber to the power minus one,"Complement of the derived SI unit weber as unit of the Josephson constant, which value is equal to the 384 597,891-fold of the reference value gigahertz divided by volt.",3.5,1/Wb,m⁻² x kg⁻¹ x s² x A
-1935,nan,Q24,reciprocal inch,Complement of the unit inch according to the Anglo-American and Imperial system of units.,3.5,1/in,"39,370 08 m⁻¹"
-1936,nan,Q25,dioptre,Unit used at the statement of relative refractive indexes of optical systems as complement of the focal length with correspondence to: 1 dpt = 1/m.,3.5,dpt,m⁻¹
-1937,nan,Q26,one per one,Value of the quotient from two physical units of the same kind as a numerator and denominator whereas the units are shortened mutually.,3.5,1/1,1/1
-1938,nan,Q27,newton metre per metre,Unit for length-related rotational moment as product of the derived SI unit newton and the SI base unit metre divided by the SI base unit metre.,3.5,N·m/m²,m x kg x s⁻²
-1939,nan,Q28,kilogram per square metre pascal second,Unit for the ability of a material to allow the transition of steam.,3.5,kg/(m²·Pa·s),kg/(m² x Pa x s)
-1940,nan,Q29,microgram per hectogram,Microgram per hectogram.,1S,µg/hg,10⁻8
-1941,nan,Q30,pH (potential of Hydrogen),The activity of the (solvated) hydrogen ion (a logarithmic measure used to state the acidity or alkalinity of a chemical solution).,2,pH,-log10(mol/l)
-1942,nan,Q31,kilojoule per gram,nan,1S,kJ/g,10⁶ J/kg
-1943,nan,Q32,femtolitre,nan,1S,fl,10-18 m3
-1944,nan,Q33,picolitre,nan,1S,pl,10-15 m3
-1945,nan,Q34,nanolitre,nan,1S,nl,10-12 m3
-1946,nan,Q35,megawatts per minute,A unit of power defining the total amount of bulk energy transferred or consumer per minute.,1M,MW/min,1.667 × 104 W/s
-1947,nan,Q36,square metre per cubic metre,A unit of the amount of surface area per unit volume of an object or collection of objects.,3.1,m2/m3,1 m2/m3
-1948,¦,Q37,Standard cubic metre per day,Standard cubic metre (temperature 15°C and pressure 1013.25 millibars ) per day,2.0,nan,1.15741 × 10-5 m3/s
-1949,¦,Q38,Standard cubic metre per hour,Standard cubic metre (temperature 15°C and pressure 1013.25 millibars ) per hour,2.0,nan,2.77778 × 10-4 m3/s
-1950,¦,Q39,Normalized cubic metre per day,Normalized cubic metre (temperature 0°C and pressure 1013.25 millibars ) per day,2.0,nan,1.15741 × 10-5 m3/s
-1951,¦,Q40,Normalized cubic metre per hour,Normalized cubic metre (temperature 0°C and pressure 1013.25 millibars ) per hour,2.0,nan,2.77778 × 10-4 m3/s
-1952,¦,Q41,Joule per normalised cubic metre,Joule per normalised cubic metre (temperature 0°C and pressure 1013.25 millibars).,2.0,nan,nan
-1953,¦,Q42,Joule per standard cubic metre,Joule per standard cubic metre (temperature 15°C and pressure 1013.25 millibars).,2.0,nan,nan
-1954,nan,Q3,meal,A unit of count defining the number of meals (meal: an amount of food to be eaten on a single occasion).,3.9,nan,nan
-1955,nan,QA,page - facsimile,A unit of count defining the number of facsimile pages.,3.5,nan,nan
-1956,nan,QAN,quarter (of a year),A unit of time defining the number of quarters (3 months).,3.8,nan,nan
-1957,nan,QB,page - hardcopy,"A unit of count defining the number of hardcopy pages (hardcopy page: a page rendered as printed or written output on paper, film, or other permanent medium).",3.5,nan,nan
-1958,X,QD,quarter dozen,nan,3.7,nan,3
-1959,X,QH,quarter hour,nan,3.8,nan,900 s
-1960,X,QK,quarter kilogram,nan,3.8,nan,nan
-1961,nan,QR,quire,"A unit of count for paper, expressed as the number of quires (quire: a number of paper sheets, typically 25).",3.5,qr,nan
-1962,D,QT,quart (US),Use liquid quart (common code QTL),2,qt (US),"0,946 352 9 x 10⁻³ m³"
-1963,nan,QTD,dry quart (US),nan,2,dry qt (US),"1,101 221 x 10⁻³ m³"
-1964,nan,QTI,quart (UK),nan,2,qt (UK),"1,136 522 5 x 10⁻³ m³"
-1965,nan,QTL,liquid quart (US),nan,2,liq qt (US),"9,463 529 x 10⁻⁴ m³"
-1966,nan,QTR,quarter (UK),"A traditional unit of weight equal to 1/4 hundredweight. In the United Kingdom, one quarter equals 28 pounds.",3.5,Qr (UK),"12,700 59 kg"
-1967,nan,R1,pica,A unit of count defining the number of picas. (pica: typographical length equal to 12 points or 4.22 mm (approx.)).,3.5,nan,"4,217 518 x 10⁻³ m"
-1968,X,R4,calorie,Use International Table (IT) calorie (common code D70),3.5,cal,"4,186 8 J"
-1969,nan,R9,thousand cubic metre,A unit of volume equal to one thousand cubic metres.,3.8,nan,10³m³
-1970,X,RA,rack,nan,3.3,nan,nan
-1971,X,RD,rod,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-1972,X,RG,ring,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-1973,nan,RH,running or operating hour,A unit of time defining the number of hours of operation.,3.1,nan,nan
-1974,X,RK,roll metric measure,nan,3.3,nan,nan
-1975,X,RL,reel,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-1976,nan,RM,ream,"A unit of count for paper, expressed as the number of reams (ream: a large quantity of paper sheets, typically 500).",3.5,nan,nan
-1977,X,RN,ream metric measure,nan,3.5,nan,nan
-1978,X,RO,roll,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-1979,nan,ROM,room,A unit of count defining the number of rooms.,3.9,nan,nan
-1980,nan,RP,pound per ream,"A unit of mass for paper, expressed as pounds per ream. (ream: a large quantity of paper, typically 500 sheets).",3.5,nan,nan
-1981,nan,RPM,revolutions per minute,Refer ISO/TC12 SI Guide,1,r/min,"1,67 x 10⁻²/s"
-1982,nan,RPS,revolutions per second,Refer ISO/TC12 SI Guide,1,r/s,1/s
-1983,X,RS,reset,nan,3.9,nan,nan
-1984,nan,RT,revenue ton mile,"A unit of information typically used for billing purposes, expressed as the number of revenue tons (revenue ton: either a metric ton or a cubic metres, whichever is the larger), moved over a distance of one mile.",3.4,nan,nan
-1985,X,RU,run,nan,3.9,nan,nan
-1986,nan,S3,square foot per second,Synonym: foot squared per second,2,ft²/s,"0,092 903 04 m²/s"
-1987,nan,S4,square metre per second,Synonym: metre squared per second (square metres/second US),1,m²/s,m²/s
-1988,X,S5,sixty fourths of an inch,nan,3.8,nan,nan
-1989,X,S6,session,nan,3.9,nan,nan
-1990,X,S7,storage unit,nan,3.9,nan,nan
-1991,X,S8,standard advertising unit,nan,3.9,nan,nan
-1992,X,SA,sack,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-1993,nan,SAN,half year (6 months),A unit of time defining the number of half years (6 months).,3.8,nan,nan
-1994,nan,SCO,score,A unit of count defining the number of units in multiples of 20.,3.7,nan,20
-1995,nan,SCR,scruple,nan,3.5,nan,"1,295 982 g"
-1996,X,SD,solid pound,nan,3.1,nan,nan
-1997,X,SE,section,nan,3.9,nan,nan
-1998,nan,SEC,second [unit of time],nan,1,s,s
-1999,nan,SET,set,A unit of count defining the number of sets (set: a number of objects grouped together).,3.2,nan,nan
-2000,nan,SG,segment,A unit of information equal to 64000 bytes.,3.9,nan,nan
-2001,D,SHT,shipping ton,A unit of mass defining the number of tons for shipping.,3.4,nan,nan
-2002,nan,SIE,siemens,nan,1,S,A/V
-2003,X,SK,split tank truck,nan,3.4,nan,nan
-2004,X,SL,slipsheet,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-2005,¦,SM3,Standard cubic metre,Standard cubic metre (temperature 15°C and pressure 1013.25 millibars ),2,nan,m3
-2006,nan,SMI,mile (statute mile),nan,2,mile,"1 609,344 m"
-2007,X,SN,square rod,nan,3.8,rd²,"25,292 9 m²"
-2008,X,SO,spool,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-2009,X,SP,shelf package,nan,3.9,nan,nan
-2010,nan,SQ,square,A unit of count defining the number of squares (square: rectangular shape).,3.9,nan,nan
-2011,nan,SQR,"square, roofing","A unit of count defining the number of squares of roofing materials, measured in multiples of 100 square feet.",3.1,nan,nan
-2012,nan,SR,strip,A unit of count defining the number of strips (strip: long narrow piece of an object).,3.9,nan,nan
-2013,X,SS,sheet metric measure,nan,3.3,nan,nan
-2014,X,SST,short standard (7200 matches),nan,3.5,nan,nan
-2015,X,ST,sheet,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-2016,nan,STC,stick,A unit of count defining the number of sticks (stick: slender and often cylindrical piece of a substance).,3.9,nan,nan
-2017,nan,STI,stone (UK),nan,2,st,"6,350 293 kg"
-2018,nan,STK,"stick, cigarette",A unit of count defining the number of cigarettes in the smallest unit for stock-taking and/or duty computation.,3.9,nan,nan
-2019,nan,STL,standard litre,"A unit of volume defining the number of litres of a product at a temperature of 15 degrees Celsius, especially in relation to hydrocarbon oils.",3.1,nan,nan
-2020,nan,STN,ton (US) or short ton (UK/US),Synonym: net ton (2000 lb),2,ton (US),"0,907184 7 x 10³ kg"
-2021,nan,STW,straw,A unit of count defining the number of straws (straw: a slender tube used for sucking up liquids).,3.9,nan,nan
-2022,X,SV,skid,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.9,nan,nan
-2023,nan,SW,skein,A unit of count defining the number of skeins (skein: a loosely-coiled bundle of yarn or thread).,3.9,nan,nan
-2024,nan,SX,shipment,A unit of count defining the number of shipments (shipment: an amount of goods shipped or transported).,3.4,nan,nan
-2025,nan,SYR,syringe,"A unit of count defining the number of syringes (syringe: a small device for pumping, spraying and/or injecting liquids through a small aperture).",3.9,nan,nan
-2026,nan,T0,telecommunication line in service,A unit of count defining the number of lines in service.,3.5,nan,nan
-2027,X,T1,thousand pound gross,nan,3.8,nan,nan
-2028,nan,T3,thousand piece,"A unit of count defining the number of pieces in multiples of 1000 (piece: a single item, article or exemplar).",3.8,nan,nan
-2029,X,T4,thousand bag,nan,3.8,nan,nan
-2030,X,T5,thousand casing,nan,3.8,nan,nan
-2031,X,T6,thousand gallon (US),nan,3.8,nan,"3,785 412 m³"
-2032,X,T7,thousand impression,nan,3.8,nan,nan
-2033,X,T8,thousand linear inch,nan,3.8,nan,nan
-2034,X,TA,tenth cubic foot,nan,3.8,nan,nan
-2035,nan,TAH,kiloampere hour (thousand ampere hour),nan,1M,kA·h,"3,6 x 10⁶ C"
-2036,nan,TAN,total acid number,A unit of chemistry defining the amount of potassium hydroxide (KOH) in milligrams that is needed to neutralize the acids in one gram of oil. It is an important quality measurement of crude oil.,3.5,TAN,mg KOH/g 
-2037,X,TC,truckload,nan,3.4,nan,nan
-2038,X,TD,therm,nan,3.8,nan,"10⁵ x  1 055,056 J"
-2039,X,TE,tote,nan,3.3,nan,nan
-2040,X,TF,ten square yard,nan,3.8,nan,nan
-2041,nan,TI,thousand square inch,nan,3.8,nan,nan
-2042,nan,TIC,"metric ton, including container","A unit of mass defining the number of metric tons of a product, including its container.",3.1,nan,nan
-2043,nan,TIP,"metric ton, including inner packaging","A unit of mass defining the number of metric tons of a product, including its inner packaging materials.",3.1,nan,nan
-2044,X,TJ,thousand square centimetre,nan,3.8,nan,nan
-2045,X,TK,"tank, rectangular","Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.4,nan,nan
-2046,nan,TKM,tonne kilometre,"A unit of information typically used for billing purposes, expressed as the number of tonnes (metric tons) moved over a distance of one kilometre. ",3.4,t·km,10⁶ kg x m
-2047,X,TL,thousand foot (linear),nan,3.8,nan,nan
-2048,nan,TMS,"kilogram of imported meat, less offal","A unit of mass equal to one thousand grams of imported meat, disregarding less valuable by-products such as the entrails.",3.5,nan,nan
-2049,X,TN,tin,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-2050,nan,TNE,tonne (metric ton),Synonym: metric ton,1S,t,10³ kg
-2051,nan,TP,ten pack,A unit of count defining the number of items in multiples of 10.,3.2,nan,nan
-2052,nan,TPI,teeth per inch,The number of teeth per inch.,3.1,TPI,0.0254 /m
-2053,nan,TPR,ten pair,A unit of count defining the number of pairs in multiples of 10 (pair: item described by two's).,3.8,nan,nan
-2054,X,TQ,thousand foot,nan,3.8,nan,nan
-2055,nan,TQD,thousand cubic metre per day,A unit of volume equal to one thousand cubic metres per day.,3.8,km³/d,"1,157 41 x 10⁻² m³/s"
-2056,X,TR,ten square foot,nan,3.8,nan,nan
-2057,nan,TRL,trillion (EUR),nan,3.7,nan,10¹⁸
-2058,X,TS,thousand square foot,nan,3.8,nan,nan
-2059,X,TSD,tonne of substance 90 % dry,nan,3.1,nan,nan
-2060,X,TSH,ton of steam per hour,nan,3.1,nan,nan
-2061,nan,TST,ten set,A unit of count defining the number of sets in multiples of 10 (set: a number of objects grouped together).,3.9,nan,nan
-2062,X,TT,thousand linear metre,nan,3.8,nan,nan
-2063,nan,TTS,ten thousand sticks,A unit of count defining the number of sticks in multiples of 10000 (stick: slender and often cylindrical piece of a substance).,3.9,nan,nan
-2064,X,TU,tube,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-2065,X,TV,thousand kilogram,nan,3.8,nan,10³kg
-2066,X,TW,thousand sheet,nan,3.8,nan,nan
-2067,X,TY,"tank, cylindrical","Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.4,nan,nan
-2068,nan,U1,treatment,"A unit of count defining the number of treatments (treatment: subjection to the action of a chemical, physical or biological agent).",3.9,nan,nan
-2069,nan,U2,tablet,A unit of count defining the number of tablets (tablet: a small flat or compressed solid object).,3.9,nan,nan
-2070,D,UA,torr,nan,2,Torr,"133,322 4 Pa"
-2071,nan,UB,telecommunication line in service average,A unit of count defining the average number of lines in service.,3.5,nan,nan
-2072,nan,UC,telecommunication port,A unit of count defining the number of network access ports.,3.5,nan,nan
-2073,X,UD,tenth minute,nan,3.8,nan,6 s
-2074,X,UE,tenth hour,nan,3.8,nan,360 s
-2075,X,UF,usage per telecommunication line average,nan,3.5,nan,nan
-2076,X,UH,ten thousand yard,nan,3.8,nan,nan
-2077,X,UM,million unit,nan,3.8,nan,nan
-2078,nan,VA,volt - ampere per kilogram,nan,3.9,V·A / kg,V x A / kg
-2079,X,VI,vial,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-2080,nan,VLT,volt,nan,1,V,V
-2081,nan,VP,percent volume,"A measure of concentration, typically expressed as the percentage volume of a solute in a solution.",3.7,nan,nan
-2082,X,VQ,bulk,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-2083,X,VS,visit,nan,3.9,nan,nan
-2084,nan,W2,wet kilo,"A unit of mass defining the number of kilograms of a product, including the water content of the product.",3.1,nan,nan
-2085,X,W4,two week,nan,3.8,nan,nan
-2086,nan,WA,watt per kilogram,nan,3.9,W/kg,1 W/kg
-2087,nan,WB,wet pound,"A unit of mass defining the number of pounds of a material, including the water content of the material.",3.1,nan,nan
-2088,nan,WCD,cord,A unit of volume used for measuring lumber. One board foot equals 1/12 of a cubic foot.,3.5,nan,"3,63 m³"
-2089,nan,WE,wet ton,"A unit of mass defining the number of tons of a material, including the water content of the material.",3.1,nan,nan
-2090,nan,WEB,weber,nan,1,Wb,Wb
-2091,nan,WEE,week,nan,2,wk,"6,048 x 10⁵ s"
-2092,nan,WG,wine gallon,A unit of volume equal to 231 cubic inches.,3.1,nan,nan
-2093,X,WH,wheel,nan,3.9,nan,nan
-2094,nan,WHR,watt hour,nan,1,W·h,"3,6 x 10³ J"
-2095,X,WI,weight per square inch,nan,3.9,nan,nan
-2096,nan,WM,working month,A unit of time defining the number of working months.,3.1,nan,nan
-2097,X,WR,wrap,nan,3.3,nan,nan
-2098,nan,WSD,standard,"A unit of volume of finished lumber equal to 165 cubic feet.,Synonym: standard cubic foot",3.5,std,"4,672 m³"
-2099,nan,WTT,watt,nan,1,W,W
-2100,D,WW,millilitre of water,A unit of volume equal to the number of millilitres of water.,3.1,nan,nan
-2101,nan,X1,Gunter's chain,A unit of distance used or formerly used by British surveyors.,2,ch (UK),"20,116 8 m"
-2102,nan,YDK,square yard,nan,2,yd²,"8,361 274 x 10⁻¹ m²"
-2103,nan,YDQ,cubic yard,nan,2,yd³,"0,764 555 m³"
-2104,X,YL,hundred linear yard,nan,3.8,nan,nan
-2105,nan,YRD,yard,nan,2,yd,"0,914 4 m"
-2106,X,YT,ten yard,nan,3.8,nan,nan
-2107,X,Z1,lift van,nan,3.4,nan,nan
-2108,nan,Z11,hanging container,A unit of count defining the number of hanging containers.,3.9,nan,nan
-2109,X,Z2,chest,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-2110,X,Z3,cask,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-2111,X,Z4,hogshead,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
-2112,X,Z5,lug,nan,3.9,nan,nan
-2113,X,Z6,conference point,nan,3.5,nan,nan
-2114,X,Z8,newspage agate line,nan,3.9,nan,nan
-2115,nan,ZP,page,A unit of count defining the number of pages.,3.5,nan,nan
-2116,nan,ZZ,mutually defined,A unit of measure as agreed in common between two or more parties.,3.9,nan,nan
+,Status,CommonCode,Name,Description,LevelAndCategory,Symbol,ConversionFactor
+0,X,05,lift,nan,3.9,nan,nan
+1,X,06,small spray,nan,3.9,nan,nan
+2,X,08,heat lot,nan,3.9,nan,nan
+3,nan,10,group,A unit of count defining the number of groups (group: set of items classified together).,3.9,nan,nan
+4,nan,11,outfit,A unit of count defining the number of outfits (outfit: a complete set of equipment / materials / objects used for a specific purpose).,3.9,nan,nan
+5,nan,13,ration,A unit of count defining the number of rations (ration: a single portion of provisions).,3.9,nan,nan
+6,nan,14,shot,"A unit of liquid measure, especially related to spirits.",3.9,nan,nan
+7,nan,15,"stick, military",A unit of count defining the number of military sticks (military stick: bombs or paratroops released in rapid succession from an aircraft).,3.9,nan,nan
+8,X,16,hundred fifteen kg drum,nan,3.3,nan,nan
+9,X,17,hundred lb drum,nan,3.3,nan,nan
+10,X,18,fiftyfive gallon (US) drum,nan,3.3,nan,nan
+11,X,19,tank truck,nan,3.4,nan,nan
+12,nan,20,twenty foot container,A unit of count defining the number of shipping containers that measure 20 foot in length.,3.4,nan,nan
+13,nan,21,forty foot container,A unit of count defining the number of shipping containers that measure 40 foot in length.,3.4,nan,nan
+14,nan,22,decilitre per gram,nan,1M,dl/g,10⁻¹ x m³/kg
+15,nan,23,gram per cubic centimetre,nan,1S,g/cm³,10³ kg/m³
+16,nan,24,theoretical pound,A unit of mass defining the expected mass of material expressed as the number of pounds.,3.1,nan,nan
+17,nan,25,gram per square centimetre,nan,1M,g/cm²,10 kg/m²
+18,X,26,actual ton,nan,3.1,nan,nan
+19,nan,27,theoretical ton,"A unit of mass defining the expected mass of material, expressed as the number of tons.",3.1,nan,nan
+20,nan,28,kilogram per square metre,nan,1,kg/m²,kg/m²
+21,X,29,pound per thousand square foot,nan,3.8,lb/kft²,nan
+22,X,30,horse power day per air dry metric ton,nan,3.5,nan,nan
+23,X,31,catch weight,nan,3.9,nan,nan
+24,X,32,kilogram per air dry metric ton,nan,3.5,nan,nan
+25,nan,33,kilopascal square metre per gram,nan,1M,kPa·m²/g,10⁶ m/s²
+26,nan,34,kilopascal per millimetre,nan,1M,kPa/mm,10⁶ kg/(m² x s²)
+27,nan,35,millilitre per square centimetre second,nan,1M,ml/(cm²·s),10⁻² m/s
+28,X,36,cubic foot per minute per square foot,Conversion factor required,1M,ft³/(min/ft²),nan
+29,nan,37,ounce per square foot,nan,2,oz/ft²,"0,305 151 7 kg/m²"
+30,nan,38,"ounce per square foot per 0,01inch",nan,3.9,oz/(ft²/cin),nan
+31,nan,40,millilitre per second,nan,1M,ml/s,10⁻⁶ m³/s
+32,nan,41,millilitre per minute,nan,1M,ml/min,"1,666 67 x 10⁻⁸ m³/s"
+33,X,43,super bulk bag,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+34,X,44,fivehundred kg bulk bag,nan,3.3,nan,nan
+35,X,45,threehundred kg bulk bag,nan,3.3,nan,nan
+36,X,46,fifty lb bulk bag,nan,3.3,nan,nan
+37,X,47,fifty lb bag,nan,3.3,nan,nan
+38,X,48,bulk car load,nan,3.4,nan,nan
+39,X,53,theoretical kilogram,nan,3.1,nan,nan
+40,X,54,theoretical tonne,nan,3.1,nan,nan
+41,nan,56,sitas,A unit of area for tin plate equal to a surface area of 100 square metres.,3.9,nan,nan
+42,nan,57,mesh,A unit of count defining the number of strands per inch as a measure of the fineness of a woven product.,3.9,nan,nan
+43,nan,58,net kilogram,A unit of mass defining the total number of kilograms after deductions.,3.1,nan,nan
+44,nan,59,part per million,A unit of proportion equal to 10⁻⁶.,3.7,ppm,1 x 10⁻⁶
+45,nan,60,percent weight,A unit of proportion equal to 10⁻².,3.7,nan,1 x 10⁻²
+46,nan,61,part per billion (US),A unit of proportion equal to 10⁻⁹.,3.7,ppb,1 x 10⁻⁹
+47,X,62,percent per 1000 hour,nan,3.7,nan,nan
+48,X,63,failure rate in time,nan,3.9,nan,nan
+49,D,64,"pound per square inch, gauge",nan,3.1,nan,"7,030 696 x 10² kg/m²"
+50,D,66,oersted,nan,3.5,Oe,"7,957 747 x 10 A/m"
+51,X,69,test specific scale,nan,3.9,nan,nan
+52,X,71,volt ampere per pound,nan,3.9,nan,nan
+53,X,72,watt per pound,nan,3.9,nan,nan
+54,X,73,ampere tum per centimetre,nan,3.9,nan,nan
+55,nan,74,millipascal,nan,1S,mPa,10⁻³ Pa
+56,D,76,gauss,nan,3.5,Gs,10⁻⁴ T
+57,nan,77,milli-inch,nan,2,mil,"25,4 x 10⁻⁶ m"
+58,D,78,kilogauss,nan,3.5,kGs,10⁻¹ T
+59,nan,80,pound per square inch absolute,nan,2,lb/in²,"7,030 696 x 10² kg/m²"
+60,nan,81,henry,nan,1,H,H
+61,D,84,kilopound-force per square inch,"A unit of pressure defining the number of kilopounds force per square inch.,Use kip per square inch (common code N20).",2,klbf/in²,"6,894 757 x 10⁶ Pa"
+62,nan,85,foot pound-force,nan,2,ft·lbf,"1,355 818 J"
+63,nan,87,pound per cubic foot,nan,2,lb/ft³,"1,601 846 x 10¹ kg/m³"
+64,nan,89,poise,nan,2,P,"0,1 Pa x s"
+65,X,90,Saybold universal second,nan,3.9,nan,nan
+66,nan,91,stokes,nan,2,St,10⁻⁴ m²/s
+67,X,92,calorie per cubic centimetre,nan,3.9,nan,nan
+68,X,93,calorie per gram,Use International Table (IT) calorie per gram (common code D75).,3.5,cal/g,"4,186 8 x 10³ J/kg"
+69,X,94,curl unit,nan,3.9,nan,nan
+70,X,95,twenty thousand gallon (US) tankcar,nan,3.4,nan,nan
+71,X,96,ten thousand gallon (US) tankcar,nan,3.4,nan,nan
+72,X,97,ten kg drum,nan,3.3,nan,nan
+73,X,98,fifteen kg drum,nan,3.3,nan,nan
+74,X,1A,car mile,nan,3.5,nan,nan
+75,X,1B,car count,nan,3.5,nan,nan
+76,X,1C,locomotive count,nan,3.5,nan,nan
+77,X,1D,caboose count,nan,3.5,nan,nan
+78,X,1E,empty car,nan,3.5,nan,nan
+79,X,1F,train mile,nan,3.5,nan,nan
+80,X,1G,fuel usage gallon (US),nan,3.5,nan,nan
+81,X,1H,caboose mile,nan,3.5,nan,nan
+82,nan,1I,fixed rate,A unit of quantity expressed as a predetermined or set rate for usage of a facility or service.,3.9,nan,nan
+83,X,1J,ton mile,nan,3.5,nan,nan
+84,X,1K,locomotive mile,nan,3.5,nan,nan
+85,X,1L,total car count,nan,3.5,nan,nan
+86,X,1M,total car mile,nan,3.5,nan,nan
+87,X,1X,quarter mile,nan,3.8,nan,nan
+88,nan,2A,radian per second,Refer ISO/TC12 SI Guide,1,rad/s,rad/s
+89,nan,2B,radian per second squared,Refer ISO/TC12 SI Guide,1,rad/s²,rad/s²
+90,nan,2C,roentgen,nan,2,R,"2,58 x 10⁻⁴ C/kg"
+91,nan,2G,volt AC,A unit of electric potential in relation to alternating current (AC).,3.1,V,V
+92,nan,2H,volt DC,A unit of electric potential in relation to direct current (DC).,3.1,V,V
+93,nan,2I,British thermal unit (international table) per hour,nan,2,BtuIT/h,"2,930 711x 10⁻¹ W"
+94,nan,2J,cubic centimetre per second,nan,1S,cm³/s,10⁻⁶ m³/s
+95,nan,2K,cubic foot per hour,nan,2,ft³/h,"7,865 79 x 10⁻⁶ m³/s"
+96,nan,2L,cubic foot per minute,nan,2,ft³/min,"4,719 474 x 10⁻⁴ m³/s"
+97,nan,2M,centimetre per second,nan,1S,cm/s,10⁻² m/s
+98,nan,2N,decibel,nan,1,dB,"0,115 129 3 Np"
+99,nan,2P,kilobyte,A unit of information equal to 10³ (1000) bytes.,3.6,kbyte,nan
+100,nan,2Q,kilobecquerel,nan,1S,kBq,10³ Bq
+101,nan,2R,kilocurie,nan,2S,kCi,"3,7 x 10¹³ Bq"
+102,nan,2U,megagram,nan,1S,Mg,10³ kg
+103,X,2V,megagram per hour,nan,3.8,Mg/h,nan
+104,X,2W,bin,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+105,nan,2X,metre per minute,nan,1M,m/min,"0,016 666 m/s"
+106,nan,2Y,milliroentgen,nan,2,mR,"2,58 x 10⁻⁷ C/kg"
+107,nan,2Z,millivolt,nan,1S,mV,10⁻³ V
+108,nan,3B,megajoule,nan,1S,MJ,10⁶ J
+109,nan,3C,manmonth,A unit of count defining the number of months for a person or persons to perform an undertaking.,3.9,nan,nan
+110,X,3E,pound per pound of product,nan,3.9,nan,nan
+111,X,3G,pound per piece of product,nan,3.9,nan,nan
+112,X,3H,kilogram per kilogram of product,nan,3.9,nan,nan
+113,X,3I,kilogram per piece of product,nan,3.9,nan,nan
+114,X,4A,bobbin,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+115,X,4B,cap,nan,3.9,nan,nan
+116,nan,4C,centistokes,nan,2,cSt,10⁻⁶ m²/s
+117,X,4E,twenty pack,nan,3.2,nan,nan
+118,nan,4G,microlitre,nan,1M,µl,10⁻⁹ m³
+119,nan,4H,micrometre (micron),nan,1S,µm,10⁻⁶ m
+120,nan,4K,milliampere,nan,1S,mA,10⁻³ A
+121,nan,4L,megabyte,A unit of information equal to 10⁶ (1000000) bytes.,3.6,Mbyte,nan
+122,nan,4M,milligram per hour,nan,1M,mg/h,"2,777 78 x 10⁻¹⁰ kg/s"
+123,nan,4N,megabecquerel,nan,1S,MBq,10⁶ Bq
+124,nan,4O,microfarad,nan,1S,µF,10⁻⁶ F
+125,nan,4P,newton per metre,nan,1,N/m,N/m
+126,nan,4Q,ounce inch,nan,2,oz·in,"7,200 778 x 10⁻⁴ kg x m"
+127,nan,4R,ounce foot,nan,2,oz·ft,"8,640 934 x 10⁻³ kg x m"
+128,nan,4T,picofarad,nan,1S,pF,10⁻¹² F
+129,nan,4U,pound per hour,nan,2,lb/h,"1,259 979 x 10⁻⁴ kg/s"
+130,nan,4W,ton (US) per hour,nan,2,ton (US) /h,"2,519 958 x 10⁻¹ kg/s"
+131,nan,4X,kilolitre per hour,nan,1M,kl/h,"2,777 78 x 10⁻⁴ m³/s"
+132,nan,5A,barrel (US) per minute,nan,2,barrel (US)/min,"2,649 79 x 10⁻³ m³/s"
+133,nan,5B,batch,A unit of count defining the number of batches (batch: quantity of material produced in one operation or number of animals or persons coming at once).,3.9,nan,nan
+134,X,5C,gallon(US) per thousand,nan,3.9,nan,nan
+135,nan,5E,MMSCF/day,A unit of volume equal to one million (1000000) cubic feet of gas per day.,3.9,nan,nan
+136,X,5F,pound per thousand,nan,3.9,nan,nan
+137,X,5G,pump,nan,3.9,nan,nan
+138,X,5H,stage,nan,3.9,nan,nan
+139,X,5I,standard cubic foot,Use standard (common code WSD),2,std,"4,672 m³"
+140,nan,5J,hydraulic horse power,A unit of power defining the hydraulic horse power delivered by a fluid pump depending on the viscosity of the fluid.,3.5,nan,nan
+141,X,5K,count per minute,nan,3.9,nan,nan
+142,X,5P,seismic level,nan,3.9,nan,nan
+143,X,5Q,seismic line,nan,3.9,nan,nan
+144,D,A1,15 °C calorie,nan,2,cal₁₅,"4,188 46  J"
+145,nan,A10,ampere square metre per joule second,nan,1,A·m²/(J·s),(A x s)/kg
+146,nan,A11,angstrom,nan,1,Å,10⁻¹⁰ m
+147,nan,A12,astronomical unit,nan,1,ua,"1,495 978 70 x 10¹¹ m"
+148,nan,A13,attojoule,nan,1S,aJ,10⁻¹⁸ J
+149,nan,A14,barn,nan,1,b,10⁻²⁸ m²
+150,nan,A15,barn per electronvolt,nan,1,b/eV,"6,241 51 x 10⁻¹⁰ m²/J"
+151,nan,A16,barn per steradian electronvolt,nan,1,b/(sr·eV),"6,241 51 x 10⁻¹⁰ m²/(sr xJ)"
+152,nan,A17,barn per steradian,nan,1,b/sr,1 x 10⁻²⁸ m²/sr
+153,nan,A18,becquerel per kilogram,nan,1,Bq/kg,"27,027 x 10⁻¹² Ci/kg"
+154,nan,A19,becquerel per cubic metre,nan,1,Bq/m³,Bq/m³
+155,nan,A2,ampere per centimetre,nan,1S,A/cm,10² A/m
+156,nan,A20,British thermal unit (international table) per second square foot degree Rankine,nan,2,BtuIT/(s·ft²·°R),"20 441,7 W/(m² x K)"
+157,nan,A21,British thermal unit (international table) per pound degree Rankine,nan,2,BtuIT/(lb·°R),"4 186,8 J/(kg x K)"
+158,nan,A22,British thermal unit (international table) per second foot degree Rankine,nan,2,BtuIT/(s·ft·°R),"6 230,64 W/(m x K)"
+159,nan,A23,British thermal unit (international table) per hour square foot degree Rankine,nan,2,BtuIT/(h·ft²·°R),"5,678 26 W/ (m² x K)"
+160,nan,A24,candela per square metre,nan,1,cd/m²,cd/m²
+161,D,A25,cheval vapeur,Synonym: metric horse power,2,CV,"7,354 988 x 10² W"
+162,nan,A26,coulomb metre,nan,1,C·m,A x s x m
+163,nan,A27,coulomb metre squared per volt,nan,1,C·m²/V,A² x  s⁴/kg
+164,nan,A28,coulomb per cubic centimetre,nan,1S,C/cm³,10⁶ C/m³
+165,nan,A29,coulomb per cubic metre,nan,1,C/m³,C/m³
+166,nan,A3,ampere per millimetre,nan,1S,A/mm,10³ A/m
+167,nan,A30,coulomb per cubic millimetre,nan,1S,C/mm³,10⁹ C/m³
+168,nan,A31,coulomb per kilogram second,nan,1,C/(kg·s),A/kg
+169,nan,A32,coulomb per mole,nan,1,C/mol,A x s/mol
+170,nan,A33,coulomb per square centimetre,nan,1S,C/cm²,10⁴ C/m²
+171,nan,A34,coulomb per square metre,nan,1,C/m²,C/m²
+172,nan,A35,coulomb per square millimetre,nan,1S,C/mm²,10⁶ C/m²
+173,nan,A36,cubic centimetre per mole,nan,1S,cm³/mol,10⁻⁶ m³/mol
+174,nan,A37,cubic decimetre per mole,nan,1S,dm³/mol,10⁻³ m³/mol
+175,nan,A38,cubic metre per coulomb,nan,1,m³/C,m³/A x s
+176,nan,A39,cubic metre per kilogram,nan,1,m³/kg,m³/kg
+177,nan,A4,ampere per square centimetre,nan,1S,A/cm²,10⁴ A/m²
+178,nan,A40,cubic metre per mole,nan,1,m³/mol,m³/mol
+179,nan,A41,ampere per square metre,nan,1,A/m²,A/m²
+180,nan,A42,curie per kilogram,nan,2,Ci/kg,"3,7 x 10¹⁰ Bq/kg"
+181,nan,A43,deadweight tonnage,"A unit of mass defining the difference between the weight of a ship when completely empty and its weight when completely loaded, expressed as the number of tons.",3.4,dwt,nan
+182,nan,A44,decalitre,nan,1M,dal,10⁻² m³
+183,nan,A45,decametre,nan,1M,dam,10 m
+184,nan,A47,decitex,A unit of yarn density. One decitex equals a mass of 1 gram per 10 kilometres of length.,3.5,dtex (g/10km),nan
+185,nan,A48,degree Rankine,Refer ISO 80000-5 (Quantities and units — Part 5: Thermodynamics),2,°R,5/9 x K
+186,nan,A49,denier,A unit of yarn density. One denier equals a mass of 1 gram per 9 kilometres of length.,3.5,den (g/9 km),nan
+187,nan,A5,ampere square metre,nan,1,A·m²,A x m²
+188,D,A50,dyne second per cubic centimetre,nan,2,dyn·s/cm³,10 Pa x s/m
+189,D,A51,dyne second per centimetre,nan,2,dyn·s/cm,10⁻³ N x s/m
+190,D,A52,dyne second per centimetre to the fifth power,nan,2,dyn·s/cm⁵,10⁵ Pa x s/m³
+191,nan,A53,electronvolt,nan,1,eV,"1,602 176 487 x 10⁻¹⁹ J"
+192,nan,A54,electronvolt per metre,nan,1,eV/m,"1,602 176 487 x 10⁻¹⁹ J/m"
+193,nan,A55,electronvolt square metre,nan,1,eV·m²,"1,602 176 487 x 10⁻¹⁹ J x m²"
+194,nan,A56,electronvolt square metre per kilogram,nan,1,eV·m²/kg,"1,602 176 487 x 10⁻¹⁹ J x m²/kg"
+195,D,A57,erg,nan,2,erg,10⁻⁷J
+196,D,A58,erg per centimetre,nan,2,erg/cm,10⁻⁵ J/m
+197,nan,A59,8-part cloud cover,"A unit of count defining the number of eighth-parts as a measure of the celestial dome cloud coverage.,Synonym: OKTA , OCTA",3.9,nan,nan
+198,nan,A6,ampere per square metre kelvin squared,nan,1,A/(m²·K²),A/(m² x K²)
+199,D,A60,erg per cubic centimetre,nan,2,erg/cm³,10⁻¹ J/m³
+200,D,A61,erg per gram,nan,2,erg/g,10⁻⁴ J/kg
+201,D,A62,erg per gram second,nan,2,erg/g·s,10⁻⁴ W/kg
+202,D,A63,erg per second,nan,2,erg/s,10⁻⁷ W
+203,D,A64,erg per second square centimetre,nan,2,erg/(s·cm²),10⁻³ W/m²
+204,D,A65,erg per square centimetre second,nan,2,erg/(cm²·s),10⁻³ W/m²
+205,D,A66,erg square centimetre,nan,2,erg·cm²,10⁻¹¹ J x m²
+206,D,A67,erg square centimetre per gram,nan,2,erg·cm²/g,10⁻⁸ J x m²/kg
+207,nan,A68,exajoule,nan,1S,EJ,10¹⁸ J
+208,nan,A69,farad per metre,nan,1,F/m,kg⁻¹ x m⁻³ x s⁴ x A²
+209,nan,A7,ampere per square millimetre,nan,1S,A/mm²,10⁶ A/m²
+210,nan,A70,femtojoule,nan,1S,fJ,10⁻¹⁵ J
+211,nan,A71,femtometre,nan,1S,fm,10⁻¹⁵ m
+212,nan,A73,foot per second squared,nan,2,ft/s²,"0,304 8 m/s²"
+213,nan,A74,foot pound-force per second,nan,2,ft·lbf/s,"1,355 818 W"
+214,nan,A75,freight ton,"A unit of information typically used for billing purposes, defined as either the number of metric tons or the number of cubic metres, whichever is the larger.",3.4,nan,nan
+215,nan,A76,gal,nan,1S,Gal,10⁻² m/s²
+216,D,A77,Gaussian CGS (Centimetre-Gram-Second system) unit of displacement,nan,3.5,nan,nan
+217,D,A78,Gaussian CGS (Centimetre-Gram-Second system) unit of electric current,nan,3.5,nan,nan
+218,D,A79,Gaussian CGS (Centimetre-Gram-Second system) unit of electric charge,nan,3.5,nan,nan
+219,nan,A8,ampere second,nan,1,A·s,C
+220,D,A80,Gaussian CGS (Centimetre-Gram-Second system) unit of electric field strength,nan,3.5,nan,nan
+221,D,A81,Gaussian CGS (Centimetre-Gram-Second system) unit of electric polarization,nan,3.5,nan,nan
+222,D,A82,Gaussian CGS (Centimetre-Gram-Second system) unit of electric potential,nan,3.5,nan,nan
+223,D,A83,Gaussian CGS (Centimetre-Gram-Second system) unit of magnetization,nan,3.5,nan,nan
+224,nan,A84,gigacoulomb per cubic metre,nan,1S,GC/m³,10⁹ C/m³
+225,nan,A85,gigaelectronvolt,nan,1S,GeV,10⁹ eV
+226,nan,A86,gigahertz,nan,1S,GHz,10⁹ Hz
+227,nan,A87,gigaohm,nan,1S,GΩ,10⁹ Ω
+228,nan,A88,gigaohm metre,nan,1S,GΩ·m,10⁹ Ω x m
+229,nan,A89,gigapascal,nan,1S,GPa,10⁹ Pa
+230,nan,A9,rate,A unit of quantity expressed as a rate for usage of a facility or service.,3.9,nan,nan
+231,nan,A90,gigawatt,nan,1S,GW,10⁹ W
+232,nan,A91,gon,Synonym: grade,2,gon,"1,570 796 x 10⁻² rad"
+233,nan,A93,gram per cubic metre,nan,1M,g/m³,10⁻³ kg/m³
+234,nan,A94,gram per mole,nan,1S,g/mol,10⁻³ kg/mol
+235,nan,A95,gray,nan,1,Gy,m²/s²
+236,nan,A96,gray per second,nan,1,Gy/s,m²/s³
+237,nan,A97,hectopascal,nan,1S,hPa,10² Pa
+238,nan,A98,henry per metre,nan,1,H/m,H/m
+239,nan,A99,bit,A unit of information equal to one binary digit.,3.6,bit,nan
+240,nan,AA,ball,A unit of count defining the number of balls (ball: object formed in the shape of sphere).,3.9,nan,nan
+241,nan,AB,bulk pack,A unit of count defining the number of items per bulk pack.,3.9,pk,nan
+242,nan,ACR,acre,nan,2,acre,"4 046,873 m²"
+243,nan,ACT,activity,A unit of count defining the number of activities (activity: a unit of work or action).,3.2,nan,nan
+244,nan,AD,byte,A unit of information equal to 8 bits.,3.6,byte,nan
+245,nan,AE,ampere per metre,nan,1,A/m,A/m
+246,nan,AH,additional minute,A unit of time defining the number of minutes in addition to the referenced minutes.,3.5,nan,nan
+247,nan,AI,average minute per call,A unit of count defining the number of minutes for the average interval of a call.,3.5,nan,nan
+248,X,AJ,cop,nan,3.9,nan,nan
+249,nan,AK,fathom,nan,2,fth,"1,828 8 m"
+250,nan,AL,access line,A unit of count defining the number of telephone access lines.,3.5,nan,nan
+251,X,AM,ampoule,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+252,nan,AMH,ampere hour,A unit of electric charge defining the amount of charge accumulated by a steady flow of one ampere for one hour.,1M,A·h,"3,6 x 10³ C"
+253,nan,AMP,ampere,nan,1,A,A
+254,nan,ANN,year,"Unit of time equal to 365,25 days.,Synonym: Julian year",2,y,"3,155 76 x 10⁷ s"
+255,X,AP,aluminium pound only,nan,3.1,nan,nan
+256,nan,APZ,troy ounce or apothecary ounce,nan,2,tr oz,"3,110 348 x 10⁻³ kg"
+257,nan,AQ,anti-hemophilic factor (AHF) unit,A unit of measure for blood potency (US).,3.9,nan,nan
+258,X,AR,suppository,nan,3.3,nan,nan
+259,D,ARE,are,Synonym: square decametre,2.0,a,10² m²
+260,nan,AS,assortment,A unit of count defining the number of assortments (assortment: set of items grouped in a mixed collection).,3.9,nan,nan
+261,nan,ASM,alcoholic strength by mass,A unit of mass defining the alcoholic strength of a liquid.,3.5,nan,nan
+262,nan,ASU,alcoholic strength by volume,"A unit of volume defining the alcoholic strength of a liquid (e.g. spirit, wine, beer, etc), often at a specific temperature.",3.5,nan,nan
+263,nan,ATM,standard atmosphere,nan,1,atm,1 013 25 Pa
+264,D,ATT,technical atmosphere,nan,2,at,"98 066,5 Pa"
+265,X,AV,capsule,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+266,X,AW,powder filled vial,nan,3.3,nan,nan
+267,nan,AWG,american wire gauge,A unit of distance used for measuring the diameter of small tubes or wires such as the outer diameter of hypotermic or suture needles.,2,AWG,nan
+268,nan,AY,assembly,A unit of count defining the number of assemblies (assembly: items that consist of component parts).,3.9,nan,nan
+269,nan,AZ,British thermal unit (international table) per pound,nan,2,BtuIT/lb,2 326 J/kg
+270,X,B0,Btu per cubic foot,nan,3.9,BTU/ft³,nan
+271,nan,B1,barrel (US) per day,nan,3.5,barrel (US)/d,"1,840 13 x 10⁻⁶ m³/s"
+272,nan,B10,bit per second,A unit of information equal to one binary digit per second.,3.6,bit/s,nan
+273,nan,B11,joule per kilogram kelvin,nan,1,J/(kg·K),J/(kg x K)
+274,nan,B12,joule per metre,nan,1,J/m,J/m
+275,nan,B13,joule per square metre,Synonym: joule per metre squared,1,J/m²,J/m²
+276,nan,B14,joule per metre to the fourth power,nan,1,J/m⁴,J/m⁴
+277,nan,B15,joule per mole,nan,1,J/mol,J/mol
+278,nan,B16,joule per mole kelvin,nan,1,J/(mol·K),J/(mol x K)
+279,nan,B17,credit,A unit of count defining the number of entries made to the credit side of an account.,3.9,nan,nan
+280,nan,B18,joule second,nan,1,J·s,J x s
+281,nan,B19,digit,A unit of information defining the quantity of numerals used to form a number.,3.7,nan,nan
+282,X,B2,bunk,nan,3.9,nan,nan
+283,nan,B20,joule square metre per kilogram,nan,1,J·m²/kg,J x m²/kg
+284,nan,B21,kelvin per watt,nan,1,K/W,K/W
+285,nan,B22,kiloampere,nan,1S,kA,10³ A
+286,nan,B23,kiloampere per square metre,nan,1S,kA/m²,10³ A/m²
+287,nan,B24,kiloampere per metre,nan,1S,kA/m,10³ A/m
+288,nan,B25,kilobecquerel per kilogram,nan,1S,kBq/kg,10³ Bq/kg
+289,nan,B26,kilocoulomb,nan,1S,kC,10³ C
+290,nan,B27,kilocoulomb per cubic metre,nan,1S,kC/m³,10³ C/m³
+291,nan,B28,kilocoulomb per square metre,nan,1S,kC/m²,10³ C/m²
+292,nan,B29,kiloelectronvolt,nan,1S,keV,10³ eV
+293,nan,B3,batting pound,A unit of mass defining the number of pounds of wadded fibre.,3.1,nan,nan
+294,nan,B30,gibibit,A unit of information equal to 2³⁰ bits (binary digits).,3.6,Gibit,nan
+295,nan,B31,kilogram metre per second,nan,1,kg·m/s,kg x m/s
+296,nan,B32,kilogram metre squared,nan,1,kg·m²,kg x m²
+297,nan,B33,kilogram metre squared per second,nan,1,kg·m²/s,kg x m²/s
+298,nan,B34,kilogram per cubic decimetre,nan,1S,kg/dm³,10³ kg/m³
+299,nan,B35,kilogram per litre,nan,1S,kg/l or kg/L,10³ kg/m³
+300,D,B36,calorie (thermochemical) per gram,nan,2,calth/g,4 184 J/kg
+301,D,B37,kilogram-force,nan,2,kgf,"9,806 65 N"
+302,D,B38,kilogram-force metre,nan,2,kgf·m,"9,806 65 N x m"
+303,D,B39,kilogram-force metre per second,nan,2,kgf·m/s,"9,806 65 W"
+304,nan,B4,"barrel, imperial",A unit of volume used to measure beer.  One beer barrel equals 36 imperial gallons.,3.5,nan,nan
+305,D,B40,kilogram-force per square metre,nan,2,kgf/m²,"9,806 65 Pa"
+306,nan,B41,kilojoule per kelvin,nan,1S,kJ/K,10³ J/K
+307,nan,B42,kilojoule per kilogram,nan,1S,kJ/kg,10³ J/kg
+308,nan,B43,kilojoule per kilogram kelvin,nan,1S,kJ/(kg·K),10³ J/(kg x K)
+309,nan,B44,kilojoule per mole,nan,1S,kJ/mol,10³ J/mol
+310,nan,B45,kilomole,nan,1S,kmol,10³ mol
+311,nan,B46,kilomole per cubic metre,nan,1S,kmol/m³,10³ mol/m³
+312,nan,B47,kilonewton,nan,1S,kN,10³ N
+313,nan,B48,kilonewton metre,nan,1S,kN·m,10³ N x m
+314,nan,B49,kiloohm,nan,1S,kΩ,10³ Ω
+315,X,B5,billet,nan,3.9,nan,nan
+316,nan,B50,kiloohm metre,nan,1S,kΩ·m,10³ Ω x m
+317,D,B51,kilopond,Synonym: kilogram-force,2,kp,"9,806 65 N"
+318,nan,B52,kilosecond,nan,1S,ks,10³ s
+319,nan,B53,kilosiemens,nan,1S,kS,10³ S
+320,nan,B54,kilosiemens per metre,nan,1S,kS/m,10³ S/m
+321,nan,B55,kilovolt per metre,nan,1S,kV/m,10³ V/m
+322,nan,B56,kiloweber per metre,nan,1S,kWb/m,10³ Wb/m
+323,nan,B57,light year,A unit of length defining the distance that light travels in a vacuum in one year.,2,ly,"9,460 73 x 10¹⁵ m"
+324,nan,B58,litre per mole,nan,1M,l/mol,10⁻³ m³/mol
+325,nan,B59,lumen hour,nan,1S,lm·h,"3,6 x 10³ s x cd x sr"
+326,X,B6,bun,nan,3.9,nan,nan
+327,nan,B60,lumen per square metre,nan,1,lm/m²,cd x sr/m²
+328,nan,B61,lumen per watt,nan,1,lm/W,cd x sr/W
+329,nan,B62,lumen second,nan,1,lm·s,s x cd x sr
+330,nan,B63,lux hour,nan,1S,lx·h,"3,6 x 10³ s x cd x sr / m²"
+331,nan,B64,lux second,nan,1,lx·s,s x cd x sr / m²
+332,D,B65,maxwell,nan,3.5,Mx,10⁻⁸ Wb
+333,nan,B66,megaampere per square metre,nan,1S,MA/m²,10⁶ A/m²
+334,nan,B67,megabecquerel per kilogram,nan,1S,MBq/kg,10⁶ Bq/kg
+335,nan,B68,gigabit,A unit of information equal to 10⁹ bits (binary digits).,3.6,Gbit,nan
+336,nan,B69,megacoulomb per cubic metre,nan,1S,MC/m³,10⁶ C/m³
+337,nan,B7,cycle,A unit of count defining the number of cycles (cycle: a recurrent period of definite duration).,3.9,nan,nan
+338,nan,B70,megacoulomb per square metre,nan,1S,MC/m²,10⁶ C/m²
+339,nan,B71,megaelectronvolt,nan,1S,MeV,10⁶ eV
+340,nan,B72,megagram per cubic metre,nan,1S,Mg/m³,10³ kg/m³
+341,nan,B73,meganewton,nan,1S,MN,10⁶ N
+342,nan,B74,meganewton metre,nan,1S,MN·m,10⁶ N x m
+343,nan,B75,megaohm,nan,1S,MΩ,10⁶ Ω
+344,nan,B76,megaohm metre,nan,1S,MΩ·m,10⁶ Ω x m
+345,nan,B77,megasiemens per metre,nan,1S,MS/m,10⁶ S/m
+346,nan,B78,megavolt,nan,1S,MV,10⁶ V
+347,nan,B79,megavolt per metre,nan,1S,MV/m,10⁶ V/m
+348,nan,B8,joule per cubic metre,nan,1,J/m³,J/m³
+349,nan,B80,gigabit per second,A unit of information equal to 10⁹ bits (binary digits) per second.,3.6,Gbit/s,nan
+350,nan,B81,reciprocal metre squared reciprocal second,nan,1,m⁻²/s,m⁻²/s
+351,nan,B82,inch per linear foot,A unit of length defining the number of inches per linear foot.,3.1,nan,nan
+352,nan,B83,metre to the fourth power,nan,1,m⁴,m⁴
+353,nan,B84,microampere,nan,1S,µA,10⁻⁶ A
+354,nan,B85,microbar,nan,1S,µbar,10⁻¹ Pa
+355,nan,B86,microcoulomb,nan,1S,µC,10⁻⁶ C
+356,nan,B87,microcoulomb per cubic metre,nan,1S,µC/m³,10⁻⁶ C/m³
+357,nan,B88,microcoulomb per square metre,nan,1S,µC/m²,10⁻⁶ C/m²
+358,nan,B89,microfarad per metre,nan,1S,µF/m,10⁻⁶ F/m
+359,X,B9,batt,nan,3.9,nan,nan
+360,nan,B90,microhenry,nan,1S,µH,10⁻⁶ H
+361,nan,B91,microhenry per metre,nan,1S,µH/m,10⁻⁶ H/m
+362,nan,B92,micronewton,nan,1S,µN,10⁻⁶ N
+363,nan,B93,micronewton metre,nan,1S,µN·m,10⁻⁶ N x m
+364,nan,B94,microohm,nan,1S,µΩ,10⁻⁶ Ω
+365,nan,B95,microohm metre,nan,1S,µΩ·m,10⁻⁶ Ω x m
+366,nan,B96,micropascal,nan,1S,µPa,10⁻⁶ Pa
+367,nan,B97,microradian,nan,1S,µrad,10⁻⁶ rad
+368,nan,B98,microsecond,nan,1S,µs,10⁻⁶ s
+369,nan,B99,microsiemens,nan,1S,µS,10⁻⁶ S
+370,nan,BAR,bar [unit of pressure],nan,1,bar,10⁵ Pa
+371,nan,BB,base box,"A unit of area of 112 sheets of tin mil products (tin plate, tin free steel or black plate) 14 by 20 inches, or 31,360 square inches.",3.5,nan,nan
+372,X,BD,board,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+373,X,BE,bundle,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+374,nan,BFT,board foot,A unit of volume defining the number of cords (cord: a stack of firewood of 128 cubic feet).,3.5,fbm,nan
+375,X,BG,bag,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+376,X,BH,brush,nan,3.9,nan,nan
+377,nan,BHP,brake horse power,nan,2,BHP,"7,457 x 10² W"
+378,nan,BIL,billion (EUR),Synonym: trillion (US),3.7,nan,10¹²
+379,X,BJ,bucket,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+380,X,BK,basket,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+381,X,BL,bale,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+382,nan,BLD,dry barrel (US),nan,2,bbl (US),"1,156 27 x 10⁻¹ m³"
+383,nan,BLL,barrel (US),nan,2,barrel (US),"158,987 3 x 10⁻³ m³"
+384,X,BO,bottle,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+385,nan,BP,hundred board foot,A unit of volume equal to one hundred board foot.,3.5,nan,nan
+386,nan,BPM,beats per minute,The number of beats per minute.,3.1,BPM,1.667 x 10-2 /s
+387,nan,BQL,becquerel,nan,1,Bq,"27,027 x 10⁻¹² Ci"
+388,X,BR,bar [unit of packaging],"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+389,X,BT,bolt,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+390,nan,BTU,British thermal unit (international table),nan,2,BtuIT,"1,055 056 x 10³ J"
+391,nan,BUA,bushel (US),nan,2,bu (US),"3,523 907 x 10⁻² m³"
+392,nan,BUI,bushel (UK),nan,2,bushel (UK),"3,636 872 x 10⁻² m³"
+393,X,BW,base weight,nan,3.9,nan,nan
+394,X,BX,box,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+395,X,BZ,million BTUs,nan,3.8,nan,nan
+396,nan,C0,call,A unit of count defining the number of calls (call: communication session or visitation).,3.5,nan,nan
+397,X,C1,composite product pound (total weight),nan,3.9,nan,nan
+398,nan,C10,millifarad,nan,1S,mF,10⁻³ F
+399,nan,C11,milligal,nan,1M,mGal,10⁻⁵ m/s²
+400,nan,C12,milligram per metre,nan,1S,mg/m,10⁻⁶ kg/m
+401,nan,C13,milligray,nan,1S,mGy,10⁻³ Gy
+402,nan,C14,millihenry,nan,1S,mH,10⁻³ H
+403,nan,C15,millijoule,nan,1S,mJ,10⁻³ J
+404,nan,C16,millimetre per second,nan,1S,mm/s,10⁻³ m/s
+405,nan,C17,millimetre squared per second,nan,1S,mm²/s,10⁻⁶ m²/s
+406,nan,C18,millimole,nan,1S,mmol,10⁻³ mol
+407,nan,C19,mole per kilogram,nan,1,mol/kg,mol/kg
+408,X,C2,carset,nan,3.5,nan,nan
+409,nan,C20,millinewton,nan,1S,mN,10⁻³ N
+410,nan,C21,kibibit,A unit of information equal to 2¹⁰ (1024) bits (binary digits).,3.6,Kibit,nan
+411,nan,C22,millinewton per metre,nan,1S,mN/m,10⁻³ N/m
+412,nan,C23,milliohm metre,nan,1S,mΩ·m,10⁻³ Ω x m
+413,nan,C24,millipascal second,nan,1S,mPa·s,10⁻³ Pa x s
+414,nan,C25,milliradian,nan,1S,mrad,10⁻³ rad
+415,nan,C26,millisecond,nan,1S,ms,10⁻³ s
+416,nan,C27,millisiemens,nan,1S,mS,10⁻³ S
+417,nan,C28,millisievert,nan,1S,mSv,10⁻³ Sv
+418,nan,C29,millitesla,nan,1S,mT,10⁻³ T
+419,nan,C3,microvolt per metre,nan,1S,µV/m,10⁻⁶ V/m
+420,nan,C30,millivolt per metre,nan,1S,mV/m,10⁻³ V/m
+421,nan,C31,milliwatt,nan,1S,mW,10⁻³ W
+422,nan,C32,milliwatt per square metre,nan,1S,mW/m²,10⁻³ W/m²
+423,nan,C33,milliweber,nan,1S,mWb,10⁻³ Wb
+424,nan,C34,mole,nan,1,mol,mol
+425,nan,C35,mole per cubic decimetre,nan,1S,mol/dm³,10³ mol/m³
+426,nan,C36,mole per cubic metre,nan,1,mol/m³,mol/m³
+427,nan,C37,kilobit,A unit of information equal to 10³ (1000) bits (binary digits).,3.6,kbit,nan
+428,nan,C38,mole per litre,nan,1,mol/l,10³ mol/m³
+429,nan,C39,nanoampere,nan,1S,nA,10⁻⁹ A
+430,X,C4,carload,nan,3.5,nan,nan
+431,nan,C40,nanocoulomb,nan,1S,nC,10⁻⁹ C
+432,nan,C41,nanofarad,nan,1S,nF,10⁻⁹ F
+433,nan,C42,nanofarad per metre,nan,1S,nF/m,10⁻⁹ F/m
+434,nan,C43,nanohenry,nan,1S,nH,10⁻⁹ H
+435,nan,C44,nanohenry per metre,nan,1S,nH/m,10⁻⁹ H/m
+436,nan,C45,nanometre,nan,1S,nm,10⁻⁹ m
+437,nan,C46,nanoohm metre,nan,1S,nΩ·m,10⁻⁹ Ω·x m
+438,nan,C47,nanosecond,nan,1S,ns,10⁻⁹ s
+439,nan,C48,nanotesla,nan,1S,nT,10⁻⁹ T
+440,nan,C49,nanowatt,nan,1S,nW,10⁻⁹ W
+441,X,C5,cost,nan,3.9,nan,nan
+442,nan,C50,neper,nan,1,Np,Np
+443,nan,C51,neper per second,nan,1,Np/s,Np/s
+444,nan,C52,picometre,nan,1S,pm,10⁻¹² m
+445,nan,C53,newton metre second,nan,1,N·m·s,N x m x s
+446,nan,C54,newton metre squared per kilogram squared,nan,1,N·m²/kg²,N x m²/kg²
+447,nan,C55,newton per square metre,nan,1S,N/m²,Pa
+448,nan,C56,newton per square millimetre,nan,1S,N/mm²,10⁶ Pa
+449,nan,C57,newton second,nan,1,N·s,N x s
+450,nan,C58,newton second per metre,nan,1,N·s/m,N x s/m
+451,nan,C59,octave,A unit used in music to describe the ratio in frequency between notes.,1,nan,nan
+452,X,C6,cell,nan,3.9,nan,nan
+453,nan,C60,ohm centimetre,nan,1S,Ω·cm,10⁻² Ω x m 
+454,nan,C61,ohm metre,nan,1,Ω·m,Ω x m
+455,nan,C62,one,Synonym: unit,1,1,1
+456,nan,C63,parsec,nan,1,pc,"3,085 678 x 10¹⁶ m"
+457,nan,C64,pascal per kelvin,nan,1,Pa/K,Pa/K
+458,nan,C65,pascal second,nan,1,Pa·s,Pa x s
+459,nan,C66,pascal second per cubic metre,nan,1,Pa·s/m³,Pa x s/m³
+460,nan,C67,pascal second per metre,nan,1,Pa· s/m,Pa x s/m
+461,nan,C68,petajoule,nan,1S,PJ,10¹⁵ J
+462,nan,C69,phon,A unit of subjective sound loudness. A sound has loudness p phons if it seems to the listener to be equal in loudness to the sound of a pure tone of frequency 1 kilohertz and strength p decibels.,1,nan,nan
+463,nan,C7,centipoise,nan,2,cP,10⁻³ Pa x s
+464,nan,C70,picoampere,nan,1S,pA,10⁻¹² A
+465,nan,C71,picocoulomb,nan,1S,pC,10⁻¹² C
+466,nan,C72,picofarad per metre,nan,1S,pF/m,10⁻¹² F/m
+467,nan,C73,picohenry,nan,1S,pH,10⁻¹² H
+468,nan,C74,kilobit per second,A unit of information equal to 10³ (1000) bits (binary digits) per second.,3.6,kbit/s,10³ bit/s
+469,nan,C75,picowatt,nan,1S,pW,10⁻¹² W
+470,nan,C76,picowatt per square metre,nan,1S,pW/m²,10⁻¹² W/m²
+471,X,C77,pound gage,nan,3.1,nan,nan
+472,nan,C78,pound-force,nan,2,lbf,"4,448 222 N"
+473,nan,C79,kilovolt ampere hour,A unit of accumulated energy of 1000 volt amperes over a period of one hour.,3.1,kVAh,nan
+474,nan,C8,millicoulomb per kilogram,nan,1S,mC/kg,10⁻³ C/kg
+475,nan,C80,rad,nan,2,rad,10⁻² Gy
+476,nan,C81,radian,nan,1,rad,rad
+477,nan,C82,radian square metre per mole,nan,1,rad·m²/mol,rad x m²/mol
+478,nan,C83,radian square metre per kilogram,nan,1,rad·m²/kg,rad x m²/kg
+479,nan,C84,radian per metre,nan,1,rad/m,rad/m
+480,nan,C85,reciprocal angstrom,nan,1,Å⁻¹,10¹⁰ m⁻¹
+481,nan,C86,reciprocal cubic metre,nan,1,m⁻³,m⁻³
+482,nan,C87,reciprocal cubic metre per second,Synonym: reciprocal second per cubic metre,1,m⁻³/s,m⁻³/s
+483,nan,C88,reciprocal electron volt per cubic metre,nan,1,eV⁻¹/m³,"6,241 46 x 10¹⁸ J⁻¹/m³"
+484,nan,C89,reciprocal henry,nan,1,H⁻¹,H⁻¹
+485,nan,C9,coil group,A unit of count defining the number of coil groups (coil group: groups of items arranged by lengths of those items placed in a joined sequence of concentric circles).,3.9,nan,nan
+486,nan,C90,reciprocal joule per cubic metre,nan,1,J⁻¹/m³,J⁻¹/m³
+487,nan,C91,reciprocal kelvin or kelvin to the power minus one,nan,1,K⁻¹,K⁻¹
+488,nan,C92,reciprocal metre,nan,1,m⁻¹,m⁻¹
+489,nan,C93,reciprocal square metre,Synonym: reciprocal metre squared,1,m⁻²,m⁻²
+490,nan,C94,reciprocal minute,nan,1S,min⁻¹,"1,666 667 x 10⁻² s"
+491,nan,C95,reciprocal mole,nan,1,mol⁻¹,mol⁻¹
+492,nan,C96,reciprocal pascal or pascal to the power minus one,nan,1,Pa⁻¹,Pa⁻¹
+493,nan,C97,reciprocal second,nan,1,s⁻¹,s⁻¹
+494,X,C98,reciprocal second per cubic metre,nan,1,s⁻¹/m³,s⁻¹/m³
+495,nan,C99,reciprocal second per metre squared,nan,1,s⁻¹/m²,s⁻¹/m²
+496,X,CA,can,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+497,nan,CCT,carrying capacity in metric ton,"A unit of mass defining the carrying capacity, expressed as the number of metric tons.",3.4,nan,nan
+498,nan,CDL,candela,nan,1,cd,cd
+499,nan,CEL,degree Celsius,Refer ISO 80000-5 (Quantities and units — Part 5: Thermodynamics),1,°C,1 x K
+500,nan,CEN,hundred,A unit of count defining the number of units in multiples of 100.,3.7,nan,100
+501,nan,CG,card,A unit of count defining the number of units of card (card: thick stiff paper or cardboard).,3.9,nan,nan
+502,nan,CGM,centigram,nan,1M,cg,10⁻⁵ kg
+503,X,CH,container,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.4,nan,nan
+504,X,CJ,cone,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.9,nan,nan
+505,X,CK,connector,nan,3.9,nan,nan
+506,nan,CKG,coulomb per kilogram,nan,1,C/kg,A x s/kg
+507,X,CL,coil,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+508,nan,CLF,hundred leave,"A unit of count defining the number of leaves, expressed in units of one hundred leaves.",3.8,nan,nan
+509,nan,CLT,centilitre,nan,1S,cl,10⁻⁵ m³
+510,nan,CMK,square centimetre,nan,1S,cm²,10⁻⁴ m²
+511,nan,CMQ,cubic centimetre,nan,1S,cm³,10⁻⁶ m³
+512,nan,CMT,centimetre,nan,"1S,3.5",cm,10⁻² m
+513,nan,CNP,hundred pack,A unit of count defining the number of hundred-packs (hundred-pack: set of one hundred items packaged together).,"3.2,3.8",nan,nan
+514,nan,CNT,cental (UK),A unit of mass equal to one hundred weight (US).,3.5,nan,"45,359 237 kg"
+515,X,CO,carboy,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+516,nan,COU,coulomb,nan,1,C,A x s
+517,X,CQ,cartridge,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.9,nan,nan
+518,X,CR,crate,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+519,X,CS,case,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+520,X,CT,carton,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+521,nan,CTG,content gram,A unit of mass defining the number of grams of a named item in a product.,3.1,nan,nan
+522,nan,CTM,metric carat,nan,3.5,nan,200 mg
+523,nan,CTN,content ton (metric),A unit of mass defining the number of metric tons of a named item in a product.,3.1,nan,nan
+524,X,CU,cup,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+525,nan,CUR,curie,nan,2,Ci,"3,7 x 10¹⁰ Bq"
+526,X,CV,cover,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+527,nan,CWA,hundred pound (cwt) / hundred weight (US),nan,2,cwt (US),"45,359 2 kg"
+528,nan,CWI,hundred weight (UK),nan,2,cwt (UK),"50,802 35 kg"
+529,X,CY,cylinder,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+530,X,CZ,combo,nan,3.9,nan,nan
+531,nan,D03,kilowatt hour per hour,A unit of accumulated energy of a thousand watts over a period of one hour.,3.1,kW·h/h,nan
+532,nan,D04,lot [unit of weight],A unit of weight equal to about 1/2 ounce or 15 grams.,3.2,nan,nan
+533,nan,D1,reciprocal second per steradian,nan,1,s⁻¹/sr,s⁻¹/sr
+534,nan,D10,siemens per metre,nan,1,S/m,S/m
+535,nan,D11,mebibit,A unit of information equal to 2²⁰ (1048576) bits (binary digits).,3.6,Mibit,nan
+536,nan,D12,siemens square metre per mole,nan,1,S·m²/mol,S x m²/mol
+537,nan,D13,sievert,nan,1,Sv,m²/s²
+538,X,D14,thousand linear yard,nan,3.8,nan,nan
+539,nan,D15,sone,A unit of subjective sound loudness. One sone is the loudness of a pure tone of frequency one kilohertz and strength 40 decibels.,1,nan,nan
+540,nan,D16,square centimetre per erg,nan,2,cm²/erg,10³ m²/J
+541,nan,D17,square centimetre per steradian erg,nan,2,cm²/(sr·erg),10³ m²/(sr x J)
+542,nan,D18,metre kelvin,nan,1,m·K,m x K
+543,nan,D19,square metre kelvin per watt,nan,1,m²·K/W,m² x K/W
+544,nan,D2,reciprocal second per steradian metre squared,nan,1,s⁻¹/(sr·m²),s⁻¹/(sr x m²)
+545,nan,D20,square metre per joule,nan,1,m²/J,m²/J
+546,nan,D21,square metre per kilogram,nan,1,m²/kg,m²/kg
+547,nan,D22,square metre per mole,nan,1,m²/mol,m²/mol
+548,nan,D23,pen gram (protein),A unit of count defining the number of grams of amino acid prescribed for parenteral/enteral therapy.,3.9,nan,nan
+549,nan,D24,square metre per steradian,nan,1,m²/sr,m²/sr
+550,nan,D25,square metre per steradian joule,nan,1,m²/(sr·J),m²/(sr x J)
+551,nan,D26,square metre per volt second,nan,1,m²/(V·s),m²/(V x s)
+552,nan,D27,steradian,nan,1,sr,sr
+553,X,D28,syphon,nan,3.9,nan,nan
+554,nan,D29,terahertz,nan,1S,THz,10¹² Hz
+555,nan,D30,terajoule,nan,1S,TJ,10¹² J
+556,nan,D31,terawatt,nan,1S,TW,10¹² W
+557,nan,D32,terawatt hour,nan,1S,TW·h,"3,6 x 10¹⁵ J"
+558,nan,D33,tesla,nan,1,T,T
+559,nan,D34,tex,A unit of yarn density. One decitex equals a mass of 1 gram per 1 kilometre of length.,3.5,tex (g/km),10⁻⁶ kg/m
+560,D,D35,calorie (thermochemical),nan,2,calth,"4,184 J"
+561,nan,D36,megabit,A unit of information equal to 10⁶ (1000000) bits (binary digits).,3.6,Mbit,nan
+562,D,D37,calorie (thermochemical) per gram kelvin,nan,2,calth/(g·K),"4,184 x 10³ J/(kg x K)"
+563,D,D38,calorie (thermochemical) per second centimetre kelvin,nan,2,calth/(s·cm·K),"418,4 W/(m x K)"
+564,D,D39,calorie (thermochemical) per second square centimetre kelvin,nan,2,calth/(s·cm²·K),"4,184 x10⁴ W/(m² x K)"
+565,X,D40,thousand litre,nan,3.8,nan,m³
+566,nan,D41,tonne per cubic metre,nan,1S,t/m³,10³ kg/m³
+567,nan,D42,tropical year,nan,2,y (tropical),"3,155 692 5 x 10⁷ s"
+568,nan,D43,unified atomic mass unit,nan,1,u,"1,660 538 782 x 10⁻²⁷ kg"
+569,nan,D44,var,The name of the unit is an acronym for volt-ampere-reactive.,1,var,V x A
+570,nan,D45,volt squared per kelvin squared,nan,1,V²/K²,V²/K²
+571,nan,D46,volt - ampere,nan,1,V·A,W
+572,nan,D47,volt per centimetre,nan,1S,V/cm,V/m x 10²
+573,nan,D48,volt per kelvin,nan,1,V/K,V/K
+574,nan,D49,millivolt per kelvin,nan,1S,mV/K,10⁻³ V/K
+575,nan,D5,kilogram per square centimetre,nan,2,kg/cm²,10⁴ kg/m²
+576,nan,D50,volt per metre,nan,1,V/m,V/m
+577,nan,D51,volt per millimetre,nan,1S,V/mm,10³ V/m
+578,nan,D52,watt per kelvin,nan,1,W/K,W/K
+579,nan,D53,watt per metre kelvin,nan,1,W/(m·K),W/(m x K)
+580,nan,D54,watt per square metre,nan,1,W/m²,W/m²
+581,nan,D55,watt per square metre kelvin,nan,1,W/(m²·K),W/(m² x K)
+582,nan,D56,watt per square metre kelvin to the fourth power,nan,1,W/(m²·K⁴),W/(m² x K⁴)
+583,nan,D57,watt per steradian,nan,1,W/sr,W/sr
+584,nan,D58,watt per steradian square metre,nan,1,W/(sr·m²),W/(sr x m²)
+585,nan,D59,weber per metre,nan,1,Wb/m,Wb/m
+586,nan,D6,roentgen per second,nan,2,R/s,"2,58 x 10⁻⁴ C/(kg x s)"
+587,nan,D60,weber per millimetre,nan,1S,Wb/mm,10³ Wb/m
+588,nan,D61,minute [unit of angle],nan,1,',"2,908 882 x 10⁻⁴ rad"
+589,nan,D62,second [unit of angle],nan,1,"""","4,848 137 x 10⁻⁶ rad"
+590,nan,D63,book,A unit of count defining the number of books (book: set of items bound together or written document of a material whole).,3.9,nan,nan
+591,X,D64,block,nan,3.9,nan,nan
+592,nan,D65,round,A unit of count defining the number of rounds (round: A circular or cylindrical object).,3.9,nan,nan
+593,X,D66,cassette,nan,3.9,nan,nan
+594,X,D67,dollar per hour,nan,3.9,nan,nan
+595,nan,D68,number of words,A unit of count defining the number of words.,3.7,nan,nan
+596,nan,D69,inch to the fourth power,nan,2,in⁴,"41,623 14 x 10⁻⁸ m⁴"
+597,X,D7,sandwich,nan,3.9,nan,nan
+598,D,D70,calorie (international table),nan,2,calIT,"4,186 8 J"
+599,D,D71,calorie (international table) per second centimetre kelvin,nan,2,calIT/(s·cm·K),"418,68 W/(m x K)"
+600,D,D72,calorie (international table) per second square centimetre kelvin,nan,2,calIT/(s·cm²·K),"4,186 8 x 10⁴ W/(m² x K)"
+601,nan,D73,joule square metre,nan,1,J·m²,J x m²
+602,nan,D74,kilogram per mole,nan,1,kg/mol,kg/mol
+603,D,D75,calorie (international table) per gram,nan,2,calIT/g,"4 186,8 J/kg"
+604,D,D76,calorie (international table) per gram kelvin,nan,2,calIT/(g·K),"4 186,8 J/(kg x K)"
+605,nan,D77,megacoulomb,nan,1S,MC,10⁶ C
+606,nan,D78,megajoule per second,A unit of accumulated energy equal to one million joules per second.,3.1,MJ/s,nan
+607,X,D79,beam,nan,3.3,nan,nan
+608,X,D8,draize score,nan,3.7,nan,nan
+609,nan,D80,microwatt,nan,1S,µW,10⁻⁶ W
+610,nan,D81,microtesla,nan,1S,µT,10⁻⁶ T
+611,nan,D82,microvolt,nan,1S,µV,10⁻⁶ V
+612,nan,D83,millinewton metre,nan,1S,mN·m,10⁻³ N x m
+613,nan,D85,microwatt per square metre,nan,1S,µW/m²,10⁻⁶ W/m²
+614,nan,D86,millicoulomb,nan,1S,mC,10⁻³ C
+615,nan,D87,millimole per kilogram,nan,1S,mmol/kg,10⁻³ mol/kg
+616,nan,D88,millicoulomb per cubic metre,nan,1S,mC/m³,10⁻³ C/m³
+617,nan,D89,millicoulomb per square metre,nan,1S,mC/m²,10⁻³ C/m²
+618,D,D9,dyne per square centimetre,nan,"2,3.9",dyn/cm²,10⁻¹ Pa
+619,X,D90,cubic metre (net),nan,3.1,nan,nan
+620,nan,D91,rem,nan,2,rem,10⁻² Sv
+621,X,D92,band,nan,3.9,nan,nan
+622,nan,D93,second per cubic metre,nan,1,s/m³,s/m³
+623,nan,D94,second per cubic metre radian,nan,1,s/(rad·m³),s/(rad x m³)
+624,nan,D95,joule per gram,nan,1S,J/g,J/(10⁻³ x kg)
+625,X,D96,pound gross,nan,3.1,nan,nan
+626,X,D97,pallet/unit load,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.4,nan,nan
+627,X,D98,mass pound,nan,3.1,nan,nan
+628,X,D99,sleeve,nan,3.3,nan,nan
+629,nan,DAA,decare,nan,1M,daa,10³ m²
+630,nan,DAD,ten day,A unit of time defining the number of days in multiples of 10.,3.2,nan,nan
+631,nan,DAY,day,nan,1,d,86 400 s
+632,nan,DB,dry pound,"A unit of mass defining the number of pounds of a product, disregarding the water content of the product.",3.1,nan,nan
+633,X,DC,disk (disc),nan,3.9,nan,nan
+634,nan,DD,degree [unit of angle],nan,1,°,"1,745 329 x 10⁻² rad"
+635,X,DE,deal,nan,3.9,nan,nan
+636,nan,DEC,decade,A unit of count defining the number of decades (decade: quantity equal to 10 or time equal to 10 years).,3.8,nan,nan
+637,nan,DG,decigram,nan,1M,dg,10⁻⁴ kg
+638,X,DI,dispenser,nan,3.3,nan,nan
+639,nan,DJ,decagram,nan,1M,dag,10⁻² kg
+640,nan,DLT,decilitre,nan,1M,dl,10⁻⁴ m³
+641,nan,DMA,cubic decametre,nan,1S,dam³,10³ m³
+642,nan,DMK,square decimetre,nan,1S,dm²,10⁻² m²
+643,nan,DMO,standard kilolitre,"A unit of volume defining the number of kilolitres of a product at a temperature of 15 degrees Celsius, especially in relation to hydrocarbon oils.",3.1,nan,nan
+644,nan,DMQ,cubic decimetre,nan,1S,dm³,10⁻³ m³
+645,nan,DMT,decimetre,nan,1M,dm,10⁻¹ m
+646,nan,DN,decinewton metre,nan,1S,dN·m,10⁻¹ N x m
+647,nan,DPC,dozen piece,"A unit of count defining the number of pieces in multiples of 12 (piece: a single item, article or exemplar).",3.2,nan,nan
+648,nan,DPR,dozen pair,A unit of count defining the number of pairs in multiples of 12 (pair: item described by two's).,3.2,nan,nan
+649,nan,DPT,displacement tonnage,"A unit of mass defining the volume of sea water a ship displaces, expressed as the number of tons.",3.4,nan,nan
+650,X,DQ,data record,nan,3.6,nan,nan
+651,X,DR,drum,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+652,nan,DRA,dram (US),"Synonym: drachm (UK), troy dram",3.5,nan,"3,887 935 g"
+653,nan,DRI,dram (UK),Synonym: avoirdupois dram,3.5,nan,"1,771 745 g"
+654,nan,DRL,dozen roll,"A unit of count defining the number of rolls, expressed in twelve roll units.",3.2,nan,nan
+655,X,DRM,drachm (UK),nan,3.5,nan,"3,887 935 g"
+656,X,DS,display,nan,3.9,nan,nan
+657,nan,DT,dry ton,"A unit of mass defining the number of tons of a product, disregarding the water content of the product.",3.1,nan,nan
+658,nan,DTN,decitonne,"Synonym: centner, metric 100 kg; quintal, metric 100 kg","1M,3.5",dt or dtn,10² kg
+659,D,DU,dyne,nan,2,dyn,10⁻⁵ N
+660,nan,DWT,pennyweight,nan,3.5,nan,"1,555 174 g"
+661,D,DX,dyne per centimetre,nan,2,dyn/cm,10⁻³ N/m
+662,X,DY,directory book,nan,3.9,nan,nan
+663,nan,DZN,dozen,A unit of count defining the number of units in multiples of 12.,3.7,DOZ,12
+664,nan,DZP,dozen pack,A unit of count defining the number of packs in multiples of 12 (pack: standard packaging unit).,3.2,nan,nan
+665,nan,E01,newton per square centimetre,A measure of pressure expressed in newtons per square centimetre.,1M,N/cm²,10⁴ Pa
+666,nan,E07,megawatt hour per hour,A unit of accumulated energy of a million watts over a period of one hour.,3.1,MW·h/h,nan
+667,nan,E08,megawatt per hertz,A unit of energy expressed as the load change in million watts that will cause a frequency shift of one hertz.,3.1,MW/Hz,nan
+668,nan,E09,milliampere hour,A unit of power load delivered at the rate of one thousandth of an ampere over a period of one hour.,1M,mA·h,"3,6 C"
+669,nan,E10,degree day,A unit of measure used in meteorology and engineering to measure the demand for heating or cooling over a given period of days.,3.5,deg da,nan
+670,D,E11,gigacalorie,A unit of heat energy equal to one thousand million calories.,3.5,nan,10⁹ cal
+671,nan,E12,mille,A unit of count defining the number of cigarettes in units of 1000.,3.9,nan,nan
+672,nan,E14,kilocalorie (international table),A unit of heat energy equal to one thousand calories.,2,kcalIT,"4,186 8 x 10³ J"
+673,nan,E15,kilocalorie (thermochemical) per hour,A unit of energy equal to one thousand calories per hour.,2,kcalth/h,"1,162 22 W"
+674,nan,E16,million Btu(IT) per hour,A unit of power equal to one million British thermal units per hour.,3.1,BtuIT/h,"293 071,1 W"
+675,nan,E17,cubic foot per second,A unit of volume equal to one cubic foot passing a given point in a period of one second.,3.1,ft³/s,"2,831 685 x 10⁻² m³/s"
+676,nan,E18,tonne per hour,A unit of weight or mass equal to one tonne per hour.,2,t/h,"2,777 78 x 10⁻¹ kg/s"
+677,nan,E19,ping,A unit of area equal to 3.3 square metres.,3.1,nan,"3,305 m²"
+678,X,E2,belt,nan,3.9,nan,nan
+679,nan,E20,megabit per second,A unit of information equal to 10⁶ (1000000) bits (binary digits) per second.,3.6,Mbit/s,nan
+680,nan,E21,shares,A unit of count defining the number of shares (share: a total or portion of the parts into which a business entity’s capital is divided).,3.7,nan,nan
+681,nan,E22,TEU,A unit of count defining the number of twenty-foot equivalent units (TEUs) as a measure of containerized cargo capacity.,3.4,nan,nan
+682,nan,E23,tyre,"A unit of count defining the number of tyres (a solid or air-filled covering placed around a wheel rim to form a soft contact with the road, absorb shock and provide traction).",3.7,nan,nan
+683,nan,E25,active unit,A unit of count defining the number of active units within a substance.,3.9,nan,nan
+684,nan,E27,dose,A unit of count defining the number of doses (dose: a definite quantity of a medicine or drug).,3.9,nan,nan
+685,nan,E28,air dry ton,"A unit of mass defining the number of tons of a product, disregarding the water content of the product.",3.1,nan,nan
+686,X,E3,trailer,nan,3.4,nan,nan
+687,nan,E30,strand,"A unit of count defining the number of strands (strand: long, thin, flexible, single thread, strip of fibre, constituent filament or multiples of the same, twisted together).",3.7,nan,nan
+688,nan,E31,square metre per litre,A unit of count defining the number of square metres per litre.,3.1,m²/l,nan
+689,nan,E32,litre per hour,A unit of count defining the number of litres per hour.,3.1,l/h,"2,777 78 x 10⁻⁷ m³/s"
+690,nan,E33,foot per thousand,A unit of count defining the number of feet per thousand units.,3.1,nan,"3,048 x 10⁻⁴ m"
+691,nan,E34,gigabyte,A unit of information equal to 10⁹ bytes.,3.6,Gbyte,nan
+692,nan,E35,terabyte,A unit of information equal to 10¹² bytes.,3.6,Tbyte,nan
+693,nan,E36,petabyte,A unit of information equal to 10¹⁵ bytes.,3.6,Pbyte,nan
+694,nan,E37,pixel,A unit of count defining the number of pixels (pixel: picture element).,3.6,nan,nan
+695,nan,E38,megapixel,A unit of count equal to 10⁶ (1000000) pixels (picture elements).,3.6,nan,nan
+696,nan,E39,dots per inch,A unit of information defining the number of dots per linear inch as a measure of the resolution or sharpness of a graphic image.,3.6,dpi,nan
+697,nan,E4,gross kilogram,A unit of mass defining the total number of kilograms before deductions.,3.1,nan,nan
+698,nan,E40,part per hundred thousand,A unit of proportion equal to 10⁻⁵.,3.7,ppht,1 x 10⁻⁵
+699,nan,E41,kilogram-force per square millimetre,A unit of pressure defining the number of kilograms force per square millimetre.,2,kgf/mm²,"9,806 65 x 10⁶ Pa"
+700,nan,E42,kilogram-force per square centimetre,A unit of pressure defining the number of kilograms force per square centimetre.,2,kgf/cm²,"9,806 65 x 10⁴ Pa"
+701,nan,E43,joule per square centimetre,A unit of energy defining the number of joules per square centimetre.,1M,J/cm²,10⁴ J/m²
+702,nan,E44,kilogram-force metre per square centimetre,A unit of torsion defining the torque kilogram-force metre per square centimetre.,3.5,kgf·m/cm²,nan
+703,nan,E45,milliohm,nan,1S,mΩ,10⁻³ Ω
+704,nan,E46,kilowatt hour per cubic metre,A unit of energy consumption expressed as kilowatt hour per cubic metre.,3.1,kW·h/m³,"3,6 x 10⁶ J/m³"
+705,nan,E47,kilowatt hour per kelvin,A unit of energy consumption expressed as kilowatt hour per kelvin.,3.1,kW·h/K,"3,6 x 10⁶ J/K"
+706,nan,E48,service unit,A unit of count defining the number of service units (service unit: defined period / property / facility / utility of supply).,3.5,nan,nan
+707,nan,E49,working day,A unit of count defining the number of working days (working day: a day on which work is ordinarily performed).,3.5,nan,nan
+708,X,E5,metric long ton,Use ton (UK) or long ton (US) (common code LTN),3.1,nan,nan
+709,nan,E50,accounting unit,A unit of count defining the number of accounting units.,3.5,nan,nan
+710,nan,E51,job,A unit of count defining the number of jobs.,3.5,nan,nan
+711,nan,E52,run foot,A unit of count defining the number feet per run.,3.5,nan,nan
+712,nan,E53,test,A unit of count defining the number of tests.,3.5,nan,nan
+713,nan,E54,trip,A unit of count defining the number of trips.,3.5,nan,nan
+714,nan,E55,use,A unit of count defining the number of times an object is used.,3.5,nan,nan
+715,nan,E56,well,A unit of count defining the number of wells.,3.5,nan,nan
+716,nan,E57,zone,A unit of count defining the number of zones.,3.5,nan,nan
+717,nan,E58,exabit per second,A unit of information equal to 10¹⁸ bits (binary digits) per second.,3.6,Ebit/s,nan
+718,nan,E59,exbibyte,A unit of information equal to 2⁶⁰ bytes.,3.6,Eibyte,nan
+719,nan,E60,pebibyte,A unit of information equal to 2⁵⁰ bytes.,3.6,Pibyte,nan
+720,nan,E61,tebibyte,A unit of information equal to 2⁴⁰ bytes.,3.6,Tibyte,nan
+721,nan,E62,gibibyte,A unit of information equal to 2³⁰ bytes.,3.6,Gibyte,nan
+722,nan,E63,mebibyte,A unit of information equal to 2²⁰ bytes.,3.6,Mibyte,nan
+723,nan,E64,kibibyte,A unit of information equal to 2¹⁰ bytes.,3.6,Kibyte,nan
+724,nan,E65,exbibit per metre,A unit of information equal to 2⁶⁰ bits (binary digits) per metre.,3.6,Eibit/m,nan
+725,nan,E66,exbibit per square metre,A unit of information equal to 2⁶⁰ bits (binary digits) per square metre.,3.6,Eibit/m²,nan
+726,nan,E67,exbibit per cubic metre,A unit of information equal to 2⁶⁰ bits (binary digits) per cubic metre.,3.6,Eibit/m³,nan
+727,nan,E68,gigabyte per second,A unit of information equal to 10⁹ bytes per second.,3.6,Gbyte/s,nan
+728,nan,E69,gibibit per metre,A unit of information equal to 2³⁰ bits (binary digits) per metre.,3.6,Gibit/m,nan
+729,nan,E70,gibibit per square metre,A unit of information equal to 2³⁰ bits (binary digits) per square metre.,3.6,Gibit/m²,nan
+730,nan,E71,gibibit per cubic metre,A unit of information equal to 2³⁰ bits (binary digits) per cubic metre.,3.6,Gibit/m³,nan
+731,nan,E72,kibibit per metre,A unit of information equal to 2¹⁰ bits (binary digits) per metre.,3.6,Kibit/m,nan
+732,nan,E73,kibibit per square metre,A unit of information equal to 2¹⁰ bits (binary digits) per square metre.,3.6,Kibit/m²,nan
+733,nan,E74,kibibit per cubic metre,A unit of information equal to 2¹⁰ bits (binary digits) per cubic metre.,3.6,Kibit/m³,nan
+734,nan,E75,mebibit per metre,A unit of information equal to 2²⁰ bits (binary digits) per metre.,3.6,Mibit/m,nan
+735,nan,E76,mebibit per square metre,A unit of information equal to 2²⁰ bits (binary digits) per square metre.,3.6,Mibit/m²,nan
+736,nan,E77,mebibit per cubic metre,A unit of information equal to 2²⁰ bits (binary digits) per cubic metre.,3.6,Mibit/m³,nan
+737,nan,E78,petabit,A unit of information equal to 10¹⁵ bits (binary digits).,3.6,Pbit,nan
+738,nan,E79,petabit per second,A unit of information equal to 10¹⁵ bits (binary digits) per second.,3.6,Pbit/s,nan
+739,nan,E80,pebibit per metre,A unit of information equal to 2⁵⁰ bits (binary digits) per metre.,3.6,Pibit/m,nan
+740,nan,E81,pebibit per square metre,A unit of information equal to 2⁵⁰ bits (binary digits) per square metre.,3.6,Pibit/m²,nan
+741,nan,E82,pebibit per cubic metre,A unit of information equal to 2⁵⁰ bits (binary digits) per cubic metre.,3.6,Pibit/m³,nan
+742,nan,E83,terabit,A unit of information equal to 10¹² bits (binary digits).,3.6,Tbit,nan
+743,nan,E84,terabit per second,A unit of information equal to 10¹² bits (binary digits) per second.,3.6,Tbit/s,nan
+744,nan,E85,tebibit per metre,A unit of information equal to 2⁴⁰ bits (binary digits) per metre.,3.6,Tibit/m,nan
+745,nan,E86,tebibit per cubic metre,A unit of information equal to 2⁴⁰ bits (binary digits) per cubic metre.,3.6,Tibit/m³,nan
+746,nan,E87,tebibit per square metre,A unit of information equal to 2⁴⁰ bits (binary digits) per square metre.,3.6,Tibit/m²,nan
+747,nan,E88,bit per metre,A unit of information equal to 1 bit (binary digit) per metre.,3.6,bit/m,nan
+748,nan,E89,bit per square metre,A unit of information equal to 1 bit (binary digit) per square metre.,3.6,bit/m²,nan
+749,nan,E90,reciprocal centimetre,nan,3.1,cm⁻¹,10² m⁻¹
+750,nan,E91,reciprocal day,nan,3.1,d⁻¹,"1,157 41 × 10⁻⁵ s⁻¹"
+751,nan,E92,cubic decimetre per hour,nan,1S,dm³/h,"2,777 78 × 10⁻⁷ m³ x s⁻¹"
+752,nan,E93,kilogram per hour,nan,1S,kg/h,"2,777 78 × 10⁻⁴ kg x s⁻¹"
+753,nan,E94,kilomole per second,nan,1S,kmol/s,10³ s⁻¹ x mol
+754,nan,E95,mole per second,nan,1S,mol/s,s⁻¹ x mol
+755,nan,E96,degree per second,nan,1M,°/s,"1,745 329 x 10⁻² rad x s⁻¹"
+756,nan,E97,millimetre per degree Celcius metre,nan,1M,mm/(°C·m),10⁻³ K⁻¹
+757,nan,E98,degree Celsius per kelvin,nan,1M,°C/K,1.0
+758,nan,E99,hectopascal per bar,nan,1M,hPa/bar,10⁻³
+759,nan,EA,each,A unit of count defining the number of items regarded as separate units.,3.2,nan,nan
+760,nan,EB,electronic mail box,A unit of count defining the number of electronic mail boxes.,3.9,nan,nan
+761,X,EC,each per month,nan,3.9,nan,nan
+762,X,EP,eleven pack,nan,3.2,nan,nan
+763,nan,EQ,equivalent gallon,A unit of volume defining the number of gallons of product produced from concentrate.,3.1,nan,nan
+764,X,EV,envelope,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.9,nan,nan
+765,nan,F01,bit per cubic metre,A unit of information equal to 1 bit (binary digit) per cubic metre.,3.6,bit/m³,nan
+766,nan,F02,kelvin per kelvin,nan,1M,K/K,1.0
+767,nan,F03,kilopascal per bar,nan,1M,kPa/bar,10⁻²
+768,nan,F04,millibar per bar,nan,1M,mbar/bar,10⁻³
+769,nan,F05,megapascal per bar,nan,1M,MPa/bar,10¹
+770,nan,F06,poise per bar,nan,2,P/bar,10⁻⁶ s
+771,nan,F07,pascal per bar,nan,1M,Pa/bar,10⁻⁵
+772,nan,F08,milliampere per inch,nan,2,mA/in,"3,937 007 874 015 75 x 10⁻² A x m⁻¹"
+773,X,F1,thousand cubic foot per day,nan,3.8,nan,nan
+774,nan,F10,kelvin per hour,nan,1M,K/h,"2,777 78 × 10⁻⁴ s⁻¹ x K"
+775,nan,F11,kelvin per minute,nan,1M,K/min,"1,666 67 × 10⁻² s⁻¹ x K"
+776,nan,F12,kelvin per second,nan,1M,K/s,s⁻¹ x K
+777,nan,F13,slug,A unit of mass. One slug is the mass accelerated at 1 foot per second per second by a force of 1 pound.,2,slug,"1,459 390 x 10¹ kg"
+778,nan,F14,gram per kelvin,nan,1M,g/K,10⁻³ kg x K⁻¹
+779,nan,F15,kilogram per kelvin,nan,1M,kg/K,kg x K⁻¹
+780,nan,F16,milligram per kelvin,nan,1M,mg/K,10⁻⁶ kg x K⁻¹
+781,nan,F17,pound-force per foot,nan,2,lbf/ft,"1,459 39 × 10¹ kg x s⁻²"
+782,nan,F18,kilogram square centimetre,nan,1M,kg·cm²,10⁻⁴ kg m²
+783,nan,F19,kilogram square millimetre,nan,1M,kg·mm²,10⁻⁶ kg m²
+784,nan,F20,pound inch squared,nan,2,lb·in²,"2,926 397 x 10⁻⁴ kg x m²"
+785,nan,F21,pound-force inch,nan,2,lbf·in,"1,129 85 × 10⁻¹ kg x m² x s⁻²"
+786,nan,F22,pound-force foot per ampere,nan,2,lbf·ft/A,"1,355 82 kg x m² x s⁻² x A⁻¹"
+787,nan,F23,gram per cubic decimetre,nan,1M,g/dm³,kg x m⁻³
+788,nan,F24,kilogram per kilomol,nan,1M,kg/kmol,10⁻³ kg x mol⁻¹
+789,nan,F25,gram per hertz,nan,1M,g/Hz,10⁻³ kg x s
+790,nan,F26,gram per day,nan,1M,g/d,"1,157 41 × 10⁻⁸ kg x s⁻¹"
+791,nan,F27,gram per hour,nan,1M,g/h,"2,777 78 × 10⁻⁷ kg x s⁻¹"
+792,nan,F28,gram per minute,nan,1M,g/min,"1,666 67 × 10⁻⁵ kg x s⁻¹"
+793,nan,F29,gram per second,nan,1M,g/s,10⁻³ kg x s⁻¹
+794,nan,F30,kilogram per day,nan,1M,kg/d,"1,157 41 × 10⁻⁵ kg x s⁻¹"
+795,nan,F31,kilogram per minute,nan,1M,kg/min,"1,666 67 × 10⁻² kg x s⁻¹"
+796,nan,F32,milligram per day,nan,1M,mg/d,"1,157 41 × 10⁻¹¹ kg x s⁻¹"
+797,nan,F33,milligram per minute,nan,1M,mg/min,"1,666 67 × 10⁻⁸ kg x s⁻¹"
+798,nan,F34,milligram per second,nan,1M,mg/s,10⁻⁶ kg x s⁻¹
+799,nan,F35,gram per day kelvin,nan,1M,g/(d·K),"1,157 41 × 10⁻⁸ kg x s⁻¹ x K⁻¹"
+800,nan,F36,gram per hour kelvin,nan,1M,g/(h·K),"2,777 78 × 10⁻⁷ kg x s⁻¹ x K⁻¹"
+801,nan,F37,gram per minute kelvin,nan,1M,g/(min·K),"1,666 67 × 10⁻⁵ kg x s⁻¹ x K⁻¹"
+802,nan,F38,gram per second kelvin,nan,1M,g/(s·K),10⁻³ kg x s⁻¹ x K⁻¹
+803,nan,F39,kilogram per day kelvin,nan,1M,kg/(d·K),"1,157 41 × 10⁻⁵ kg x s⁻¹ x K⁻¹"
+804,nan,F40,kilogram per hour kelvin,nan,1M,kg/(h·K),"2,777 78 × 10⁻⁴ kg x s⁻¹ x K⁻¹"
+805,nan,F41,kilogram per minute kelvin,nan,1M,kg/(min·K),"1,666 67 × 10⁻²kg x s⁻¹ x K⁻¹"
+806,nan,F42,kilogram per second kelvin,nan,1M,kg/(s·K),kg x s⁻¹ x K⁻¹
+807,nan,F43,milligram per day kelvin,nan,1M,mg/(d·K),"1,157 41 × 10⁻¹¹ kg x s⁻¹ x K⁻¹"
+808,nan,F44,milligram per hour kelvin,nan,1M,mg/(h·K),"2,777 78 × 10⁻¹⁰ kg x s⁻¹ x K⁻¹"
+809,nan,F45,milligram per minute kelvin,nan,1M,mg/(min·K),"1,666 67 × 10⁻⁸ kg x s⁻¹ x K⁻¹"
+810,nan,F46,milligram per second kelvin,nan,1M,mg/(s·K),10⁻⁶ kg x s⁻¹ x K⁻¹
+811,nan,F47,newton per millimetre,nan,1M,N/mm,10³ kg x s⁻²
+812,nan,F48,pound-force per inch,nan,2,lbf/in,"1,751 27 × 10² kg x s⁻²"
+813,nan,F49,rod [unit of distance],A unit of distance equal to 5.5 yards (16 feet 6 inches).,2,rd (US),"5,029 210 m"
+814,nan,F50,micrometre per kelvin,nan,1M,µm/K,10⁻⁶ m x K⁻¹
+815,nan,F51,centimetre per kelvin,nan,1M,cm/K,10⁻² m x K⁻¹
+816,nan,F52,metre per kelvin,nan,1M,m/K,m x K⁻¹
+817,nan,F53,millimetre per kelvin,nan,1M,mm/K,10⁻³ m x K⁻¹
+818,nan,F54,milliohm per metre,nan,1M,mΩ/m,10⁻³ Ω/m
+819,nan,F55,ohm per mile (statute mile),nan,2,Ω/mi,"6,213 71 × 10⁻⁴  Ω/m"
+820,nan,F56,ohm per kilometre,nan,1M,Ω/km,10⁻³ Ω/m
+821,nan,F57,milliampere per pound-force per square inch,nan,2,mA/(lbf/in²),"1,450 38 × 10⁻⁷ kg⁻¹ x m x s² x A"
+822,nan,F58,reciprocal bar,nan,1M,1/bar,bar⁻¹
+823,nan,F59,milliampere per bar,nan,1M,mA/bar,10⁻⁸ kg⁻¹ x m x s² x A
+824,nan,F60,degree Celsius per bar,nan,1M,°C/bar,10⁻⁵ kg⁻¹ x m x s² x K
+825,nan,F61,kelvin per bar,nan,1M,K/bar,10⁻⁵ kg⁻¹ x m x s² x K
+826,nan,F62,gram per day bar,nan,1M,g/(d·bar),"1,157 41 × 10⁻¹³ m x s"
+827,nan,F63,gram per hour bar,nan,1M,g/(h·bar),"2,777 78 × 10⁻¹² m x s"
+828,nan,F64,gram per minute bar,nan,1M,g/(min·bar),"1,666 67 × 10⁻¹⁰ m x s"
+829,nan,F65,gram per second bar,nan,1M,g/(s·bar),10⁻⁸ m x s
+830,nan,F66,kilogram per day bar,nan,1M,kg/(d·bar),"1,157 41 × 10⁻¹⁰ m x s"
+831,nan,F67,kilogram per hour bar,nan,1M,kg/(h·bar),"2,777 78 × 10⁻⁹ m x s"
+832,nan,F68,kilogram per minute bar,nan,1M,kg/(min·bar),"1,666 67 × 10⁻⁷ m x s"
+833,nan,F69,kilogram per second bar,nan,1M,kg/(s·bar),10⁻⁵ m x s
+834,nan,F70,milligram per day bar,nan,1M,mg/(d·bar),"1,157 41 × 10⁻¹⁶ m x s"
+835,nan,F71,milligram per hour bar,nan,1M,mg/(h·bar),"2,777 78 × 10⁻¹⁵ m x s"
+836,nan,F72,milligram per minute bar,nan,1M,mg/(min·bar),"1,666 67 × 10⁻¹³ m x s"
+837,nan,F73,milligram per second bar,nan,1M,mg/(s·bar),10⁻¹¹ m x s
+838,nan,F74,gram per bar,nan,1M,g/bar,10⁻⁸ m x s²
+839,nan,F75,milligram per bar,nan,1M,mg/bar,10⁻¹¹ m x s²
+840,nan,F76,milliampere per millimetre,nan,1M,mA/mm,m⁻¹ x A
+841,nan,F77,pascal second per kelvin,nan,1M,Pa.s/K,kg x m⁻¹ x s⁻¹ x K⁻¹
+842,nan,F78,inch of water,nan,2,inH₂O,"2,490 89 × 10² kg x m⁻¹ x s⁻²"
+843,nan,F79,inch of mercury,nan,2,inHg,"3,386 39 × 10³ kg x m⁻¹ x s⁻²"
+844,nan,F80,water horse power,A unit of power defining the amount of power required to move a given volume of water against acceleration of gravity to a specified elevation (pressure head).,2,nan,"7,460 43 x 10² W"
+845,nan,F81,bar per kelvin,nan,1M,bar/K,10⁵ kg x m⁻¹ x s⁻² x K⁻¹
+846,nan,F82,hectopascal per kelvin,nan,1M,hPa/K,10² kg x m⁻¹ x s⁻² x K⁻¹
+847,nan,F83,kilopascal per kelvin,nan,1M,kPa/K,10³ kg x m⁻¹ x s⁻² x K⁻¹
+848,nan,F84,millibar per kelvin,nan,1M,mbar/K,10² kg x m⁻¹ x s⁻² x K⁻¹
+849,nan,F85,megapascal per kelvin,nan,1M,MPa/K,10⁶ kg x m⁻¹ x s⁻² x K⁻¹
+850,nan,F86,poise per kelvin,nan,2,P/K,10⁻¹ kg x m⁻¹ x s⁻¹ x K⁻¹
+851,nan,F87,volt per litre minute,nan,1M,V/(l·min),"1,666 67 × 10¹ kg x m⁻¹ x s⁻⁴ x A⁻¹"
+852,nan,F88,newton centimetre,nan,1M,N·cm,10⁻² kg x m² x s⁻²
+853,nan,F89,newton metre per degree,nan,1M,Nm/°,"57,295 788 kg x m² x s⁻² x rad⁻¹"
+854,X,F9,fibre per cubic centimetre of air,nan,3.9,nan,nan
+855,nan,F90,newton metre per ampere,nan,1M,N·m/A,kg x m² x s⁻² x A⁻¹
+856,nan,F91,bar litre per second,nan,1M,bar·l/s,10² kg x m² x s⁻³
+857,nan,F92,bar cubic metre per second,nan,1M,bar·m³/s,10⁵ kg x m² x s⁻³
+858,nan,F93,hectopascal litre per second,nan,1M,hPa·l/s,10⁻¹ kg x m² x s⁻³
+859,nan,F94,hectopascal cubic metre per second,nan,1M,hPa·m³/s,10² kg x m² x s⁻³
+860,nan,F95,millibar litre per second,nan,1M,mbar·l/s,10⁻¹ kg x m² x s⁻³
+861,nan,F96,millibar cubic metre per second,nan,1M,mbar·m³/s,10² kg x m² x s⁻³
+862,nan,F97,megapascal litre per second,nan,1M,MPa·l/s,10³ kg x m² x s⁻³
+863,nan,F98,megapascal cubic metre per second,nan,1M,MPa·m³/s,10⁶ kg x m² x s⁻³
+864,nan,F99,pascal litre per second,nan,1M,Pa·l/s,10⁻³ kg x m² x s⁻³
+865,nan,FAH,degree Fahrenheit,Refer ISO 80000-5 (Quantities and units — Part 5: Thermodynamics),2,°F,5/9 x K
+866,nan,FAR,farad,nan,1,F,F
+867,X,FB,field,nan,3.9,nan,nan
+868,nan,FBM,fibre metre,A unit of length defining the number of metres of individual fibre.,3.1,nan,nan
+869,nan,FC,thousand cubic foot,A unit of volume equal to one thousand cubic foot.,3.8,kft³,nan
+870,X,FD,million particle per cubic foot,nan,3.9,nan,nan
+871,X,FE,track foot,nan,3.5,nan,nan
+872,nan,FF,hundred cubic metre,A unit of volume equal to one hundred cubic metres.,3.8,nan,nan
+873,X,FG,transdermal patch,nan,3.9,nan,nan
+874,nan,FH,micromole,nan,1S,µmol,10⁻⁶ mol
+875,nan,FIT,failures in time,A unit of count defining the number of failures that can be expected over a specified time interval. Failure rates of semiconductor components are often specified as FIT (failures in time unit) where 1 FIT = 10⁻⁹ /h.,3.8,FIT,"2,777 78 × 10⁻¹³ s⁻¹"
+876,nan,FL,flake ton,A unit of mass defining the number of tons of a flaked substance (flake: a small flattish fragment).,3.1,nan,nan
+877,X,FM,million cubic foot,nan,3.8,Mft³,nan
+878,nan,FOT,foot,nan,2,ft,"0,304 8 m"
+879,nan,FP,pound per square foot,nan,2,lb/ft²,"4,882 428 kg/m²"
+880,nan,FR,foot per minute,nan,2,ft/min,"5,08 x 10⁻³ m/s"
+881,nan,FS,foot per second,nan,2,ft/s,"0,304 8 m/s"
+882,nan,FTK,square foot,nan,2,ft²,"9,290 304 x 10⁻² m²"
+883,nan,FTQ,cubic foot,nan,2,ft³,"2,831 685 x 10⁻² m³"
+884,nan,G01,pascal cubic metre per second,nan,1M,Pa·m³/s,kg x m² x s⁻³
+885,nan,G04,centimetre per bar,nan,1M,cm/bar,10⁻⁷ kg⁻¹ x m² x s²
+886,nan,G05,metre per bar,nan,1M,m/bar,10⁻⁵ kg⁻¹ x m² x s²
+887,nan,G06,millimetre per bar,nan,1M,mm/bar,10⁻⁸ kg⁻¹ x m² x s²
+888,nan,G08,square inch per second,nan,2,in²/s,"6,451 6 × 10⁻⁴ m² x s⁻¹"
+889,nan,G09,square metre per second kelvin,nan,1M,m²/(s·K),m² x s⁻¹ x K⁻¹
+890,nan,G10,stokes per kelvin,nan,2,St/K,10⁻⁴ m² x s⁻¹ x K⁻¹
+891,nan,G11,gram per cubic centimetre bar,nan,1M,g/(cm³·bar),10⁻² m⁻² x s²
+892,nan,G12,gram per cubic decimetre bar,nan,1M,g/(dm³·bar),10⁻⁵ m⁻² x s²
+893,nan,G13,gram per litre bar,nan,1M,g/(l·bar),10⁻⁵ m⁻² x s²
+894,nan,G14,gram per cubic metre bar,nan,1M,g/(m³·bar),10⁻⁸ m⁻² x s²
+895,nan,G15,gram per millilitre bar,nan,1M,g/(ml·bar),10⁻² m⁻² x s²
+896,nan,G16,kilogram per cubic centimetre bar,nan,1M,kg/(cm³·bar),10¹ m⁻² x s²
+897,nan,G17,kilogram per litre bar,nan,1M,kg/(l·bar),10⁻² m⁻² x s²
+898,nan,G18,kilogram per cubic metre bar,nan,1M,kg/(m³·bar),10⁻⁵ m⁻² x s²
+899,nan,G19,newton metre per kilogram,nan,1M,N·m/kg,m² x s⁻²
+900,nan,G2,US gallon per minute,nan,2,gal (US) /min,"6,309 020 x 10⁻⁵ m³/s"
+901,nan,G20,pound-force foot per pound,nan,2,lbf·ft/lb,"2,989 07 m² x s⁻²"
+902,nan,G21,cup [unit of volume],nan,2,cup (US),"2,365 882 x 10⁻⁴ m³"
+903,nan,G23,peck,nan,2,pk (US),"8,809 768 x 10⁻³ m³"
+904,nan,G24,tablespoon (US),nan,2,tablespoon (US),"1,478 676 x 10⁻⁵ m³"
+905,nan,G25,teaspoon (US),nan,2,teaspoon (US),"4,928 922 x 10⁻⁶ m³"
+906,nan,G26,stere,nan,1M,st,m³
+907,nan,G27,cubic centimetre per kelvin,nan,1M,cm³/K,10⁻⁶ m³ x K⁻¹
+908,nan,G28,litre per kelvin,nan,1M,l/K,10⁻³ m³ x K⁻¹
+909,nan,G29,cubic metre per kelvin,nan,1M,m³/K,m³ x K⁻¹
+910,nan,G3,Imperial gallon per minute,nan,2,gal (UK) /min,"7,576 82 x 10⁻⁵ m³/s"
+911,nan,G30,millilitre per kelvin,nan,1M,ml/K,10⁻⁶ m³ x K⁻¹
+912,nan,G31,kilogram per cubic centimetre,nan,1M,kg/cm³,10⁶ kg x m⁻³
+913,nan,G32,ounce (avoirdupois) per cubic yard,nan,2,oz/yd³,"3,707 98 × 10⁻² kg x m⁻³"
+914,nan,G33,gram per cubic centimetre kelvin,nan,1M,g/(cm³·K),10³ kg x m⁻³ x K⁻¹
+915,nan,G34,gram per cubic decimetre kelvin,nan,1M,g/(dm³·K),kg x m⁻³ x K⁻¹
+916,nan,G35,gram per litre kelvin,nan,1M,g/(l·K),kg x m⁻³ x K⁻¹
+917,nan,G36,gram per cubic metre kelvin,nan,1M,g/(m³·K),10⁻³ kg x m⁻³ x K⁻¹
+918,nan,G37,gram per millilitre kelvin,nan,1M,g/(ml·K),10³ kg x m⁻³ x K⁻¹
+919,nan,G38,kilogram per cubic centimetre kelvin,nan,1M,kg/(cm³·K),10⁶ kg x m⁻³ x K⁻¹
+920,nan,G39,kilogram per litre kelvin,nan,1M,kg/(l·K),10³ kg x m⁻³ x K⁻¹
+921,nan,G40,kilogram per cubic metre kelvin,nan,1M,kg/(m³·K),kg x m⁻³ x K⁻¹
+922,nan,G41,square metre per second bar,nan,1M,m²/(s·bar),10⁻⁵ kg⁻¹ x m³ x s
+923,nan,G42,microsiemens per centimetre,nan,1M,µS/cm,10⁻⁴ S/m
+924,nan,G43,microsiemens per metre,nan,1M,µS/m,10⁻⁶ S/m
+925,nan,G44,nanosiemens per centimetre,nan,1M,nS/cm,10⁻⁷ S/m
+926,nan,G45,nanosiemens per metre,nan,1M,nS/m,10⁻⁹ S/m
+927,nan,G46,stokes per bar,nan,2,St/bar,10⁻⁹ kg⁻¹ x m³ x s
+928,nan,G47,cubic centimetre per day,nan,1M,cm³/d,"1,157 41 × 10⁻¹¹ m³ x s⁻¹"
+929,nan,G48,cubic centimetre per hour,nan,1M,cm³/h,"2,777 78 × 10⁻¹⁰ m³ x s⁻¹"
+930,nan,G49,cubic centimetre per minute,nan,1M,cm³/min,"1,666 67 × 10⁻⁸ m³ x s⁻¹"
+931,nan,G50,gallon (US) per hour,nan,2,gal/h,"1,051 5 × 10⁻⁶ m³ x s⁻¹"
+932,nan,G51,litre per second,nan,1M,l/s,10⁻³ m³ x s⁻¹
+933,nan,G52,cubic metre per day,nan,1M,m³/d,"1,157 41 × 10⁻⁵ m³ x s⁻¹"
+934,nan,G53,cubic metre per minute,nan,1M,m³/min,"1,666 67 × 10⁻² m³ x s⁻¹"
+935,nan,G54,millilitre per day,nan,1M,ml/d,"1,157 41 × 10⁻¹¹ m³ x s⁻¹"
+936,nan,G55,millilitre per hour,nan,1M,ml/h,"2,777 78 × 10⁻¹⁰ m³ x s⁻¹"
+937,nan,G56,cubic inch per hour,nan,2,in³/h,"4,551 96 × 10⁻⁹ m³ x s⁻¹"
+938,nan,G57,cubic inch per minute,nan,2,in³/min,"2,731 18 × 10⁻⁷ m³ x s⁻¹"
+939,nan,G58,cubic inch per second,nan,2,in³/s,"1,638 71 × 10⁻⁵ m³ x s⁻¹"
+940,nan,G59,milliampere per litre minute,nan,1M,mA/(l·min),"1,666 67 × 10⁻² m⁻³ x s⁻¹ x A"
+941,nan,G60,volt per bar,nan,1M,V/bar,10⁻⁵ m³ x s⁻¹ x A⁻¹
+942,nan,G61,cubic centimetre per day kelvin,nan,1M,cm³/(d·K),"1,157 41 × 10⁻¹¹ m³ x s⁻¹ x K⁻¹"
+943,nan,G62,cubic centimetre per hour kelvin,nan,1M,cm³/(h·K),"2,777 78 × 10⁻¹⁰ m³ x s⁻¹ x K⁻¹"
+944,nan,G63,cubic centimetre per minute kelvin,nan,1M,cm³/(min·K),"1,666 67 × 10⁻⁸ m³ x s⁻¹ x K⁻¹"
+945,nan,G64,cubic centimetre per second kelvin,nan,1M,cm³/(s·K),10⁻⁶ m³ x s⁻¹ x K⁻¹
+946,nan,G65,litre per day kelvin,nan,1M,l/(d·K),"1,157 41 × 10⁻⁸ m³ x s⁻¹ x K⁻¹"
+947,nan,G66,litre per hour kelvin,nan,1M,l/(h·K),"2,777 78 × 10⁻⁷ m³ x s⁻¹ x K⁻¹"
+948,nan,G67,litre per minute kelvin,nan,1M,l/(min·K),"1,666 67 × 10⁻⁵ m³ x s⁻¹ x K⁻¹"
+949,nan,G68,litre per second kelvin,nan,1M,l/(s·K),10⁻³ m³ x s⁻¹ x K⁻¹
+950,nan,G69,cubic metre per day kelvin,nan,1M,m³/(d·K),"1,157 41 × 10⁻⁵ m³ x s⁻¹ x K⁻¹"
+951,X,G7,microfiche sheet,nan,3.9,nan,nan
+952,nan,G70,cubic metre per hour kelvin,nan,1M,m³/(h·K),"2,777 78 × 10⁻⁴ m³ x s⁻¹ x K⁻¹"
+953,nan,G71,cubic metre per minute kelvin,nan,1M,m³/(min·K),"1,666 67 × 10⁻² m³ x s⁻¹ x K⁻¹"
+954,nan,G72,cubic metre per second kelvin,nan,1M,m³/(s·K),m³ x s⁻¹ x K⁻¹
+955,nan,G73,millilitre per day kelvin,nan,1M,ml/(d·K),"1,157 41 × 10⁻¹¹ m³ x s⁻¹ x K⁻¹"
+956,nan,G74,millilitre per hour kelvin,nan,1M,ml/(h·K),"2,777 78 × 10⁻¹⁰ m³ x s⁻¹ x K⁻¹"
+957,nan,G75,millilitre per minute kelvin,nan,1M,ml/(min·K),"1,666 67 × 10⁻⁸ m³ x s⁻¹ x K⁻¹"
+958,nan,G76,millilitre per second kelvin,nan,1M,ml/(s·K),10⁻⁶ m³ x s⁻¹ x K⁻¹
+959,nan,G77,millimetre to the fourth power,nan,1M,mm⁴,10⁻¹² m⁴
+960,nan,G78,cubic centimetre per day bar,nan,1M,cm³/(d·bar),"1,157 41 × 10⁻¹⁶ kg⁻¹ x m⁴ x s"
+961,nan,G79,cubic centimetre per hour bar,nan,1M,cm³/(h·bar),"2,777 78 × 10⁻¹⁵ kg⁻¹ x m⁴ x s"
+962,nan,G80,cubic centimetre per minute bar,nan,1M,cm³/(min·bar),"1,666 67 × 10⁻¹³ kg⁻¹ x m⁴ x s"
+963,nan,G81,cubic centimetre per second bar,nan,1M,cm³/(s·bar),10⁻¹¹ kg⁻¹ x m⁴ x s
+964,nan,G82,litre per day bar,nan,1M,l/(d·bar),"1,157 41 × 10⁻¹³ kg⁻¹ x m⁴ x s"
+965,nan,G83,litre per hour bar,nan,1M,l/(h·bar),"2,777 78 × 10⁻¹² kg⁻¹ x m⁴ x s"
+966,nan,G84,litre per minute bar,nan,1M,l/(min·bar),"1,666 67 × 10⁻¹⁰ kg⁻¹ x m⁴ x s"
+967,nan,G85,litre per second bar,nan,1M,l/(s·bar),10⁻⁸ kg⁻¹ x m⁴ x s
+968,nan,G86,cubic metre per day bar,nan,1M,m³/(d·bar),"1,157 41 × 10⁻¹⁰ kg⁻¹ x m⁴ x s"
+969,nan,G87,cubic metre per hour bar,nan,1M,m³/(h·bar),"2,777 78 × 10⁻⁹ kg⁻¹ x m⁴ x s"
+970,nan,G88,cubic metre per minute bar,nan,1M,m³/(min·bar),"1,666 67 × 10⁻⁷ kg⁻¹ x m⁴ x s"
+971,nan,G89,cubic metre per second bar,nan,1M,m³/(s·bar),10⁻⁵ kg⁻¹ x m⁴ x s
+972,nan,G90,millilitre per day bar,nan,1M,ml/(d·bar),"1,157 41 x 10⁻¹⁶ x kg⁻¹ x m⁴ x s"
+973,nan,G91,millilitre per hour bar,nan,1M,ml/(h·bar),"2,777 78 x 10⁻¹⁵ x kg⁻¹ x m⁴ x s"
+974,nan,G92,millilitre per minute bar,nan,1M,ml/(min·bar),"1,666 67 × 10⁻¹³ x kg⁻¹ x m⁴ x s"
+975,nan,G93,millilitre per second bar,nan,1M,ml/(s·bar),10⁻¹¹ kg⁻¹ x m⁴ x s
+976,nan,G94,cubic centimetre per bar,nan,1M,cm³/bar,10⁻¹¹ kg⁻¹ x m⁴ x s²
+977,nan,G95,litre per bar,nan,1M,l/bar,10⁻⁸ kg⁻¹ x m⁴ x s²
+978,nan,G96,cubic metre per bar,nan,1M,m³/bar,10⁻⁵ kg⁻¹ x m⁴ x s²
+979,nan,G97,millilitre per bar,nan,1M,ml/bar,10⁻¹¹ kg⁻¹ x m⁴ x s²
+980,nan,G98,microhenry per kiloohm,nan,1M,µH/kΩ,10⁻⁹ s
+981,nan,G99,microhenry per ohm,nan,1M,µH/Ω,10⁻⁶ s
+982,nan,GB,gallon (US) per day,nan,3.5,gal (US)/d,"4,381 264 x 10⁻⁸ m³/s"
+983,nan,GBQ,gigabecquerel,nan,1M,GBq,10⁹ Bq
+984,X,GC,gram per 100 gram,nan,3.7,nan,nan
+985,X,GD,gross barrel,nan,3.1,nan,nan
+986,nan,GDW,"gram, dry weight","A unit of mass defining the number of grams of a product, disregarding the water content of the product.",3.1,nan,nan
+987,nan,GE,pound per gallon (US),nan,2,lb/gal (US),"1,198 264 x 10² kg/m³"
+988,nan,GF,gram per metre (gram per 100 centimetres),nan,1M,g/m,10⁻³ kg/m
+989,nan,GFI,gram of fissile isotope,A unit of mass defining the number of grams of a fissile isotope (fissile isotope: an isotope whose nucleus is able to be split when irradiated with low energy neutrons).,3.1,gi F/S,nan
+990,nan,GGR,great gross,A unit of count defining the number of units in multiples of 1728 (12 x 12 x 12).,3.7,nan,1728
+991,X,GH,half gallon (US),nan,3.8,nan,nan
+992,nan,GIA,gill (US),nan,3.5,gi (US),"1,182 941 x 10⁻⁴ m³"
+993,nan,GIC,"gram, including container","A unit of mass defining the number of grams of a product, including its container.",3.1,nan,nan
+994,nan,GII,gill (UK),nan,3.5,gi (UK),"1,420 653 x 10⁻⁴ m³"
+995,nan,GIP,"gram, including inner packaging","A unit of mass defining the number of grams of a product, including its inner packaging materials.",3.1,nan,nan
+996,nan,GJ,gram per millilitre,nan,1S,g/ml,10³ kg/m³
+997,X,GK,gram per kilogram,nan,3.7,nan,nan
+998,nan,GL,gram per litre,nan,1S,g/l,kg/m³
+999,nan,GLD,dry gallon (US),nan,2,dry gal (US),"4,404 884 x 10⁻³ m³"
+1000,nan,GLI,gallon (UK),nan,2,gal (UK),"4,546 092 x 10⁻³ m³"
+1001,nan,GLL,gallon (US),nan,2,gal (US),"3,785 412 x 10⁻³ m³"
+1002,nan,GM,gram per square metre,nan,1M,g/m²,10⁻³ kg/m²
+1003,X,GN,gross gallon,nan,3.1,nan,nan
+1004,nan,GO,milligram per square metre,nan,1,mg/m²,10⁻⁶ kg/m²
+1005,nan,GP,milligram per cubic metre,nan,1M,mg/m³,10⁻⁶ kg/m³
+1006,nan,GQ,microgram per cubic metre,nan,1M,µg/m³,10⁻⁹ kg/m³
+1007,nan,GRM,gram,nan,1S,g,10⁻³ kg
+1008,nan,GRN,grain,nan,2,gr,"64,798 91 x 10⁻⁶ kg"
+1009,nan,GRO,gross,A unit of count defining the number of units in multiples of 144 (12 x 12).,3.7,gr,144
+1010,D,GRT,gross register ton,"A unit of mass equal to the total cubic footage before deductions, where 1 register ton is equal to 100 cubic feet. Refer International Convention on tonnage measurement of ships.",3.4,nan,nan
+1011,D,GT,gross ton,"A unit of mass equal to 2240 pounds. Refer International Convention on Tonnage measurement of Ships.,Synonym: ton (UK) or long ton (US) (common code LTN)","3.1,3.4",nan,nan
+1012,nan,GV,gigajoule,nan,1S,GJ,10⁹ J
+1013,X,GW,gallon per thousand cubic foot,nan,3.5,nan,nan
+1014,nan,GWH,gigawatt hour,nan,1S,GW·h,"3,6 x 10¹² J"
+1015,X,GY,gross yard,nan,3.1,nan,nan
+1016,X,GZ,gage system,nan,3.9,nan,nan
+1017,nan,H03,henry per kiloohm,nan,1M,H/kΩ,10⁻³ s
+1018,nan,H04,henry per ohm,nan,1M,H/Ω,s
+1019,nan,H05,millihenry per kiloohm,nan,1M,mH/kΩ,10⁻⁶ s
+1020,nan,H06,millihenry per ohm,nan,1M,mH/Ω,10⁻³ s
+1021,nan,H07,pascal second per bar,nan,1M,Pa·s/bar,10⁻⁵ s
+1022,nan,H08,microbecquerel,nan,1M,µBq,10⁻⁶ Bq
+1023,nan,H09,reciprocal year,nan,1M,1/y,"3,168 81 x 10⁻⁸ s⁻¹"
+1024,X,H1,half page – electronic,nan,3.9,nan,nan
+1025,nan,H10,reciprocal hour,nan,1M,1/h,"2,777 78 × 10⁻⁴ s⁻¹"
+1026,nan,H11,reciprocal month,nan,1M,1/mo,"3,802 57 × 10⁻⁷ s⁻¹"
+1027,nan,H12,degree Celsius per hour,nan,1M,°C/h,"2,777 78 x 10⁻⁴ s⁻¹ K"
+1028,nan,H13,degree Celsius per minute,nan,1M,°C/min,"1,666 67 x 10⁻² s⁻¹ K"
+1029,nan,H14,degree Celsius per second,nan,1M,°C/s,s⁻¹ K
+1030,nan,H15,square centimetre per gram,nan,1M,cm²/g,10⁻¹ kg⁻¹ x m²
+1031,nan,H16,square decametre,Synonym: are,1S,dam²,10² m²
+1032,nan,H18,square hectometre,Synonym: hectare,1S,hm²,10⁴ m²
+1033,nan,H19,cubic hectometre,nan,1S,hm³,10⁶ m³
+1034,X,H2,half litre,nan,3.8,nan,nan
+1035,nan,H20,cubic kilometre,nan,1S,km³,10⁹ m³
+1036,nan,H21,blank,A unit of count defining the number of blanks.,3.2,nan,nan
+1037,nan,H22,volt square inch per pound-force,nan,2.0,V/(lbf/in²),"1,450 377 439 8 × 10⁻⁴ m³ x s⁻¹ x A⁻¹"
+1038,nan,H23,volt per inch,nan,2.0,V/in,"3,937 007 874 × 10¹ m x kg x s⁻³ x A⁻¹"
+1039,nan,H24,volt per microsecond,nan,1S,V/µs,10⁶ V/s
+1040,nan,H25,percent per kelvin,"A unit of proportion, equal to 0.01, in relation to the SI base unit Kelvin.",3.7,%/K,10⁻² K⁻¹
+1041,nan,H26,ohm per metre,nan,1M,Ω/m,Ω/m
+1042,nan,H27,degree per metre,nan,2,°/m,"1,745 329 x 10⁻² rad/m"
+1043,nan,H28,microfarad per kilometre,nan,1S,µF/km,10⁻⁹ F/m
+1044,nan,H29,microgram per litre,nan,1M,µg/l,10⁻⁶ m⁻³ x kg
+1045,nan,H30,square micrometre (square micron),nan,1S,µm²,10⁻¹² m²
+1046,nan,H31,ampere per kilogram,nan,1.0,A/kg,A x kg⁻¹
+1047,nan,H32,ampere squared second,nan,1.0,A²·s,A² x s
+1048,nan,H33,farad per kilometre,nan,1S,F/km,10⁻³ F/m
+1049,nan,H34,hertz metre,nan,2,Hz·m,Hz x m
+1050,nan,H35,kelvin metre per watt,nan,1.0,K·m/W,K x m⁻¹ x kg⁻¹ x s³
+1051,nan,H36,megaohm per kilometre,nan,1M,MΩ/km,10³ Ω/m
+1052,nan,H37,megaohm per metre,nan,1M,MΩ/m,10⁶ Ω/m
+1053,nan,H38,megaampere,nan,1S,MA,10⁶ A
+1054,nan,H39,megahertz kilometre,nan,2,MHz·km,10⁹ Hz x m
+1055,nan,H40,newton per ampere,nan,1.0,N/A,kg x m x s⁻² x A⁻¹
+1056,nan,H41,"newton metre watt to the power minus 0,5",nan,2.0,N·m·W⁻⁰‧⁵,kg x m² x s⁻² x W⁻⁰‧⁵
+1057,nan,H42,pascal per metre,nan,1M,Pa/m,m⁻² kg x s⁻²
+1058,nan,H43,siemens per centimetre,nan,1S,S/cm,10² S/m
+1059,nan,H44,teraohm,nan,1S,TΩ,10¹² Ω
+1060,nan,H45,volt second per metre,nan,1.0,V·s/m,m x kg x s⁻² x A⁻¹
+1061,nan,H46,volt per second,nan,1S,V/s,m² x kg x s⁻⁴ x A⁻¹
+1062,nan,H47,watt per cubic metre,nan,1.0,W/m³,m⁻¹ x kg x s⁻³
+1063,nan,H48,attofarad,nan,1S,aF,10⁻¹⁸ m⁻² x kg⁻¹ x s⁴ x A²
+1064,nan,H49,centimetre per hour,nan,1M,cm/h,"0,277 777 778 × 10⁻⁶ m x s⁻¹"
+1065,nan,H50,reciprocal cubic centimetre,nan,1M,cm⁻³,10⁶ m⁻³
+1066,nan,H51,decibel per kilometre,nan,1.0,dB/km,10⁻⁴ B/m
+1067,nan,H52,decibel per metre,nan,1.0,dB/m,10⁻¹ B/m
+1068,nan,H53,kilogram per bar,nan,1M,kg/bar,10⁻⁵ m x s²
+1069,nan,H54,kilogram per cubic decimetre kelvin,nan,1M,(kg/dm³)/K,10³ m⁻³ x kg x K⁻¹
+1070,nan,H55,kilogram per cubic decimetre bar,nan,1M,(kg/dm³)/bar,10⁻² m⁻² x s²
+1071,nan,H56,kilogram per square metre second,nan,1.0,kg/(m²·s),kg m⁻² x s⁻¹
+1072,nan,H57,inch per two pi radiant,nan,2.0,in/revolution,"2,54 x 10⁻² m/(2 x π x rad)"
+1073,nan,H58,metre per volt second,nan,1.0,m/(V·s),m⁻¹ x kg⁻¹ x s² x A
+1074,nan,H59,square metre per newton,nan,1.0,m²/N,m x kg⁻¹ x s²
+1075,nan,H60,cubic metre per cubic metre,nan,1M,m³/m³,1.0
+1076,nan,H61,millisiemens per centimetre,nan,1S,mS/cm,10⁻¹ S/m
+1077,nan,H62,millivolt per minute,nan,1M,mV/min,"1,666 666 667 × 10⁻⁵ m² x kg x s⁻⁴ x A⁻¹"
+1078,nan,H63,milligram per square centimetre,nan,1S,mg/cm²,10⁻² m⁻² x kg
+1079,nan,H64,milligram per gram,nan,1S,mg/g,10⁻³ 1
+1080,nan,H65,millilitre per cubic metre,nan,1M,ml/m³,10⁻⁶ 1
+1081,nan,H66,millimetre per year,nan,2.0,mm/y,"3,15576 × 10⁴ m x s⁻¹"
+1082,nan,H67,millimetre per hour,nan,2.0,mm/h,"0,277 777 778 × 10⁻⁷ m x s⁻¹"
+1083,nan,H68,millimole per gram,nan,1M,mmol/g,mol x kg⁻¹
+1084,nan,H69,picopascal per kilometre,nan,1M,pPa/km,10⁻¹⁵ m⁻² x kg x s⁻²
+1085,nan,H70,picosecond,nan,1.0,ps,10⁻¹² s
+1086,nan,H71,percent per month,"A unit of proportion, equal to 0.01, in relation to a month.",3.7,%/mo,nan
+1087,nan,H72,percent per hectobar,"A unit of proportion, equal to 0.01, in relation to 100-fold of the unit bar.",3.7,%/hbar,nan
+1088,nan,H73,percent per decakelvin,"A unit of proportion, equal to 0.01, in relation to 10-fold of the SI base unit Kelvin.",3.7,%/daK,10⁻³ K⁻¹
+1089,nan,H74,watt per metre,nan,1M,W/m,W m⁻¹
+1090,nan,H75,decapascal,nan,1M,daPa,10¹ Pa
+1091,nan,H76,gram per millimetre,nan,1M,g/mm,10¹ kg x m⁻¹
+1092,nan,H77,module width,A unit of measure used to describe the breadth of electronic assemblies as an installation standard or mounting dimension.,3,MW,nan
+1093,D,H78,conventional centimetre of water,nan,2,cm H₂O,"9,806 65 × 10¹ Pa"
+1094,nan,H79,French gauge,"A unit of distance used for measuring the diameter of small tubes such as urological instruments and catheters.,Synonym: French, Charrière, Charrière gauge",2,Fg,"0,333 333 333 × 10⁻³ m"
+1095,nan,H80,rack unit,A unit of measure used to describe the height in rack units of equipment intended for mounting in a 19-inch rack or a 23-inch rack. One rack unit is 1.75 inches (44.45 mm) high.,3,U or RU,"4,445 × 10⁻² m"
+1096,nan,H81,millimetre per minute,nan,1M,mm/min,"1,666 666 667 × 10⁻⁵ m x s⁻¹"
+1097,nan,H82,big point,A unit of length defining the number of big points (big point: Adobe software(US) defines the big point to be exactly 1/72 inch (0.013 888 9 inch or 0.352 777 8 millimeters)),3.5,bp,"0,352 777 8 × 10⁻³ m"
+1098,nan,H83,litre per kilogram,nan,1M,l/kg,10⁻³ m³ x kg⁻¹
+1099,nan,H84,gram millimetre,nan,1M,g·mm,10⁻⁶ kg x m
+1100,nan,H85,reciprocal week,nan,1M,1/wk,"1,647 989 452 868 × 10⁻⁶ s⁻¹"
+1101,nan,H87,piece,"A unit of count defining the number of pieces (piece: a single item, article or exemplar).",3.8,nan,nan
+1102,nan,H88,megaohm kilometre,nan,1S,MΩ·km,10⁹ Ω x m
+1103,nan,H89,percent per ohm,"A unit of proportion, equal to 0.01, in relation to the SI derived unit ohm.",3.7,%/Ω,10⁻² Ω⁻¹
+1104,nan,H90,percent per degree,"A unit of proportion, equal to 0.01, in relation to an angle of one degree.",3.7,%/°,"0,572 957 8 rad⁻¹"
+1105,nan,H91,percent per ten thousand,"A unit of proportion, equal to 0.01, in relation to multiples of ten thousand.",3.7,%/10000,10⁻⁶
+1106,nan,H92,percent per one hundred thousand,"A unit of proportion, equal to 0.01, in relation to multiples of one hundred thousand.",3.7,%/100000,10⁻⁷
+1107,nan,H93,percent per hundred,"A unit of proportion, equal to 0.01, in relation to multiples of one hundred.",3.7,%/100,10⁻⁴
+1108,nan,H94,percent per thousand,"A unit of proportion, equal to 0.01, in relation to multiples of one thousand.",3.7,%/1000,10⁻⁵
+1109,nan,H95,percent per volt,"A unit of proportion, equal to 0.01, in relation to the SI derived unit volt.",3.7,%/V,10⁻² V⁻¹
+1110,nan,H96,percent per bar,"A unit of proportion, equal to 0.01, in relation to an atmospheric pressure of one bar.",3.7,%/bar,10⁻⁷ Pa⁻¹
+1111,nan,H98,percent per inch,"A unit of proportion, equal to 0.01, in relation to an inch.",3.7,%/in,"0,393 700 8 m⁻¹"
+1112,nan,H99,percent per metre,"A unit of proportion, equal to 0.01, in relation to a metre.",3.7,%/m,10⁻² m⁻¹
+1113,nan,HA,hank,"A unit of length, typically for yarn.",3.9,nan,nan
+1114,D,HAR,hectare,Synonym: square hectometre,2.0,ha,10⁴ m²
+1115,nan,HBA,hectobar,nan,1M,hbar,10⁷ Pa
+1116,nan,HBX,hundred boxes,A unit of count defining the number of boxes in multiples of one hundred box units.,3.2,nan,nan
+1117,nan,HC,hundred count,A unit of count defining the number of units counted in multiples of 100.,3.7,nan,nan
+1118,X,HD,half dozen,nan,3.7,nan,6
+1119,nan,HDW,"hundred kilogram, dry weight","A unit of mass defining the number of hundred kilograms of a product, disregarding the water content of the product.",3.1,nan,nan
+1120,X,HE,hundredth of a carat,nan,3.5,nan,nan
+1121,nan,HEA,head,A unit of count defining the number of heads (head: a person or animal considered as one of a number).,3.5,nan,nan
+1122,X,HF,hundred foot,nan,3.8,nan,nan
+1123,nan,HGM,hectogram,nan,1M,hg,10⁻¹ kg
+1124,nan,HH,hundred cubic foot,A unit of volume equal to one hundred cubic foot.,3.8,nan,nan
+1125,X,HI,hundred sheet,nan,3.8,nan,nan
+1126,nan,HIU,hundred international unit,A unit of count defining the number of international units in multiples of 100.,3.7,nan,nan
+1127,D,HJ,metric horse power,nan,2,metric hp,"735,498 75 W"
+1128,X,HK,hundred kilogram,nan,3.8,nan,nan
+1129,nan,HKM,"hundred kilogram, net mass","A unit of mass defining the number of hundred kilograms of a product, after deductions.",3.1,nan,nan
+1130,X,HL,hundred foot (linear),nan,3.8,nan,nan
+1131,nan,HLT,hectolitre,nan,1S,hl,10⁻¹ m³
+1132,nan,HM,mile per hour (statute mile),nan,2,mile/h,"0,447 04 m/s"
+1133,nan,HMQ,million cubic metre,A unit of volume equal to one million cubic metres.,3.8,Mm³,nan
+1134,nan,HMT,hectometre,nan,1M,hm,10² m
+1135,D,HN,conventional millimetre of mercury,nan,2,mm Hg,"133,322 4 Pa"
+1136,X,HO,hundred troy ounce,nan,3.8,nan,nan
+1137,D,HP,conventional millimetre of water,nan,2,mm H₂O,"9,806 65 Pa"
+1138,nan,HPA,hectolitre of pure alcohol,A unit of volume equal to one hundred litres of pure alcohol.,3.1,nan,nan
+1139,X,HS,hundred square foot,nan,3.8,nan,nan
+1140,X,HT,half hour,nan,3.8,nan,nan
+1141,nan,HTZ,hertz,nan,1,Hz,Hz
+1142,nan,HUR,hour,nan,1,h,3 600 s
+1143,X,HY,hundred yard,nan,3.8,nan,nan
+1144,nan,IA,inch pound (pound inch),nan,2,in·lb,"1,152 12 x 10⁻² kg x m"
+1145,X,IC,count per inch,nan,3.9,nan,nan
+1146,nan,IE,person,A unit of count defining the number of persons.,3.9,nan,nan
+1147,X,IF,inches of water,Use inch of water (common code F78),3.1,nan,nan
+1148,X,II,column inch,nan,3.9,nan,nan
+1149,X,IL,inch per minute,nan,3.5,nan,nan
+1150,X,IM,impression,nan,3.9,nan,nan
+1151,nan,INH,inch,nan,2,in,"25,4 x 10⁻³ m"
+1152,nan,INK,square inch,nan,2,in²,"6,451 6 x 10⁻⁴ m²"
+1153,nan,INQ,cubic inch,Synonym: inch cubed,2,in³,"16,387 064 x 10⁻⁶ m³"
+1154,X,IP,insurance policy,nan,3.9,nan,nan
+1155,nan,ISD,international sugar degree,"A unit of measure defining the sugar content of a solution, expressed in degrees.",3.5,nan,nan
+1156,X,IT,count per centimetre,nan,3.9,nan,nan
+1157,nan,IU,inch per second,nan,2,in/s,"0,025 4 m/s"
+1158,nan,IUG,international unit per gram,A unit of count defining the number of international units per gram.,3.7,nan,nan
+1159,nan,IV,inch per second squared,nan,2,in/s²,"0,025 4 m/s²"
+1160,nan,J10,percent per millimetre,"A unit of proportion, equal to 0.01, in relation to a millimetre.",3.7,%/mm,10 m⁻¹
+1161,nan,J12,per mille per psi,A unit of pressure equal to one thousandth of a psi (pound-force per square inch).,3.7,‰/psi,"1,450 377 x 10⁻⁷ Pa⁻¹"
+1162,nan,J13,degree API,A unit of relative density as a measure of how heavy or light a petroleum liquid is compared to water (API: American Petroleum Institute).,3.5,°API,nan
+1163,nan,J14,degree Baume (origin scale),A traditional unit of relative density for liquids. Named after Antoine Baumé.,3.5,°Bé,nan
+1164,nan,J15,degree Baume (US heavy),A unit of relative density for liquids heavier than water.,3.5,°Bé (US heavy),nan
+1165,nan,J16,degree Baume (US light),A unit of relative density for liquids lighter than water.,3.5,°Bé (US light),nan
+1166,nan,J17,degree Balling,"A unit of density as a measure of sugar content, especially of beer wort. Named after Karl Balling.",3.5,°Balling,nan
+1167,nan,J18,degree Brix,A unit of proportion used in measuring the dissolved sugar-to-water mass ratio of a liquid. Named after Adolf Brix.,3.5,°Bx,nan
+1168,nan,J19,degree Fahrenheit hour square foot per British thermal unit (thermochemical),nan,2,°F·h·ft²/Btuth,"0,176 228 m² x K/W"
+1169,nan,J2,joule per kilogram,nan,1,J/kg,J/kg
+1170,nan,J20,degree Fahrenheit per kelvin,nan,2,°F/K,"0,555 555 6"
+1171,nan,J21,degree Fahrenheit per bar,nan,2,°F/bar,"0,555 555 6 x 10⁻⁵ K/Pa"
+1172,nan,J22,degree Fahrenheit hour square foot per British thermal unit (international table),nan,2,°F·h·ft²/BtuIT,"0,176 110 2 m² x K/W"
+1173,nan,J23,degree Fahrenheit per hour,nan,2,°F/h,"1,543 210 x 10⁻⁴ K/s"
+1174,nan,J24,degree Fahrenheit per minute,nan,2,°F/min,"9,259 259 x 10⁻³  K/s"
+1175,nan,J25,degree Fahrenheit per second,nan,2,°F/s,"0,555 555 6 K/s"
+1176,nan,J26,reciprocal degree Fahrenheit,nan,2,1/°F,"1,8 1/K"
+1177,nan,J27,degree Oechsle,"A unit of density as a measure of sugar content of must, the unfermented liqueur from which wine is made. Named after Ferdinand Oechsle.",3.5,°Oechsle,nan
+1178,nan,J28,degree Rankine per hour,nan,2,°R/h,"1,543 210 x 10⁻⁴ K/s"
+1179,nan,J29,degree Rankine per minute,nan,2,°R/min,"9,259 259 x 10⁻³  K/s"
+1180,nan,J30,degree Rankine per second,nan,2,°R/s,"0,555 555 6 K/s"
+1181,nan,J31,degree Twaddell,A unit of density for liquids that are heavier than water.  1 degree Twaddle represents a difference in specific gravity of 0.005.,3.5,°Tw,nan
+1182,nan,J32,micropoise,nan,2,µP,10⁻⁶ Pa x s
+1183,nan,J33,microgram per kilogram,nan,1S,µg/kg,10⁻⁹
+1184,nan,J34,microgram per cubic metre kelvin,nan,2,(µg/m³)/K,10⁻⁹ (kg/m³)/K
+1185,nan,J35,microgram per cubic metre bar,nan,2,(µg/m³)/bar,10⁻¹⁴ (kg/m³)/Pa
+1186,nan,J36,microlitre per litre,nan,1S,µl/l,10⁻⁶
+1187,nan,J38,baud,A unit of signal transmission speed equal to one signalling event per second.,3.6,Bd,nan
+1188,nan,J39,British thermal unit (mean),nan,2,Btu,"1,055 87 x 10³ J"
+1189,nan,J40,British thermal unit (international table) foot per hour square foot degree Fahrenheit,nan,2,BtuIT·ft/(h·ft²·°F),"1,730 735 W/(m x K)"
+1190,nan,J41,British thermal unit (international table) inch per hour square foot degree Fahrenheit,nan,2,BtuIT·in/(h·ft²·°F),"0,144 227 9 W/(m x K)"
+1191,nan,J42,British thermal unit (international table) inch per second square foot degree Fahrenheit,nan,2,BtuIT·in/(s·ft²·°F),"5,192 204 x 10² W/(m x K)"
+1192,nan,J43,British thermal unit (international table) per pound degree Fahrenheit,nan,2,BtuIT/(lb·°F),"4,186 8 x 10³ J/(kg x K)"
+1193,nan,J44,British thermal unit (international table) per minute,nan,2,BtuIT/min,"17,584 266 W"
+1194,nan,J45,British thermal unit (international table) per second,nan,2,BtuIT/s,"1,055 056 x 10³ W"
+1195,nan,J46,British thermal unit (thermochemical) foot per hour square foot degree Fahrenheit,nan,2,Btuth·ft/(h·ft²·°F),"1,729 577 W/(m x K)"
+1196,nan,J47,British thermal unit (thermochemical) per hour,nan,2,Btuth/h,"0,292 875 1 W"
+1197,nan,J48,British thermal unit (thermochemical) inch per hour square foot degree Fahrenheit,nan,2,Btuth·in/(h·ft²·°F),"0,144 131 4 W/(m x K)"
+1198,nan,J49,British thermal unit (thermochemical) inch per second square foot degree Fahrenheit,nan,2,Btuth·in/(s·ft²·°F),"5,188 732 x 10² W/(m x K)"
+1199,nan,J50,British thermal unit (thermochemical) per pound degree Fahrenheit,nan,2,Btuth/(lb·°F),"4,184 x 10³ J/(kg x K)"
+1200,nan,J51,British thermal unit (thermochemical) per minute,nan,2,Btuth/min,"17,572 50 W"
+1201,nan,J52,British thermal unit (thermochemical) per second,nan,2,Btuth/s,"1,054 350 x 10³ W"
+1202,nan,J53,coulomb square metre per kilogram,nan,2,C·m²/kg,C x m²/kg
+1203,nan,J54,megabaud,A unit of signal transmission speed equal to 10⁶ (1000000) signaling events per second.,3.6,MBd,10⁶ Bd
+1204,nan,J55,watt second,nan,1S,W·s,W x s
+1205,nan,J56,bar per bar,nan,2,bar/bar,1
+1206,nan,J57,barrel (UK petroleum),nan,2,bbl (UK liq.),"0,159 113 15 m³"
+1207,nan,J58,barrel (UK petroleum) per minute,nan,2,bbl (UK liq.)/min,"2,651 886 m³/s"
+1208,nan,J59,barrel (UK petroleum) per day,nan,2,bbl (UK liq.)/d,"1,841 587 4 x 10⁻⁶ m³/s"
+1209,nan,J60,barrel (UK petroleum) per hour,nan,2,bbl (UK liq.)/h,"4,419 810 x 10⁻⁵ m³/s"
+1210,nan,J61,barrel (UK petroleum) per second,nan,2,bbl (UK liq.)/s,"0,159 113 15 m³/s"
+1211,nan,J62,barrel (US petroleum) per hour,nan,2,bbl (US)/h,"4,416 314 x 10⁻⁵ m³/s"
+1212,nan,J63,barrel (US petroleum) per second,nan,2,bbl (US)/s,"0,158 987 3 m³/s"
+1213,nan,J64,bushel (UK) per day,nan,2,bu (UK)/d,"4,209 343 x 10⁻⁷ m³/s"
+1214,nan,J65,bushel (UK) per hour,nan,2,bu (UK)/h,"1,010 242 x 10⁻⁵ m³/s"
+1215,nan,J66,bushel (UK) per minute,nan,2,bu (UK)/min,"6,061 453 x 10⁻⁴ m³/s"
+1216,nan,J67,bushel (UK) per second,nan,2,bu (UK)/s,"3,636 872 x 10⁻² m³/s"
+1217,nan,J68,bushel (US dry) per day,nan,2,bu (US dry)/d,"4,078 596 x 10⁻⁷ m³/s"
+1218,nan,J69,bushel (US dry) per hour,nan,2,bu (US dry)/h,"9,788 631 x 10⁻⁶ m³/s"
+1219,nan,J70,bushel (US dry) per minute,nan,2,bu (US dry)/min,"5,873 178 x 10⁻⁴ m³/s"
+1220,nan,J71,bushel (US dry) per second,nan,2,bu (US dry)/s,"3,523 907 x 10⁻² m³/s"
+1221,nan,J72,centinewton metre,nan,1S,cN·m,10⁻² N x m
+1222,nan,J73,centipoise per kelvin,nan,2,cP/K,10⁻³  Pa x s/K
+1223,nan,J74,centipoise per bar,nan,2,cP/bar,10⁻⁸ s
+1224,nan,J75,calorie (mean),nan,2,cal,"4,190 02 J"
+1225,nan,J76,calorie (international table) per gram degree Celsius,nan,2,calIT/(g·°C),"4,186 8 x 10³ J/(kg x K)"
+1226,nan,J78,calorie (thermochemical) per centimetre second degree Celsius,nan,2,calth/(cm·s·°C),"4,184 x 10² W/(m x K)"
+1227,nan,J79,calorie (thermochemical) per gram degree Celsius,nan,2,calth/(g·°C),"4,184 x 10³ J/(kg x K)"
+1228,nan,J81,calorie (thermochemical) per minute,nan,2,calth/min,"6,973 333 x 10⁻² W"
+1229,nan,J82,calorie (thermochemical) per second,nan,2,calth/s,"4,184 W"
+1230,nan,J83,clo,nan,2,clo,"0,155 m² x K/W"
+1231,nan,J84,centimetre per second kelvin,nan,2,(cm/s)/K,10⁻² (m/s)/K
+1232,nan,J85,centimetre per second bar,nan,2,(cm/s)/bar,10⁻⁷ (m/s)/Pa
+1233,nan,J87,cubic centimetre per cubic metre,nan,1S,cm³/m³,10⁻⁶
+1234,D,J89,centimetre of mercury,nan,2,cm Hg,"1,333 224 x 10³ Pa"
+1235,nan,J90,cubic decimetre per day,nan,1S,dm³/d,"1,157 41 x 10⁻⁸ m³/s"
+1236,nan,J91,cubic decimetre per cubic metre,nan,1S,dm³/m³,10⁻³
+1237,nan,J92,cubic decimetre per minute,nan,1S,dm³/min,"1,666 67 x 10⁻⁵ m³/s"
+1238,nan,J93,cubic decimetre per second,nan,1S,dm³/s,10⁻³ m³/s
+1239,D,J94,dyne centimetre,nan,2,dyn·cm,10⁻⁷ N x m
+1240,nan,J95,ounce (UK fluid) per day,nan,2,fl oz (UK)/d,"3,288 549 x 10⁻¹⁰ m³/s"
+1241,nan,J96,ounce (UK fluid) per hour,nan,2,fl oz (UK)/h,"7,892 517 x 10⁻⁹ m³/s"
+1242,nan,J97,ounce (UK fluid) per minute,nan,2,fl oz (UK)/min,"4,735 51 x 10⁻⁷ m³/s"
+1243,nan,J98,ounce (UK fluid) per second,nan,2,fl oz (UK)/s,"2,841 306 x 10⁻⁵ m³/s"
+1244,nan,J99,ounce (US fluid) per day,nan,2,fl oz (US)/d,"3,422 862 x 10⁻¹⁰ m³/s"
+1245,X,JB,jumbo,nan,3.4,nan,nan
+1246,nan,JE,joule per kelvin,nan,1,J/K,J/K
+1247,X,JG,jug,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+1248,nan,JK,megajoule per kilogram,nan,1S,MJ/kg,10⁶ J/kg
+1249,nan,JM,megajoule per cubic metre,nan,1M,MJ/m³,10⁶ J/m³
+1250,nan,JNT,pipeline joint,A count of the number of pipeline joints.,3.5,nan,nan
+1251,X,JO,joint,nan,3.9,nan,nan
+1252,nan,JOU,joule,nan,1,J,J
+1253,nan,JPS,hundred metre,A unit of count defining the number of 100 metre lengths.,3.1,nan,nan
+1254,X,JR,jar,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+1255,nan,JWL,number of jewels,A unit of count defining the number of jewels (jewel: precious stone).,3.7,nan,nan
+1256,nan,K1,kilowatt demand,A unit of measure defining the power load measured at predetermined intervals.,3.5,nan,nan
+1257,nan,K10,ounce (US fluid) per hour,nan,2,fl oz (US)/h,"8,214 869 x 10⁻⁹ m³/s"
+1258,nan,K11,ounce (US fluid) per minute,nan,2,fl oz (US)/min,"4,928 922 x 10⁻⁷ m³/s"
+1259,nan,K12,ounce (US fluid) per second,nan,2,fl oz (US)/s,"2,957 353 x 10⁻⁵ m³/s"
+1260,nan,K13,foot per degree Fahrenheit,nan,2,ft/°F,"0,548 64 m/K"
+1261,nan,K14,foot per hour,nan,2,ft/h,"8,466 667 x 10⁻⁵m/s"
+1262,nan,K15,foot pound-force per hour,nan,2,ft·lbf/h,"3,766 161 x 10⁻⁴ W"
+1263,nan,K16,foot pound-force per minute,nan,2,ft·lbf/min,"2,259 697 x 10⁻² W"
+1264,nan,K17,foot per psi,nan,2,ft/psi,"4,420 750 x 10⁻⁵ m/Pa"
+1265,nan,K18,foot per second degree Fahrenheit,nan,2,(ft/s)/°F,"0,548 64  (m/s)/K"
+1266,nan,K19,foot per second psi,nan,2,(ft/s)/psi,"4,420 750 x 10⁻⁵ (m/s)/Pa"
+1267,nan,K2,kilovolt ampere reactive demand,A unit of measure defining the reactive power demand equal to one kilovolt ampere of reactive power.,3.5,nan,nan
+1268,nan,K20,reciprocal cubic foot,nan,2,1/ft³,"35,314 66 m⁻³"
+1269,nan,K21,cubic foot per degree Fahrenheit,nan,2,ft³/°F,"5,097 033 x 10⁻² m³/K"
+1270,nan,K22,cubic foot per day,nan,2,ft³/d,"3,277 413 x 10⁻⁷ m³/s"
+1271,nan,K23,cubic foot per psi,nan,2,ft³/psi,"4,107 012 x 10⁻⁶ m³/Pa"
+1272,D,K24,foot of water,nan,2,ft H₂O,"2,989 067 x 10³  Pa"
+1273,D,K25,foot of mercury,nan,2,ft Hg,"4,063 666 x 10⁴ Pa"
+1274,nan,K26,gallon (UK) per day,nan,2,gal (UK)/d,"5,261 678 x 10⁻⁸ m³/s"
+1275,nan,K27,gallon (UK) per hour,nan,2,gal (UK)/h,"1,262 803 x 10⁻⁶ m³/s"
+1276,nan,K28,gallon (UK) per second,nan,2,gal (UK)/s,"4,546 09 x 10⁻³ m³/s"
+1277,nan,K3,kilovolt ampere reactive hour,A unit of measure defining the accumulated reactive energy equal to one kilovolt ampere of reactive power per hour.,3.5,kvar·h,nan
+1278,nan,K30,gallon (US liquid) per second,nan,2,gal (US liq.)/s,"3,785 412 x 10⁻³ m³/s"
+1279,nan,K31,gram-force per square centimetre,nan,2,gf/cm²,"98,066 5 Pa"
+1280,nan,K32,gill (UK) per day,nan,2,gi (UK)/d,"1,644 274 x 10⁻⁵ m³/s"
+1281,nan,K33,gill (UK) per hour,nan,2,gi (UK)/h,"3,946 258 x 10⁻⁸ m³/s"
+1282,nan,K34,gill (UK) per minute,nan,2,gi (UK)/min,"0,023 677 55 m³/s"
+1283,nan,K35,gill (UK) per second,nan,2,gi (UK)/s,"1,420 653 x 10⁻⁴ m³/s"
+1284,nan,K36,gill (US) per day,nan,2,gi (US)/d,"1,369 145 x 10⁻⁹ m³/s"
+1285,nan,K37,gill (US) per hour,nan,2,gi (US)/h,"3,285 947 x 10⁻⁸ m³/s"
+1286,nan,K38,gill (US) per minute,nan,2,gi (US)/min,"1,971 568 x 10⁻⁶ m³/s"
+1287,nan,K39,gill (US) per second,nan,2,gi (US)/s,"1,182 941 x 10⁻⁴ m³/s"
+1288,nan,K40,standard acceleration of free fall,nan,2,gn,"9,806 65 m/s²"
+1289,nan,K41,grain per gallon (US),nan,2,gr/gal (US),"1,711 806 x 10⁻² kg/m³"
+1290,nan,K42,horsepower (boiler),nan,2,boiler hp,"9,809 50 x 10³ W"
+1291,nan,K43,horsepower (electric),nan,2,electric hp,746 W
+1292,nan,K45,inch per degree Fahrenheit,nan,2,in/°F,"4,572 x 10⁻² m/K"
+1293,nan,K46,inch per psi,nan,2,in/psi,"3,683 959 x 10⁻⁶ m/Pa"
+1294,nan,K47,inch per second degree Fahrenheit,nan,2,(in/s)/°F,"4,572 x 10⁻² (m/s)/K"
+1295,nan,K48,inch per second psi,nan,2,(in/s)/psi,"3,683 959 x 10⁻⁶ (m/s)/Pa"
+1296,nan,K49,reciprocal cubic inch,nan,2,1/in³,"6,102 375 9 x 10⁴ m⁻³"
+1297,D,K5,kilovolt ampere (reactive),Use kilovar (common code KVR),1S,kvar,10³ V x A
+1298,nan,K50,kilobaud,A unit of signal transmission speed equal to 10³ (1000) signaling events per second.,3.6,kBd,10³ Bd
+1299,nan,K51,kilocalorie (mean),nan,2,kcal,"4,190 02 x 10³ J"
+1300,nan,K52,kilocalorie (international table) per hour metre degree Celsius,nan,2,kcal/(m·h·°C),"1,163 J/(m x s x K)"
+1301,nan,K53,kilocalorie (thermochemical),nan,2,kcalth,"4,184 x 10³ J"
+1302,nan,K54,kilocalorie (thermochemical) per minute,nan,2,kcalth/min,"69,733 33 W"
+1303,nan,K55,kilocalorie (thermochemical) per second,nan,2,kcalth/s,"4,184 x 10³ W"
+1304,nan,K58,kilomole per hour,nan,1S,kmol/h,"2,777 78 x 10⁻¹ mol/s"
+1305,nan,K59,kilomole per cubic metre kelvin,nan,2,(kmol/m³)/K,10³ (mol/m³)/K
+1306,nan,K6,kilolitre,nan,1M,kl,m³
+1307,nan,K60,kilomole per cubic metre bar,nan,2,(kmol/m³)/bar,10⁻² (mol/m³)/Pa
+1308,nan,K61,kilomole per minute,nan,1S,kmol/min,"16,666 7 mol/s"
+1309,nan,K62,litre per litre,nan,1S,l/l,1
+1310,nan,K63,reciprocal litre,nan,2,1/l,10³ m⁻³
+1311,nan,K64,pound (avoirdupois) per degree Fahrenheit,nan,2,lb/°F,"0,816 466 3 kg/K"
+1312,nan,K65,pound (avoirdupois) square foot,nan,2,lb·ft²,"4,214 011 x 10⁻² kg x m²"
+1313,nan,K66,pound (avoirdupois) per day,nan,2,lb/d,"5,249 912 x 10⁻⁶ kg/s"
+1314,nan,K67,pound per foot hour,nan,2,lb/(ft·h),"4,133 789 x 10⁻⁴ Pa x s"
+1315,nan,K68,pound per foot second,nan,2,lb/(ft·s),"1,488 164 Pa x s"
+1316,nan,K69,pound (avoirdupois) per cubic foot degree Fahrenheit,nan,2,(lb/ft³)/°F,"28,833 23 (kg/m³)/K"
+1317,nan,K70,pound (avoirdupois) per cubic foot psi,nan,2,(lb/ft³)/psi,"2,323 282 x 10⁻³"
+1318,nan,K71,pound (avoirdupois) per gallon (UK),nan,2,lb/gal (UK),"99,776 37 kg/m³"
+1319,nan,K73,pound (avoirdupois) per hour degree Fahrenheit,nan,2,(lb/h)/°F,"2,267 962 x 10⁻⁴ (kg/s)/K"
+1320,nan,K74,pound (avoirdupois) per hour psi,nan,2,(lb/h)/psi,"1,827 445 x 10⁻⁸ (kg/s)/Pa"
+1321,nan,K75,pound (avoirdupois) per cubic inch degree Fahrenheit,nan,2,(lb/in³)/°F,"4,982 384 x 10⁴ (kg/m³)/K"
+1322,nan,K76,pound (avoirdupois) per cubic inch psi,nan,2,(lb/in³)/psi,"4,014 632 (kg/m³)/Pa"
+1323,nan,K77,pound (avoirdupois) per psi,nan,2,lb/psi,"6,578 802 x 10⁻⁵ kg/Pa"
+1324,nan,K78,pound (avoirdupois) per minute,nan,2,lb/min,"7,559 873 x 10⁻³ kg/s"
+1325,nan,K79,pound (avoirdupois) per minute degree Fahrenheit,nan,2,lb/(min·°F),"1,360 777  x 10⁻² (kg/s)/K"
+1326,nan,K80,pound (avoirdupois) per minute psi,nan,2,(lb/min)/psi,"1,096 467 x 10⁻⁶ (kg/s)/Pa"
+1327,nan,K81,pound (avoirdupois) per second,nan,2,lb/s,"0,453 592 4 kg/s"
+1328,nan,K82,pound (avoirdupois) per second degree Fahrenheit,nan,2,(lb/s)/°F,"0,816 466 3 (kg/s)/K"
+1329,nan,K83,pound (avoirdupois) per second psi,nan,2,(lb/s)/psi,"6,578 802 x 10⁻⁵ (kg/s)/Pa"
+1330,nan,K84,pound per cubic yard,nan,2,lb/yd³,"0,593 276 4 kg/m³"
+1331,nan,K85,pound-force per square foot,nan,2,lbf/ft²,"47,880 26 Pa"
+1332,nan,K86,pound-force per square inch degree Fahrenheit,nan,2,psi/°F,"1,241 056 x 10⁴ Pa/K"
+1333,nan,K87,psi cubic inch per second,nan,2,psi·in³/s,"0,112 985 Pa x m³/s"
+1334,nan,K88,psi litre per second,nan,2,psi·l/s,"6,894 757 Pa x m³/s"
+1335,nan,K89,psi cubic metre per second,nan,2,psi·m³/s,"6,894 757  x 10³ Pa x m³/s"
+1336,nan,K90,psi cubic yard per second,nan,2,psi·yd³/s,"5,271 420 x 10³ Pa x m³/s"
+1337,nan,K91,pound-force second per square foot,nan,2,lbf·s/ft²,"47,880 26 Pa x s"
+1338,nan,K92,pound-force second per square inch,nan,2,lbf·s/in²,"6,894 757  x 10³ Pa x s"
+1339,nan,K93,reciprocal psi,nan,2,1/psi,"1,450 377 x 10⁻⁴ Pa⁻¹"
+1340,nan,K94,quart (UK liquid) per day,nan,2,qt (UK liq.)/d,"1,315 420 x 10⁻⁸ m³/s"
+1341,nan,K95,quart (UK liquid) per hour,nan,2,qt (UK liq.)/h,"3,157 008 x 10⁻⁷ m³/s"
+1342,nan,K96,quart (UK liquid) per minute,nan,2,qt (UK liq.)/min,"1,894 205 x 10⁻⁵ m³/s"
+1343,nan,K97,quart (UK liquid) per second,nan,2,qt (UK liq.)/s,"1,136 523 x 10⁻³ m³/s"
+1344,nan,K98,quart (US liquid) per day,nan,2,qt (US liq.)/d,"1,095 316 x 10⁻⁸ m³/s"
+1345,nan,K99,quart (US liquid) per hour,nan,2,qt (US liq.)/h,"2,628 758 x 10⁻⁷ m³/s"
+1346,nan,KA,cake,"A unit of count defining the number of cakes (cake: object shaped into a flat, compact mass).",3.9,nan,nan
+1347,nan,KAT,katal,A unit of catalytic activity defining the catalytic activity of enzymes and other catalysts.,1M,kat,s⁻¹ x mol
+1348,nan,KB,kilocharacter,A unit of information equal to 10³ (1000) characters.,3.9,nan,nan
+1349,nan,KBA,kilobar,nan,1M,kbar,10⁸ Pa
+1350,nan,KCC,kilogram of choline chloride,A unit of mass equal to one thousand grams of choline chloride.,3.1,kg C₅ H₁₄ClNO,nan
+1351,X,KD,kilogram decimal,nan,3.9,nan,nan
+1352,nan,KDW,kilogram drained net weight,"A unit of mass defining the net number of kilograms of a product, disregarding the liquid content of the product.",3.1,kg/net eda,nan
+1353,nan,KEL,kelvin,Refer ISO 80000-5 (Quantities and units — Part 5: Thermodynamics),1,K,K
+1354,X,KF,kilopacket,nan,3.9,nan,nan
+1355,X,KG,keg,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+1356,nan,KGM,kilogram,A unit of mass equal to one thousand grams.,1,kg,kg
+1357,nan,KGS,kilogram per second,nan,1,kg/s,kg/s
+1358,nan,KHY,kilogram of hydrogen peroxide,A unit of mass equal to one thousand grams of hydrogen peroxide.,3.1,kg H₂O₂,nan
+1359,nan,KHZ,kilohertz,nan,1S,kHz,10³ Hz
+1360,nan,KI,kilogram per millimetre width,nan,3.1,nan,10³ kg/m
+1361,nan,KIC,"kilogram, including container","A unit of mass defining the number of kilograms of a product, including its container.",3.1,nan,nan
+1362,nan,KIP,"kilogram, including inner packaging","A unit of mass defining the number of kilograms of a product, including its inner packaging materials.",3.1,nan,nan
+1363,nan,KJ,kilosegment,A unit of information equal to 10³ (1000) segments.,3.6,nan,nan
+1364,nan,KJO,kilojoule,nan,1S,kJ,10³ J
+1365,nan,KL,kilogram per metre,nan,1,kg/m,kg/m
+1366,nan,KLK,lactic dry material percentage,A unit of proportion defining the percentage of dry lactic material in a product.,3.5,nan,nan
+1367,nan,KLX,kilolux,A unit of illuminance equal to one thousand lux.,1M,klx,10³ cd x sr / m²
+1368,nan,KMA,kilogram of methylamine,A unit of mass equal to one thousand grams of methylamine.,3.1,kg met.am.,nan
+1369,nan,KMH,kilometre per hour,nan,1S,km/h,"0,277 778 m/s"
+1370,nan,KMK,square kilometre,nan,1S,km²,10⁶ m²
+1371,nan,KMQ,kilogram per cubic metre,A unit of weight expressed in kilograms of a substance that fills a volume of one cubic metre.,1,kg/m³,kg/m³
+1372,nan,KMT,kilometre,nan,1S,km,10³ m
+1373,nan,KNI,kilogram of nitrogen,A unit of mass equal to one thousand grams of nitrogen.,3.1,kg N,nan
+1374,nan,KNM,kilonewton per square metre,Pressure expressed in kN/m2.,1S,kN/m2,103pascal
+1375,nan,KNS,kilogram named substance,A unit of mass equal to one kilogram of a named substance.,3.1,nan,nan
+1376,nan,KNT,knot,nan,1,kn,"0,514 444 m/s"
+1377,nan,KO,milliequivalence caustic potash per gram of product,A unit of count defining the number of milligrams of potassium hydroxide per gram of product as a measure of the concentration of potassium hydroxide in the product.,3.9,nan,nan
+1378,nan,KPA,kilopascal,nan,1S,kPa,10³ Pa
+1379,nan,KPH,kilogram of potassium hydroxide (caustic potash),A unit of mass equal to one thousand grams of potassium hydroxide (caustic potash).,3.1,kg KOH,nan
+1380,nan,KPO,kilogram of potassium oxide,A unit of mass equal to one thousand grams of potassium oxide.,3.1,kg K₂O,nan
+1381,nan,KPP,kilogram of phosphorus pentoxide (phosphoric anhydride),A unit of mass equal to one thousand grams of phosphorus pentoxide phosphoric anhydride.,3.1,nan,nan
+1382,nan,KR,kiloroentgen,nan,2,kR,"2,58 x 10⁻¹ C/kg"
+1383,X,KS,thousand pound per square inch,nan,3.8,nan,nan
+1384,nan,KSD,kilogram of substance 90 % dry,A unit of mass equal to one thousand grams of a named substance that is 90% dry.,3.1,kg 90 % sdt,nan
+1385,nan,KSH,kilogram of sodium hydroxide (caustic soda),A unit of mass equal to one thousand grams of sodium hydroxide (caustic soda).,3.1,kg NaOH,nan
+1386,nan,KT,kit,"A unit of count defining the number of kits (kit: tub, barrel or pail).",3.2,nan,nan
+1387,X,KTM,kilometre,nan,1S,km,10³ m
+1388,nan,KTN,kilotonne,nan,1M,kt,10⁶ kg
+1389,nan,KUR,kilogram of uranium,A unit of mass equal to one thousand grams of uranium.,3.1,kg U,nan
+1390,nan,KVA,kilovolt - ampere,nan,1S,kV·A,10³ V x A
+1391,nan,KVR,kilovar,nan,1S,kvar,10³ V x A
+1392,nan,KVT,kilovolt,nan,1S,kV,10³ V
+1393,nan,KW,kilogram per millimetre,nan,1M,kg/mm,10³ kg/m
+1394,nan,KWH,kilowatt hour,nan,1S,kW·h,"3,6 x 10⁶ J"
+1395,+,KWY,kilowatt year,killowatt year,2,kW/year,nan
+1396,¦,KWN,Kilowatt hour per normalized cubic metre,Kilowatt hour per normalized cubic metre (temperature 0°C and pressure 1013.25 millibars ).,2,nan,nan
+1397,nan,KWO,kilogram of tungsten trioxide,A unit of mass equal to one thousand grams of tungsten trioxide.,3.1,kg WO₃,nan
+1398,¦,KWS,Kilowatt hour per standard cubic metre,Kilowatt hour per standard cubic metre (temperature 15°C and pressure 1013.25 millibars).,2,nan,nan
+1399,nan,KWT,kilowatt,nan,1S,kW,10³ W
+1400,nan,KX,millilitre per kilogram,nan,1M,ml/kg,10⁻⁶ m³/kg
+1401,nan,L10,quart (US liquid) per minute,nan,2,qt (US liq.)/min,"1,577 255 x 10⁻⁵ m³/s"
+1402,nan,L11,quart (US liquid) per second,nan,2,qt (US liq.)/s,"9,463 529 x 10⁻⁴ m³/s"
+1403,nan,L12,metre per second kelvin,nan,2,(m/s)/K,(m/s)/K
+1404,nan,L13,metre per second bar,nan,2,(m/s)/bar,10⁻⁵ (m/s)/Pa
+1405,nan,L14,square metre hour degree Celsius per kilocalorie (international table),nan,2,m²·h·°C/kcal,"0,859 845 2 m² x s x K/J"
+1406,nan,L15,millipascal second per kelvin,nan,2,mPa·s/K,10⁻³ Pa x s/K
+1407,nan,L16,millipascal second per bar,nan,2,mPa·s/bar,10⁻⁸ s
+1408,nan,L17,milligram per cubic metre kelvin,nan,2,(mg/m³)/K,10⁻⁶ (kg/m³)/K
+1409,nan,L18,milligram per cubic metre bar,nan,2,(mg/m³)/bar,10⁻¹¹ (kg/m³)/Pa
+1410,nan,L19,millilitre per litre,nan,1S,ml/l,10⁻³
+1411,nan,L2,litre per minute,nan,1M,l/min,"1,666 67 x 10⁻⁵ m³/s"
+1412,nan,L20,reciprocal cubic millimetre,nan,1S,1/mm³,10⁹ m⁻³
+1413,nan,L21,cubic millimetre per cubic metre,nan,1S,mm³/m³,10⁹
+1414,nan,L23,mole per hour,nan,1S,mol/h,"2,777 78 x 10⁻⁴ mol/s"
+1415,nan,L24,mole per kilogram kelvin,nan,2,(mol/kg)/K,(mol/kg)/K
+1416,nan,L25,mole per kilogram bar,nan,2,(mol/kg)/bar,10⁻⁵ (mol/kg)/Pa
+1417,nan,L26,mole per litre kelvin,nan,2,(mol/l)/K,10³ (mol/m³)/K
+1418,nan,L27,mole per litre bar,nan,2,(mol/l)/bar,10⁻² (mol/m³)/Pa
+1419,nan,L28,mole per cubic metre kelvin,nan,2,(mol/m³)/K,(mol/m³)/K
+1420,nan,L29,mole per cubic metre bar,nan,2,(mol/m³)/bar,10⁻⁵ (mol/m³)/Pa
+1421,nan,L30,mole per minute,nan,1S,mol/min,"1,666 67 x 10⁻² mol/s"
+1422,nan,L31,milliroentgen aequivalent men,nan,2,mrem,10⁻⁵ Sv
+1423,nan,L32,nanogram per kilogram,nan,1S,ng/kg,10⁻¹²
+1424,nan,L33,ounce (avoirdupois) per day,nan,2,oz/d,"3,281 194 x 10⁻⁷kg/s"
+1425,nan,L34,ounce (avoirdupois) per hour,nan,2,oz/h,"7,874 867 x 10⁻⁶ kg/s"
+1426,nan,L35,ounce (avoirdupois) per minute,nan,2,oz/min,"4,724 92 x 10⁻⁴ kg/s"
+1427,nan,L36,ounce (avoirdupois) per second,nan,2,oz/s,"2,834 952 x 10⁻² kg/s"
+1428,nan,L37,ounce (avoirdupois) per gallon (UK),nan,2,oz/gal (UK),"6,236 023 kg/m³"
+1429,nan,L38,ounce (avoirdupois) per gallon (US),nan,2,oz/gal (US),"7,489 152 kg/m³"
+1430,nan,L39,ounce (avoirdupois) per cubic inch,nan,2,oz/in³,"1,729 994 x 10³ kg/m³"
+1431,nan,L40,ounce (avoirdupois)-force,nan,2,ozf,"0,278 013 9 N"
+1432,nan,L41,ounce (avoirdupois)-force inch,nan,2,ozf·in,"7,061 552 x 10⁻³ N x m"
+1433,nan,L42,picosiemens per metre,nan,2,pS/m,10⁻¹² S/m
+1434,nan,L43,peck (UK),nan,2,pk (UK),"9,092 181 x 10⁻³ m³"
+1435,nan,L44,peck (UK) per day,nan,2,pk (UK)/d,"1,052 336 x 10⁻⁷ m³/s"
+1436,nan,L45,peck (UK) per hour,nan,2,pk (UK)/h,"2,525 606 x 10⁻⁶ m³/s"
+1437,nan,L46,peck (UK) per minute,nan,2,pk (UK)/min,"1,515 363 5 x 10⁻⁴ m³/s"
+1438,nan,L47,peck (UK) per second,nan,2,pk (UK)/s,"9,092 181 x 10⁻³ m³/s"
+1439,nan,L48,peck (US dry) per day,nan,2,pk (US dry)/d,"1,019 649 x 10⁻⁷ m³/s"
+1440,nan,L49,peck (US dry) per hour,nan,2,pk (US dry)/h,"2,447 158 x 10⁻⁶ m³/s"
+1441,nan,L50,peck (US dry) per minute,nan,2,pk (US dry)/min,"1,468 295 x 10⁻⁴ m³/s"
+1442,nan,L51,peck (US dry) per second,nan,2,pk (US dry)/s,"8,809 768 x 10⁻³ m³/s"
+1443,nan,L52,psi per psi,nan,2,psi/psi,1.0
+1444,nan,L53,pint (UK) per day,nan,2,pt (UK)/d,"6,577 098 x 10⁻⁹ m³/s"
+1445,nan,L54,pint (UK) per hour,nan,2,pt (UK)/h,"1,578 504 x 10⁻⁷ m³/s"
+1446,nan,L55,pint (UK) per minute,nan,2,pt (UK)/min,"9,471 022 x 10⁻⁶ m³/s"
+1447,nan,L56,pint (UK) per second,nan,2,pt (UK)/s,"5,682 613 x 10⁻⁴ m³/s"
+1448,nan,L57,pint (US liquid) per day,nan,2,pt (US liq.)/d,"5,476 580 x 10⁻⁹ m³/s"
+1449,nan,L58,pint (US liquid) per hour,nan,2,pt (US liq.)/h,"1,314 379 x 10⁻⁷ m³/s"
+1450,nan,L59,pint (US liquid) per minute,nan,2,pt (US liq.)/min,"7,886 275 x 10⁻⁶ m³/s"
+1451,nan,L60,pint (US liquid) per second,nan,2,pt (US liq.)/s,"4,731 765 x 10⁻⁴ m³/s"
+1452,X,L61,pint (US dry),Use dry pint (common code PTD),2,pt (US dry),"5,506 105 x 10⁻⁴ m³"
+1453,X,L62,quart (US dry),Use dry quart (US) (common code QTD),2,qt (US dry),"1,101 221 x 10⁻³ m³"
+1454,nan,L63,slug per day,nan,2,slug/d,"1,689 109 x 10⁻⁴ kg/s"
+1455,nan,L64,slug per foot second,nan,2,slug/(ft·s),"47,880 26 Pa x s"
+1456,nan,L65,slug per cubic foot,nan,2,slug/ft³,"5,153 788 x 10² kg/m³"
+1457,nan,L66,slug per hour,nan,2,slug/h,"4,053 861 x 10⁻³ kg/s"
+1458,nan,L67,slug per minute,nan,2,slug/min,"0,243 231 7 kg/s"
+1459,nan,L68,slug per second,nan,2,slug/s,"14,593 90 kg/s"
+1460,nan,L69,tonne per kelvin,nan,2,t/K,10³ kg/K
+1461,nan,L70,tonne per bar,nan,2,t/bar,10⁻² kg/Pa
+1462,nan,L71,tonne per day,nan,2,t/d,"1,157 41 x 10⁻² kg/s"
+1463,nan,L72,tonne per day kelvin,nan,2,(t/d)/K,"1,157 41 x 10⁻² (kg/s)/K"
+1464,nan,L73,tonne per day bar,nan,2,(t/d)/bar,"1,157 41 x 10⁻⁷ (kg/s)/Pa"
+1465,nan,L74,tonne per hour kelvin,nan,2,(t/h)/K,"2,777 78 x 10⁻¹ (kg/s)/K"
+1466,nan,L75,tonne per hour bar,nan,2,(t/h)/bar,"2,777 78 x 10⁻⁶ (kg/s)/Pa"
+1467,nan,L76,tonne per cubic metre kelvin,nan,2,(t/m³)/K,10³ (kg/m³)/K
+1468,nan,L77,tonne per cubic metre bar,nan,2,(t/m³)/bar,10⁻² (kg/m³)/Pa
+1469,nan,L78,tonne per minute,nan,2,t/min,"16,666 7 kg/s"
+1470,nan,L79,tonne per minute kelvin,nan,2,(t/min)/K,"16,666 7 (kg/s)/K"
+1471,nan,L80,tonne per minute bar,nan,2,(t/min)/bar,"1,666 67 x 10⁻⁴ (kg/s)/Pa"
+1472,nan,L81,tonne per second,nan,2,t/s,10³ kg/s
+1473,nan,L82,tonne per second kelvin,nan,2,(t/s)/K,10³ (kg/s)/K
+1474,nan,L83,tonne per second bar,nan,2,(t/s)/bar,10⁻² (kg/s)/Pa
+1475,nan,L84,ton (UK shipping),nan,2,British shipping ton,"1,189 3 m³"
+1476,nan,L85,ton long per day,nan,2,ton (UK)/d,"1,175 980 x 10⁻² kg/s"
+1477,nan,L86,ton (US shipping),nan,2,(US) shipping ton,"1,132 6 m³"
+1478,nan,L87,ton short per degree Fahrenheit,nan,2,ton (US)/°F,"1,632 932 x 10³ kg/K"
+1479,nan,L88,ton short per day,nan,2,ton (US)/d,"1,049 982 x 10⁻² kg/s"
+1480,nan,L89,ton short per hour degree Fahrenheit,nan,2,ton (US)/(h·°F),"0,453 592 2 kg/s x K"
+1481,nan,L90,ton short per hour psi,nan,2,(ton (US)/h)/psi,"3,654 889 x 10⁻⁵ (kg/s)/Pa"
+1482,nan,L91,ton short per psi,nan,2,ton (US)/psi,"0,131 576"
+1483,nan,L92,ton (UK long) per cubic yard,nan,2,ton.l/yd³ (UK),"1,328 939 x 10³ kg/m³"
+1484,nan,L93,ton (US short) per cubic yard,nan,2,ton.s/yd³ (US),"1,186 553 x 10³ kg/m³"
+1485,nan,L94,ton-force (US short),nan,2,ton.sh-force,"8,896 443 x 10³ N"
+1486,nan,L95,common year,nan,2,y (365 days),"3,153 6 x 10⁷ s"
+1487,nan,L96,sidereal year,nan,2,y (sidereal),"3,155 815 x 10⁷ s"
+1488,nan,L98,yard per degree Fahrenheit,nan,2,yd/°F,"1,645 92 m/K"
+1489,nan,L99,yard per psi,nan,2,yd/psi,"1,326 225 x 10⁻⁴ m/Pa"
+1490,nan,LA,pound per cubic inch,nan,2,lb/in³,"2,767 990 x 10⁴ kg/m³"
+1491,nan,LAC,lactose excess percentage,A unit of proportion defining the percentage of lactose in a product that exceeds a defined percentage level.,3.5,nan,nan
+1492,nan,LBR,pound,nan,2,lb,"0,453 592 37 kg"
+1493,nan,LBT,troy pound (US),nan,3.5,nan,"373,241 7 g"
+1494,X,LC,linear centimetre,nan,3.1,nan,nan
+1495,nan,LD,litre per day,nan,1M,l/d,"1,157 41 x 10⁻⁸ m³/s"
+1496,X,LE,lite,nan,3.9,nan,nan
+1497,nan,LEF,leaf,A unit of count defining the number of leaves.,3.5,nan,nan
+1498,nan,LF,linear foot,A unit of count defining the number of feet (12-inch) in length of a uniform width object.,3.1,nan,nan
+1499,nan,LH,labour hour,A unit of time defining the number of labour hours.,3.1,nan,nan
+1500,X,LI,linear inch,nan,3.1,nan,nan
+1501,X,LJ,large spray,nan,3.9,nan,nan
+1502,nan,LK,link,A unit of distance equal to 0.01 chain.,3.9,nan,nan
+1503,nan,LM,linear metre,A unit of count defining the number of metres in length of a uniform width object.,3.1,nan,nan
+1504,nan,LN,length,A unit of distance defining the linear extent of an item measured from end to end.,3.9,nan,nan
+1505,nan,LO,lot [unit of procurement],A unit of count defining the number of lots (lot: a collection of associated items).,3.9,nan,nan
+1506,nan,LP,liquid pound,A unit of mass defining the number of pounds of a liquid substance.,3.1,nan,nan
+1507,nan,LPA,litre of pure alcohol,A unit of volume equal to one litre of pure alcohol.,3.1,nan,nan
+1508,nan,LR,layer,A unit of count defining the number of layers.,3.9,nan,nan
+1509,nan,LS,lump sum,A unit of count defining the number of whole or a complete monetary amounts.,3.9,nan,nan
+1510,nan,LTN,ton (UK) or long ton (US),Synonym: gross ton (2240 lb),2,ton (UK),"1,016 047 x 10³ kg"
+1511,nan,LTR,litre,nan,1,l,10⁻³ m³
+1512,nan,LUB,"metric ton, lubricating oil",A unit of mass defining the number of metric tons of lubricating oil.,3.1,nan,nan
+1513,nan,LUM,lumen,nan,1,lm,cd x sr
+1514,nan,LUX,lux,nan,1,lx,cd x sr / m²
+1515,X,LX,linear yard per pound,nan,3.1,nan,nan
+1516,nan,LY,linear yard,A unit of count defining the number of 36-inch units in length of a uniform width object.,3.1,nan,nan
+1517,X,M0,magnetic tape,nan,3.6,nan,nan
+1518,nan,M1,milligram per litre,nan,1M,mg/l,10⁻³ kg/m³
+1519,nan,M10,reciprocal cubic yard,nan,2,1/yd³,"1,307 951 m⁻³"
+1520,nan,M11,cubic yard per degree Fahrenheit,nan,2,yd³/°F,"1,376 199 m³/K"
+1521,nan,M12,cubic yard per day,nan,2,yd³/d,"8,849 015 x 10⁻⁶ m³/s"
+1522,nan,M13,cubic yard per hour,nan,2,yd³/h,"2,123 764 x 10⁻⁴ m³/s"
+1523,nan,M14,cubic yard per psi,nan,2,yd³/psi,"1,108 893 x 10⁻⁴ m³/Pa"
+1524,nan,M15,cubic yard per minute,nan,2,yd³/min,"1,274 258 x 10⁻² m³/s"
+1525,nan,M16,cubic yard per second,nan,2,yd³/s,"0,764 554 9 m³/s"
+1526,nan,M17,kilohertz metre,nan,2,kHz·m,10³ Hz x m
+1527,nan,M18,gigahertz metre,nan,2,GHz·m,10⁹ Hz x m
+1528,nan,M19,Beaufort,"An empirical measure for describing wind speed based mainly on observed sea conditions. The Beaufort scale indicates the wind speed by numbers that typically range from 0 for calm, to 12 for hurricane.",3,Bft,nan
+1529,nan,M20,reciprocal megakelvin or megakelvin to the power minus one,nan,2,1/MK,10⁻⁶ K⁻¹
+1530,nan,M21,reciprocal kilovolt - ampere reciprocal hour,nan,2,1/kVAh,"2,777 778 x 10⁻⁷ (V x A x s)⁻¹"
+1531,nan,M22,millilitre per square centimetre minute,nan,2,(ml/min)/cm²,"2,777 778 x 10⁻⁶  (m³/s)/m²"
+1532,nan,M23,newton per centimetre,nan,1M,N/cm,10² N/m
+1533,nan,M24,ohm kilometre,nan,1M,Ω·km,10³ Ω x m
+1534,nan,M25,percent per degree Celsius,"A unit of proportion, equal to 0.01, in relation to a temperature of one degree.",3.7,%/°C,10⁻² °C⁻¹
+1535,nan,M26,gigaohm per metre,nan,2,GΩ/m,10⁹ Ω/m
+1536,nan,M27,megahertz metre,nan,2,MHz·m,10⁶ Hz x m
+1537,nan,M29,kilogram per kilogram,nan,1S,kg/kg,1
+1538,nan,M30,reciprocal volt - ampere reciprocal second,nan,1S,1/(V·A·s),(V x A x s)⁻¹
+1539,nan,M31,kilogram per kilometre,nan,1S,kg/km,10⁻³ kg/m
+1540,nan,M32,pascal second per litre,nan,2,Pa·s/l,10³ Pa x s/m³
+1541,nan,M33,millimole per litre,nan,1S,mmol/l,mol/m³
+1542,nan,M34,newton metre per square metre,nan,1S,N·m/m²,N x m/m²
+1543,nan,M35,millivolt - ampere,nan,1S,mV·A,10⁻³ V x A
+1544,nan,M36,30-day month,"A unit of count defining the number of months expressed in multiples of 30 days, one day equals 24 hours.",3.7,mo (30 days),"2,592 000 x 10⁶ s"
+1545,nan,M37,actual/360,"A unit of count defining the number of years expressed in multiples of 360 days, one day equals 24 hours.",3.7,y (360 days),"3,110 400 0 x 10⁷ s"
+1546,nan,M38,kilometre per second squared,1000-fold of the SI base unit metre divided by the power of the SI base unit second by exponent 2.,1M,km/s²,10³ m/s²
+1547,nan,M39,centimetre per second squared,"0,01-fold of the SI base unit metre divided by the power of the SI base unit second by exponent 2.",1M,cm/s²,10⁻² m/s²
+1548,nan,M4,monetary value,A unit of measure expressed as a monetary amount.,3.9,nan,nan
+1549,nan,M40,yard per second squared,Unit of the length according to the Anglo-American and Imperial system of units divided by the power of the SI base unit second by exponent 2.,2,yd/s²,"9,144 x 10⁻¹ m/s²"
+1550,nan,M41,millimetre per second squared,"0,001-fold of the SI base unit metre divided by the power of the SI base unit second by exponent 2.",1M,mm/s²,10⁻³ m/s²
+1551,nan,M42,mile (statute mile) per second squared,Unit of the length according to the Imperial system of units divided by the power of the SI base unit second by exponent 2.,2,mi/s²,"1,609 344 x 10³ m/s²"
+1552,nan,M43,mil,"Unit to indicate an angle at military zone, equal to the 6400th part of the full circle of the 360° or 2·p·rad.",2,mil,"9,817 477  x 10⁻⁴ rad"
+1553,nan,M44,revolution,Unit to identify an angle of the full circle of 360° or 2·p·rad (Refer ISO/TC12 SI Guide).,2,rev,"6,283 185 rad"
+1554,nan,M45,degree [unit of angle] per second squared,360 part of a full circle divided by the power of the SI base unit second and the exponent 2.,1M,°/s²,"1,745 329 x 10⁻² rad / s"
+1555,nan,M46,revolution per minute,Unit of the angular velocity.,2.0,r/min,"0,104 719 8 rad/s"
+1556,nan,M47,circular mil,"Unit of an area, of which the size is given by a diameter of length of 1 mm (0,001 in) based on the formula: area = p·(diameter/2)².",2,cmil,"5,067 075 x 10⁻¹⁰ m²"
+1557,nan,M48,square mile (based on U.S. survey foot),"Unit of the area, which is mainly common in the agriculture and forestry.",2,mi² (US survey),"2,589 998 x 10⁶ m²"
+1558,nan,M49,chain (based on U.S. survey foot),Unit of the length according the Anglo-American system of units.,2,ch (US survey) ,"2,011684 x 10 m"
+1559,nan,M5,microcurie,nan,2S,µCi,"3,7 x 10⁴ Bq"
+1560,nan,M50,furlong,Unit commonly used in Great Britain at rural distances: 1 furlong = 40 rods = 10 chains (UK) = 1/8 mile = 1/10 furlong = 220 yards = 660 foot.,2,fur,"2,011 68 x 10² m"
+1561,nan,M51,foot (U.S. survey),"Unit commonly used in the United States for ordnance survey.,",2,ft (US survey) ,"3,048 006 x 10⁻¹ m"
+1562,nan,M52,mile (based on U.S. survey foot),Unit commonly used in the United States for ordnance survey.,2,mi (US survey) ,"1,609347 x 10³ m"
+1563,nan,M53,metre per pascal,SI base unit metre divided by the derived SI unit pascal.,1M,m/Pa,kg⁻¹ x m² x s²
+1564,nan,M55,metre per radiant,Unit of the translation factor for implementation from rotation to linear movement.,1S,m/rad,m/rad
+1565,nan,M56,shake,Unit for a very short period.,2,shake,10⁻⁸ s
+1566,nan,M57,mile per minute,Unit of velocity from the Imperial system of units.,2,mi/min,"26,822 4 m/s"
+1567,nan,M58,mile per second,Unit of the velocity from the Imperial system of units.,2,mi/s,"1,609 344 x 10³ m/s"
+1568,nan,M59,metre per second pascal,SI base unit meter divided by the product of SI base unit second and the derived SI unit pascal.,1S,(m/s)/Pa,m² x kg⁻¹ x s
+1569,nan,M60,metre per hour,SI base unit metre divided by the unit hour.,2,m/h,"2,777 78 x 10⁻⁴ m/s"
+1570,nan,M61,inch per year,Unit of the length according to the Anglo-American and Imperial system of units divided by the unit common year with 365 days.,2,in/y,"8,048 774 x 10⁻¹⁰ m/s"
+1571,nan,M62,kilometre per second,1000-fold of the SI base unit metre divided by the SI base unit second.,2,km/s,10³ m/s
+1572,nan,M63,inch per minute,Unit inch according to the Anglo-American and Imperial system of units divided by the unit minute.,2,in/min,"4,233 333 x 10⁻⁴ m/s"
+1573,nan,M64,yard per second,Unit yard according to the Anglo-American and Imperial system of units divided by the SI base unit second.,2,yd/s,"9,144 x 10⁻¹ m/s"
+1574,nan,M65,yard per minute,Unit yard according to the Anglo-American and Imperial system of units divided by the unit minute.,2,yd/min,"1,524 x 10⁻² m/s"
+1575,nan,M66,yard per hour,Unit yard according to the Anglo-American and Imperial system of units divided by the unit hour.,2,yd/h,"2,54 x 10⁻⁴ m/s"
+1576,nan,M67,acre-foot (based on U.S. survey foot),"Unit of the volume, which is used in the United States to measure/gauge the capacity of reservoirs.",2,acre-ft (US survey),"1,233 489 x 10³ m³"
+1577,nan,M68,cord (128 ft3),Traditional unit of the volume of stacked firewood which has been measured with a cord.,2,cord,"3,624 556 m³"
+1578,nan,M69,cubic mile (UK statute),Unit of volume according to the Imperial system of units.,2,mi³,"4,168 182 x 10⁹ m³"
+1579,nan,M7,micro-inch,nan,2,µin,"25,4 x 10⁻⁹ m"
+1580,nan,M70,"ton, register",Traditional unit of the cargo capacity.,2,RT,"2,831 685 m³"
+1581,nan,M71,cubic metre per pascal,Power of the SI base unit meter by exponent 3 divided by the derived SI base unit pascal.,1S,m³/Pa,kg⁻¹ x m⁴ x s²
+1582,nan,M72,bel,Logarithmic relationship to base 10.,1M,B,B
+1583,nan,M73,kilogram per cubic metre pascal,SI base unit kilogram divided by the product of the power of the SI base unit metre with exponent 3 and the derived SI unit pascal.,1M,(kg/m³)/Pa,m⁻² x s²
+1584,nan,M74,kilogram per pascal,SI base unit kilogram divided by the derived SI unit pascal.,2.0,kg/Pa,m x s²
+1585,nan,M75,kilopound-force,1000-fold of the unit of the force pound-force (lbf) according to the Anglo-American system of units with the relationship.,2,kip,"4,448 222 x 10³ N"
+1586,nan,M76,poundal,"Non SI-conforming unit of the power, which corresponds to a mass of a pound multiplied with the acceleration of a foot per square second.",2,pdl,"1,382 550 x 10⁻¹ N"
+1587,nan,M77,kilogram metre per second squared,Product of the SI base unit kilogram and the SI base unit metre divided by the power of the SI base unit second by exponent 2.,2,kg·m/s²,(kg x m)/s²
+1588,nan,M78,pond,"0,001-fold of the unit of the weight, defined as a mass of 1 kg which finds out about a weight strength from 1 kp by the gravitational force at sea level which corresponds to a strength of 9,806 65 newton.",2,p,"9,806 65 x 10⁻³ N"
+1589,nan,M79,square foot per hour,Power of the unit foot according to the Anglo-American and Imperial system of units by exponent 2 divided by the unit of time hour.,2,ft²/h,"2,580 64 x 10⁻⁵ m²/s"
+1590,nan,M80,stokes per pascal,CGS (Centimetre-Gram-Second system) unit stokes divided by the derived SI unit pascal.,2,St/Pa,10⁻⁴ kg⁻¹ x m³ x s
+1591,nan,M81,square centimetre per second,"0,000 1-fold of the power of the SI base unit metre by exponent 2 divided by the SI base unit second.",2,cm²/s,10⁻⁴ m²/s
+1592,nan,M82,square metre per second pascal,Power of the SI base unit metre with the exponent 2 divided by the SI base unit second and the derived SI unit pascal.,1.0,(m²/s)/Pa,kg⁻¹ x m³ x s
+1593,nan,M83,denier,Traditional unit for the indication of the linear mass of textile fibers and yarns.,2.0,den,"1,111 111 x 10⁻⁷ kg/m"
+1594,nan,M84,pound per yard,Unit for linear mass according to avoirdupois system of units.,2,lb/yd,"4,960 546 x 10⁻¹ kg/m"
+1595,nan,M85,"ton, assay",Non SI-conforming unit of the mass used in the mineralogy to determine the concentration of precious metals in ore according to the mass of the precious metal in milligrams in a sample of the mass of an assay sound (number of troy ounces in a short ton (1 000 lb)).,2,nan,"2,916 667 x 10⁻² kg"
+1596,nan,M86,pfund,Outdated unit of the mass used in Germany.,2,pfd,"0,5 kg"
+1597,nan,M87,kilogram per second pascal,SI base unit kilogram divided by the product of the SI base unit second and the derived SI unit pascal.,1S,(kg/s)/Pa,m x s
+1598,nan,M88,tonne per month,Unit tonne divided by the unit month.,2,t/mo,"3,802 570 537 68 x 10⁻⁴ kg/s"
+1599,nan,M89,tonne per year,Unit tonne divided by the unit year with 365 days.,2,t/y,"3,168 808 781 x 10⁻⁵ kg/s"
+1600,nan,M9,million Btu per 1000 cubic foot,nan,3.9,MBTU/kft³,nan
+1601,nan,M90,kilopound per hour,1000-fold of the unit of the mass avoirdupois pound according to the avoirdupois unit system divided by the unit hour.,2,klb/h,"0,125 997 889 kg/s"
+1602,nan,M91,pound per pound,Proportion of the mass consisting of the avoirdupois pound according to the avoirdupois unit system divided by the avoirdupois pound according to the avoirdupois unit system.,2.0,lb/lb,1.0
+1603,nan,M92,pound-force foot,Product of the unit pound-force according to the Anglo-American system of units and the unit foot according to the Anglo-American and the Imperial system of units.,2,lbf·ft,"1,355 818 N x m"
+1604,nan,M93,newton metre per radian,Product of the derived SI unit newton and the SI base unit metre divided by the unit radian.,1M,N·m/rad,m² x kg x s⁻² x rad⁻¹
+1605,nan,M94,kilogram metre,Unit of imbalance as a product of the SI base unit kilogram and the SI base unit metre.,1S,kg·m,kg x m
+1606,nan,M95,poundal foot,Product of the non SI-conforming unit of the force poundal and the unit foot according to the Anglo-American and Imperial system of units .,2,pdl·ft,"4,214 011 x 10⁻² N x m"
+1607,nan,M96,poundal inch,Product of the non SI-conforming unit of the force poundal and the unit inch according to the Anglo-American and Imperial system of units .,2,pdl·in,"3,511 677 10⁻³ N x m"
+1608,nan,M97,dyne metre,CGS (Centimetre-Gram-Second system) unit of the rotational moment.,2,dyn·m,10⁻⁵ N x m
+1609,nan,M98,kilogram centimetre per second,"Product of the SI base unit kilogram and the 0,01-fold of the SI base unit metre divided by the SI base unit second.",1M,kg·(cm/s),10⁻² kg x m/s
+1610,nan,M99,gram centimetre per second,"Product of the 0,001-fold of the SI base unit kilogram and the 0,01-fold of the SI base unit metre divided by the SI base unit second.",1M,g·(cm/s),10⁻⁵ kg x m/s
+1611,X,MA,machine per unit,nan,3.9,nan,nan
+1612,nan,MAH,megavolt ampere reactive hour,A unit of electrical reactive power defining the total amount of reactive power across a power system.,3.1,Mvar·h,nan
+1613,nan,MAL,megalitre,nan,1M,Ml,10³ m³
+1614,nan,MAM,megametre,nan,2,Mm,10⁶ m
+1615,nan,MAR,megavar,A unit of electrical reactive power represented by a current of one thousand amperes flowing due a potential difference of one thousand volts where the sine of the phase angle between them is 1.,1M,Mvar,nan
+1616,nan,MAW,megawatt,A unit of power defining the rate of energy transferred or consumed when a current of 1000 amperes flows due to a potential of 1000 volts at unity power factor.,1S,MW,10⁶ W
+1617,nan,MBE,thousand standard brick equivalent,A unit of count defining the number of one thousand brick equivalent units.,3.5,nan,nan
+1618,nan,MBF,thousand board foot,A unit of volume equal to one thousand board foot.,3.5,nan,nan
+1619,nan,MBR,millibar,nan,1S,mbar,10² Pa
+1620,nan,MC,microgram,nan,1S,µg,10⁻⁹ kg
+1621,nan,MCU,millicurie,nan,2S,mCi,"3,7 x 10⁷ Bq"
+1622,nan,MD,air dry metric ton,"A unit of count defining the number of metric tons of a product, disregarding the water content of the product.",3.1,nan,nan
+1623,X,MF,milligram per square foot per side,nan,3.1,nan,nan
+1624,nan,MGM,milligram,nan,1S,mg,10⁻⁶ kg
+1625,nan,MHZ,megahertz,nan,1S,MHz,10⁶ Hz
+1626,nan,MIK,square mile (statute mile),nan,2,mi²,"2,589 988 km²"
+1627,nan,MIL,thousand,nan,3.7,nan,10³
+1628,nan,MIN,minute [unit of time],nan,1,min,60 s
+1629,nan,MIO,million,nan,3.7,nan,10⁶
+1630,nan,MIU,million international unit,A unit of count defining the number of international units in multiples of 10⁶.,3.7,nan,nan
+1631,X,MK,milligram per square inch,nan,3.5,mg/in²,nan
+1632,nan,MLD,milliard,Synonym: billion (US),3.7,nan,10⁹
+1633,nan,MLT,millilitre,nan,1S,ml,10⁻⁶ m³
+1634,nan,MMK,square millimetre,nan,1S,mm²,10⁻⁶ m²
+1635,nan,MMQ,cubic millimetre,nan,1S,mm³,10⁻⁹ m³
+1636,nan,MMT,millimetre,nan,1S,mm,10⁻³ m
+1637,nan,MND,"kilogram, dry weight","A unit of mass defining the number of kilograms of a product, disregarding the water content of the product.",3.1,nan,nan
+1638,nan,MON,month,"Unit of time equal to 1/12 of a year of 365,25 days.",2,mo,"2,629 800 x 10⁶ s"
+1639,nan,MPA,megapascal,nan,1S,MPa,10⁶ Pa
+1640,X,MQ,thousand metre,nan,3.8,nan,10³m
+1641,nan,MQH,cubic metre per hour,nan,1M,m³/h,"2,777 78 x 10⁻⁴ m³/s"
+1642,nan,MQS,cubic metre per second,nan,1,m³/s,m³/s
+1643,nan,MSK,metre per second squared,nan,1,m/s²,m/s²
+1644,X,MT,mat,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+1645,nan,MTK,square metre,nan,1,m²,m²
+1646,nan,MTQ,cubic metre,Synonym: metre cubed,1,m³,m³
+1647,nan,MTR,metre,nan,1,m,m
+1648,nan,MTS,metre per second,nan,1,m/s,m/s
+1649,X,MV,number of mults,nan,3.7,nan,nan
+1650,nan,MVA,megavolt - ampere,nan,1S,MV·A,10⁶ V x A
+1651,nan,MWH,megawatt hour (1000 kW.h),A unit of power defining the total amount of bulk energy transferred or consumed.,1S,MW·h,"3,6 x 10⁹ J"
+1652,nan,N1,pen calorie,A unit of count defining the number of calories prescribed daily for parenteral/enteral therapy.,3.9,nan,nan
+1653,nan,N10,pound foot per second,Product of the avoirdupois pound according to the avoirdupois unit system and the unit foot according to the Anglo-American and Imperial system of units divided by the SI base unit second.,2.0,lb·(ft/s),"1,382 550 x 10⁻¹ kg x m/s"
+1654,nan,N11,pound inch per second,Product of the avoirdupois pound according to the avoirdupois unit system and the unit inch according to the Anglo-American and Imperial system of units divided by the SI base unit second.,2.0,lb·(in/s),"1,152 125 x 10⁻² kg x m/s"
+1655,nan,N12,Pferdestaerke,"Obsolete unit of the power relating to DIN 1301-3:1979: 1 PS = 735,498 75 W.",2,PS,"7,354 988 x 10² W"
+1656,nan,N13,centimetre of mercury (0 ºC),"Non SI-conforming unit of pressure, at which a value of 1 cmHg meets the static pressure, which is generated by a mercury at a temperature of 0 °C with a height of 1 centimetre .",2,cmHg (0 ºC),"1,333 22 x 10³ Pa"
+1657,nan,N14,centimetre of water (4 ºC),"Non SI-conforming unit of pressure, at which a value of 1 cmH2O meets the static pressure, which is generated by a head of water at a temperature of 4 °C with a height of 1 centimetre .",2,cmH₂O (4 °C),"9,806 38 x 10 Pa"
+1658,nan,N15,foot of water (39.2 ºF),"Non SI-conforming unit of pressure according to the Anglo-American and Imperial system for units, whereas the value of 1 ftH2O is equivalent to the static pressure, which is generated by a head of water at a temperature 39,2°F with a height of 1 foot .",2,"ftH₂O (39,2 ºF)","2,988 98 x 10³  Pa"
+1659,nan,N16,inch of mercury (32 ºF),"Non SI-conforming unit of pressure according to the Anglo-American and Imperial system for units, whereas the value of 1 inHg meets the static pressure, which is generated by a mercury at a temperature of 32°F with a height of 1 inch.",2,inHG (32 ºF),"3,386 38 x 10³  Pa"
+1660,nan,N17,inch of mercury (60 ºF),"Non SI-conforming unit of pressure according to the Anglo-American and Imperial system for units, whereas the value of 1 inHg meets the static pressure, which is generated by a mercury at a temperature of 60°F with a height of 1 inch.",2,inHg (60 ºF),"3,376 85 x 10³  Pa"
+1661,nan,N18,inch of water (39.2 ºF),"Non SI-conforming unit of pressure according to the Anglo-American and Imperial system for units, whereas the value of 1 inH2O meets the static pressure, which is generated by a head of water at a temperature of 39,2°F with a height of 1 inch .",2,"inH₂O (39,2 ºF)","2,490 82 × 10² Pa"
+1662,nan,N19,inch of water (60 ºF),"Non SI-conforming unit of pressure according to the Anglo-American and Imperial system for units, whereas the value of 1 inH2O meets the static pressure, which is generated by a head of water at a temperature of 60°F with a height of 1 inch .",2,inH₂O (60 ºF),"2,488 4 × 10² Pa"
+1663,X,N2,number of lines,nan,3.9,nan,nan
+1664,nan,N20,kip per square inch,Non SI-conforming unit of the pressure according to the Anglo-American system of units as the 1000-fold of the unit of the force pound-force divided by the power of the unit inch by exponent 2.,2,ksi,"6,894 757 x 10⁶ Pa"
+1665,nan,N21,poundal per square foot,"Non SI-conforming unit of pressure by the Imperial system of units according to NIST: 1 pdl/ft² = 1,488 164 Pa.",2,pdl/ft²,"1,488 164 Pa"
+1666,nan,N22,ounce (avoirdupois) per square inch,Unit of the surface specific mass (avoirdupois ounce according to the avoirdupois system of units according to the surface square inch according to the Anglo-American and Imperial system of units).,2,oz/in²,"4,394 185 x 10 kg/m²"
+1667,nan,N23,conventional metre of water,"Not SI-conforming unit of pressure, whereas a value of 1 mH2O is equivalent to the static pressure, which is produced by one metre high water column .",2,mH₂O,"9,806 65 x 10³ Pa"
+1668,nan,N24,gram per square millimetre,"0,001-fold of the SI base unit kilogram divided by the 0.000 001-fold of the power of the SI base unit meter by exponent 2.",2,g/mm²,10³ kg/m²
+1669,nan,N25,pound per square yard,Unit for areal-related mass as a unit pound according to the avoirdupois unit system divided by the power of the unit yard according to the Anglo-American and Imperial system of units with exponent 2.,2,lb/yd²,"5,424 919 x 10⁻¹ kg/m²"
+1670,nan,N26,poundal per square inch,Non SI-conforming unit of the pressure according to the Imperial system of units (poundal by square inch).,2,pdl/in²,"2,142 957 × 10² Pa"
+1671,nan,N27,foot to the fourth power,"Power of the unit foot according to the Anglo-American and Imperial system of units by exponent 4 according to NIST: 1 ft4 = 8,630 975 m4.",2,ft⁴,"8,630 975 x 10⁻³ m⁴"
+1672,nan,N28,cubic decimetre per kilogram,"0,001 fold of the power of the SI base unit meter by exponent 3 divided by the SI based unit kilogram.",1M,dm³/kg,10⁻³ m³ x kg⁻¹
+1673,nan,N29,cubic foot per pound,Power of the unit foot according to the Anglo-American and Imperial system of units by exponent 3 divided by the unit avoirdupois pound according to the avoirdupois unit system.,2.0,ft³/lb,"6,242 796 x 10⁻² m³/kg"
+1674,nan,N3,print point,nan,3.5,nan,"0,013 8 in (approx)"
+1675,nan,N30,cubic inch per pound,Power of the unit inch according to the Anglo-American and Imperial system of units by exponent 3 divided by the avoirdupois pound according to the avoirdupois unit system .,2.0,in³/lb,"3,612 728 x 10⁻⁵ m³/kg"
+1676,nan,N31,kilonewton per metre,1000-fold of the derived SI unit newton divided by the SI base unit metre.,1M,kN/m,10³ N/m
+1677,nan,N32,poundal per inch,Non SI-conforming unit of the surface tension according to the Imperial unit system as quotient poundal by inch.,2.0,pdl/in,"5,443 110 N/m"
+1678,nan,N33,pound-force per yard,Unit of force per unit length based on the Anglo-American system of units.,2.0,lbf/yd,"4,864 635 N/m"
+1679,nan,N34,poundal second per square foot,Non SI-conforming unit of viscosity.,2.0,(pdl/ft²)·s,"1,488 164 Pa x s"
+1680,nan,N35,poise per pascal,CGS (Centimetre-Gram-Second system) unit poise divided by the derived SI unit pascal.,2,P/Pa,"0,1 s"
+1681,nan,N36,newton second per square metre,Unit of the dynamic viscosity as a product of unit of the pressure (newton by square metre) multiplied with the SI base unit second.,1S,(N/m²)·s,Pa x s
+1682,nan,N37,kilogram per metre second,Unit of the dynamic viscosity as a quotient SI base unit kilogram divided by the SI base unit metre and by the SI base unit second.,1.0,kg/(m·s),Pa x s
+1683,nan,N38,kilogram per metre minute,Unit of the dynamic viscosity as a quotient SI base unit kilogram divided by the SI base unit metre and by the unit minute.,1.0,kg/(m·min),"1,666 67 × 10⁻² Pa x s"
+1684,nan,N39,kilogram per metre day,Unit of the dynamic viscosity as a quotient SI base unit kilogram divided by the SI base unit metre and by the unit day.,1M,kg/(m·d),"1,157 41 × 10⁻⁵ Pa x s"
+1685,nan,N40,kilogram per metre hour,Unit of the dynamic viscosity as a quotient SI base unit kilogram divided by the SI base unit metre and by the unit hour.,1M,kg/(m·h),"2,777 78 × 10⁻⁴ Pa x s"
+1686,nan,N41,gram per centimetre second,"Unit of the dynamic viscosity as a quotient of the 0,001-fold of the SI base unit kilogram divided by the 0,01-fold of the SI base unit metre and SI base unit second.",1M,g/(cm·s),"0,1 Pa x s"
+1687,nan,N42,poundal second per square inch,Non SI-conforming unit of dynamic viscosity according to the Imperial system of units as product unit of the pressure (poundal by square inch) multiplied by the SI base unit second.,2.0,(pdl/in²)·s,"2,142 957 x 10² Pa x s"
+1688,nan,N43,pound per foot minute,Unit of the dynamic viscosity according to the Anglo-American unit system.,2.0,lb/(ft·min),"2,480 273 x 10⁻²  Pa x s"
+1689,nan,N44,pound per foot day,Unit of the dynamic viscosity according to the Anglo-American unit system.,2.0,lb/(ft·d),"1,722 412 x 10⁻⁵ Pa x s"
+1690,nan,N45,cubic metre per second pascal,Power of the SI base unit meter by exponent 3 divided by the product of the SI base unit second and the derived SI base unit pascal.,1S,(m³/s)/Pa,kg⁻¹ x m⁴ x s
+1691,nan,N46,foot poundal,Unit of the work (force-path).,2,ft·pdl,"4,214 011 x 10⁻² J"
+1692,nan,N47,inch poundal,Unit of work (force multiplied by path) according to the Imperial system of units as a product unit inch multiplied by poundal.,2.0,in·pdl,"3,511 677 x 10⁻³ J"
+1693,nan,N48,watt per square centimetre,"Derived SI unit watt divided by the power of the 0,01-fold the SI base unit metre by exponent 2.",2.0,W/cm²,10⁴ W/m²
+1694,nan,N49,watt per square inch,Derived SI unit watt divided by the power of the unit inch according to the Anglo-American and Imperial system of units by exponent 2.,2.0,W/in²,"1,550 003 x 10³ W/m²"
+1695,nan,N50,British thermal unit (international table) per square foot hour,Unit of the surface heat flux according to the Imperial system of units.,2.0,BtuIT/(ft²·h),"3,154 591 W/m²"
+1696,nan,N51,British thermal unit (thermochemical) per square foot hour,Unit of the surface heat flux according to the Imperial system of units.,2.0,Btuth/(ft²·h),"3,152 481 W/m²"
+1697,nan,N52,British thermal unit (thermochemical) per square foot minute,Unit of the surface heat flux according to the Imperial system of units.,2.0,Btuth/(ft²·min) ,"1,891 489 x 10² W/m²"
+1698,nan,N53,British thermal unit (international table) per square foot second,Unit of the surface heat flux according to the Imperial system of units.,2.0,BtuIT/(ft²·s),"1,135 653 x 10⁴ W/m²"
+1699,nan,N54,British thermal unit (thermochemical) per square foot second,Unit of the surface heat flux according to the Imperial system of units.,2.0,Btuth/(ft²·s),"1,134 893 x 10⁴ W/m²"
+1700,nan,N55,British thermal unit (international table) per square inch second,Unit of the surface heat flux according to the Imperial system of units.,2.0,BtuIT/(in²·s),"1,634 246 x 10⁶ W/m²"
+1701,nan,N56,calorie (thermochemical) per square centimetre minute,Unit of the surface heat flux according to the Imperial system of units.,2.0,calth/(cm²·min),"6,973 333 x 10² W/m²"
+1702,nan,N57,calorie (thermochemical) per square centimetre second,Unit of the surface heat flux according to the Imperial system of units.,2.0,calth/(cm²·s),"4,184 x 10⁴ W/m²"
+1703,nan,N58,British thermal unit (international table) per cubic foot,Unit of the energy density according to the Imperial system of units.,2.0,BtuIT/ft³,"3,725 895 x10⁴ J/m³"
+1704,nan,N59,British thermal unit (thermochemical) per cubic foot,Unit of the energy density according to the Imperial system of units.,2.0,Btuth/ft³,"3,723 403 x10⁴ J/m³"
+1705,nan,N60,British thermal unit (international table) per degree Fahrenheit,Unit of the heat capacity according to the Imperial system of units.,2.0,BtuIT/ºF,"1,899 101 x 10³ J/K"
+1706,nan,N61,British thermal unit (thermochemical) per degree Fahrenheit,Unit of the heat capacity according to the Imperial system of units.,2.0,Btuth/ºF,"1,897 830 x 10³ J/K"
+1707,nan,N62,British thermal unit (international table) per degree Rankine,Unit of the heat capacity according to the Imperial system of units.,2.0,BtuIT/ºR,"1,899 101 x 10³ J/K"
+1708,nan,N63,British thermal unit (thermochemical) per degree Rankine,Unit of the heat capacity according to the Imperial system of units.,2.0,Btuth/ºR,"1,897 830 x 10³ J/K"
+1709,nan,N64,British thermal unit (thermochemical) per pound degree Rankine,Unit of the heat capacity (British thermal unit according to the international table according to the Rankine degree) according to the Imperial system of units divided by the unit avoirdupois pound according to the avoirdupois system of units.,2,(Btuth/°R)/lb,"4,184 x 10³ J/(kg x K)"
+1710,nan,N65,kilocalorie (international table) per gram kelvin,"Unit of the mass-related heat capacity as quotient 1000-fold of the calorie (international table) divided by the product of the 0,001-fold of the SI base units kilogram and kelvin.",2,(kcalIT/K)/g,"4,186 8 x 10⁶ J/(kg x K)"
+1711,nan,N66,British thermal unit (39 ºF),Unit of heat energy according to the Imperial system of units in a reference temperature of 39 °F.,2,Btu (39 ºF) ,"1,059 67  x 10³ J"
+1712,nan,N67,British thermal unit (59 ºF),Unit of heat energy according to the Imperial system of units in a reference temperature of 59 °F.,2,Btu (59 ºF),"1,054 80  x 10³ J"
+1713,nan,N68,British thermal unit (60 ºF),Unit of head energy according to the Imperial system of units at a reference temperature of 60 °F.,2,Btu (60 ºF) ,"1,054 68  x 10³ J"
+1714,nan,N69,calorie (20 ºC),"Unit for quantity of heat, which is to be required for 1 g air free water at a constant pressure from 101,325 kPa, to warm up the pressure of standard atmosphere at sea level, from 19,5 °C on 20,5 °C.",2,cal₂₀,"4,181 90"
+1715,nan,N70,quad (1015 BtuIT),Unit of heat energy according to the imperial system of units.,2,quad,"1,055 056 × 10¹⁸ J"
+1716,nan,N71,therm (EC),"Unit of heat energy in commercial use, within the EU defined: 1 thm (EC) = 100 000 BtuIT.",2,thm (EC),"1,055 06 × 10⁸ J"
+1717,nan,N72,therm (U.S.),Unit of heat energy in commercial use.,2,thm (US),"1,054 804 × 10⁸ J"
+1718,nan,N73,British thermal unit (thermochemical) per pound,Unit of the heat energy according to the Imperial system of units divided the unit avoirdupois pound according to the avoirdupois system of units.,2,Btuth/lb,"2,324 444 x 10³ J/kg"
+1719,nan,N74,British thermal unit (international table) per hour square foot degree Fahrenheit,Unit of the heat transition coefficient according to the Imperial system of units.,2,BtuIT/(h·ft²·ºF),"5,678 263 W/(m² x K)"
+1720,nan,N75,British thermal unit (thermochemical) per hour square foot degree Fahrenheit,Unit of the heat transition coefficient according to the imperial system of units.,2,Btuth/(h·ft²·ºF),"5,674 466 W/(m² x K)"
+1721,nan,N76,British thermal unit (international table) per second square foot degree Fahrenheit,Unit of the heat transition coefficient according to the imperial system of units.,2,BtuIT/(s·ft²·ºF),"2,044 175 x 10⁴ W/(m² x K)"
+1722,nan,N77,British thermal unit (thermochemical) per second square foot degree Fahrenheit,Unit of the heat transition coefficient according to the imperial system of units.,2,Btuth/(s·ft²·ºF) ,"2,042 808 x 10⁴ W/(m² x K)"
+1723,nan,N78,kilowatt per square metre kelvin,1000-fold of the derived SI unit watt divided by the product of the power of the SI base unit metre by exponent 2 and the SI base unit kelvin.,1M,kW/(m²·K),10³ W/(m² x K)
+1724,nan,N79,kelvin per pascal,SI base unit kelvin divided by the derived SI unit pascal.,1S,K/Pa,kg⁻¹ x m x s² x K
+1725,nan,N80,watt per metre degree Celsius,Derived SI unit watt divided by the product of the SI base unit metre and the unit for temperature degree Celsius.,1M,W/(m·°C),W/(m x K)
+1726,nan,N81,kilowatt per metre kelvin,1000-fold of the derived SI unit watt divided by the product of the SI base unit metre and the SI base unit kelvin.,1M,kW/(m·K),10³ W/(m x K)
+1727,nan,N82,kilowatt per metre degree Celsius,1000-fold of the derived SI unit watt divided by the product of the SI base unit metre and the unit for temperature degree Celsius.,1M,kW/(m·°C),10³ W/(m x K)
+1728,nan,N83,metre per degree Celcius metre,SI base unit metre divided by the product of the unit degree Celsius and the SI base unit metre.,2.0,m/(°C·m),K⁻¹
+1729,nan,N84,degree Fahrenheit hour per British thermal unit (international table),Non SI-conforming unit of the thermal resistance according to the Imperial system of units.,2.0,ºF/(BtuIT/h),"1,895 634 K/W"
+1730,nan,N85,degree Fahrenheit hour per British thermal unit (thermochemical),Non SI-conforming unit of the thermal resistance according to the Imperial system of units.,2.0,ºF/(Btuth/h),"1,896 903 K/W"
+1731,nan,N86,degree Fahrenheit second per British thermal unit (international table),Non SI-conforming unit of the thermal resistance according to the Imperial system of units.,2.0,ºF/(BtuIT/s),"5,265 651 x 10⁻⁴ K/W"
+1732,nan,N87,degree Fahrenheit second per British thermal unit (thermochemical),Non SI-conforming unit of the thermal resistance according to the Imperial system of units.,2.0,ºF/(Btuth/s),"5,269 175 x 10⁻⁴ K/W"
+1733,nan,N88,degree Fahrenheit hour square foot per British thermal unit (international table) inch,Unit of specific thermal resistance according to the Imperial system of units.,2.0,ºF·h·ft²/(BtuIT·in),"6,933 472 K x m/W"
+1734,nan,N89,degree Fahrenheit hour square foot per British thermal unit (thermochemical) inch,Unit of specific thermal resistance according to the Imperial system of units.,2.0,ºF·h·ft²/(Btuth·in),"6,938 112 K x m/W"
+1735,nan,N90,kilofarad,1000-fold of the derived SI unit farad.,1M,kF,10³ F
+1736,nan,N91,reciprocal joule,Reciprocal of the derived SI unit joule.,1.0,1/J,1/J
+1737,nan,N92,picosiemens,"0,000 000 000 001-fold of the derived SI unit siemens.",1M,pS,10⁻¹² S
+1738,nan,N93,ampere per pascal,SI base unit ampere divided by the derived SI unit pascal.,1M,A/Pa,kg⁻¹ x m x s² x A
+1739,nan,N94,franklin,"CGS (Centimetre-Gram-Second system) unit of the electrical charge, where the charge amounts to exactly 1 Fr where the force of 1 dyn on an equal load is performed at a distance of 1 cm.",2.0,Fr,"3,335 641 x 10⁻¹⁰ C"
+1740,nan,N95,ampere minute,A unit of electric charge defining the amount of charge accumulated by a steady flow of one ampere for one minute..,1M,A·min,60 C
+1741,nan,N96,biot,CGS (Centimetre-Gram-Second system) unit of the electric power which is defined by a force of 2 dyn per cm between two parallel conductors of infinite length with negligible cross-section in the distance of 1 cm.,2.0,Bi,10¹ A
+1742,nan,N97,gilbert,"CGS (Centimetre-Gram-Second system) unit of the magnetomotive force, which is defined by the work to increase the magnetic potential of a positive common pol with 1 erg.",2.0,Gi,"7,957 747 x 10⁻¹ A"
+1743,nan,N98,volt per pascal,Derived SI unit volt divided by the derived SI unit pascal.,1M,V/Pa,m³ x s⁻¹ x A⁻¹
+1744,nan,N99,picovolt,"0,000 000 000 001-fold of the derived SI unit volt.",1M,pV,10⁻¹² V
+1745,nan,NA,milligram per kilogram,nan,1S,mg/kg,10⁻⁶  1
+1746,nan,NAR,number of articles,A unit of count defining the number of articles (article: item).,3.7,nan,nan
+1747,X,NB,barge,nan,3.4,nan,nan
+1748,X,NBB,number of bobbins,nan,3.7,nan,nan
+1749,X,NC,car,nan,3.5,nan,nan
+1750,nan,NCL,number of cells,"A unit of count defining the number of cells (cell: an enclosed or circumscribed space, cavity, or volume).",3.7,nan,nan
+1751,X,ND,net barrel,nan,3.1,nan,nan
+1752,X,NE,net litre,nan,3.1,nan,nan
+1753,nan,NEW,newton,nan,1,N,(kg x m)/s²
+1754,nan,NF,message,A unit of count defining the number of messages.,3.9,nan,nan
+1755,X,NG,net gallon (us),nan,3.1,nan,nan
+1756,X,NH,message hour,nan,3.5,nan,nan
+1757,X,NI,net imperial gallon,nan,3.1,nan,nan
+1758,nan,NIL,nil,A unit of count defining the number of instances of nothing.,3.8,(),nan
+1759,nan,NIU,number of international units,A unit of count defining the number of international units.,3.7,nan,nan
+1760,X,NJ,number of screens,nan,3.7,nan,nan
+1761,nan,NL,load,A unit of volume defining the number of loads (load: a quantity of items carried or processed at one time).,3.4,nan,nan
+1762,¦,NM3,Normalised cubic metre,Normalised cubic metre (temperature 0°C and pressure 1013.25 millibars ),2,nan,m3
+1763,nan,NMI,nautical mile,nan,1,n mile,1 852 m
+1764,nan,NMP,number of packs,A unit of count defining the number of packs (pack: a collection of objects packaged together).,3.7,nan,nan
+1765,X,NN,train,nan,3.5,nan,nan
+1766,X,NPL,number of parcels,nan,3.7,nan,nan
+1767,D,NPR,number of pairs,A unit of count defining the number of pairs (pair: item described by two's).,3.7,nan,use pair
+1768,nan,NPT,number of parts,A unit of count defining the number of parts (part: component of a larger entity).,3.7,nan,nan
+1769,D,NQ,mho,nan,2,nan,S
+1770,D,NR,micromho,nan,2,nan,10⁻⁶ S
+1771,X,NRL,number of rolls,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.7,nan,nan
+1772,nan,NT,net ton,"A unit of mass equal to 2000 pounds, see ton (US).  Refer International Convention on tonnage measurement of Ships.",3.4,nan,nan
+1773,D,NTT,net register ton,"A unit of mass equal to the total cubic footage after deductions, where 1 register ton is equal to 100 cubic feet. Refer International Convention on tonnage measurement of Ships.",3.4,nan,nan
+1774,nan,NU,newton metre,nan,1,N·m,N x m
+1775,X,NV,vehicle,nan,3.4,nan,nan
+1776,nan,NX,part per thousand,"A unit of proportion equal to 10⁻³. ,Synonym: per mille",3.7,‰,1 x 10⁻³
+1777,X,NY,pound per air dry metric ton,nan,3.5,nan,nan
+1778,nan,OA,panel,"A unit of count defining the number of panels (panel: a distinct, usually rectangular, section of a surface).",3.9,nan,nan
+1779,nan,ODE,ozone depletion equivalent,"A unit of mass defining the ozone depletion potential in kilograms of a product relative to the calculated depletion for the reference substance, Trichlorofluoromethane (CFC-11).",3.1,nan,nan
+1780,nan,ODG,ODS Grams,"A unit of measure calculated by multiplying the mass of the substance in grams and the ozone-depleting potential for the substance.,",3.1,nan,nan
+1781,nan,ODK,ODS Kilograms,A unit of measure calculated by multiplying the mass of the substance in kilograms and the ozone-depleting potential for the substance.,3.1,nan,nan
+1782,nan,ODM,ODS Milligrams,A unit of measure calculated by multiplying the mass of the substance in milligrams and the ozone-depleting potential for the substance.,3.1,nan,nan
+1783,nan,OHM,ohm,nan,1,Ω,Ω
+1784,nan,ON,ounce per square yard,nan,2,oz/yd²,"3,390 575 x 10⁻² kg/m²"
+1785,nan,ONZ,ounce (avoirdupois),nan,2,oz,"2,834 952 x 10⁻² kg"
+1786,X,OP,two pack,nan,3.2,nan,nan
+1787,nan,OPM,oscillations per minute,The number of oscillations per minute.,2,o/min,1.667 x 10-2 /s
+1788,nan,OT,overtime hour,A unit of time defining the number of overtime hours.,3.1,nan,nan
+1789,D,OZ,ounce av,A unit of measure equal to 1/16 of a pound or about 28.3495 grams (av = avoirdupois). Use ounce (common code ONZ).,3.1,nan,nan
+1790,nan,OZA,fluid ounce (US),nan,2,fl oz (US),"2,957 353 x 10⁻⁵ m³"
+1791,nan,OZI,fluid ounce (UK),nan,2,fl oz (UK),"2,841 306 x 10⁻⁵ m³"
+1792,X,P0,page - electronic,nan,3.9,nan,nan
+1793,nan,P1,percent,A unit of proportion equal to 0.01.,3.7,% or pct,1 x 10⁻²
+1794,nan,P10,coulomb per metre,Derived SI unit coulomb divided by the SI base unit metre.,1.0,C/m,m⁻¹ x s x A
+1795,nan,P11,kiloweber,1000 fold of the derived SI unit weber.,1M,kWb,10³ Wb
+1796,nan,P12,gamma,Unit of magnetic flow density.,2.0,γ,10⁻⁹ T
+1797,nan,P13,kilotesla,1000-fold of the derived SI unit tesla.,1M,kT,10³ T
+1798,nan,P14,joule per second,Quotient of the derived SI unit joule divided by the SI base unit second.,1.0,J/s,W
+1799,nan,P15,joule per minute,Quotient from the derived SI unit joule divided by the unit minute.,1M,J/min,"1,666 67 × 10⁻² W"
+1800,nan,P16,joule per hour,Quotient from the derived SI unit joule divided by the unit hour.,1M,J/h,"2,777 78 × 10⁻⁴ W"
+1801,nan,P17,joule per day,Quotient from the derived SI unit joule divided by the unit day.,1M,J/d,"1,157 41 × 10⁻⁵ W"
+1802,nan,P18,kilojoule per second,Quotient from the 1000-fold of the derived SI unit joule divided by the SI base unit second.,1M,kJ/s,10³ W
+1803,nan,P19,kilojoule per minute,Quotient from the 1000-fold of the derived SI unit joule divided by the unit minute.,1M,kJ/min,"1,666 67 × 10 W"
+1804,nan,P2,pound per foot,nan,2,lb/ft,"1,488 164 kg/m"
+1805,nan,P20,kilojoule per hour,Quotient from the 1000-fold of the derived SI unit joule divided by the unit hour.,1M,kJ/h,"2,777 78 x 10⁻¹ W"
+1806,nan,P21,kilojoule per day,Quotient from the 1000-fold of the derived SI unit joule divided by the unit day.,1M,kJ/d,"1,157 41 x 10⁻² W"
+1807,nan,P22,nanoohm,"0,000 000 001-fold of the derived SI unit ohm.",1M,nΩ,10⁻⁹ Ω
+1808,nan,P23,ohm circular-mil per foot,Unit of resistivity.,2.0,Ω·cmil/ft ,"1,662 426 x 10⁻⁹ Ω x m"
+1809,nan,P24,kilohenry,1000-fold of the derived SI unit henry.,1M,kH,10³ H
+1810,nan,P25,lumen per square foot,Derived SI unit lumen divided by the power of the unit foot according to the Anglo-American and Imperial system of units by exponent 2.,2.0,lm/ft²,"1,076 391 x 10¹ cd x sr / m²"
+1811,nan,P26,phot,"CGS (Centimetre-Gram-Second system) unit of luminance, defined as lumen by square centimetre.",2.0,ph,10⁴ cd x sr / m²
+1812,nan,P27,footcandle,"Non SI conform traditional unit, defined as density of light which impinges on a surface which has a distance of one foot from a light source, which shines with an intensity of an international candle.",2.0,ftc,"1,076 391 x 10¹ cd x sr / m²"
+1813,nan,P28,candela per square inch,SI base unit candela divided by the power of unit inch according to the Anglo-American and Imperial system of units by exponent 2.,2.0,cd/in²,"1,550 003 x 10³ cd/m²"
+1814,nan,P29,footlambert,"Unit of the luminance according to the Anglo-American system of units, defined as emitted or reflected luminance of a lm/ft².",2.0,ftL,"3,426 259 cd/m²"
+1815,X,P3,three pack,nan,3.2,nan,nan
+1816,nan,P30,lambert,"CGS (Centimetre-Gram-Second system) unit of luminance, defined as the emitted or reflected luminance by one lumen per square centimetre.",2.0,Lb,"3,183 099 x 10³ cd/m²"
+1817,nan,P31,stilb,"CGS (Centimetre-Gram-Second system) unit of luminance, defined as emitted or reflected luminance by one lumen per square centimetre.",2.0,sb,10⁴ cd/m²
+1818,nan,P32,candela per square foot,Base unit SI candela divided by the power of the unit foot according to the Anglo-American and Imperial system of units by exponent 2.,2.0,cd/ft²,"1,076 391 x 10 cd/m²"
+1819,nan,P33,kilocandela,1000-fold of the SI base unit candela.,1M,kcd,10³ cd
+1820,nan,P34,millicandela,"0,001-fold of the SI base unit candela.",1M,mcd,10⁻³ cd
+1821,nan,P35,Hefner-Kerze,"Obsolete, non-legal unit of the power in Germany relating to DIN 1301-3:1979: 1 HK = 0,903 cd.",2.0,HK,"0,903 cd"
+1822,nan,P36,international candle,"Obsolete, non-legal unit of the power in Germany relating to DIN 1301-3:1979: 1 HK = 1,019 cd.",2.0,IK,"1,019 cd"
+1823,nan,P37,British thermal unit (international table) per square foot,Unit of the areal-related energy transmission according to the Imperial system of units.,2.0,BtuIT/ft²,"1,135 653 x 10⁴ J/m²"
+1824,nan,P38,British thermal unit (thermochemical) per square foot,Unit of the areal-related energy transmission according to the Imperial system of units.,2.0,Btuth/ft²,"1,134 893 x 10⁴ J/m²"
+1825,nan,P39,calorie (thermochemical) per square centimetre,Unit of the areal-related energy transmission according to the Imperial system of units.,2.0,calth/cm²,"4,184 x 10⁴ J/m²"
+1826,X,P4,four pack,nan,3.2,nan,nan
+1827,nan,P40,langley,CGS (Centimetre-Gram-Second system) unit of the areal-related energy transmission (as a measure of the incident quantity of heat of solar radiation on the earth's surface).,2.0,Ly,"4,184 x 10⁴ J/m²"
+1828,nan,P41,decade (logarithmic),"1 Dec := log2 10 ˜ 3,32 according to the logarithm for frequency range between f1 and f2, when f2/f1 = 10.",2,dec,dec
+1829,nan,P42,pascal squared second,Unit of the set as a product of the power of derived SI unit pascal with exponent 2 and the SI base unit second.,1.0,Pa²·s,m⁻² x kg² x s⁻³
+1830,nan,P43,bel per metre,Unit bel divided by the SI base unit metre.,1M,B/m,B/m
+1831,nan,P44,pound mole,Non SI-conforming unit of quantity of a substance relating that one pound mole of a chemical composition corresponds to the same number of pounds as the molecular weight of one molecule of this composition in atomic mass units.,2.0,lbmol,"453,592 4 mol"
+1832,nan,P45,pound mole per second,Non SI-conforming unit of the power of the amount of substance non-SI compliant unit of the molar flux relating that a pound mole of a chemical composition the same number of pound corresponds like the molecular weight of a molecule of this composition in atomic mass units.,2.0,lbmol/s,"4,535 924 x 10² mol/s"
+1833,nan,P46,pound mole per minute,Non SI-conforming unit of the power of the amount of substance non-SI compliant unit of the molar flux relating that a pound mole of a chemical composition the same number of pound corresponds like the molecular weight of a molecule of this composition in atomic mass units.,2.0,lbmol/h,"7,559 873 mol/s"
+1834,nan,P47,kilomole per kilogram,1000-fold of the SI base unit mol divided by the SI base unit kilogram.,1M,kmol/kg,10³ mol/kg
+1835,nan,P48,pound mole per pound,Non SI-conforming unit of the material molar flux divided by the avoirdupois pound for mass according to the avoirdupois unit system.,2.0,lbmol/lb,10³ mol/kg
+1836,nan,P49,newton square metre per ampere,Product of the derived SI unit newton and the power of SI base unit metre with exponent 2 divided by the SI base unit ampere.,1S,N·m²/A,m³ x kg x s⁻²  x A⁻¹
+1837,nan,P5,five pack,A unit of count defining the number of five-packs (five-pack: set of five items packaged together).,3.2,nan,nan
+1838,nan,P50,weber metre,Product of the derived SI unit weber and SI base unit metre.,1S,Wb·m,m³ x kg x s⁻²  x A⁻¹
+1839,nan,P51,mol per kilogram pascal,SI base unit mol divided by the product of the SI base unit kilogram and the derived SI unit pascal.,1S,(mol/kg)/Pa,m x kg⁻² x s² x mol
+1840,nan,P52,mol per cubic metre pascal,SI base unit mol divided by the product of the power from the SI base unit metre with exponent 3 and the derived SI unit pascal.,1S,(mol/m³)/Pa,m⁻² x kg⁻¹ x s² x mol
+1841,nan,P53,unit pole,CGS (Centimetre-Gram-Second system) unit for magnetic flux of a magnetic pole (according to the interaction of identical poles of 1 dyn at a distance of a cm).,2.0,unit pole ,"1,256 637 x 10⁻⁷ Wb"
+1842,nan,P54,milligray per second,"0,001-fold of the derived SI unit gray divided by the SI base unit second.",1M,mGy/s,10⁻³ Gy/s
+1843,nan,P55,microgray per second,"0,000 001-fold of the derived SI unit gray divided by the SI base unit second.",1M,µGy/s,10⁻⁶ Gy/s
+1844,nan,P56,nanogray per second,"0,000 000 001-fold of the derived SI unit gray divided by the SI base unit second.",1M,nGy/s,10⁻⁹ Gy/s
+1845,nan,P57,gray per minute,SI derived unit gray divided by the unit minute.,1M,Gy/min,"1,666 67 × 10⁻² Gy/s"
+1846,nan,P58,milligray per minute,"0,001-fold of the derived SI unit gray divided by the unit minute.",1M,mGy/min,"1,666 67 × 10⁻⁵ Gy/s"
+1847,nan,P59,microgray per minute,"0,000 001-fold of the derived SI unit gray divided by the unit minute.",1M,µGy/min,"1,666 67 × 10⁻⁸ Gy/s"
+1848,X,P6,six pack,nan,3.2,nan,nan
+1849,nan,P60,nanogray per minute,"0,000 000 001-fold of the derived SI unit gray divided by the unit minute.",1M,nGy/min,"1,666 67 × 10⁻¹¹ Gy/s"
+1850,nan,P61,gray per hour,SI derived unit gray divided by the unit hour.,1M,Gy/h,"2,777 78 × 10⁻⁴ Gy/s"
+1851,nan,P62,milligray per hour,"0,001-fold of the derived SI unit gray divided by the unit hour.",1M,mGy/h,"2,777 78 × 10⁻⁷ Gy/s"
+1852,nan,P63,microgray per hour,"0,000 001-fold of the derived SI unit gray divided by the unit hour.",1M,µGy/h,"2,777 78 × 10⁻¹⁰ Gy/s"
+1853,nan,P64,nanogray per hour,"0,000 000 001-fold of the derived SI unit gray divided by the unit hour.",1M,nGy/h,"2,777 78 × 10⁻¹³ Gy/s"
+1854,nan,P65,sievert per second,Derived SI unit sievert divided by the SI base unit second.,2.0,Sv/s,Sv/s
+1855,nan,P66,millisievert per second,"0,001-fold of the derived SI unit sievert divided by the SI base unit second.",2.0,mSv/s,10⁻³ Sv/s
+1856,nan,P67,microsievert per second,"0,000 001-fold of the derived SI unit sievert divided by the SI base unit second.",2.0,µSv/s,10⁻⁶ Sv/s
+1857,nan,P68,nanosievert per second,"0,000 000 001-fold of the derived SI unit sievert divided by the SI base unit second.",2.0,nSv/s,10⁻⁹ Sv/s
+1858,nan,P69,rem per second,"Unit for the equivalent tin rate relating to DIN 1301-3:1979: 1 rem/s = 0,01 J/(kg·s) = 1 Sv/s.",2.0,rem/s,10⁻² Sv/s
+1859,X,P7,seven pack,nan,3.2,nan,nan
+1860,nan,P70,sievert per hour,Derived SI unit sievert divided by the unit hour.,2.0,Sv/h,"2,777 78 × 10⁻⁴ Sv/s"
+1861,nan,P71,millisievert per hour,"0,001-fold of the derived SI unit sievert divided by the unit hour.",2.0,mSv/h,"0,277 777 778 × 10⁻⁷ Sv/s"
+1862,nan,P72,microsievert per hour,"0,000 001-fold of the derived SI unit sievert divided by the unit hour.",2.0,µSv/h,"0,277 777 778 × 10⁻¹⁰ Sv/s"
+1863,nan,P73,nanosievert per hour,"0,000 000 001-fold of the derived SI unit sievert divided by the unit hour.",2.0,nSv/h,"0,277 777 778 × 10⁻¹³ Sv/s"
+1864,nan,P74,sievert per minute,Derived SI unit sievert divided by the unit minute.,2.0,Sv/min,"0,016 666 Sv/s"
+1865,nan,P75,millisievert per minute,"0,001-fold of the derived SI unit sievert divided by the unit minute.",2.0,mSv/min,"1,666 666 667 × 10⁻⁵ Sv/s"
+1866,nan,P76,microsievert per minute,"0,000 001-fold of the derived SI unit sievert divided by the unit minute.",2.0,µSv/min,"1,666 666 667 × 10⁻⁸ Sv/s"
+1867,nan,P77,nanosievert per minute,"0,000 000 001-fold of the derived SI unit sievert divided by the unit minute.",2.0,nSv/min,"1,666 666 667 × 10⁻¹¹ Sv/s"
+1868,nan,P78,reciprocal square inch,Complement of the power of the unit inch according to the Anglo-American and Imperial system of units by exponent 2.,2.0,1/in²,"1,550 003 x 10³ m⁻²"
+1869,nan,P79,pascal square metre per kilogram,"Unit of the burst index as derived unit for pressure pascal related to the substance, represented as a quotient from the SI base unit kilogram divided by the power of the SI base unit metre by exponent 2.",1.0,Pa/(kg/m²),m/s²
+1870,X,P8,eight pack,nan,3.2,nan,nan
+1871,nan,P80,millipascal per metre,"0,001-fold of the derived SI unit pascal divided by the SI base unit metre.",1M,mPa/m,10⁻³ kg/(m² x s²)
+1872,nan,P81,kilopascal per metre,1000-fold of the derived SI unit pascal divided by the SI base unit metre.,1M,kPa/m,10³ kg/(m² x s²)
+1873,nan,P82,hectopascal per metre,100-fold of the derived SI unit pascal divided by the SI base unit metre.,1M,hPa/m,10² kg/(m² x s²)
+1874,nan,P83,standard atmosphere per metre,Outdated unit of the pressure divided by the SI base unit metre.,2.0,Atm/m,"1,013 25 x 10⁵ kg/(m² x s²)"
+1875,nan,P84,technical atmosphere per metre,Obsolete and non-legal unit of the pressure which is generated by a 10 metre water column divided by the SI base unit metre.,2.0,at/m,"9,806 65 x 10⁴  kg/(m² x s²)"
+1876,nan,P85,torr per metre,CGS (Centimetre-Gram-Second system) unit of the pressure divided by the SI base unit metre.,2.0,Torr/m,"1,333 224 x 10² kg/(m² x s²)"
+1877,nan,P86,psi per inch,Compound unit for pressure (pound-force according to the Anglo-American unit system divided by the power of the unit inch according to the Anglo-American and Imperial system of units with the exponent 2) divided by the unit inch according to the Anglo-American and Imperial system of units .,2.0,psi/in,"2,714 471 x 10⁵ kg/(m² x s²)"
+1878,nan,P87,cubic metre per second square metre,Unit of volume flow cubic meters by second related to the transmission surface in square metres.,1M,(m³/s)/m²,m/s
+1879,nan,P88,rhe,Non SI-conforming unit of fluidity of dynamic viscosity.,3.5,rhe,10 m x kg⁻¹ x s
+1880,nan,P89,pound-force foot per inch,Unit for length-related rotational moment according to the Anglo-American and Imperial system of units.,3.5,lbf·ft/in,"53,378 66 m x kg / s²"
+1881,X,P9,nine pack,nan,3.2,nan,nan
+1882,nan,P90,pound-force inch per inch,Unit for length-related rotational moment according to the Anglo-American and Imperial system of units.,3.5,lbf·in/in,"4,448 222 m x kg / s²"
+1883,nan,P91,perm (0 ºC),"Traditional unit for the ability of a material to allow the transition of the steam, defined at a temperature of 0 °C as steam transmittance, where the mass of one grain steam penetrates an area of one foot squared at a pressure from one inch mercury per hour.",3.5,perm (0 ºC) ,"5,721 35 x 10⁻¹¹ kg/(m² x Pa x s)"
+1884,nan,P92,perm (23 ºC),"Traditional unit for the ability of a material to allow the transition of the steam, defined at a temperature of 23 °C as steam transmittance at which the mass of one grain of steam penetrates an area of one square foot at a pressure of one inch mercury per hour.",3.5,perm (23 ºC) ,"5,745 25 x 10⁻¹¹ kg/(m² x Pa x s)"
+1885,nan,P93,byte per second,Unit byte divided by the SI base unit second.,3.6,byte/s,byte/s
+1886,nan,P94,kilobyte per second,1000-fold of the unit byte divided by the SI base unit second.,3.6,kbyte/s,10³ byte/s
+1887,nan,P95,megabyte per second,1 000 000-fold of the unit byte divided by the SI base unit second.,3.6,Mbyte/s,10⁶ byte/s
+1888,nan,P96,reciprocal volt,Reciprocal of the derived SI unit volt.,3.5,1/V,m⁻² x kg⁻¹ x s³ x A
+1889,nan,P97,reciprocal radian,Reciprocal of the unit radian.,3.5,1/rad,1/rad
+1890,nan,P98,pascal to the power sum of stoichiometric numbers,"Unit of the equilibrium constant on the basis of the pressure(ISO 80000-9:2009, 9-35.a).",3.5,PaΣνB,nan
+1891,nan,P99,mole per cubiv metre to the power sum of stoichiometric numbers,"Unit of the equilibrium constant on the basis of the concentration (ISO 80000-9:2009, 9-36.a).",3.5,(mol/m³)∑νB,nan
+1892,X,PA,packet,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+1893,nan,PAL,pascal,nan,1,Pa,Pa
+1894,X,PB,pair inch,nan,3.8,nan,nan
+1895,nan,PD,pad,A unit of count defining the number of pads (pad: block of paper sheets fastened together at one end).,3.9,nan,nan
+1896,X,PE,pound equivalent,nan,3.1,nan,nan
+1897,X,PF,pallet (lift),"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+1898,nan,PFL,proof litre,"A unit of volume equal to one litre of proof spirits, or the alcohol equivalent thereof. Used for measuring the strength of distilled alcoholic liquors, expressed as a percentage of the alcohol content of a standard mixture at a specific temperature.",3.1,nan,nan
+1899,X,PG,plate,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+1900,nan,PGL,proof gallon,"A unit of volume equal to one gallon of proof spirits, or the alcohol equivalent thereof. Used for measuring the strength of distilled alcoholic liquors, expressed as a percentage of the alcohol content of a standard mixture at a specific temperature.",3.1,nan,nan
+1901,nan,PI,pitch,A unit of count defining the number of characters that fit in a horizontal inch.,3.5,nan,nan
+1902,X,PK,pack,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).,Synonym: package",3.3,nan,nan
+1903,X,PL,pail,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+1904,nan,PLA,degree Plato,"A unit of proportion defining the sugar content of a product, especially in relation to beer.",3.5,°P,nan
+1905,X,PM,pound percentage,nan,3.1,nan,nan
+1906,X,PN,pound net,nan,3.1,nan,nan
+1907,nan,PO,pound per inch of length,nan,2,lb/in,"1,785 797 x 10¹ kg/m"
+1908,nan,PQ,page per inch,"A unit of quantity defining the degree of thickness of a bound publication, expressed as the number of pages per inch of thickness.",3.5,ppi,nan
+1909,nan,PR,pair,A unit of count defining the number of pairs (pair: item described by two's).,3.7,nan,2
+1910,nan,PS,pound-force per square inch,nan,2,lbf/in²,"6,894 757 x 10³ Pa"
+1911,D,PT,pint (US),Use liquid pint (common code PTL),2,pt (US),"4, 731 76 x 10⁻⁴ m³"
+1912,nan,PTD,dry pint (US),nan,2,dry pt (US),"5,506 105 x 10⁻⁴ m³"
+1913,nan,PTI,pint (UK),nan,2,pt (UK),"5, 682 61 x 10⁻⁴ m³"
+1914,nan,PTL,liquid pint (US),nan,2,liq pt (US),"4, 731 765 x 10⁻⁴ m³"
+1915,nan,PTN,portion,"A quantity of allowance of food allotted to, or enough for, one person.",3.5,PTN,nan
+1916,X,PU,tray / tray pack,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+1917,X,PV,half pint (US),nan,3.8,nan,nan
+1918,X,PW,pound per inch of width,nan,3.1,nan,nan
+1919,X,PY,peck dry (US),nan,3.5,nan,nan
+1920,X,PZ,peck dry (UK),nan,3.5,nan,nan
+1921,nan,Q10,joule per tesla,Unit of the magnetic dipole moment of the molecule as derived SI unit joule divided by the derived SI unit tesla.,3.5,J/T,m² x A
+1922,nan,Q11,erlang,Unit of the market value according to the feature of a single feature as a statistical measurement of the existing utilization.,3.6,E,1 E
+1923,nan,Q12,octet,Synonym for byte: 1 octet = 8 bit = 1 byte.,3.6,o,8 bit
+1924,nan,Q13,octet per second,Unit octet divided by the SI base unit second.,3.6,o/s,8 bit/s
+1925,nan,Q14,shannon,"Logarithmic unit for information equal to the content of decision of a sentence of two mutually exclusive events, expressed as a logarithm to base 2.",3.6,Sh,nan
+1926,nan,Q15,hartley,"Logarithmic unit for information equal to the content of decision of a sentence of ten mutually exclusive events, expressed as a logarithm to base 10.",3.6,Hart,nan
+1927,nan,Q16,natural unit of information,"Logarithmic unit for information equal to the content of decision of a sentence of ,718 281 828 459 mutually exclusive events, expressed as a logarithm to base Euler value e.",3.6,nat,nat
+1928,nan,Q17,shannon per second,"Time related logarithmic unit for information equal to the content of decision of a sentence of two mutually exclusive events, expressed as a logarithm to base 2.",3.6,Sh/s,Sh/s
+1929,nan,Q18,hartley per second,"Time related logarithmic unit for information equal to the content of decision of a sentence of ten mutually exclusive events, expressed as a logarithm to base 10.",3.6,Hart/s,Hart/s
+1930,nan,Q19,natural unit of information per second,"Time related logarithmic unit for information equal to the content of decision of a sentence of 2,718 281 828 459 mutually exclusive events, expressed as a logarithm to base of the Euler value e.",3.6,nat/s,nat/s
+1931,nan,Q20,second per kilogramm,"Unit of the Einstein transition probability for spontaneous or inducing emissions and absorption according to ISO 80000-7:2008, expressed as SI base unit second divided by the SI base unit kilogram.",3.5,s/kg,kg⁻¹ x s
+1932,nan,Q21,watt square metre,"Unit of the first radiation constants c1 = 2·p·h·c0², the value of which is 3,741 771 18·10?¹6-fold   that of the comparative value of the product of the derived SI unit watt multiplied with the power of the SI base unit metre with the exponent 2.",3.5,W·m²,m⁴ x kg x s⁻³
+1933,nan,Q22,second per radian cubic metre,Unit of the density of states as an expression of angular frequency as complement of the product of hertz and radiant and the power of SI base unit metre by exponent 3 .,3.5,1/(Hz·rad·m³),m⁻³ x s x rad⁻¹
+1934,nan,Q23,weber to the power minus one,"Complement of the derived SI unit weber as unit of the Josephson constant, which value is equal to the 384 597,891-fold of the reference value gigahertz divided by volt.",3.5,1/Wb,m⁻² x kg⁻¹ x s² x A
+1935,nan,Q24,reciprocal inch,Complement of the unit inch according to the Anglo-American and Imperial system of units.,3.5,1/in,"39,370 08 m⁻¹"
+1936,nan,Q25,dioptre,Unit used at the statement of relative refractive indexes of optical systems as complement of the focal length with correspondence to: 1 dpt = 1/m.,3.5,dpt,m⁻¹
+1937,nan,Q26,one per one,Value of the quotient from two physical units of the same kind as a numerator and denominator whereas the units are shortened mutually.,3.5,1/1,1/1
+1938,nan,Q27,newton metre per metre,Unit for length-related rotational moment as product of the derived SI unit newton and the SI base unit metre divided by the SI base unit metre.,3.5,N·m/m²,m x kg x s⁻²
+1939,nan,Q28,kilogram per square metre pascal second,Unit for the ability of a material to allow the transition of steam.,3.5,kg/(m²·Pa·s),kg/(m² x Pa x s)
+1940,nan,Q29,microgram per hectogram,Microgram per hectogram.,1S,µg/hg,10⁻8
+1941,nan,Q30,pH (potential of Hydrogen),The activity of the (solvated) hydrogen ion (a logarithmic measure used to state the acidity or alkalinity of a chemical solution).,2,pH,-log10(mol/l)
+1942,nan,Q31,kilojoule per gram,nan,1S,kJ/g,10⁶ J/kg
+1943,nan,Q32,femtolitre,nan,1S,fl,10-18 m3
+1944,nan,Q33,picolitre,nan,1S,pl,10-15 m3
+1945,nan,Q34,nanolitre,nan,1S,nl,10-12 m3
+1946,nan,Q35,megawatts per minute,A unit of power defining the total amount of bulk energy transferred or consumer per minute.,1M,MW/min,1.667 × 104 W/s
+1947,nan,Q36,square metre per cubic metre,A unit of the amount of surface area per unit volume of an object or collection of objects.,3.1,m2/m3,1 m2/m3
+1948,¦,Q37,Standard cubic metre per day,Standard cubic metre (temperature 15°C and pressure 1013.25 millibars ) per day,2.0,nan,1.15741 × 10-5 m3/s
+1949,¦,Q38,Standard cubic metre per hour,Standard cubic metre (temperature 15°C and pressure 1013.25 millibars ) per hour,2.0,nan,2.77778 × 10-4 m3/s
+1950,¦,Q39,Normalized cubic metre per day,Normalized cubic metre (temperature 0°C and pressure 1013.25 millibars ) per day,2.0,nan,1.15741 × 10-5 m3/s
+1951,¦,Q40,Normalized cubic metre per hour,Normalized cubic metre (temperature 0°C and pressure 1013.25 millibars ) per hour,2.0,nan,2.77778 × 10-4 m3/s
+1952,¦,Q41,Joule per normalised cubic metre,Joule per normalised cubic metre (temperature 0°C and pressure 1013.25 millibars).,2.0,nan,nan
+1953,¦,Q42,Joule per standard cubic metre,Joule per standard cubic metre (temperature 15°C and pressure 1013.25 millibars).,2.0,nan,nan
+1954,nan,Q3,meal,A unit of count defining the number of meals (meal: an amount of food to be eaten on a single occasion).,3.9,nan,nan
+1955,nan,QA,page - facsimile,A unit of count defining the number of facsimile pages.,3.5,nan,nan
+1956,nan,QAN,quarter (of a year),A unit of time defining the number of quarters (3 months).,3.8,nan,nan
+1957,nan,QB,page - hardcopy,"A unit of count defining the number of hardcopy pages (hardcopy page: a page rendered as printed or written output on paper, film, or other permanent medium).",3.5,nan,nan
+1958,X,QD,quarter dozen,nan,3.7,nan,3
+1959,X,QH,quarter hour,nan,3.8,nan,900 s
+1960,X,QK,quarter kilogram,nan,3.8,nan,nan
+1961,nan,QR,quire,"A unit of count for paper, expressed as the number of quires (quire: a number of paper sheets, typically 25).",3.5,qr,nan
+1962,D,QT,quart (US),Use liquid quart (common code QTL),2,qt (US),"0,946 352 9 x 10⁻³ m³"
+1963,nan,QTD,dry quart (US),nan,2,dry qt (US),"1,101 221 x 10⁻³ m³"
+1964,nan,QTI,quart (UK),nan,2,qt (UK),"1,136 522 5 x 10⁻³ m³"
+1965,nan,QTL,liquid quart (US),nan,2,liq qt (US),"9,463 529 x 10⁻⁴ m³"
+1966,nan,QTR,quarter (UK),"A traditional unit of weight equal to 1/4 hundredweight. In the United Kingdom, one quarter equals 28 pounds.",3.5,Qr (UK),"12,700 59 kg"
+1967,nan,R1,pica,A unit of count defining the number of picas. (pica: typographical length equal to 12 points or 4.22 mm (approx.)).,3.5,nan,"4,217 518 x 10⁻³ m"
+1968,X,R4,calorie,Use International Table (IT) calorie (common code D70),3.5,cal,"4,186 8 J"
+1969,nan,R9,thousand cubic metre,A unit of volume equal to one thousand cubic metres.,3.8,nan,10³m³
+1970,X,RA,rack,nan,3.3,nan,nan
+1971,X,RD,rod,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+1972,X,RG,ring,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+1973,nan,RH,running or operating hour,A unit of time defining the number of hours of operation.,3.1,nan,nan
+1974,X,RK,roll metric measure,nan,3.3,nan,nan
+1975,X,RL,reel,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+1976,nan,RM,ream,"A unit of count for paper, expressed as the number of reams (ream: a large quantity of paper sheets, typically 500).",3.5,nan,nan
+1977,X,RN,ream metric measure,nan,3.5,nan,nan
+1978,X,RO,roll,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+1979,nan,ROM,room,A unit of count defining the number of rooms.,3.9,nan,nan
+1980,nan,RP,pound per ream,"A unit of mass for paper, expressed as pounds per ream. (ream: a large quantity of paper, typically 500 sheets).",3.5,nan,nan
+1981,nan,RPM,revolutions per minute,Refer ISO/TC12 SI Guide,1,r/min,"1,67 x 10⁻²/s"
+1982,nan,RPS,revolutions per second,Refer ISO/TC12 SI Guide,1,r/s,1/s
+1983,X,RS,reset,nan,3.9,nan,nan
+1984,nan,RT,revenue ton mile,"A unit of information typically used for billing purposes, expressed as the number of revenue tons (revenue ton: either a metric ton or a cubic metres, whichever is the larger), moved over a distance of one mile.",3.4,nan,nan
+1985,X,RU,run,nan,3.9,nan,nan
+1986,nan,S3,square foot per second,Synonym: foot squared per second,2,ft²/s,"0,092 903 04 m²/s"
+1987,nan,S4,square metre per second,Synonym: metre squared per second (square metres/second US),1,m²/s,m²/s
+1988,X,S5,sixty fourths of an inch,nan,3.8,nan,nan
+1989,X,S6,session,nan,3.9,nan,nan
+1990,X,S7,storage unit,nan,3.9,nan,nan
+1991,X,S8,standard advertising unit,nan,3.9,nan,nan
+1992,X,SA,sack,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+1993,nan,SAN,half year (6 months),A unit of time defining the number of half years (6 months).,3.8,nan,nan
+1994,nan,SCO,score,A unit of count defining the number of units in multiples of 20.,3.7,nan,20
+1995,nan,SCR,scruple,nan,3.5,nan,"1,295 982 g"
+1996,X,SD,solid pound,nan,3.1,nan,nan
+1997,X,SE,section,nan,3.9,nan,nan
+1998,nan,SEC,second [unit of time],nan,1,s,s
+1999,nan,SET,set,A unit of count defining the number of sets (set: a number of objects grouped together).,3.2,nan,nan
+2000,nan,SG,segment,A unit of information equal to 64000 bytes.,3.9,nan,nan
+2001,D,SHT,shipping ton,A unit of mass defining the number of tons for shipping.,3.4,nan,nan
+2002,nan,SIE,siemens,nan,1,S,A/V
+2003,X,SK,split tank truck,nan,3.4,nan,nan
+2004,X,SL,slipsheet,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+2005,¦,SM3,Standard cubic metre,Standard cubic metre (temperature 15°C and pressure 1013.25 millibars ),2,nan,m3
+2006,nan,SMI,mile (statute mile),nan,2,mile,"1 609,344 m"
+2007,X,SN,square rod,nan,3.8,rd²,"25,292 9 m²"
+2008,X,SO,spool,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+2009,X,SP,shelf package,nan,3.9,nan,nan
+2010,nan,SQ,square,A unit of count defining the number of squares (square: rectangular shape).,3.9,nan,nan
+2011,nan,SQR,"square, roofing","A unit of count defining the number of squares of roofing materials, measured in multiples of 100 square feet.",3.1,nan,nan
+2012,nan,SR,strip,A unit of count defining the number of strips (strip: long narrow piece of an object).,3.9,nan,nan
+2013,X,SS,sheet metric measure,nan,3.3,nan,nan
+2014,X,SST,short standard (7200 matches),nan,3.5,nan,nan
+2015,X,ST,sheet,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+2016,nan,STC,stick,A unit of count defining the number of sticks (stick: slender and often cylindrical piece of a substance).,3.9,nan,nan
+2017,nan,STI,stone (UK),nan,2,st,"6,350 293 kg"
+2018,nan,STK,"stick, cigarette",A unit of count defining the number of cigarettes in the smallest unit for stock-taking and/or duty computation.,3.9,nan,nan
+2019,nan,STL,standard litre,"A unit of volume defining the number of litres of a product at a temperature of 15 degrees Celsius, especially in relation to hydrocarbon oils.",3.1,nan,nan
+2020,nan,STN,ton (US) or short ton (UK/US),Synonym: net ton (2000 lb),2,ton (US),"0,907184 7 x 10³ kg"
+2021,nan,STW,straw,A unit of count defining the number of straws (straw: a slender tube used for sucking up liquids).,3.9,nan,nan
+2022,X,SV,skid,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.9,nan,nan
+2023,nan,SW,skein,A unit of count defining the number of skeins (skein: a loosely-coiled bundle of yarn or thread).,3.9,nan,nan
+2024,nan,SX,shipment,A unit of count defining the number of shipments (shipment: an amount of goods shipped or transported).,3.4,nan,nan
+2025,nan,SYR,syringe,"A unit of count defining the number of syringes (syringe: a small device for pumping, spraying and/or injecting liquids through a small aperture).",3.9,nan,nan
+2026,nan,T0,telecommunication line in service,A unit of count defining the number of lines in service.,3.5,nan,nan
+2027,X,T1,thousand pound gross,nan,3.8,nan,nan
+2028,nan,T3,thousand piece,"A unit of count defining the number of pieces in multiples of 1000 (piece: a single item, article or exemplar).",3.8,nan,nan
+2029,X,T4,thousand bag,nan,3.8,nan,nan
+2030,X,T5,thousand casing,nan,3.8,nan,nan
+2031,X,T6,thousand gallon (US),nan,3.8,nan,"3,785 412 m³"
+2032,X,T7,thousand impression,nan,3.8,nan,nan
+2033,X,T8,thousand linear inch,nan,3.8,nan,nan
+2034,X,TA,tenth cubic foot,nan,3.8,nan,nan
+2035,nan,TAH,kiloampere hour (thousand ampere hour),nan,1M,kA·h,"3,6 x 10⁶ C"
+2036,nan,TAN,total acid number,A unit of chemistry defining the amount of potassium hydroxide (KOH) in milligrams that is needed to neutralize the acids in one gram of oil. It is an important quality measurement of crude oil.,3.5,TAN,mg KOH/g 
+2037,X,TC,truckload,nan,3.4,nan,nan
+2038,X,TD,therm,nan,3.8,nan,"10⁵ x  1 055,056 J"
+2039,X,TE,tote,nan,3.3,nan,nan
+2040,X,TF,ten square yard,nan,3.8,nan,nan
+2041,nan,TI,thousand square inch,nan,3.8,nan,nan
+2042,nan,TIC,"metric ton, including container","A unit of mass defining the number of metric tons of a product, including its container.",3.1,nan,nan
+2043,nan,TIP,"metric ton, including inner packaging","A unit of mass defining the number of metric tons of a product, including its inner packaging materials.",3.1,nan,nan
+2044,X,TJ,thousand square centimetre,nan,3.8,nan,nan
+2045,X,TK,"tank, rectangular","Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.4,nan,nan
+2046,nan,TKM,tonne kilometre,"A unit of information typically used for billing purposes, expressed as the number of tonnes (metric tons) moved over a distance of one kilometre. ",3.4,t·km,10⁶ kg x m
+2047,X,TL,thousand foot (linear),nan,3.8,nan,nan
+2048,nan,TMS,"kilogram of imported meat, less offal","A unit of mass equal to one thousand grams of imported meat, disregarding less valuable by-products such as the entrails.",3.5,nan,nan
+2049,X,TN,tin,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+2050,nan,TNE,tonne (metric ton),Synonym: metric ton,1S,t,10³ kg
+2051,nan,TP,ten pack,A unit of count defining the number of items in multiples of 10.,3.2,nan,nan
+2052,nan,TPI,teeth per inch,The number of teeth per inch.,3.1,TPI,0.0254 /m
+2053,nan,TPR,ten pair,A unit of count defining the number of pairs in multiples of 10 (pair: item described by two's).,3.8,nan,nan
+2054,X,TQ,thousand foot,nan,3.8,nan,nan
+2055,nan,TQD,thousand cubic metre per day,A unit of volume equal to one thousand cubic metres per day.,3.8,km³/d,"1,157 41 x 10⁻² m³/s"
+2056,X,TR,ten square foot,nan,3.8,nan,nan
+2057,nan,TRL,trillion (EUR),nan,3.7,nan,10¹⁸
+2058,X,TS,thousand square foot,nan,3.8,nan,nan
+2059,X,TSD,tonne of substance 90 % dry,nan,3.1,nan,nan
+2060,X,TSH,ton of steam per hour,nan,3.1,nan,nan
+2061,nan,TST,ten set,A unit of count defining the number of sets in multiples of 10 (set: a number of objects grouped together).,3.9,nan,nan
+2062,X,TT,thousand linear metre,nan,3.8,nan,nan
+2063,nan,TTS,ten thousand sticks,A unit of count defining the number of sticks in multiples of 10000 (stick: slender and often cylindrical piece of a substance).,3.9,nan,nan
+2064,X,TU,tube,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+2065,X,TV,thousand kilogram,nan,3.8,nan,10³kg
+2066,X,TW,thousand sheet,nan,3.8,nan,nan
+2067,X,TY,"tank, cylindrical","Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.4,nan,nan
+2068,nan,U1,treatment,"A unit of count defining the number of treatments (treatment: subjection to the action of a chemical, physical or biological agent).",3.9,nan,nan
+2069,nan,U2,tablet,A unit of count defining the number of tablets (tablet: a small flat or compressed solid object).,3.9,nan,nan
+2070,D,UA,torr,nan,2,Torr,"133,322 4 Pa"
+2071,nan,UB,telecommunication line in service average,A unit of count defining the average number of lines in service.,3.5,nan,nan
+2072,nan,UC,telecommunication port,A unit of count defining the number of network access ports.,3.5,nan,nan
+2073,X,UD,tenth minute,nan,3.8,nan,6 s
+2074,X,UE,tenth hour,nan,3.8,nan,360 s
+2075,X,UF,usage per telecommunication line average,nan,3.5,nan,nan
+2076,X,UH,ten thousand yard,nan,3.8,nan,nan
+2077,X,UM,million unit,nan,3.8,nan,nan
+2078,nan,VA,volt - ampere per kilogram,nan,3.9,V·A / kg,V x A / kg
+2079,X,VI,vial,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+2080,nan,VLT,volt,nan,1,V,V
+2081,nan,VP,percent volume,"A measure of concentration, typically expressed as the percentage volume of a solute in a solution.",3.7,nan,nan
+2082,X,VQ,bulk,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+2083,X,VS,visit,nan,3.9,nan,nan
+2084,nan,W2,wet kilo,"A unit of mass defining the number of kilograms of a product, including the water content of the product.",3.1,nan,nan
+2085,X,W4,two week,nan,3.8,nan,nan
+2086,nan,WA,watt per kilogram,nan,3.9,W/kg,1 W/kg
+2087,nan,WB,wet pound,"A unit of mass defining the number of pounds of a material, including the water content of the material.",3.1,nan,nan
+2088,nan,WCD,cord,A unit of volume used for measuring lumber. One board foot equals 1/12 of a cubic foot.,3.5,nan,"3,63 m³"
+2089,nan,WE,wet ton,"A unit of mass defining the number of tons of a material, including the water content of the material.",3.1,nan,nan
+2090,nan,WEB,weber,nan,1,Wb,Wb
+2091,nan,WEE,week,nan,2,wk,"6,048 x 10⁵ s"
+2092,nan,WG,wine gallon,A unit of volume equal to 231 cubic inches.,3.1,nan,nan
+2093,X,WH,wheel,nan,3.9,nan,nan
+2094,nan,WHR,watt hour,nan,1,W·h,"3,6 x 10³ J"
+2095,X,WI,weight per square inch,nan,3.9,nan,nan
+2096,nan,WM,working month,A unit of time defining the number of working months.,3.1,nan,nan
+2097,X,WR,wrap,nan,3.3,nan,nan
+2098,nan,WSD,standard,"A unit of volume of finished lumber equal to 165 cubic feet.,Synonym: standard cubic foot",3.5,std,"4,672 m³"
+2099,nan,WTT,watt,nan,1,W,W
+2100,D,WW,millilitre of water,A unit of volume equal to the number of millilitres of water.,3.1,nan,nan
+2101,nan,X1,Gunter's chain,A unit of distance used or formerly used by British surveyors.,2,ch (UK),"20,116 8 m"
+2102,nan,YDK,square yard,nan,2,yd²,"8,361 274 x 10⁻¹ m²"
+2103,nan,YDQ,cubic yard,nan,2,yd³,"0,764 555 m³"
+2104,X,YL,hundred linear yard,nan,3.8,nan,nan
+2105,nan,YRD,yard,nan,2,yd,"0,914 4 m"
+2106,X,YT,ten yard,nan,3.8,nan,nan
+2107,X,Z1,lift van,nan,3.4,nan,nan
+2108,nan,Z11,hanging container,A unit of count defining the number of hanging containers.,3.9,nan,nan
+2109,X,Z2,chest,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+2110,X,Z3,cask,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+2111,X,Z4,hogshead,"Use UN/ECE Recommendation 21 (refer to Note 2 in the spreadsheet introduction, 1st sheet).",3.3,nan,nan
+2112,X,Z5,lug,nan,3.9,nan,nan
+2113,X,Z6,conference point,nan,3.5,nan,nan
+2114,X,Z8,newspage agate line,nan,3.9,nan,nan
+2115,nan,ZP,page,A unit of count defining the number of pages.,3.5,nan,nan
+2116,nan,ZZ,mutually defined,A unit of measure as agreed in common between two or more parties.,3.9,nan,nan
```

### Comparing `filip-0.3.0/filip/models/ngsi_v2/iot.py` & `filip-0.4.0/filip/models/ngsi_v2/iot.py`

 * *Ordering differences only*

 * *Files 17% similar despite different names*

```diff
@@ -1,611 +1,611 @@
-"""
-Module contains models for accessing and interaction with FIWARE's IoT-Agents.
-"""
-from __future__ import annotations
-import logging
-import itertools
-from enum import Enum
-from typing import Any, Dict, Optional, List, Union
-import pytz
-from pydantic import field_validator, ConfigDict, BaseModel, Field, AnyHttpUrl
-from filip.models.base import NgsiVersion, DataType
-from filip.models.ngsi_v2.base import \
-    BaseAttribute, \
-    BaseValueAttribute, \
-    BaseNameAttribute
-from filip.utils.validators import validate_fiware_datatype_string_protect, \
-    validate_fiware_datatype_standard
-
-logger = logging.getLogger()
-
-
-class ExpressionLanguage(str, Enum):
-    """
-    Options for expression language
-    """
-    LEGACY = "legacy"
-    JEXL = "jexl"
-
-
-class PayloadProtocol(str, Enum):
-    """
-    Options for payload protocols
-    """
-    IOTA_JSON = "IoTA-JSON"
-    IOTA_UL = "PDI-IoTA-UltraLight"
-    LORAWAN = "LoRaWAN"
-
-
-class TransportProtocol(str, Enum):
-    """
-    Options for transport protocols
-    """
-    MQTT = "MQTT"
-    AMQP = "AMQP"
-    HTTP = "HTTP"
-
-
-class IoTABaseAttribute(BaseAttribute, BaseNameAttribute):
-    """
-    Base model for device attributes
-    """
-
-    expression: Optional[str] = Field(
-        default=None,
-        description="indicates that the value of the target attribute will "
-                    "not be the plain value or the measurement, but an "
-                    "expression based on a combination of the reported values. "
-                    "See the Expression Language definition for details "
-                    "(https://iotagent-node-lib.readthedocs.io/en/latest/"
-                    "expressionLanguage/index.html)"
-    )
-    entity_name: Optional[str] = Field(
-        default=None,
-        description="entity_name: the presence of this attribute indicates "
-                    "that the value will not be stored in the original device "
-                    "entity but in a new entity with an ID given by this "
-                    "attribute. The type of this additional entity can be "
-                    "configured with the entity_type attribute. If no type is "
-                    "configured, the device entity type is used instead. "
-                    "Entity names can be defined as expressions, using the "
-                    "Expression Language definition. "
-                    "(https://iotagent-node-lib.readthedocs.io/en/latest/"
-                    "expressionLanguage/index.html) Allowed characters "
-                    "are the ones in the plain ASCII set, except the following "
-                    "ones: control characters, whitespace, &, ?, / and #.",
-        max_length=256,
-        min_length=1,
-    )
-    valid_entity_name = field_validator("entity_name")(validate_fiware_datatype_standard)
-    entity_type: Optional[str] = Field(
-        default=None,
-        description="configures the type of an alternative entity. "
-                    "Allowed characters "
-                    "are the ones in the plain ASCII set, except the following "
-                    "ones: control characters, whitespace, &, ?, / and #.",
-        max_length=256,
-        min_length=1,
-    )
-    valid_entity_type = field_validator("entity_type")(validate_fiware_datatype_standard)
-    reverse: Optional[str] = Field(
-        default=None,
-        description="add bidirectionality expressions to the attribute. See "
-                    "the bidirectionality transformation plugin in the "
-                    "Data Mapping Plugins section for details. "
-                    "(https://iotagent-node-lib.readthedocs.io/en/latest/api/"
-                    "index.html#data-mapping-plugins)"
-    )
-
-    def __eq__(self, other):
-        if isinstance(other, BaseAttribute):
-            return self.name == other.name
-        else:
-            return self.model_dump() == other
-
-
-class DeviceAttribute(IoTABaseAttribute):
-    """
-    Model for active device attributes
-    """
-    object_id: Optional[str] = Field(
-        default=None,
-        description="name of the attribute as coming from the device."
-    )
-
-
-class LazyDeviceAttribute(BaseNameAttribute):
-    """
-    Model for lazy device attributes
-    """
-    type: Union[DataType, str] = Field(
-        default=DataType.TEXT,
-        description="The attribute type represents the NGSI value type of the "
-                    "attribute value. Note that FIWARE NGSI has its own type "
-                    "system for attribute values, so NGSI value types are not "
-                    "the same as JSON types. Allowed characters "
-                    "are the ones in the plain ASCII set, except the following "
-                    "ones: control characters, whitespace, &, ?, / and #.",
-        max_length=256,
-        min_length=1,
-    )
-    valid_type = field_validator("type")(validate_fiware_datatype_string_protect)
-
-
-class DeviceCommand(BaseModel):
-    """
-    Model for commands
-    """
-    name: str = Field(
-        description="ID of the attribute in the target entity in the "
-                    "Context Broker. Allowed characters "
-                    "are the ones in the plain ASCII set, except the following "
-                    "ones: control characters, whitespace, &, ?, / and #.",
-        max_length=256,
-        min_length=1,
-    )
-    valid_name = field_validator("name")(validate_fiware_datatype_string_protect)
-    type: Union[DataType, str] = Field(
-        description="name of the type of the attribute in the target entity. ",
-        default=DataType.COMMAND
-    )
-
-
-class StaticDeviceAttribute(IoTABaseAttribute, BaseValueAttribute):
-    """
-    Model for static device attributes
-    """
-    pass
-
-
-class ServiceGroup(BaseModel):
-    """
-    Model for device service group.
-    https://iotagent-node-lib.readthedocs.io/en/latest/api/index.html#service-group-api
-    """
-    service: Optional[str] = Field(
-        default=None,
-        description="ServiceGroup of the devices of this type"
-    )
-    subservice: Optional[str] = Field(
-        default=None,
-        description="Subservice of the devices of this type.",
-        pattern="^/"
-    )
-    resource: str = Field(
-        description="string representing the Southbound resource that will be "
-                    "used to assign a type to a device  (e.g.: pathname in the "
-                    "southbound port)."
-    )
-    apikey: str = Field(
-        description="API Key string. It is a key used for devices belonging "
-                    "to this service_group. If "", service_group does not use "
-                    "apikey, but it must be specified."
-    )
-    timestamp: Optional[bool] = Field(
-        default=None,
-        description="Optional flag about whether or not to add the TimeInstant "
-                    "attribute to the device entity created, as well as a "
-                    "TimeInstant metadata to each attribute, with the current "
-                    "timestamp. With NGSI-LD, the Standard observedAt "
-                    "property-of-a-property is created instead."
-    )
-    entity_type: Optional[str] = Field(
-        default=None,
-        description="name of the Entity type to assign to the group. "
-                    "Allowed characters "
-                    "are the ones in the plain ASCII set, except the following "
-                    "ones: control characters, whitespace, &, ?, / and #.",
-        max_length=256,
-        min_length=1,
-    )
-    valid_entity_type = field_validator("entity_type")(validate_fiware_datatype_standard)
-    trust: Optional[str] = Field(
-        default=None,
-        description="trust token to use for secured access to the "
-                    "Context Broker for this type of devices (optional; only "
-                    "needed for secured scenarios)."
-    )
-    cbHost: Optional[AnyHttpUrl] = Field(
-        default=None,
-        description="Context Broker connection information. This options can "
-                    "be used to override the global ones for specific types of "
-                    "devices."
-    )
-    @field_validator('cbHost')
-    @classmethod
-    def validate_cbHost(cls, value):
-        """
-        convert cbHost to str
-        Returns:
-            timezone
-        """
-        return str(value)
-    lazy: Optional[List[LazyDeviceAttribute]] = Field(
-        default=[],
-        desription="list of common lazy attributes of the device. For each "
-                   "attribute, its name and type must be provided."
-    )
-    commands: Optional[List[DeviceCommand]] = Field(
-        default=[],
-        desription="list of common commands attributes of the device. For each "
-                   "attribute, its name and type must be provided, additional "
-                   "metadata is optional"
-    )
-    attributes: Optional[List[DeviceAttribute]] = Field(
-        default=[],
-        description="list of common commands attributes of the device. For "
-                    "each attribute, its name and type must be provided, "
-                    "additional metadata is optional."
-    )
-    static_attributes: Optional[List[StaticDeviceAttribute]] = Field(
-        default=[],
-        description="this attributes will be added to all the entities of this "
-                    "group 'as is', additional metadata is optional."
-    )
-    internal_attributes: Optional[List[Dict[str, Any]]] = Field(
-        default=[],
-        description="optional section with free format, to allow specific "
-                    "IoT Agents to store information along with the devices "
-                    "in the Device Registry."
-    )
-    expressionLanguage: Optional[ExpressionLanguage] = Field(
-        default="legacy",
-        description="optional boolean value, to set expression language used "
-                    "to compute expressions, possible values are: "
-                    "legacy or jexl. When not set or wrongly set, legacy "
-                    "is used as default value."
-    )
-    explicitAttrs: Optional[bool] = Field(
-        default=False,
-        description="optional boolean value, to support selective ignore "
-                    "of measures so that IOTA does not progress. If not "
-                    "specified default is false."
-    )
-    autoprovision: Optional[bool] = Field(
-        default=True,
-        description="optional boolean: If false, autoprovisioned devices "
-                    "(i.e. devices that are not created with an explicit "
-                    "provision operation but when the first measure arrives) "
-                    "are not allowed in this group. "
-                    "Default (in the case of omitting the field) is true."
-    )
-    ngsiVersion: Optional[NgsiVersion] = Field(
-        default="v2",
-        description="optional string value used in mixed mode to switch between"
-                    " NGSI-v2 and NGSI-LD payloads. Possible values are: "
-                    "v2 or ld. The default is v2. When not running in mixed "
-                    "mode, this field is ignored.")
-    defaultEntityNameConjunction: Optional[str] = Field(
-        default=None,
-        description="optional string value to set default conjunction string "
-                    "used to compose a default entity_name when is not "
-                    "provided at device provisioning time."
-    )
-
-
-class DeviceSettings(BaseModel):
-    """
-    Model for iot device settings
-    """
-    model_config = ConfigDict(validate_assignment=True)
-    timezone: Optional[str] = Field(
-        default='Europe/London',
-        description="Time zone of the sensor if it has any"
-    )
-    timestamp: Optional[bool] = Field(
-        default=None,
-        description="Optional flag about whether or not to add the TimeInstant "
-                    "attribute to the device entity created, as well as a "
-                    "TimeInstant metadata to each attribute, with the current "
-                    "timestamp. With NGSI-LD, the Standard observedAt "
-                    "property-of-a-property is created instead."
-    )
-    apikey: Optional[str] = Field(
-        default=None,
-        description="Optional Apikey key string to use instead of group apikey"
-    )
-    endpoint: Optional[AnyHttpUrl] = Field(
-        default=None,
-        description="Endpoint where the device is going to receive commands, "
-                    "if any."
-    )
-    protocol: Optional[Union[PayloadProtocol, str]] = Field(
-        default=None,
-        description="Name of the device protocol, for its use with an "
-                    "IoT Manager."
-    )
-    transport: Optional[Union[TransportProtocol, str]] = Field(
-        default=None,
-        description="Name of the device transport protocol, for the IoT Agents "
-                    "with multiple transport protocols."
-    )
-    expressionLanguage: Optional[ExpressionLanguage] = Field(
-        default=None,
-        description="optional boolean value, to set expression language used "
-                    "to compute expressions, possible values are: "
-                    "legacy or jexl. When not set or wrongly set, legacy "
-                    "is used as default value."
-    )
-    explicitAttrs: Optional[bool] = Field(
-        default=False,
-        description="optional boolean value, to support selective ignore "
-                    "of measures so that IOTA does not progress. If not "
-                    "specified default is false."
-    )
-
-
-class Device(DeviceSettings):
-    """
-    Model for iot devices.
-    https://iotagent-node-lib.readthedocs.io/en/latest/api/index.html#device-api
-    """
-    model_config = ConfigDict(validate_default=True, validate_assignment=True)
-    device_id: str = Field(
-        description="Device ID that will be used to identify the device"
-    )
-    service: Optional[str] = Field(
-        default=None,
-        description="Name of the service the device belongs to "
-                    "(will be used in the fiware-service header).",
-        max_length=50
-    )
-    service_path: Optional[str] = Field(
-        default="/",
-        description="Name of the subservice the device belongs to "
-                    "(used in the fiware-servicepath header).",
-        max_length=51,
-        pattern="^/"
-    )
-    entity_name: str = Field(
-        description="Name of the entity representing the device in "
-                    "the Context Broker Allowed characters "
-                    "are the ones in the plain ASCII set, except the following "
-                    "ones: control characters, whitespace, &, ?, / and #.",
-        max_length=256,
-        min_length=1,
-    )
-    valid_entity_name = field_validator("entity_name")(validate_fiware_datatype_standard)
-    entity_type: str = Field(
-        description="Type of the entity in the Context Broker. "
-                    "Allowed characters "
-                    "are the ones in the plain ASCII set, except the following "
-                    "ones: control characters, whitespace, &, ?, / and #.",
-        max_length=256,
-        min_length=1,
-    )
-    valid_entity_type = field_validator("entity_type")(validate_fiware_datatype_standard)
-    lazy: List[LazyDeviceAttribute] = Field(
-        default=[],
-        description="List of lazy attributes of the device"
-    )
-    commands: List[DeviceCommand] = Field(
-        default=[],
-        desription="List of commands of the device"
-    )
-    attributes: List[DeviceAttribute] = Field(
-        default=[],
-        description="List of active attributes of the device"
-    )
-    static_attributes: Optional[List[StaticDeviceAttribute]] = Field(
-        default=[],
-        description="List of static attributes to append to the entity. All the"
-                    " updateContext requests to the CB will have this set of "
-                    "attributes appended."
-    )
-    internal_attributes: Optional[List[Dict[str, Any]]] = Field(
-        default=[],
-        description="List of internal attributes with free format for specific "
-                    "IoT Agent configuration"
-    )
-    ngsiVersion: NgsiVersion = Field(
-        default=NgsiVersion.v2,
-        description="optional string value used in mixed mode to switch between"
-                    " NGSI-v2 and NGSI-LD payloads. Possible values are: "
-                    "v2 or ld. The default is v2. When not running in "
-                    "mixed mode, this field is ignored.")
-
-    @field_validator('timezone')
-    @classmethod
-    def validate_timezone(cls, value):
-        """
-        validate timezone
-        Returns:
-            timezone
-        """
-        assert value in pytz.all_timezones
-        return value
-
-    def get_attribute(self, attribute_name: str) -> Union[DeviceAttribute,
-                                                          LazyDeviceAttribute,
-                                                          StaticDeviceAttribute,
-                                                          DeviceCommand]:
-        """
-
-        Args:
-            attribute_name:
-
-        Returns:
-
-        """
-        for attribute in itertools.chain(self.attributes,
-                                         self.lazy,
-                                         self.static_attributes,
-                                         self.internal_attributes,
-                                         self.commands):
-            if attribute.name == attribute_name:
-                return attribute
-        msg = f"Device: {self.device_id}: Could not " \
-              f"find attribute with name {attribute_name}"
-        logger.error(msg)
-        raise KeyError(msg)
-
-    def add_attribute(self,
-                      attribute: Union[DeviceAttribute,
-                                       LazyDeviceAttribute,
-                                       StaticDeviceAttribute,
-                                       DeviceCommand],
-                      update: bool = False) -> None:
-        """
-
-        Args:
-            attribute:
-            update (bool): If 'True' and attribute does already exists tries
-                to  update the attribute if not
-        Returns:
-            None
-        """
-        try:
-            if type(attribute) == DeviceAttribute:
-                if attribute in self.attributes:
-                    raise ValueError
-
-                self.attributes.append(attribute)
-                self.__setattr__(name='attributes',
-                                 value=self.attributes)
-            elif type(attribute) == LazyDeviceAttribute:
-                if attribute in self.lazy:
-                    raise ValueError
-
-                self.lazy.append(attribute)
-                self.__setattr__(name='lazy',
-                                 value=self.lazy)
-            elif type(attribute) == StaticDeviceAttribute:
-                if attribute in self.static_attributes:
-                    raise ValueError
-
-                self.static_attributes.append(attribute)
-                self.__setattr__(name='static_attributes',
-                                 value=self.static_attributes)
-            elif type(attribute) == DeviceCommand:
-                if attribute in self.commands:
-                    raise ValueError
-
-                self.commands.append(attribute)
-                self.__setattr__(name='commands',
-                                 value=self.commands)
-            else:
-                raise ValueError
-        except ValueError:
-            if update:
-                self.update_attribute(attribute, append=False)
-                logger.warning("Device: %s: Attribute already "
-                               "exists. Will update: \n %s",
-                               self.device_id, attribute.model_dump_json(indent=2))
-            else:
-                logger.error("Device: %s: Attribute already "
-                             "exists: \n %s", self.device_id,
-                             attribute.model_dump_json(indent=2))
-                raise
-
-    def update_attribute(self,
-                         attribute: Union[DeviceAttribute,
-                                          LazyDeviceAttribute,
-                                          StaticDeviceAttribute,
-                                          DeviceCommand],
-                         append: bool = False) -> None:
-        """
-        Updates existing device attribute
-
-        Args:
-            attribute: Attribute to add to device configuration
-            append (bool): Adds attribute if not exist
-
-        Returns:
-            None
-        """
-        try:
-            if type(attribute) == DeviceAttribute:
-                idx = self.attributes.index(attribute)
-                self.attributes[idx].model_dump().update(attribute.model_dump())
-            elif type(attribute) == LazyDeviceAttribute:
-                idx = self.lazy.index(attribute)
-                self.lazy[idx].model_dump().update(attribute.model_dump())
-            elif type(attribute) == StaticDeviceAttribute:
-                idx = self.static_attributes.index(attribute)
-                self.static_attributes[idx].model_dump().update(attribute.model_dump())
-            elif type(attribute) == DeviceCommand:
-                idx = self.commands.index(attribute)
-                self.commands[idx].model_dump().update(attribute.model_dump())
-        except ValueError:
-            if append:
-                logger.warning("Device: %s: Could not find "
-                               "attribute: \n %s",
-                               self.device_id, attribute.model_dump_json(indent=2))
-                self.add_attribute(attribute=attribute)
-            else:
-                msg = f"Device: {self.device_id}: Could not find "\
-                      f"attribute: \n {attribute.model_dump_json(indent=2)}"
-                raise KeyError(msg)
-
-    def delete_attribute(self, attribute: Union[DeviceAttribute,
-                                                LazyDeviceAttribute,
-                                                StaticDeviceAttribute,
-                                                DeviceCommand]):
-        """
-        Deletes attribute from device
-        Args:
-            attribute: ()
-
-        Returns:
-
-        """
-        try:
-            if type(attribute) == DeviceAttribute:
-                self.attributes.remove(attribute)
-            elif type(attribute) == LazyDeviceAttribute:
-                self.lazy.remove(attribute)
-            elif type(attribute) == StaticDeviceAttribute:
-                self.static_attributes.remove(attribute)
-            elif type(attribute) == DeviceCommand:
-                self.commands.remove(attribute)
-            else:
-                raise ValueError
-        except ValueError:
-            logger.warning("Device: %s: Could not delete "
-                           "attribute: \n %s",
-                           self.device_id, attribute.model_dump_json(indent=2))
-            raise
-
-        logger.info("Device: %s: Attribute deleted! \n %s",
-                    self.device_id, attribute.model_dump_json(indent=2))
-
-    def get_command(self, command_name: str):
-        """
-        Short for self.get_attributes
-        Args:
-            command_name (str):
-        Returns:
-
-        """
-        return self.get_attribute(attribute_name=command_name)
-
-    def add_command(self, command: DeviceCommand, update: bool = False):
-        """
-        Short for self.add_attribute
-        Args:
-            command (DeviceCommand):
-            update (bool): Update command if it already exists
-        Returns:
-        """
-        self.add_attribute(attribute=command, update=update)
-
-    def update_command(self, command: DeviceCommand, append: bool = False):
-        """
-        Short for self.update_attribute
-        Args:
-            command:
-            append:
-        Returns:
-        """
-        self.update_attribute(attribute=command, append=append)
-
-    def delete_command(self, command: DeviceCommand):
-        """
-        Short for self.delete_attribute
-        Args:
-            command:
-
-        Returns:
-            None
-        """
-        self.delete_attribute(attribute=command)
+"""
+Module contains models for accessing and interaction with FIWARE's IoT-Agents.
+"""
+from __future__ import annotations
+import logging
+import itertools
+from enum import Enum
+from typing import Any, Dict, Optional, List, Union
+import pytz
+from pydantic import field_validator, ConfigDict, BaseModel, Field, AnyHttpUrl
+from filip.models.base import NgsiVersion, DataType
+from filip.models.ngsi_v2.base import \
+    BaseAttribute, \
+    BaseValueAttribute, \
+    BaseNameAttribute
+from filip.utils.validators import validate_fiware_datatype_string_protect, \
+    validate_fiware_datatype_standard
+
+logger = logging.getLogger()
+
+
+class ExpressionLanguage(str, Enum):
+    """
+    Options for expression language
+    """
+    LEGACY = "legacy"
+    JEXL = "jexl"
+
+
+class PayloadProtocol(str, Enum):
+    """
+    Options for payload protocols
+    """
+    IOTA_JSON = "IoTA-JSON"
+    IOTA_UL = "PDI-IoTA-UltraLight"
+    LORAWAN = "LoRaWAN"
+
+
+class TransportProtocol(str, Enum):
+    """
+    Options for transport protocols
+    """
+    MQTT = "MQTT"
+    AMQP = "AMQP"
+    HTTP = "HTTP"
+
+
+class IoTABaseAttribute(BaseAttribute, BaseNameAttribute):
+    """
+    Base model for device attributes
+    """
+
+    expression: Optional[str] = Field(
+        default=None,
+        description="indicates that the value of the target attribute will "
+                    "not be the plain value or the measurement, but an "
+                    "expression based on a combination of the reported values. "
+                    "See the Expression Language definition for details "
+                    "(https://iotagent-node-lib.readthedocs.io/en/latest/"
+                    "expressionLanguage/index.html)"
+    )
+    entity_name: Optional[str] = Field(
+        default=None,
+        description="entity_name: the presence of this attribute indicates "
+                    "that the value will not be stored in the original device "
+                    "entity but in a new entity with an ID given by this "
+                    "attribute. The type of this additional entity can be "
+                    "configured with the entity_type attribute. If no type is "
+                    "configured, the device entity type is used instead. "
+                    "Entity names can be defined as expressions, using the "
+                    "Expression Language definition. "
+                    "(https://iotagent-node-lib.readthedocs.io/en/latest/"
+                    "expressionLanguage/index.html) Allowed characters "
+                    "are the ones in the plain ASCII set, except the following "
+                    "ones: control characters, whitespace, &, ?, / and #.",
+        max_length=256,
+        min_length=1,
+    )
+    valid_entity_name = field_validator("entity_name")(validate_fiware_datatype_standard)
+    entity_type: Optional[str] = Field(
+        default=None,
+        description="configures the type of an alternative entity. "
+                    "Allowed characters "
+                    "are the ones in the plain ASCII set, except the following "
+                    "ones: control characters, whitespace, &, ?, / and #.",
+        max_length=256,
+        min_length=1,
+    )
+    valid_entity_type = field_validator("entity_type")(validate_fiware_datatype_standard)
+    reverse: Optional[str] = Field(
+        default=None,
+        description="add bidirectionality expressions to the attribute. See "
+                    "the bidirectionality transformation plugin in the "
+                    "Data Mapping Plugins section for details. "
+                    "(https://iotagent-node-lib.readthedocs.io/en/latest/api/"
+                    "index.html#data-mapping-plugins)"
+    )
+
+    def __eq__(self, other):
+        if isinstance(other, BaseAttribute):
+            return self.name == other.name
+        else:
+            return self.model_dump() == other
+
+
+class DeviceAttribute(IoTABaseAttribute):
+    """
+    Model for active device attributes
+    """
+    object_id: Optional[str] = Field(
+        default=None,
+        description="name of the attribute as coming from the device."
+    )
+
+
+class LazyDeviceAttribute(BaseNameAttribute):
+    """
+    Model for lazy device attributes
+    """
+    type: Union[DataType, str] = Field(
+        default=DataType.TEXT,
+        description="The attribute type represents the NGSI value type of the "
+                    "attribute value. Note that FIWARE NGSI has its own type "
+                    "system for attribute values, so NGSI value types are not "
+                    "the same as JSON types. Allowed characters "
+                    "are the ones in the plain ASCII set, except the following "
+                    "ones: control characters, whitespace, &, ?, / and #.",
+        max_length=256,
+        min_length=1,
+    )
+    valid_type = field_validator("type")(validate_fiware_datatype_string_protect)
+
+
+class DeviceCommand(BaseModel):
+    """
+    Model for commands
+    """
+    name: str = Field(
+        description="ID of the attribute in the target entity in the "
+                    "Context Broker. Allowed characters "
+                    "are the ones in the plain ASCII set, except the following "
+                    "ones: control characters, whitespace, &, ?, / and #.",
+        max_length=256,
+        min_length=1,
+    )
+    valid_name = field_validator("name")(validate_fiware_datatype_string_protect)
+    type: Union[DataType, str] = Field(
+        description="name of the type of the attribute in the target entity. ",
+        default=DataType.COMMAND
+    )
+
+
+class StaticDeviceAttribute(IoTABaseAttribute, BaseValueAttribute):
+    """
+    Model for static device attributes
+    """
+    pass
+
+
+class ServiceGroup(BaseModel):
+    """
+    Model for device service group.
+    https://iotagent-node-lib.readthedocs.io/en/latest/api/index.html#service-group-api
+    """
+    service: Optional[str] = Field(
+        default=None,
+        description="ServiceGroup of the devices of this type"
+    )
+    subservice: Optional[str] = Field(
+        default=None,
+        description="Subservice of the devices of this type.",
+        pattern="^/"
+    )
+    resource: str = Field(
+        description="string representing the Southbound resource that will be "
+                    "used to assign a type to a device  (e.g.: pathname in the "
+                    "southbound port)."
+    )
+    apikey: str = Field(
+        description="API Key string. It is a key used for devices belonging "
+                    "to this service_group. If "", service_group does not use "
+                    "apikey, but it must be specified."
+    )
+    timestamp: Optional[bool] = Field(
+        default=None,
+        description="Optional flag about whether or not to add the TimeInstant "
+                    "attribute to the device entity created, as well as a "
+                    "TimeInstant metadata to each attribute, with the current "
+                    "timestamp. With NGSI-LD, the Standard observedAt "
+                    "property-of-a-property is created instead."
+    )
+    entity_type: Optional[str] = Field(
+        default=None,
+        description="name of the Entity type to assign to the group. "
+                    "Allowed characters "
+                    "are the ones in the plain ASCII set, except the following "
+                    "ones: control characters, whitespace, &, ?, / and #.",
+        max_length=256,
+        min_length=1,
+    )
+    valid_entity_type = field_validator("entity_type")(validate_fiware_datatype_standard)
+    trust: Optional[str] = Field(
+        default=None,
+        description="trust token to use for secured access to the "
+                    "Context Broker for this type of devices (optional; only "
+                    "needed for secured scenarios)."
+    )
+    cbHost: Optional[AnyHttpUrl] = Field(
+        default=None,
+        description="Context Broker connection information. This options can "
+                    "be used to override the global ones for specific types of "
+                    "devices."
+    )
+    @field_validator('cbHost')
+    @classmethod
+    def validate_cbHost(cls, value):
+        """
+        convert cbHost to str
+        Returns:
+            timezone
+        """
+        return str(value)
+    lazy: Optional[List[LazyDeviceAttribute]] = Field(
+        default=[],
+        desription="list of common lazy attributes of the device. For each "
+                   "attribute, its name and type must be provided."
+    )
+    commands: Optional[List[DeviceCommand]] = Field(
+        default=[],
+        desription="list of common commands attributes of the device. For each "
+                   "attribute, its name and type must be provided, additional "
+                   "metadata is optional"
+    )
+    attributes: Optional[List[DeviceAttribute]] = Field(
+        default=[],
+        description="list of common commands attributes of the device. For "
+                    "each attribute, its name and type must be provided, "
+                    "additional metadata is optional."
+    )
+    static_attributes: Optional[List[StaticDeviceAttribute]] = Field(
+        default=[],
+        description="this attributes will be added to all the entities of this "
+                    "group 'as is', additional metadata is optional."
+    )
+    internal_attributes: Optional[List[Dict[str, Any]]] = Field(
+        default=[],
+        description="optional section with free format, to allow specific "
+                    "IoT Agents to store information along with the devices "
+                    "in the Device Registry."
+    )
+    expressionLanguage: Optional[ExpressionLanguage] = Field(
+        default="legacy",
+        description="optional boolean value, to set expression language used "
+                    "to compute expressions, possible values are: "
+                    "legacy or jexl. When not set or wrongly set, legacy "
+                    "is used as default value."
+    )
+    explicitAttrs: Optional[bool] = Field(
+        default=False,
+        description="optional boolean value, to support selective ignore "
+                    "of measures so that IOTA does not progress. If not "
+                    "specified default is false."
+    )
+    autoprovision: Optional[bool] = Field(
+        default=True,
+        description="optional boolean: If false, autoprovisioned devices "
+                    "(i.e. devices that are not created with an explicit "
+                    "provision operation but when the first measure arrives) "
+                    "are not allowed in this group. "
+                    "Default (in the case of omitting the field) is true."
+    )
+    ngsiVersion: Optional[NgsiVersion] = Field(
+        default="v2",
+        description="optional string value used in mixed mode to switch between"
+                    " NGSI-v2 and NGSI-LD payloads. Possible values are: "
+                    "v2 or ld. The default is v2. When not running in mixed "
+                    "mode, this field is ignored.")
+    defaultEntityNameConjunction: Optional[str] = Field(
+        default=None,
+        description="optional string value to set default conjunction string "
+                    "used to compose a default entity_name when is not "
+                    "provided at device provisioning time."
+    )
+
+
+class DeviceSettings(BaseModel):
+    """
+    Model for iot device settings
+    """
+    model_config = ConfigDict(validate_assignment=True)
+    timezone: Optional[str] = Field(
+        default='Europe/London',
+        description="Time zone of the sensor if it has any"
+    )
+    timestamp: Optional[bool] = Field(
+        default=None,
+        description="Optional flag about whether or not to add the TimeInstant "
+                    "attribute to the device entity created, as well as a "
+                    "TimeInstant metadata to each attribute, with the current "
+                    "timestamp. With NGSI-LD, the Standard observedAt "
+                    "property-of-a-property is created instead."
+    )
+    apikey: Optional[str] = Field(
+        default=None,
+        description="Optional Apikey key string to use instead of group apikey"
+    )
+    endpoint: Optional[AnyHttpUrl] = Field(
+        default=None,
+        description="Endpoint where the device is going to receive commands, "
+                    "if any."
+    )
+    protocol: Optional[Union[PayloadProtocol, str]] = Field(
+        default=None,
+        description="Name of the device protocol, for its use with an "
+                    "IoT Manager."
+    )
+    transport: Optional[Union[TransportProtocol, str]] = Field(
+        default=None,
+        description="Name of the device transport protocol, for the IoT Agents "
+                    "with multiple transport protocols."
+    )
+    expressionLanguage: Optional[ExpressionLanguage] = Field(
+        default=None,
+        description="optional boolean value, to set expression language used "
+                    "to compute expressions, possible values are: "
+                    "legacy or jexl. When not set or wrongly set, legacy "
+                    "is used as default value."
+    )
+    explicitAttrs: Optional[bool] = Field(
+        default=False,
+        description="optional boolean value, to support selective ignore "
+                    "of measures so that IOTA does not progress. If not "
+                    "specified default is false."
+    )
+
+
+class Device(DeviceSettings):
+    """
+    Model for iot devices.
+    https://iotagent-node-lib.readthedocs.io/en/latest/api/index.html#device-api
+    """
+    model_config = ConfigDict(validate_default=True, validate_assignment=True)
+    device_id: str = Field(
+        description="Device ID that will be used to identify the device"
+    )
+    service: Optional[str] = Field(
+        default=None,
+        description="Name of the service the device belongs to "
+                    "(will be used in the fiware-service header).",
+        max_length=50
+    )
+    service_path: Optional[str] = Field(
+        default="/",
+        description="Name of the subservice the device belongs to "
+                    "(used in the fiware-servicepath header).",
+        max_length=51,
+        pattern="^/"
+    )
+    entity_name: str = Field(
+        description="Name of the entity representing the device in "
+                    "the Context Broker Allowed characters "
+                    "are the ones in the plain ASCII set, except the following "
+                    "ones: control characters, whitespace, &, ?, / and #.",
+        max_length=256,
+        min_length=1,
+    )
+    valid_entity_name = field_validator("entity_name")(validate_fiware_datatype_standard)
+    entity_type: str = Field(
+        description="Type of the entity in the Context Broker. "
+                    "Allowed characters "
+                    "are the ones in the plain ASCII set, except the following "
+                    "ones: control characters, whitespace, &, ?, / and #.",
+        max_length=256,
+        min_length=1,
+    )
+    valid_entity_type = field_validator("entity_type")(validate_fiware_datatype_standard)
+    lazy: List[LazyDeviceAttribute] = Field(
+        default=[],
+        description="List of lazy attributes of the device"
+    )
+    commands: List[DeviceCommand] = Field(
+        default=[],
+        desription="List of commands of the device"
+    )
+    attributes: List[DeviceAttribute] = Field(
+        default=[],
+        description="List of active attributes of the device"
+    )
+    static_attributes: Optional[List[StaticDeviceAttribute]] = Field(
+        default=[],
+        description="List of static attributes to append to the entity. All the"
+                    " updateContext requests to the CB will have this set of "
+                    "attributes appended."
+    )
+    internal_attributes: Optional[List[Dict[str, Any]]] = Field(
+        default=[],
+        description="List of internal attributes with free format for specific "
+                    "IoT Agent configuration"
+    )
+    ngsiVersion: NgsiVersion = Field(
+        default=NgsiVersion.v2,
+        description="optional string value used in mixed mode to switch between"
+                    " NGSI-v2 and NGSI-LD payloads. Possible values are: "
+                    "v2 or ld. The default is v2. When not running in "
+                    "mixed mode, this field is ignored.")
+
+    @field_validator('timezone')
+    @classmethod
+    def validate_timezone(cls, value):
+        """
+        validate timezone
+        Returns:
+            timezone
+        """
+        assert value in pytz.all_timezones
+        return value
+
+    def get_attribute(self, attribute_name: str) -> Union[DeviceAttribute,
+                                                          LazyDeviceAttribute,
+                                                          StaticDeviceAttribute,
+                                                          DeviceCommand]:
+        """
+
+        Args:
+            attribute_name:
+
+        Returns:
+
+        """
+        for attribute in itertools.chain(self.attributes,
+                                         self.lazy,
+                                         self.static_attributes,
+                                         self.internal_attributes,
+                                         self.commands):
+            if attribute.name == attribute_name:
+                return attribute
+        msg = f"Device: {self.device_id}: Could not " \
+              f"find attribute with name {attribute_name}"
+        logger.error(msg)
+        raise KeyError(msg)
+
+    def add_attribute(self,
+                      attribute: Union[DeviceAttribute,
+                                       LazyDeviceAttribute,
+                                       StaticDeviceAttribute,
+                                       DeviceCommand],
+                      update: bool = False) -> None:
+        """
+
+        Args:
+            attribute:
+            update (bool): If 'True' and attribute does already exists tries
+                to  update the attribute if not
+        Returns:
+            None
+        """
+        try:
+            if type(attribute) == DeviceAttribute:
+                if attribute in self.attributes:
+                    raise ValueError
+
+                self.attributes.append(attribute)
+                self.__setattr__(name='attributes',
+                                 value=self.attributes)
+            elif type(attribute) == LazyDeviceAttribute:
+                if attribute in self.lazy:
+                    raise ValueError
+
+                self.lazy.append(attribute)
+                self.__setattr__(name='lazy',
+                                 value=self.lazy)
+            elif type(attribute) == StaticDeviceAttribute:
+                if attribute in self.static_attributes:
+                    raise ValueError
+
+                self.static_attributes.append(attribute)
+                self.__setattr__(name='static_attributes',
+                                 value=self.static_attributes)
+            elif type(attribute) == DeviceCommand:
+                if attribute in self.commands:
+                    raise ValueError
+
+                self.commands.append(attribute)
+                self.__setattr__(name='commands',
+                                 value=self.commands)
+            else:
+                raise ValueError
+        except ValueError:
+            if update:
+                self.update_attribute(attribute, append=False)
+                logger.warning("Device: %s: Attribute already "
+                               "exists. Will update: \n %s",
+                               self.device_id, attribute.model_dump_json(indent=2))
+            else:
+                logger.error("Device: %s: Attribute already "
+                             "exists: \n %s", self.device_id,
+                             attribute.model_dump_json(indent=2))
+                raise
+
+    def update_attribute(self,
+                         attribute: Union[DeviceAttribute,
+                                          LazyDeviceAttribute,
+                                          StaticDeviceAttribute,
+                                          DeviceCommand],
+                         append: bool = False) -> None:
+        """
+        Updates existing device attribute
+
+        Args:
+            attribute: Attribute to add to device configuration
+            append (bool): Adds attribute if not exist
+
+        Returns:
+            None
+        """
+        try:
+            if type(attribute) == DeviceAttribute:
+                idx = self.attributes.index(attribute)
+                self.attributes[idx].model_dump().update(attribute.model_dump())
+            elif type(attribute) == LazyDeviceAttribute:
+                idx = self.lazy.index(attribute)
+                self.lazy[idx].model_dump().update(attribute.model_dump())
+            elif type(attribute) == StaticDeviceAttribute:
+                idx = self.static_attributes.index(attribute)
+                self.static_attributes[idx].model_dump().update(attribute.model_dump())
+            elif type(attribute) == DeviceCommand:
+                idx = self.commands.index(attribute)
+                self.commands[idx].model_dump().update(attribute.model_dump())
+        except ValueError:
+            if append:
+                logger.warning("Device: %s: Could not find "
+                               "attribute: \n %s",
+                               self.device_id, attribute.model_dump_json(indent=2))
+                self.add_attribute(attribute=attribute)
+            else:
+                msg = f"Device: {self.device_id}: Could not find "\
+                      f"attribute: \n {attribute.model_dump_json(indent=2)}"
+                raise KeyError(msg)
+
+    def delete_attribute(self, attribute: Union[DeviceAttribute,
+                                                LazyDeviceAttribute,
+                                                StaticDeviceAttribute,
+                                                DeviceCommand]):
+        """
+        Deletes attribute from device
+        Args:
+            attribute: ()
+
+        Returns:
+
+        """
+        try:
+            if type(attribute) == DeviceAttribute:
+                self.attributes.remove(attribute)
+            elif type(attribute) == LazyDeviceAttribute:
+                self.lazy.remove(attribute)
+            elif type(attribute) == StaticDeviceAttribute:
+                self.static_attributes.remove(attribute)
+            elif type(attribute) == DeviceCommand:
+                self.commands.remove(attribute)
+            else:
+                raise ValueError
+        except ValueError:
+            logger.warning("Device: %s: Could not delete "
+                           "attribute: \n %s",
+                           self.device_id, attribute.model_dump_json(indent=2))
+            raise
+
+        logger.info("Device: %s: Attribute deleted! \n %s",
+                    self.device_id, attribute.model_dump_json(indent=2))
+
+    def get_command(self, command_name: str):
+        """
+        Short for self.get_attributes
+        Args:
+            command_name (str):
+        Returns:
+
+        """
+        return self.get_attribute(attribute_name=command_name)
+
+    def add_command(self, command: DeviceCommand, update: bool = False):
+        """
+        Short for self.add_attribute
+        Args:
+            command (DeviceCommand):
+            update (bool): Update command if it already exists
+        Returns:
+        """
+        self.add_attribute(attribute=command, update=update)
+
+    def update_command(self, command: DeviceCommand, append: bool = False):
+        """
+        Short for self.update_attribute
+        Args:
+            command:
+            append:
+        Returns:
+        """
+        self.update_attribute(attribute=command, append=append)
+
+    def delete_command(self, command: DeviceCommand):
+        """
+        Short for self.delete_attribute
+        Args:
+            command:
+
+        Returns:
+            None
+        """
+        self.delete_attribute(attribute=command)
```

### Comparing `filip-0.3.0/filip/models/ngsi_v2/timeseries.py` & `filip-0.4.0/filip/models/ngsi_v2/timeseries.py`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,162 +1,162 @@
-"""
-Data models for interacting with FIWARE's time series-api (aka QuantumLeap)
-"""
-from __future__ import annotations
-import logging
-from typing import Any, List, Union
-from datetime import datetime
-import numpy as np
-import pandas as pd
-from aenum import Enum
-from pydantic import ConfigDict, BaseModel, Field
-
-
-logger = logging.getLogger(__name__)
-
-
-class TimeSeriesBase(BaseModel):
-    """
-    Base model for other time series api models
-    """
-    index: Union[List[datetime], datetime] = Field(
-        default=None,
-        description="Array of the timestamps which are indexes of the response "
-                    "for the requested data. It's a parallel array to 'values'."
-                    " The timestamp will be in the ISO8601 format "
-                    "(e.g. 2010-10-10T07:09:00.792) or in milliseconds since "
-                    "epoch whichever format was used in the input "
-                    "(notification), but ALWAYS in UTC. When using aggregation "
-                    "options, the format of this remains the same, only the "
-                    "semantics will change. For example, if aggrPeriod is day, "
-                    "each index will be a valid timestamp of a moment in the "
-                    "corresponding day."
-    )
-
-
-class TimeSeriesHeader(TimeSeriesBase):
-    """
-    Model to describe an available entity in the time series api
-    """
-    model_config = ConfigDict(populate_by_name=True)
-    # aliases are required due to formally inconsistencies in the api-specs
-    entityId: str = Field(default=None,
-                          alias="id",
-                          description="The entity id the time series api."
-                                      "If the id is unique among all entity "
-                                      "types, this could be used to uniquely "
-                                      "identify the entity instance. Otherwise,"
-                                      " you will have to use the entityType "
-                                      "attribute to resolve ambiguity.")
-    entityType: str = Field(default=None,
-                            alias="type",
-                            description="The type of an entity")
-
-
-class IndexedValues(BaseModel):
-    """
-    Model for time indexed values
-    """
-    values: List[Any] = Field(
-        default=None,
-        description="Array of values of the selected attribute, in the same "
-                    "corresponding order of the 'index' array. When using "
-                    "aggregation options, the format of this remains the same, "
-                    "only the semantics will change. For example, if "
-                    "aggrPeriod is day, each value of course may not "
-                    "correspond to original measurements but rather the "
-                    "aggregate of measurements in each day."
-    )
-
-
-class AttributeValues(IndexedValues):
-    """
-    Model for indexed values that contain attribute name
-    """
-    attrName: str = Field(
-        title="Attribute name",
-        description=""
-    )
-
-
-class TimeSeries(TimeSeriesHeader):
-    """
-    Model for time series data
-    """
-    model_config = ConfigDict(populate_by_name=True)
-    attributes: List[AttributeValues] = None
-
-    def extend(self, other: TimeSeries) -> None:
-        """
-        Extends the current `TimeSeries` object with an other
-        `TimeSeries` object. With the same format.
-
-        Args:
-            other: TimeSeries Object that will be added to the original object
-
-        Returns:
-            None
-
-        Raises:
-            Assertion Error: if header fields do not fit or if index is not
-                rising
-        """
-        assert self.entityId == other.entityId
-        assert self.entityType == other.entityType
-        assert self.index[-1] < other.index[0]
-
-        for attr, other_attr in zip(self.attributes, other.attributes):
-            assert attr.attrName == other_attr.attrName
-            attr.values.extend(other_attr.values)
-        self.index.extend(other.index)
-
-    def to_pandas(self) -> pd.DataFrame:
-        """
-        Converts time series data to pandas dataframe
-        Returns:
-            pandas.DataFrame
-        """
-        index = pd.Index(data=self.index, name='datetime')
-        attr_names = [attr.attrName for attr in self.attributes]
-        values = np.array([attr.values for attr in self.attributes]).transpose()
-        columns = pd.MultiIndex.from_product(
-            [[self.entityId], [self.entityType], attr_names],
-            names=['entityId', 'entityType', 'attribute'])
-
-        return pd.DataFrame(data=values, index=index, columns=columns)
-
-
-class AggrMethod(str, Enum):
-    """
-    Aggregation Methods
-    """
-    _init_ = 'value __doc__'
-    COUNT = "count", "Number of Entries"
-    SUM = "sum", "Sum"
-    AVG = "avg", "Average"
-    MIN = "min", "Minimum"
-    MAX = "max", "Maximum"
-
-
-class AggrPeriod(str, Enum):
-    """
-    Aggregation Periods
-    """
-    _init_ = 'value __doc__'
-    YEAR = "year", "year"
-    MONTH = "month", "month"
-    DAY = "day", "day"
-    HOUR = "hour", "hour"
-    MINUTE = "minute", "minute"
-    SECOND = "second", "second"
-
-
-class AggrScope(str, Enum):
-    """
-    Aggregation Periods
-    When the query results cover historical data for
-    multiple entities instances, you can define the aggregation method to be
-    applied for each entity instance [entity] or across them [global].
-    """
-    _init_ = 'value __doc__'
-    ENTITY = "entity", "Entity (default)"
-    GLOBAL = "global", "Global"
+"""
+Data models for interacting with FIWARE's time series-api (aka QuantumLeap)
+"""
+from __future__ import annotations
+import logging
+from typing import Any, List, Union
+from datetime import datetime
+import numpy as np
+import pandas as pd
+from aenum import Enum
+from pydantic import ConfigDict, BaseModel, Field
+
+
+logger = logging.getLogger(__name__)
+
+
+class TimeSeriesBase(BaseModel):
+    """
+    Base model for other time series api models
+    """
+    index: Union[List[datetime], datetime] = Field(
+        default=None,
+        description="Array of the timestamps which are indexes of the response "
+                    "for the requested data. It's a parallel array to 'values'."
+                    " The timestamp will be in the ISO8601 format "
+                    "(e.g. 2010-10-10T07:09:00.792) or in milliseconds since "
+                    "epoch whichever format was used in the input "
+                    "(notification), but ALWAYS in UTC. When using aggregation "
+                    "options, the format of this remains the same, only the "
+                    "semantics will change. For example, if aggrPeriod is day, "
+                    "each index will be a valid timestamp of a moment in the "
+                    "corresponding day."
+    )
+
+
+class TimeSeriesHeader(TimeSeriesBase):
+    """
+    Model to describe an available entity in the time series api
+    """
+    model_config = ConfigDict(populate_by_name=True)
+    # aliases are required due to formally inconsistencies in the api-specs
+    entityId: str = Field(default=None,
+                          alias="id",
+                          description="The entity id the time series api."
+                                      "If the id is unique among all entity "
+                                      "types, this could be used to uniquely "
+                                      "identify the entity instance. Otherwise,"
+                                      " you will have to use the entityType "
+                                      "attribute to resolve ambiguity.")
+    entityType: str = Field(default=None,
+                            alias="type",
+                            description="The type of an entity")
+
+
+class IndexedValues(BaseModel):
+    """
+    Model for time indexed values
+    """
+    values: List[Any] = Field(
+        default=None,
+        description="Array of values of the selected attribute, in the same "
+                    "corresponding order of the 'index' array. When using "
+                    "aggregation options, the format of this remains the same, "
+                    "only the semantics will change. For example, if "
+                    "aggrPeriod is day, each value of course may not "
+                    "correspond to original measurements but rather the "
+                    "aggregate of measurements in each day."
+    )
+
+
+class AttributeValues(IndexedValues):
+    """
+    Model for indexed values that contain attribute name
+    """
+    attrName: str = Field(
+        title="Attribute name",
+        description=""
+    )
+
+
+class TimeSeries(TimeSeriesHeader):
+    """
+    Model for time series data
+    """
+    model_config = ConfigDict(populate_by_name=True)
+    attributes: List[AttributeValues] = None
+
+    def extend(self, other: TimeSeries) -> None:
+        """
+        Extends the current `TimeSeries` object with an other
+        `TimeSeries` object. With the same format.
+
+        Args:
+            other: TimeSeries Object that will be added to the original object
+
+        Returns:
+            None
+
+        Raises:
+            Assertion Error: if header fields do not fit or if index is not
+                rising
+        """
+        assert self.entityId == other.entityId
+        assert self.entityType == other.entityType
+        assert self.index[-1] < other.index[0]
+
+        for attr, other_attr in zip(self.attributes, other.attributes):
+            assert attr.attrName == other_attr.attrName
+            attr.values.extend(other_attr.values)
+        self.index.extend(other.index)
+
+    def to_pandas(self) -> pd.DataFrame:
+        """
+        Converts time series data to pandas dataframe
+        Returns:
+            pandas.DataFrame
+        """
+        index = pd.Index(data=self.index, name='datetime')
+        attr_names = [attr.attrName for attr in self.attributes]
+        values = np.array([attr.values for attr in self.attributes]).transpose()
+        columns = pd.MultiIndex.from_product(
+            [[self.entityId], [self.entityType], attr_names],
+            names=['entityId', 'entityType', 'attribute'])
+
+        return pd.DataFrame(data=values, index=index, columns=columns)
+
+
+class AggrMethod(str, Enum):
+    """
+    Aggregation Methods
+    """
+    _init_ = 'value __doc__'
+    COUNT = "count", "Number of Entries"
+    SUM = "sum", "Sum"
+    AVG = "avg", "Average"
+    MIN = "min", "Minimum"
+    MAX = "max", "Maximum"
+
+
+class AggrPeriod(str, Enum):
+    """
+    Aggregation Periods
+    """
+    _init_ = 'value __doc__'
+    YEAR = "year", "year"
+    MONTH = "month", "month"
+    DAY = "day", "day"
+    HOUR = "hour", "hour"
+    MINUTE = "minute", "minute"
+    SECOND = "second", "second"
+
+
+class AggrScope(str, Enum):
+    """
+    Aggregation Periods
+    When the query results cover historical data for
+    multiple entities instances, you can define the aggregation method to be
+    applied for each entity instance [entity] or across them [global].
+    """
+    _init_ = 'value __doc__'
+    ENTITY = "entity", "Entity (default)"
+    GLOBAL = "global", "Global"
```

### Comparing `filip-0.3.0/filip/semantics/ontology_parser/post_processer.py` & `filip-0.4.0/filip/semantics/ontology_parser/post_processer.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,689 +1,689 @@
-"""
-The PostProcessing gets called after the vocabulary was parsed from sources
-
-The postprocessing has the goal to add predefined values,
-compute combinedRelations, reload user settings, and precompute
-information as: duplicate labels or sort relations
-"""
-
-import datetime
-import re
-from typing import List, Optional
-
-import stringcase
-
-from filip.semantics.ontology_parser.vocabulary_builder import VocabularyBuilder
-from filip.semantics.vocabulary import Source, IdType, Vocabulary, \
-    DatatypeType, Datatype, Class
-from filip.semantics.vocabulary import CombinedDataRelation, \
-    CombinedObjectRelation, CombinedRelation
-
-
-class PostProcessor:
-    """Class offering postprocessing as cls-methods for a vocabulary"""
-
-    @classmethod
-    def post_process_vocabulary(cls, vocabulary: Vocabulary,
-                                old_vocabulary: Optional[Vocabulary] = None):
-        """Main methode to be called for post processing
-
-        Args:
-            vocabulary (Vocabulary): Freshly parsed Vocabulary
-            old_vocabulary (Vocabulary): Existing Vocabulary of which the
-                settings should be overtaken
-
-        Returns:
-            None
-        """
-
-        # all methods have to reset the state that they are editing first.
-        # consecutive calls of post_process_vocabulary need to have the same
-        # result
-        voc_builder = VocabularyBuilder(vocabulary=vocabulary)
-        cls._set_labels(voc_builder)
-        cls._add_predefined_source(voc_builder)
-        cls._add_predefined_datatypes(voc_builder)
-        cls._add_owl_thing(voc_builder)
-        cls._remove_duplicate_parents(voc_builder)
-
-        cls._log_and_clear_dependencies(voc_builder)
-        cls._compute_ancestor_classes(voc_builder)
-        cls._compute_child_classes(voc_builder)
-        cls._combine_relations(voc_builder)
-
-        if old_vocabulary is not None:
-            cls.transfer_settings(new_vocabulary=vocabulary,
-                                  old_vocabulary=old_vocabulary)
-        cls._apply_vocabulary_settings(voc_builder)
-
-        cls._ensure_parent_class(voc_builder)
-
-        cls._sort_relations(voc_builder)
-        cls._mirror_object_property_inverses(voc_builder)
-
-        cls._save_initial_label_summary(vocabulary)
-
-    @classmethod
-    def _set_labels(cls, voc_builder: VocabularyBuilder):
-        """ If entities have no label, extract their label from the iri
-
-        Args:
-            voc_builder: Builder object for Vocabulary
-
-        Returns:
-            None
-        """
-        for entity in voc_builder.vocabulary.get_all_entities():
-            entity.label = entity.get_original_label()
-
-    @classmethod
-    def _add_predefined_source(cls, voc_builder: VocabularyBuilder):
-        """ Add a special source to the vocabulary: PREDEFINED
-
-        Args:
-            voc_builder: Builder object for Vocabulary
-
-        Returns:
-            None
-        """
-        if "PREDEFINED" not in voc_builder.vocabulary.sources:
-            source = Source(source_name="Predefined",
-                            timestamp=datetime.datetime.now(), predefined=True)
-            voc_builder.add_source(source, "PREDEFINED")
-
-    @classmethod
-    def _log_and_clear_dependencies(cls, voc_builder: VocabularyBuilder):
-        """
-        remove all references to entities that are not in the vocabulary to
-        prevent program errrors as we remove information we need to reparse
-        the source each time a new source is added as than the dependency
-        could be valid. Further log the found dependencies for the user to
-        display
-
-        Args:
-            voc_builder: Builder object for Vocabulary
-
-        Returns:
-            None
-        """
-        for ontology in voc_builder.vocabulary.sources.values():
-            ontology.treat_dependency_statements(voc_builder.vocabulary)
-
-    @classmethod
-    def _add_predefined_datatypes(cls, voc_builder: VocabularyBuilder):
-        """
-        Add predefinded datatype_catalogue to the PREDEFINED source; they
-        are not included in an OWL file
-
-        Args:
-            voc_builder: Builder object for Vocabulary
-
-        Returns:
-            None
-        """
-        # Test if datatype_catalogue were already added, if yes skip
-        if 'http://www.w3.org/2002/07/owl#rational' in \
-                voc_builder.vocabulary.datatypes.keys():
-            return
-
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2002/07/owl#rational",
-                     comment="All numbers allowed",
-                     type=DatatypeType.number,
-                     number_decimal_allowed=True))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2002/07/owl#real",
-                     comment="All whole numbers allowed",
-                     type=DatatypeType.number,
-                     number_decimal_allowed=False))
-        voc_builder.add_predefined_datatype(
-            Datatype(
-                iri="http://www.w3.org/1999/02/22-rdf-syntax-ns#PlainLiteral",
-                comment="All strings allowed",
-                type=DatatypeType.string))
-        voc_builder.add_predefined_datatype(
-            Datatype(
-                iri="http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral",
-                comment="XML Syntax required",
-                type=DatatypeType.string))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2000/01/rdf-schema#Literal",
-                     comment="All strings allowed",
-                     type=DatatypeType.string))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#anyURI",
-                     comment="Needs to start with http://",
-                     type=DatatypeType.string))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#base64Binary",
-                     comment="Base64Binary",
-                     type=DatatypeType.string))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#boolean",
-                     comment="True or False",
-                     type=DatatypeType.enum,
-                     enum_values=["True", "False"]))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#byte",
-                     comment="Byte Number",
-                     type=DatatypeType.number,
-                     number_has_range=True,
-                     number_range_min=-128,
-                     number_range_max=127))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#dateTime",
-                     comment="Date with possible timezone",
-                     type=DatatypeType.date))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#dateTimeStamp",
-                     comment="Date",
-                     type=DatatypeType.date))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#decimal",
-                     comment="All decimal numbers",
-                     type=DatatypeType.number,
-                     number_decimal_allowed=True))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#double",
-                     comment="64 bit decimal",
-                     type=DatatypeType.number,
-                     number_decimal_allowed=True))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#float",
-                     comment="32 bit decimal",
-                     type=DatatypeType.number,
-                     number_decimal_allowed=True))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#hexBinary",
-                     comment="Hexadecimal",
-                     type=DatatypeType.string,
-                     allowed_chars=["0", "1", "2", "3", "4", "5", "6", "7", "8",
-                                    "9", "A", "B", "C", "D", "E", "F"]))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#int",
-                     comment="Signed 32 bit number",
-                     type=DatatypeType.number,
-                     number_has_range=True,
-                     number_range_min=-2147483648,
-                     number_range_max=2147483647))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#integer",
-                     comment="All whole numbers",
-                     type=DatatypeType.number,
-                     number_decimal_allowed=False))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#language",
-                     comment="Language code, e.g: en, en-US, fr, or fr-FR",
-                     type=DatatypeType.string))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#long",
-                     comment="Signed 64 bit integer",
-                     type=DatatypeType.number,
-                     number_has_range=True,
-                     number_range_min=-9223372036854775808,
-                     number_range_max=9223372036854775807,
-                     number_decimal_allowed=False))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#Name",
-                     comment="Name string (dont start with number)",
-                     type=DatatypeType.string))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#NCName",
-                     comment="Name string : forbidden",
-                     type=DatatypeType.string,
-                     forbidden_chars=[":"]))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#negativeInteger",
-                     comment="All negative whole numbers",
-                     type=DatatypeType.number,
-                     number_has_range=True,
-                     number_range_max=-1
-                     ))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#NMTOKEN",
-                     comment="Token string",
-                     type=DatatypeType.string))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#nonNegativeInteger",
-                     comment="All positive whole numbers",
-                     type=DatatypeType.number,
-                     number_has_range=True,
-                     number_range_min=0
-                     ))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#nonPositiveInteger",
-                     comment="All negative whole numbers",
-                     type=DatatypeType.number,
-                     number_has_range=True,
-                     number_range_max=-1
-                     ))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#normalizedString",
-                     comment="normalized String",
-                     type=DatatypeType.string
-                     ))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#positiveInteger",
-                     comment="All positive whole numbers",
-                     type=DatatypeType.number,
-                     number_has_range=True,
-                     number_range_min=0
-                     ))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#short",
-                     comment="signed 16 bit number",
-                     type=DatatypeType.number,
-                     number_has_range=True,
-                     number_range_min=-32768,
-                     number_range_max=32767
-                     ))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#string",
-                     comment="String",
-                     type=DatatypeType.string
-                     ))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#token",
-                     comment="String",
-                     type=DatatypeType.string
-                     ))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#unsignedByte",
-                     comment="unsigned 8 bit number",
-                     type=DatatypeType.number,
-                     number_has_range=True,
-                     number_range_min=0,
-                     number_range_max=255
-                     ))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#unsignedInt",
-                     comment="unsigned 32 bit number",
-                     type=DatatypeType.number,
-                     number_has_range=True,
-                     number_range_min=0,
-                     number_range_max=4294967295
-                     ))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#unsignedLong",
-                     comment="unsigned 64 bit number",
-                     type=DatatypeType.number,
-                     number_has_range=True,
-                     number_range_min=0,
-                     number_range_max=18446744073709551615
-                     ))
-        voc_builder.add_predefined_datatype(
-            Datatype(iri="http://www.w3.org/2001/XMLSchema#unsignedShort",
-                     comment="unsigned 16 bit number",
-                     type=DatatypeType.number,
-                     number_has_range=True,
-                     number_range_min=0,
-                     number_range_max=65535
-                     ))
-
-    @classmethod
-    def _add_owl_thing(cls, voc_builder: VocabularyBuilder):
-        """Add owl_thing class to the vocabulary in the predefined source
-
-        By definition each class is a subclass of owl:thing and owl:thing can be
-        a target of relation but owl thing is never mentioned explicitly in
-        ontology files.
-
-        Args:
-            voc_builder: Builder object for Vocabulary
-        Returns:
-            None
-        """
-        root_class = Class(iri="http://www.w3.org/2002/07/owl#Thing",
-                           comment="Predefined root_class",
-                           label="Thing",
-                           predefined=True)
-
-        # as it is the root object it is only a parent of classes which have no
-        # parents yet
-        for class_ in voc_builder.vocabulary.get_classes():
-            if class_.parent_class_iris == []:
-                class_.parent_class_iris.insert(0, root_class.iri)
-
-        if root_class.iri not in voc_builder.vocabulary.classes:
-            voc_builder.add_class(root_class)
-            root_class.source_ids.add("PREDEFINED")
-
-    @classmethod
-    def _remove_duplicate_parents(cls, voc_builder: VocabularyBuilder):
-        """Prevent that a class_ has the same parent iri multiple times
-
-        Args:
-            voc_builder: Builder object for Vocabulary
-        Returns:
-            None
-        """
-        for class_ in voc_builder.vocabulary.classes.values():
-            class_.parent_class_iris = list(dict.fromkeys(class_.parent_class_iris))
-
-    @classmethod
-    def _ensure_parent_class(cls, voc_builder: VocabularyBuilder):
-        """If a class has a parent class, which was provided by an other
-        ontology. And that ontology is not given, it will have no parents.
-        In that case give him Thing as direct parent
-
-        Args:
-            voc_builder: Builder object for Vocabulary
-        Returns:
-            None
-        """
-        for class_ in voc_builder.vocabulary.classes.values():
-            # Thing is the root of all
-            if not class_.iri == "http://www.w3.org/2002/07/owl#Thing":
-                if len(class_.parent_class_iris) == 0:
-                    class_.parent_class_iris.append(
-                        "http://www.w3.org/2002/07/owl#Thing")
-
-    @classmethod
-    def _apply_vocabulary_settings(cls, voc_builder: VocabularyBuilder):
-        """
-        Make the labels of all entities FIWARE safe, so that they can be used
-        as field keys
-
-        Args:
-            voc_builder: Builder object for Vocabulary
-        Returns:
-            None
-        """
-        vocabulary = voc_builder.vocabulary
-        settings = vocabulary.settings
-
-        def to_pascal_case(string: str) -> str:
-            return stringcase.pascalcase(string).replace("_", "").\
-                replace(" ", "").replace("-", "")
-
-        def to_camel_case(string: str) -> str:
-            camel_string = stringcase.camelcase(string)
-            return camel_string
-
-        def to_snake_case(string: str) -> str:
-            camel_string = to_pascal_case(string)
-            return re.sub(r'(?<!^)(?=[A-Z])', '_', camel_string).lower()
-
-        # replace all whitespaces
-        for entity in vocabulary.get_all_entities():
-            entity.label = entity.label.replace(" ", "_")
-
-        # replace al whitespaces in enum_values
-        for datatype in vocabulary.datatypes.values():
-            new_enums = []
-            for enum in datatype.enum_values:
-                new_enums.append(enum.replace(" ", "_"))
-            datatype.enum_values = new_enums
-
-        if settings.pascal_case_class_labels:
-            for class_ in vocabulary.get_classes():
-                class_.label = to_pascal_case(class_.label)
-
-        if settings.pascal_case_individual_labels:
-            for individual in vocabulary.individuals.values():
-                individual.label = to_pascal_case(individual.label)
-
-        if settings.camel_case_property_labels:
-            props = list(vocabulary.data_properties.values())
-            props.extend(vocabulary.object_properties.values())
-            for prop in props:
-                prop.label = to_camel_case(prop.label)
-
-        if settings.camel_case_datatype_labels:
-            for datatype in vocabulary.datatypes.values():
-                datatype.label = to_camel_case(datatype.label)
-
-        if settings.pascal_case_datatype_enum_labels:
-            for datatype in vocabulary.get_enum_dataytypes().values():
-                datatype.label = to_pascal_case(datatype.label)
-
-    @classmethod
-    def _save_initial_label_summary(cls, vocabulary: Vocabulary):
-        """
-        Save the label_summary existing after parsing, before the user
-        changed labels
-
-        Args:
-            vocabulary: vocabulary of which the label summary should be saved
-
-        Returns:
-            None
-        """
-        from filip.semantics.vocabulary_configurator import \
-            VocabularyConfigurator
-        vocabulary.original_label_summary = \
-            VocabularyConfigurator.get_label_conflicts_in_vocabulary(
-                vocabulary=vocabulary)
-
-    @classmethod
-    def _compute_ancestor_classes(cls, voc_builder: VocabularyBuilder):
-        """Compute all ancestor classes of classes
-
-        Args:
-            voc_builder: Builder object for Vocabulary
-        Returns:
-            None
-        """
-        vocabulary = voc_builder.vocabulary
-        # clear state
-        for class_ in vocabulary.get_classes():
-            class_.ancestor_class_iris = []
-
-        for class_ in vocabulary.get_classes():
-            queue: List[str] = []
-            queue.extend(class_.parent_class_iris)
-
-            while len(queue) > 0:
-                parent = queue.pop()
-
-                if not voc_builder.entity_is_known(parent):
-                    continue
-
-                class_.ancestor_class_iris.append(parent)
-                grand_parents = \
-                    vocabulary.get_class_by_iri(parent).parent_class_iris
-
-                for grand_parent in grand_parents:
-                    if grand_parent not in class_.ancestor_class_iris:
-                        # prevent infinite loop if inheritance circle
-                        queue.append(grand_parent)
-
-    @classmethod
-    def _compute_child_classes(cls, voc_builder: VocabularyBuilder):
-        """Compute all child classes of classes
-
-        Args:
-            voc_builder: Builder object for Vocabulary
-        Returns:
-            None
-        """
-        vocabulary = voc_builder.vocabulary
-        # clear state
-        for class_ in vocabulary.get_classes():
-            class_.child_class_iris = []
-
-        for class_ in vocabulary.get_classes():
-            for parent in class_.ancestor_class_iris:
-
-                if not voc_builder.entity_is_known(parent):
-                    continue
-
-                parent_class = vocabulary.get_class_by_iri(parent)
-                parent_class.child_class_iris.append(class_.iri)
-
-    @classmethod
-    def _combine_relations(cls, voc_builder: VocabularyBuilder):
-        """Compute all CombinedRelations
-
-        Args:
-            voc_builder: Builder object for Vocabulary
-        Returns:
-            None
-        """
-        vocabulary = voc_builder.vocabulary
-        # clear state
-        vocabulary.combined_object_relations.clear()
-        vocabulary.combined_data_relations.clear()
-
-        for class_ in vocabulary.get_classes():
-            class_.combined_object_relation_ids = []
-            class_.combined_data_relation_ids = []
-
-        for class_ in vocabulary.get_classes():
-
-            relations_with_property_iri = {}
-
-            all_relation_ids = []
-            all_relation_ids.extend(class_.get_relation_ids())
-            for ancestor_iri in class_.ancestor_class_iris:
-
-                if not voc_builder.entity_is_known(ancestor_iri):
-                    continue
-                ancestor = vocabulary.get_class_by_iri(ancestor_iri)
-                all_relation_ids.extend(ancestor.get_relation_ids())
-
-            for relation_id in all_relation_ids:
-                relation = vocabulary.get_relation_by_id(id=relation_id)
-                property_iri = relation.property_iri
-
-                if property_iri not in relations_with_property_iri:
-                    relations_with_property_iri[property_iri] = []
-
-                relations_with_property_iri[property_iri].append(relation_id)
-
-            for property_iri, rel_list in relations_with_property_iri.items():
-
-                # These ids should be derived, so that the same combined
-                # relation always ends up with the same id as a class can
-                # only have 1 combined relation of a property these ids are
-                # unique by keeping the ids always the same, we can store
-                # information more efficiently in the database (settings)
-
-                # if a property iri is not known while parsing an ontology
-                # (dependency not yet parsed) the relations with that
-                # property are going to get ignored, maybe a not should be
-                # displayed
-                if vocabulary.is_id_of_type(property_iri, IdType.data_property):
-                    id = "combined-data-relation|{}|{}".format(class_.iri,
-                                                               property_iri)
-                    combi = CombinedDataRelation(id=id,
-                                                 property_iri=property_iri,
-                                                 relation_ids=rel_list,
-                                                 class_iri=class_.iri)
-                    voc_builder.add_combined_data_relation_for_class(
-                        class_iri=class_.iri, cdata=combi)
-                elif vocabulary.is_id_of_type(property_iri,
-                                              IdType.object_property):
-                    id = "combined-object-relation|{}|{}".format(
-                        class_.iri, property_iri)
-                    combi = CombinedObjectRelation(id=id,
-                                                   property_iri=property_iri,
-                                                   relation_ids=rel_list,
-                                                   class_iri=class_.iri)
-                    voc_builder.add_combined_object_relation_for_class(
-                        class_iri=class_.iri, crel=combi)
-                else:
-                    pass
-
-    @classmethod
-    def _sort_relations(cls, voc_builder: VocabularyBuilder):
-        """sort relations alphabetically according to their labels
-
-        Args:
-            voc_builder: Builder object for Vocabulary
-        Returns:
-            None
-        """
-        vocabulary = voc_builder.vocabulary
-
-        for class_ in vocabulary.get_classes():
-            cors = class_.get_combined_object_relations(vocabulary)
-            class_.combined_object_relation_ids = \
-                cls._sort_list_of_combined_relations(cors, vocabulary)
-
-            cdrs = class_.get_combined_data_relations(vocabulary)
-            class_.combined_data_relation_ids = \
-                cls._sort_list_of_combined_relations(cdrs, vocabulary)
-
-    @classmethod
-    def _sort_list_of_combined_relations(
-            cls,
-            combined_relations: List[CombinedRelation],
-            vocabulary: Vocabulary) -> List[str]:
-        """sort given CombinedRelations according to their labels
-
-        Args:
-            vocabulary (Vocabulary)
-            combined_relations (List[CombinedRelation]): CRs to sort
-        Returns:
-            List[str], list of cr_id, sorted according to their label
-        """
-
-        property_dic = {}
-
-        for cor in combined_relations:
-            property_iri = cor.property_iri
-            label = cor.get_property_label(vocabulary=vocabulary)
-            property_dic[label + property_iri] = cor.id
-            # combine label with iri to prevent an error due to two identical
-            # labels
-        sorted_property_dic = sorted(property_dic.items())
-
-        sorted_cor_ids = []
-        for pair in sorted_property_dic:
-            sorted_cor_ids.append(pair[1])
-        return sorted_cor_ids
-
-    @classmethod
-    def _mirror_object_property_inverses(cls, voc_builder: VocabularyBuilder):
-        """
-        inverses could only be given for 1 obj_prop of the pair and needs to
-        be derived for the other also we could have the inverse inside an other
-        import (there for done in postprocessing)
-
-        Args:
-            voc_builder: Builder object for Vocabulary
-
-        Returns:
-            None
-        """
-        # the state is not cleared, instead add_inverse_property_iri() makes
-        # sure that there will be no duplicates as it is a set
-        vocabulary = voc_builder.vocabulary
-
-        for obj_prop_iri in vocabulary.object_properties:
-            obj_prop = vocabulary.get_object_property(obj_prop_iri)
-
-            for inverse_iri in obj_prop.inverse_property_iris:
-                inverse_prop = vocabulary.get_object_property(inverse_iri)
-                inverse_prop.add_inverse_property_iri(obj_prop_iri)
-
-    @classmethod
-    def transfer_settings(cls, new_vocabulary: Vocabulary,
-                          old_vocabulary: Vocabulary):
-        """
-        Transfer all the user made settings (labels, ..)
-        from an old vocabulary to a new vocabulary
-
-        Args:
-            new_vocabulary (Vocabulary): Vocabulary to which the settings should
-                be transferred
-            old_vocabulary (Vocabulary): Vocabulary of which the settings should
-                be transferred
-
-        Returns:
-            None
-        """
-
-        # label settings
-        for entity in old_vocabulary.get_all_entities():
-            new_entity = new_vocabulary.get_entity_by_iri(entity.iri)
-            if new_entity is not None:
-                new_entity.user_set_label = entity.user_set_label
-
-        # device settings
-        for iri, data_property in old_vocabulary.data_properties.items():
-            if iri in new_vocabulary.data_properties:
-                new_data_property = new_vocabulary.data_properties[iri]
-                new_data_property.field_type = data_property.field_type
-
+"""
+The PostProcessing gets called after the vocabulary was parsed from sources
+
+The postprocessing has the goal to add predefined values,
+compute combinedRelations, reload user settings, and precompute
+information as: duplicate labels or sort relations
+"""
+
+import datetime
+import re
+from typing import List, Optional
+
+import stringcase
+
+from filip.semantics.ontology_parser.vocabulary_builder import VocabularyBuilder
+from filip.semantics.vocabulary import Source, IdType, Vocabulary, \
+    DatatypeType, Datatype, Class
+from filip.semantics.vocabulary import CombinedDataRelation, \
+    CombinedObjectRelation, CombinedRelation
+
+
+class PostProcessor:
+    """Class offering postprocessing as cls-methods for a vocabulary"""
+
+    @classmethod
+    def post_process_vocabulary(cls, vocabulary: Vocabulary,
+                                old_vocabulary: Optional[Vocabulary] = None):
+        """Main methode to be called for post processing
+
+        Args:
+            vocabulary (Vocabulary): Freshly parsed Vocabulary
+            old_vocabulary (Vocabulary): Existing Vocabulary of which the
+                settings should be overtaken
+
+        Returns:
+            None
+        """
+
+        # all methods have to reset the state that they are editing first.
+        # consecutive calls of post_process_vocabulary need to have the same
+        # result
+        voc_builder = VocabularyBuilder(vocabulary=vocabulary)
+        cls._set_labels(voc_builder)
+        cls._add_predefined_source(voc_builder)
+        cls._add_predefined_datatypes(voc_builder)
+        cls._add_owl_thing(voc_builder)
+        cls._remove_duplicate_parents(voc_builder)
+
+        cls._log_and_clear_dependencies(voc_builder)
+        cls._compute_ancestor_classes(voc_builder)
+        cls._compute_child_classes(voc_builder)
+        cls._combine_relations(voc_builder)
+
+        if old_vocabulary is not None:
+            cls.transfer_settings(new_vocabulary=vocabulary,
+                                  old_vocabulary=old_vocabulary)
+        cls._apply_vocabulary_settings(voc_builder)
+
+        cls._ensure_parent_class(voc_builder)
+
+        cls._sort_relations(voc_builder)
+        cls._mirror_object_property_inverses(voc_builder)
+
+        cls._save_initial_label_summary(vocabulary)
+
+    @classmethod
+    def _set_labels(cls, voc_builder: VocabularyBuilder):
+        """ If entities have no label, extract their label from the iri
+
+        Args:
+            voc_builder: Builder object for Vocabulary
+
+        Returns:
+            None
+        """
+        for entity in voc_builder.vocabulary.get_all_entities():
+            entity.label = entity.get_original_label()
+
+    @classmethod
+    def _add_predefined_source(cls, voc_builder: VocabularyBuilder):
+        """ Add a special source to the vocabulary: PREDEFINED
+
+        Args:
+            voc_builder: Builder object for Vocabulary
+
+        Returns:
+            None
+        """
+        if "PREDEFINED" not in voc_builder.vocabulary.sources:
+            source = Source(source_name="Predefined",
+                            timestamp=datetime.datetime.now(), predefined=True)
+            voc_builder.add_source(source, "PREDEFINED")
+
+    @classmethod
+    def _log_and_clear_dependencies(cls, voc_builder: VocabularyBuilder):
+        """
+        remove all references to entities that are not in the vocabulary to
+        prevent program errrors as we remove information we need to reparse
+        the source each time a new source is added as than the dependency
+        could be valid. Further log the found dependencies for the user to
+        display
+
+        Args:
+            voc_builder: Builder object for Vocabulary
+
+        Returns:
+            None
+        """
+        for ontology in voc_builder.vocabulary.sources.values():
+            ontology.treat_dependency_statements(voc_builder.vocabulary)
+
+    @classmethod
+    def _add_predefined_datatypes(cls, voc_builder: VocabularyBuilder):
+        """
+        Add predefinded datatype_catalogue to the PREDEFINED source; they
+        are not included in an OWL file
+
+        Args:
+            voc_builder: Builder object for Vocabulary
+
+        Returns:
+            None
+        """
+        # Test if datatype_catalogue were already added, if yes skip
+        if 'http://www.w3.org/2002/07/owl#rational' in \
+                voc_builder.vocabulary.datatypes.keys():
+            return
+
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2002/07/owl#rational",
+                     comment="All numbers allowed",
+                     type=DatatypeType.number,
+                     number_decimal_allowed=True))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2002/07/owl#real",
+                     comment="All whole numbers allowed",
+                     type=DatatypeType.number,
+                     number_decimal_allowed=False))
+        voc_builder.add_predefined_datatype(
+            Datatype(
+                iri="http://www.w3.org/1999/02/22-rdf-syntax-ns#PlainLiteral",
+                comment="All strings allowed",
+                type=DatatypeType.string))
+        voc_builder.add_predefined_datatype(
+            Datatype(
+                iri="http://www.w3.org/1999/02/22-rdf-syntax-ns#XMLLiteral",
+                comment="XML Syntax required",
+                type=DatatypeType.string))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2000/01/rdf-schema#Literal",
+                     comment="All strings allowed",
+                     type=DatatypeType.string))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#anyURI",
+                     comment="Needs to start with http://",
+                     type=DatatypeType.string))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#base64Binary",
+                     comment="Base64Binary",
+                     type=DatatypeType.string))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#boolean",
+                     comment="True or False",
+                     type=DatatypeType.enum,
+                     enum_values=["True", "False"]))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#byte",
+                     comment="Byte Number",
+                     type=DatatypeType.number,
+                     number_has_range=True,
+                     number_range_min=-128,
+                     number_range_max=127))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#dateTime",
+                     comment="Date with possible timezone",
+                     type=DatatypeType.date))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#dateTimeStamp",
+                     comment="Date",
+                     type=DatatypeType.date))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#decimal",
+                     comment="All decimal numbers",
+                     type=DatatypeType.number,
+                     number_decimal_allowed=True))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#double",
+                     comment="64 bit decimal",
+                     type=DatatypeType.number,
+                     number_decimal_allowed=True))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#float",
+                     comment="32 bit decimal",
+                     type=DatatypeType.number,
+                     number_decimal_allowed=True))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#hexBinary",
+                     comment="Hexadecimal",
+                     type=DatatypeType.string,
+                     allowed_chars=["0", "1", "2", "3", "4", "5", "6", "7", "8",
+                                    "9", "A", "B", "C", "D", "E", "F"]))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#int",
+                     comment="Signed 32 bit number",
+                     type=DatatypeType.number,
+                     number_has_range=True,
+                     number_range_min=-2147483648,
+                     number_range_max=2147483647))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#integer",
+                     comment="All whole numbers",
+                     type=DatatypeType.number,
+                     number_decimal_allowed=False))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#language",
+                     comment="Language code, e.g: en, en-US, fr, or fr-FR",
+                     type=DatatypeType.string))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#long",
+                     comment="Signed 64 bit integer",
+                     type=DatatypeType.number,
+                     number_has_range=True,
+                     number_range_min=-9223372036854775808,
+                     number_range_max=9223372036854775807,
+                     number_decimal_allowed=False))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#Name",
+                     comment="Name string (dont start with number)",
+                     type=DatatypeType.string))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#NCName",
+                     comment="Name string : forbidden",
+                     type=DatatypeType.string,
+                     forbidden_chars=[":"]))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#negativeInteger",
+                     comment="All negative whole numbers",
+                     type=DatatypeType.number,
+                     number_has_range=True,
+                     number_range_max=-1
+                     ))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#NMTOKEN",
+                     comment="Token string",
+                     type=DatatypeType.string))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#nonNegativeInteger",
+                     comment="All positive whole numbers",
+                     type=DatatypeType.number,
+                     number_has_range=True,
+                     number_range_min=0
+                     ))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#nonPositiveInteger",
+                     comment="All negative whole numbers",
+                     type=DatatypeType.number,
+                     number_has_range=True,
+                     number_range_max=-1
+                     ))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#normalizedString",
+                     comment="normalized String",
+                     type=DatatypeType.string
+                     ))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#positiveInteger",
+                     comment="All positive whole numbers",
+                     type=DatatypeType.number,
+                     number_has_range=True,
+                     number_range_min=0
+                     ))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#short",
+                     comment="signed 16 bit number",
+                     type=DatatypeType.number,
+                     number_has_range=True,
+                     number_range_min=-32768,
+                     number_range_max=32767
+                     ))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#string",
+                     comment="String",
+                     type=DatatypeType.string
+                     ))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#token",
+                     comment="String",
+                     type=DatatypeType.string
+                     ))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#unsignedByte",
+                     comment="unsigned 8 bit number",
+                     type=DatatypeType.number,
+                     number_has_range=True,
+                     number_range_min=0,
+                     number_range_max=255
+                     ))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#unsignedInt",
+                     comment="unsigned 32 bit number",
+                     type=DatatypeType.number,
+                     number_has_range=True,
+                     number_range_min=0,
+                     number_range_max=4294967295
+                     ))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#unsignedLong",
+                     comment="unsigned 64 bit number",
+                     type=DatatypeType.number,
+                     number_has_range=True,
+                     number_range_min=0,
+                     number_range_max=18446744073709551615
+                     ))
+        voc_builder.add_predefined_datatype(
+            Datatype(iri="http://www.w3.org/2001/XMLSchema#unsignedShort",
+                     comment="unsigned 16 bit number",
+                     type=DatatypeType.number,
+                     number_has_range=True,
+                     number_range_min=0,
+                     number_range_max=65535
+                     ))
+
+    @classmethod
+    def _add_owl_thing(cls, voc_builder: VocabularyBuilder):
+        """Add owl_thing class to the vocabulary in the predefined source
+
+        By definition each class is a subclass of owl:thing and owl:thing can be
+        a target of relation but owl thing is never mentioned explicitly in
+        ontology files.
+
+        Args:
+            voc_builder: Builder object for Vocabulary
+        Returns:
+            None
+        """
+        root_class = Class(iri="http://www.w3.org/2002/07/owl#Thing",
+                           comment="Predefined root_class",
+                           label="Thing",
+                           predefined=True)
+
+        # as it is the root object it is only a parent of classes which have no
+        # parents yet
+        for class_ in voc_builder.vocabulary.get_classes():
+            if class_.parent_class_iris == []:
+                class_.parent_class_iris.insert(0, root_class.iri)
+
+        if root_class.iri not in voc_builder.vocabulary.classes:
+            voc_builder.add_class(root_class)
+            root_class.source_ids.add("PREDEFINED")
+
+    @classmethod
+    def _remove_duplicate_parents(cls, voc_builder: VocabularyBuilder):
+        """Prevent that a class_ has the same parent iri multiple times
+
+        Args:
+            voc_builder: Builder object for Vocabulary
+        Returns:
+            None
+        """
+        for class_ in voc_builder.vocabulary.classes.values():
+            class_.parent_class_iris = list(dict.fromkeys(class_.parent_class_iris))
+
+    @classmethod
+    def _ensure_parent_class(cls, voc_builder: VocabularyBuilder):
+        """If a class has a parent class, which was provided by an other
+        ontology. And that ontology is not given, it will have no parents.
+        In that case give him Thing as direct parent
+
+        Args:
+            voc_builder: Builder object for Vocabulary
+        Returns:
+            None
+        """
+        for class_ in voc_builder.vocabulary.classes.values():
+            # Thing is the root of all
+            if not class_.iri == "http://www.w3.org/2002/07/owl#Thing":
+                if len(class_.parent_class_iris) == 0:
+                    class_.parent_class_iris.append(
+                        "http://www.w3.org/2002/07/owl#Thing")
+
+    @classmethod
+    def _apply_vocabulary_settings(cls, voc_builder: VocabularyBuilder):
+        """
+        Make the labels of all entities FIWARE safe, so that they can be used
+        as field keys
+
+        Args:
+            voc_builder: Builder object for Vocabulary
+        Returns:
+            None
+        """
+        vocabulary = voc_builder.vocabulary
+        settings = vocabulary.settings
+
+        def to_pascal_case(string: str) -> str:
+            return stringcase.pascalcase(string).replace("_", "").\
+                replace(" ", "").replace("-", "")
+
+        def to_camel_case(string: str) -> str:
+            camel_string = stringcase.camelcase(string)
+            return camel_string
+
+        def to_snake_case(string: str) -> str:
+            camel_string = to_pascal_case(string)
+            return re.sub(r'(?<!^)(?=[A-Z])', '_', camel_string).lower()
+
+        # replace all whitespaces
+        for entity in vocabulary.get_all_entities():
+            entity.label = entity.label.replace(" ", "_")
+
+        # replace al whitespaces in enum_values
+        for datatype in vocabulary.datatypes.values():
+            new_enums = []
+            for enum in datatype.enum_values:
+                new_enums.append(enum.replace(" ", "_"))
+            datatype.enum_values = new_enums
+
+        if settings.pascal_case_class_labels:
+            for class_ in vocabulary.get_classes():
+                class_.label = to_pascal_case(class_.label)
+
+        if settings.pascal_case_individual_labels:
+            for individual in vocabulary.individuals.values():
+                individual.label = to_pascal_case(individual.label)
+
+        if settings.camel_case_property_labels:
+            props = list(vocabulary.data_properties.values())
+            props.extend(vocabulary.object_properties.values())
+            for prop in props:
+                prop.label = to_camel_case(prop.label)
+
+        if settings.camel_case_datatype_labels:
+            for datatype in vocabulary.datatypes.values():
+                datatype.label = to_camel_case(datatype.label)
+
+        if settings.pascal_case_datatype_enum_labels:
+            for datatype in vocabulary.get_enum_dataytypes().values():
+                datatype.label = to_pascal_case(datatype.label)
+
+    @classmethod
+    def _save_initial_label_summary(cls, vocabulary: Vocabulary):
+        """
+        Save the label_summary existing after parsing, before the user
+        changed labels
+
+        Args:
+            vocabulary: vocabulary of which the label summary should be saved
+
+        Returns:
+            None
+        """
+        from filip.semantics.vocabulary_configurator import \
+            VocabularyConfigurator
+        vocabulary.original_label_summary = \
+            VocabularyConfigurator.get_label_conflicts_in_vocabulary(
+                vocabulary=vocabulary)
+
+    @classmethod
+    def _compute_ancestor_classes(cls, voc_builder: VocabularyBuilder):
+        """Compute all ancestor classes of classes
+
+        Args:
+            voc_builder: Builder object for Vocabulary
+        Returns:
+            None
+        """
+        vocabulary = voc_builder.vocabulary
+        # clear state
+        for class_ in vocabulary.get_classes():
+            class_.ancestor_class_iris = []
+
+        for class_ in vocabulary.get_classes():
+            queue: List[str] = []
+            queue.extend(class_.parent_class_iris)
+
+            while len(queue) > 0:
+                parent = queue.pop()
+
+                if not voc_builder.entity_is_known(parent):
+                    continue
+
+                class_.ancestor_class_iris.append(parent)
+                grand_parents = \
+                    vocabulary.get_class_by_iri(parent).parent_class_iris
+
+                for grand_parent in grand_parents:
+                    if grand_parent not in class_.ancestor_class_iris:
+                        # prevent infinite loop if inheritance circle
+                        queue.append(grand_parent)
+
+    @classmethod
+    def _compute_child_classes(cls, voc_builder: VocabularyBuilder):
+        """Compute all child classes of classes
+
+        Args:
+            voc_builder: Builder object for Vocabulary
+        Returns:
+            None
+        """
+        vocabulary = voc_builder.vocabulary
+        # clear state
+        for class_ in vocabulary.get_classes():
+            class_.child_class_iris = []
+
+        for class_ in vocabulary.get_classes():
+            for parent in class_.ancestor_class_iris:
+
+                if not voc_builder.entity_is_known(parent):
+                    continue
+
+                parent_class = vocabulary.get_class_by_iri(parent)
+                parent_class.child_class_iris.append(class_.iri)
+
+    @classmethod
+    def _combine_relations(cls, voc_builder: VocabularyBuilder):
+        """Compute all CombinedRelations
+
+        Args:
+            voc_builder: Builder object for Vocabulary
+        Returns:
+            None
+        """
+        vocabulary = voc_builder.vocabulary
+        # clear state
+        vocabulary.combined_object_relations.clear()
+        vocabulary.combined_data_relations.clear()
+
+        for class_ in vocabulary.get_classes():
+            class_.combined_object_relation_ids = []
+            class_.combined_data_relation_ids = []
+
+        for class_ in vocabulary.get_classes():
+
+            relations_with_property_iri = {}
+
+            all_relation_ids = []
+            all_relation_ids.extend(class_.get_relation_ids())
+            for ancestor_iri in class_.ancestor_class_iris:
+
+                if not voc_builder.entity_is_known(ancestor_iri):
+                    continue
+                ancestor = vocabulary.get_class_by_iri(ancestor_iri)
+                all_relation_ids.extend(ancestor.get_relation_ids())
+
+            for relation_id in all_relation_ids:
+                relation = vocabulary.get_relation_by_id(id=relation_id)
+                property_iri = relation.property_iri
+
+                if property_iri not in relations_with_property_iri:
+                    relations_with_property_iri[property_iri] = []
+
+                relations_with_property_iri[property_iri].append(relation_id)
+
+            for property_iri, rel_list in relations_with_property_iri.items():
+
+                # These ids should be derived, so that the same combined
+                # relation always ends up with the same id as a class can
+                # only have 1 combined relation of a property these ids are
+                # unique by keeping the ids always the same, we can store
+                # information more efficiently in the database (settings)
+
+                # if a property iri is not known while parsing an ontology
+                # (dependency not yet parsed) the relations with that
+                # property are going to get ignored, maybe a not should be
+                # displayed
+                if vocabulary.is_id_of_type(property_iri, IdType.data_property):
+                    id = "combined-data-relation|{}|{}".format(class_.iri,
+                                                               property_iri)
+                    combi = CombinedDataRelation(id=id,
+                                                 property_iri=property_iri,
+                                                 relation_ids=rel_list,
+                                                 class_iri=class_.iri)
+                    voc_builder.add_combined_data_relation_for_class(
+                        class_iri=class_.iri, cdata=combi)
+                elif vocabulary.is_id_of_type(property_iri,
+                                              IdType.object_property):
+                    id = "combined-object-relation|{}|{}".format(
+                        class_.iri, property_iri)
+                    combi = CombinedObjectRelation(id=id,
+                                                   property_iri=property_iri,
+                                                   relation_ids=rel_list,
+                                                   class_iri=class_.iri)
+                    voc_builder.add_combined_object_relation_for_class(
+                        class_iri=class_.iri, crel=combi)
+                else:
+                    pass
+
+    @classmethod
+    def _sort_relations(cls, voc_builder: VocabularyBuilder):
+        """sort relations alphabetically according to their labels
+
+        Args:
+            voc_builder: Builder object for Vocabulary
+        Returns:
+            None
+        """
+        vocabulary = voc_builder.vocabulary
+
+        for class_ in vocabulary.get_classes():
+            cors = class_.get_combined_object_relations(vocabulary)
+            class_.combined_object_relation_ids = \
+                cls._sort_list_of_combined_relations(cors, vocabulary)
+
+            cdrs = class_.get_combined_data_relations(vocabulary)
+            class_.combined_data_relation_ids = \
+                cls._sort_list_of_combined_relations(cdrs, vocabulary)
+
+    @classmethod
+    def _sort_list_of_combined_relations(
+            cls,
+            combined_relations: List[CombinedRelation],
+            vocabulary: Vocabulary) -> List[str]:
+        """sort given CombinedRelations according to their labels
+
+        Args:
+            vocabulary (Vocabulary)
+            combined_relations (List[CombinedRelation]): CRs to sort
+        Returns:
+            List[str], list of cr_id, sorted according to their label
+        """
+
+        property_dic = {}
+
+        for cor in combined_relations:
+            property_iri = cor.property_iri
+            label = cor.get_property_label(vocabulary=vocabulary)
+            property_dic[label + property_iri] = cor.id
+            # combine label with iri to prevent an error due to two identical
+            # labels
+        sorted_property_dic = sorted(property_dic.items())
+
+        sorted_cor_ids = []
+        for pair in sorted_property_dic:
+            sorted_cor_ids.append(pair[1])
+        return sorted_cor_ids
+
+    @classmethod
+    def _mirror_object_property_inverses(cls, voc_builder: VocabularyBuilder):
+        """
+        inverses could only be given for 1 obj_prop of the pair and needs to
+        be derived for the other also we could have the inverse inside an other
+        import (there for done in postprocessing)
+
+        Args:
+            voc_builder: Builder object for Vocabulary
+
+        Returns:
+            None
+        """
+        # the state is not cleared, instead add_inverse_property_iri() makes
+        # sure that there will be no duplicates as it is a set
+        vocabulary = voc_builder.vocabulary
+
+        for obj_prop_iri in vocabulary.object_properties:
+            obj_prop = vocabulary.get_object_property(obj_prop_iri)
+
+            for inverse_iri in obj_prop.inverse_property_iris:
+                inverse_prop = vocabulary.get_object_property(inverse_iri)
+                inverse_prop.add_inverse_property_iri(obj_prop_iri)
+
+    @classmethod
+    def transfer_settings(cls, new_vocabulary: Vocabulary,
+                          old_vocabulary: Vocabulary):
+        """
+        Transfer all the user made settings (labels, ..)
+        from an old vocabulary to a new vocabulary
+
+        Args:
+            new_vocabulary (Vocabulary): Vocabulary to which the settings should
+                be transferred
+            old_vocabulary (Vocabulary): Vocabulary of which the settings should
+                be transferred
+
+        Returns:
+            None
+        """
+
+        # label settings
+        for entity in old_vocabulary.get_all_entities():
+            new_entity = new_vocabulary.get_entity_by_iri(entity.iri)
+            if new_entity is not None:
+                new_entity.user_set_label = entity.user_set_label
+
+        # device settings
+        for iri, data_property in old_vocabulary.data_properties.items():
+            if iri in new_vocabulary.data_properties:
+                new_data_property = new_vocabulary.data_properties[iri]
+                new_data_property.field_type = data_property.field_type
+
```

### Comparing `filip-0.3.0/filip/semantics/ontology_parser/rdfparser.py` & `filip-0.4.0/filip/semantics/ontology_parser/rdfparser.py`

 * *Ordering differences only*

 * *Files 20% similar despite different names*

```diff
@@ -1,824 +1,824 @@
-"""Module contains the RDFParser that can create a Vocabulary object out of a
-given ontology"""
-
-import uuid
-from enum import Enum
-from typing import List, Tuple
-
-import rdflib
-
-from filip.models.base import LogLevel
-from filip.semantics.ontology_parser.vocabulary_builder import VocabularyBuilder
-from filip.semantics.vocabulary import Source, IdType, \
-    Vocabulary,RestrictionType, ObjectProperty, DataProperty, Relation, \
-    TargetStatement, StatementType, DatatypeType, Datatype, Class, Individual
-
-
-specifier_base_iris = ["http://www.w3.org/2002/07/owl",
-                       "http://www.w3.org/1999/02/22-rdf-syntax-ns",
-                       "http://www.w3.org/XML/1998/namespace",
-                       "http://www.w3.org/2001/XMLSchema",
-                       "http://www.w3.org/2000/01/rdf-schema"]
-"""
-Defines a set of base iris, that describe elements that belong to the 
-description language not the ontology itself
-"""
-
-
-class Tags(str, Enum):
-    """
-    Collection of tags used as structures in ontologies, that were used more
-    than once in the rdfparser code
-    """
-    rdf_type = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#type',
-    owl_intersection = 'http://www.w3.org/2002/07/owl#intersectionOf',
-    owl_union = 'http://www.w3.org/2002/07/owl#unionOf',
-    owl_one_of = 'http://www.w3.org/2002/07/owl#oneOf',
-    owl_individual = 'http://www.w3.org/2002/07/owl#NamedIndividual',
-    owl_on_class = 'http://www.w3.org/2002/07/owl#onClass',
-    owl_on_data_range = 'http://www.w3.org/2002/07/owl#onDataRange'
-
-
-def get_iri_from_uriref(uriref: rdflib.URIRef) -> str:
-    """Give an Uriref object, returns an iri
-
-    Args:
-        uriref: Object describing the iri
-
-    Returns:
-        str
-    """
-    return str(uriref)
-
-
-def get_base_out_of_iri(iri: str) -> str:
-    """Give an iri, returns an the ontology base name
-
-       Args:
-           iri
-
-       Returns:
-           str
-       """
-    if "#" in iri:
-        index = iri.find("#")
-        return iri[:index]
-    else:
-        # for example if uri looks like:
-        # http://webprotege.stanford.edu/RDwpQ8vbi7HaApq8VoqJUXH
-        index = iri.rfind("/")
-        return iri[:index]
-
-
-class RdfParser:
-    """
-    Class that parses a given source into a vocabulary.
-    """
-    def __init__(self):
-        self.current_source = None
-        """Current source which is parsed, used for Log entries"""
-        self.current_class_iri = None
-        """Iri of class which is currently parsed, used for Log entries"""
-
-    def _add_logging_information(self, level: LogLevel,
-                                 entity_type: IdType, entity_iri: str,
-                                 msg: str):
-        """Add an entry to the parsing log
-
-        Args:
-            level (LogLevel): severe, warning or info
-            entity_type (IdType)
-            entity_iri (str)
-            msg (str): Message to inform the user about the occurred issue
-
-        Returns:
-            None
-        """
-        if self.current_source is not None:
-            self.current_source.add_parsing_log_entry(level, entity_type,
-                                                      entity_iri, msg)
-
-    def parse_source_into_vocabulary(self, source: Source,
-                                     vocabulary: Vocabulary) -> bool:
-        """ Parse a Source into the given vocabulary
-        Args:
-            source (Source)
-            vocabulary (Vocabulary)
-
-        Returns:
-            bool, True if success, False if Error occurred, as an invalid File
-        """
-
-        # if this is the predefined source don't parse it, just pretend it
-        # was successful
-        if source.predefined:
-            return True
-
-        voc_builder = VocabularyBuilder(vocabulary=vocabulary)
-        g = rdflib.Graph()
-
-        # format = rdflib.util.guess_format(source.source_path)
-        voc_builder.add_source(source)
-        voc_builder.set_current_source(source.id)
-
-        g.parse(data=source.content, format="turtle")
-
-        ontology_nodes = list(g.subjects(
-            object=rdflib.term.URIRef("http://www.w3.org/2002/07/owl#Ontology"),
-            predicate=rdflib.term.URIRef(Tags.rdf_type.value)))
-
-        # a source may have no ontology iri defined
-        # if wanted on this place more info about the ontology can be extracted
-        if len(ontology_nodes) > 0:
-            source.ontology_iri = get_iri_from_uriref(ontology_nodes[0])
-
-        self.current_source = source
-
-        self._parse_to_vocabulary(g, voc_builder)
-
-        return True
-
-    def _is_object_defined_by_other_source(self, a: rdflib.term,
-                                           graph: rdflib.Graph) -> bool:
-        """ Test if the term is defined outside the current source
-
-        Args:
-            a (rdflib.term): Term to check
-            graph (rdflib.graph): graph extracted from source
-
-        Returns:
-            bool
-        """
-
-        # if an object is defined by an other source it carries the predicate
-        # ("isDefinedBy"). Then don't parse the object
-        defined_tags = list(graph.objects(
-            subject=a, predicate=rdflib.term.URIRef(
-                "http://www.w3.org/2000/01/rdf-schema#isDefinedBy")))
-        return len(defined_tags) > 0
-
-    def _parse_to_vocabulary(self, graph: rdflib.Graph,
-                             voc_builder: VocabularyBuilder):
-        """Parse an graph that was extracted from a TTL file into the vocabulary
-
-        Args:
-            graph (rdflib.Graph)
-            voc_builder (VocabularyBuilder): Builder object to manipulate a
-                vocabulary
-
-        Returns:
-            None
-        """
-
-        # OWLClasses
-        for a in graph.subjects(
-                object=rdflib.term.URIRef(
-                    "http://www.w3.org/2002/07/owl#Class"),
-                predicate=rdflib.term.URIRef(Tags.rdf_type.value)):
-
-            if isinstance(a, rdflib.term.BNode):
-                pass
-                # owl:Class can also occure in complex target statements of
-                # relations as BNode, ignore it here
-            else:
-
-                # defined in other source -> ignore
-                if self._is_object_defined_by_other_source(a, graph=graph):
-                    continue
-
-                iri, label, comment = self._extract_annotations(graph, a)
-                c = Class(iri=iri, label=label, comment=comment)
-                voc_builder.add_class(class_=c)
-
-        # Class properties
-        found_class_iris = set()
-        for class_node in graph.subjects(
-                predicate=rdflib.term.URIRef(
-                    "http://www.w3.org/2000/01/rdf-schema#subClassOf")):
-
-            class_iri = get_iri_from_uriref(class_node)
-            found_class_iris.add(class_iri)
-
-        for class_iri in found_class_iris:
-            # parent class / relation parsing
-            for sub in graph.objects(
-                    subject=rdflib.term.URIRef(class_iri),
-                    predicate=rdflib.term.URIRef
-                        ('http://www.w3.org/2000/01/rdf-schema#subClassOf')):
-                self.current_class_iri = class_iri  # used only for logging
-                self._parse_subclass_term(graph=graph,
-                                          voc_builder=voc_builder,
-                                          node=sub,
-                                          class_iri=class_iri)
-
-        # OWlObjectProperties
-        for a in graph.subjects(
-                object=rdflib.term.URIRef(
-                    "http://www.w3.org/2002/07/owl#ObjectProperty"),
-                predicate=rdflib.term.URIRef(Tags.rdf_type.value)):
-
-            if isinstance(a, rdflib.term.BNode):
-                self._add_logging_information(LogLevel.WARNING,
-                                              IdType.object_property,
-                                              "unknown",
-                                              "Found unparseable statement")
-
-            else:
-                # defined in other source -> ignore
-                if self._is_object_defined_by_other_source(a, graph):
-                    continue
-
-                iri, label, comment = self._extract_annotations(graph, a)
-
-                obj_prop = ObjectProperty(iri=iri, label=label, comment=comment)
-                voc_builder.add_object_property(obj_prop)
-                # extract inverse properties, it can be multiple but only
-                # URIRefs allowed no union/intersection
-                for inverse_iri_node in graph.objects(subject=a,
-                        predicate=rdflib.term.URIRef(
-                        'http://www.w3.org/2002/07/owl#inverseOf')):
-                    if isinstance(inverse_iri_node, rdflib.term.BNode):
-                        self._add_logging_information(
-                            LogLevel.CRITICAL, IdType.object_property, iri,
-                            "Complex inverseProperty statements aren't allowed")
-                    else:
-                        inverse_iri = get_iri_from_uriref(inverse_iri_node)
-                        obj_prop.add_inverse_property_iri(inverse_iri)
-
-        # OWlDataProperties
-        for a in graph.subjects(
-                object=rdflib.term.URIRef(
-                    "http://www.w3.org/2002/07/owl#DatatypeProperty"),
-                predicate=rdflib.term.URIRef(Tags.rdf_type.value)):
-
-            if isinstance(a, rdflib.term.BNode):
-                self._add_logging_information(LogLevel.WARNING,
-                                              IdType.data_property, "unknown",
-                                             "Found unparseable statement")
-
-            else:
-                # defined in other source -> ignore
-                if self._is_object_defined_by_other_source(a, graph):
-                    continue
-
-                iri, label, comment = self._extract_annotations(graph, a)
-
-                data_prop = DataProperty(iri=iri, label=label, comment=comment)
-                voc_builder.add_data_property(data_prop)
-
-        # OWLDataTypes
-        # only the custom created datatype_catalogue are listed in the file,
-        # the predefined are automatically added at the start
-        # of post processing
-        for a in graph.subjects(
-                object=rdflib.term.URIRef(
-                    "http://www.w3.org/2000/01/rdf-schema#Datatype"),
-                predicate=rdflib.term.URIRef(Tags.rdf_type.value)):
-
-            if isinstance(a, rdflib.term.BNode):
-                # self._add_logging_information(LogLevel.WARNING,
-                #                              IdType.datatype, "unknown",
-                #                              "Found unparseable statement")
-                pass
-                #e.g: :
-                # customDataType4 rdf:type rdfs:Datatype ;
-                # owl:equivalentClass [ rdf:type rdfs:Datatype ;....
-                # the second Datatype triggers this if condition,
-                # but we can ignore this statement
-
-            else:
-                # defined in other source -> ignore
-                if self._is_object_defined_by_other_source(a, graph):
-                    continue
-
-                iri, label, comment = self._extract_annotations(graph, a)
-
-                datatype = Datatype(iri=iri, label=label, comment=comment)
-                voc_builder.add_datatype(datatype=datatype)
-
-                # a datatype can be empty -> use string
-                # a datatype can have multiple equivalent classes
-                # (predefined types) -> ignore for now
-                # a datatype can contain an enum of possible values ->
-                # most interesting
-                # under the predicate owl:equivalentClass is than a
-                # list(first, rest, nil) under the pred.
-                # oneOf with the values
-
-                enum_values = []
-                for equivalent_class in graph.objects(
-                        subject=a,
-                        predicate=rdflib.term.URIRef(
-                            "http://www.w3.org/2002/07/owl#equivalentClass")):
-
-                    if isinstance(equivalent_class, rdflib.term.URIRef):
-                        # points to an other defined datatype, ignore
-                        pass
-                    else:
-                        # is a bNode and points to owl:oneOf
-                        enum_literals = self.\
-                            _extract_objects_out_of_single_combination(
-                                graph, equivalent_class, accept_and=False,
-                                accept_or=False, accept_one_of=True)
-                        for literal in enum_literals:
-                            enum_values.append(str(literal))
-                datatype.enum_values = enum_values
-                if len(enum_values) > 0:
-                    datatype.type = DatatypeType.enum
-                else:
-                    datatype.type = DatatypeType.string
-
-        # OWLIndividuals
-
-        for a in graph.subjects(
-                object=rdflib.term.URIRef(Tags.owl_individual.value),
-                predicate=rdflib.term.URIRef(Tags.rdf_type.value)):
-
-            if isinstance(a, rdflib.term.BNode):
-                self._add_logging_information(LogLevel.WARNING,
-                                              IdType.individual, "unknown",
-                                             "Found unparseable statement")
-
-            else:
-                # defined in other source -> ignore
-                if self._is_object_defined_by_other_source(a, graph):
-                    continue
-
-                iri, label, comment = self._extract_annotations(graph, a)
-                objects = graph.objects(subject=a,
-                                        predicate=
-                                        rdflib.term.URIRef(Tags.rdf_type.value))
-                # superclasses = types
-                types = []
-                for object in objects:
-                    if not object == \
-                           rdflib.term.URIRef(Tags.owl_individual.value):
-                        types.extend(self.
-                            _extract_objects_out_of_layered_combination(
-                                        graph, object, True, False))
-
-                individual = Individual(iri=iri, label=label, comment=comment)
-                for type in types:
-                    individual.parent_class_iris.append(
-                        get_iri_from_uriref(type))
-                voc_builder.add_individual(individual=individual)
-
-        # As seen for example in the bricks ontology an individual can be
-        # declared with :individual1 rdf:type :Class1
-        # this type of declaration is hard to completly detect
-        # we need to see that the object is a class iri and not a specifier iri.
-        # as we may not have loaded all dependencies we can not simply look it
-        # up in vocabulary
-        # -> getbase uri of statement and filter all known specifier uris
-        for sub in graph.subjects(
-                predicate=rdflib.term.URIRef(Tags.rdf_type.value)):
-            for obj in graph.objects(subject=sub,
-                                     predicate=
-                                     rdflib.term.URIRef(Tags.rdf_type.value)):
-
-                if isinstance(obj, rdflib.term.BNode):
-                    continue
-                obj_iri = get_iri_from_uriref(obj)
-
-                obj_base_iri = get_base_out_of_iri(iri=obj_iri)
-                if obj_base_iri not in specifier_base_iris:
-                    iri, label, comment = \
-                        self._extract_annotations(graph, sub)
-                    if not voc_builder.entity_is_known(iri):
-                        iri, label, comment = \
-                            self._extract_annotations(graph, sub)
-                        individual = Individual(iri=iri,
-                                                label=label,
-                                                comment=comment)
-                        individual.parent_class_iris.append(obj_iri)
-                        voc_builder.add_individual(individual)
-
-    def _extract_annotations(self, graph: rdflib.Graph,
-                             node: rdflib.term.URIRef) -> Tuple[str, str, str]:
-        """ Extract out of a node term the owl annotations (iri, label, comment)
-
-        Args:
-            graph (rdflib.graph): Graph describing ontology
-            node (rdflib.term.URIRef): Entity node
-
-        Returns:
-            [str,str,str]: [iri, label, comment]
-        """
-        iri = str(node)
-        label = graph.label(node).title()
-        comment = graph.comment(node).title()
-
-        return iri, label, comment
-
-    def _parse_subclass_term(self, graph: rdflib.Graph,
-                             voc_builder: VocabularyBuilder,
-                             node: rdflib.term, class_iri: str):
-        """Parse a subclass term of the given node and class_iri
-
-        Args:
-            graph (rdflib.graph): Graph describing ontology
-            vocabulary (Vocabulary): Vocabualry to parse into
-            node (rdflib.term)
-            class_iri (str)
-
-        Returns:
-            None
-        """
-
-        # class could have been only defined in other source, than no class
-        # is defined, but as we have found a relation for a class, the class
-        # needs to exist
-        if class_iri not in voc_builder.vocabulary.classes:
-            voc_builder.add_class(class_=Class(iri=class_iri))
-
-        # node can be 1 of 3 things:
-        #   - a parentclass statment -> UriRef
-        #   - a relation statment -> BNode
-        #   - an intersection of parentclasses ,
-        #   relations and intersections -> BNode
-        if isinstance(node, rdflib.term.BNode):
-            # sub has no IRI and is therefore a relation
-
-            # extract the subpredicates and subobjects as statments
-            # if node is a relation:
-            #      in total there should be 3-4 statments:
-            #      rdf:type pointing to owl:Restriction
-            #      owl:onProperty pointing to a data or object property
-            #      1-2 staments which values are exepted, this can point to an
-            #      URIRef or BNode
-
-            # if node is a intersection:
-            #      it has the predicate owl:intersectionOf
-            #      and a set of objects
-
-            predicates = []
-            objects = []
-            for p in graph.predicates(subject=node):
-                predicates.append(p)
-            for o in graph.objects(subject=node):
-                objects.append(o)
-
-            # Combination of statements
-            if rdflib.term.URIRef(Tags.owl_intersection.value) in predicates:
-                objects = self._extract_objects_out_of_single_combination(
-                    graph, node, True, False)
-                for object in objects:
-                    self._parse_subclass_term(graph=graph,
-                                              voc_builder=voc_builder,
-                                              node=object, class_iri=class_iri)
-
-            elif rdflib.term.URIRef(Tags.owl_union.value) in predicates:
-                self._add_logging_information(
-                    LogLevel.CRITICAL, IdType.class_, class_iri,
-                    "Relation statements combined with or")
-
-            elif rdflib.term.URIRef(Tags.owl_one_of.value) in predicates:
-                self._add_logging_information(
-                    LogLevel.CRITICAL, IdType.class_, class_iri,
-                    "Relation statements combined with oneOf")
-
-            # Relation statement
-            else:
-
-                additional_statements = {}
-                rdf_type = ""
-                owl_on_property = ""
-
-                for i in range(len(predicates)):
-                    if predicates[i] == rdflib.term.URIRef(Tags.rdf_type.value):
-                        rdf_type = get_iri_from_uriref(objects[i])
-                    elif predicates[i] == rdflib.term.URIRef(
-                            "http://www.w3.org/2002/07/owl#onProperty"):
-                        owl_on_property = get_iri_from_uriref(objects[i])
-                    else:
-                        additional_statements[
-                            get_iri_from_uriref(predicates[i])] = objects[i]
-
-                relation_is_ok = True
-                if not rdf_type == "http://www.w3.org/2002/07/owl#Restriction":
-                    self._add_logging_information(
-                        LogLevel.CRITICAL, IdType.class_, class_iri,
-                        "Class has an unknown subClass statement")
-                    relation_is_ok = False
-
-                if owl_on_property == "":
-                    self._add_logging_information(
-                        LogLevel.CRITICAL, IdType.class_, class_iri,
-                        "Class has a relation without a property")
-                    relation_is_ok = False
-
-                # object or data relation?
-                if relation_is_ok:
-                    relation = None
-                    id = uuid.uuid4().hex
-                    # this id can and should be random. a class_iri can have a
-                    # property_iri multiple times, to assign always the same id
-                    # for the same relation is not worth the trouble
-
-                    relation = Relation(property_iri=owl_on_property, id=id)
-                    voc_builder.add_relation_for_class(class_iri, relation)
-
-                    # go through the additional statement to figure out the
-                    # targetIRI and the restrictionType/cardinality
-                    self._parse_relation_type(graph, relation,
-                                              additional_statements)
-
-        # parent-class statement or empty list element
-        else:
-            # owlThing is the root object, but it is not declared as a class
-            # in the file to prevent None pointer when looking up parents,
-            # a class that has a parent owlThing simply has no parents
-            if not get_iri_from_uriref(node) == \
-                   "http://www.w3.org/1999/02/22-rdf-syntax-ns#nil":
-                # ignore empty lists
-                if not get_iri_from_uriref(node) == \
-                       "http://www.w3.org/2002/07/owl#Thing":
-                    voc_builder.vocabulary.\
-                        get_class_by_iri(class_iri).parent_class_iris.\
-                        append(get_iri_from_uriref(node))
-
-    def _parse_relation_type(self, graph: rdflib.Graph,
-                             relation: Relation, statements: {}):
-        """
-        Parse the relation type and depending on the result the
-        cardinality or value of relation
-        
-        Args:
-            graph: underlying ontology graph
-            relation: Relation object into which the information are saved
-            statements: Ontology statements concerning the relation
-        
-        Returns:
-            None
-        """
-        treated_statements = []
-        for statement in statements:
-            if statement == "http://www.w3.org/2002/07/owl#someValuesFrom":
-                relation.restriction_type = RestrictionType.some
-                self._parse_relation_values(graph, relation,
-                                            statements[statement])
-            elif statement == "http://www.w3.org/2002/07/owl#allValuesFrom":
-                relation.restriction_type = RestrictionType.only
-                self._parse_relation_values(graph, relation,
-                                            statements[statement])
-            elif statement == "http://www.w3.org/2002/07/owl#hasValue":
-                relation.restriction_type = RestrictionType.value
-                # has Value can only point to a single value
-                self._parse_has_value(graph, relation,
-                                      statements[statement])
-            elif statement == "http://www.w3.org/2002/07/owl#maxCardinality":
-                relation.restriction_type = RestrictionType.max
-                self._parse_cardinality(graph, relation, statement,
-                                        statements, treated_statements)
-            elif statement == "http://www.w3.org/2002/07/owl#minCardinality":
-                relation.restriction_type = RestrictionType.min
-                self._parse_cardinality(graph, relation, statement,
-                                        statements, treated_statements)
-            elif statement == "http://www.w3.org/2002/07/owl#cardinality":
-                relation.restriction_type = RestrictionType.exactly
-                self._parse_cardinality(graph,  relation, statement,
-                                        statements, treated_statements)
-            elif statement == \
-                    "http://www.w3.org/2002/07/owl#maxQualifiedCardinality":
-                relation.restriction_type = RestrictionType.max
-                self._parse_cardinality(graph, relation, statement,
-                                        statements, treated_statements)
-            elif statement == \
-                    "http://www.w3.org/2002/07/owl#minQualifiedCardinality":
-                relation.restriction_type = RestrictionType.min
-                self._parse_cardinality(graph, relation, statement,
-                                        statements, treated_statements)
-            elif statement == \
-                    "http://www.w3.org/2002/07/owl#qualifiedCardinality":
-                relation.restriction_type = RestrictionType.exactly
-                self._parse_cardinality(graph, relation, statement,
-                                        statements, treated_statements)
-
-            treated_statements.append(statement)
-
-        for statement in statements:
-            if statement not in treated_statements:
-                self._add_logging_information(
-                  LogLevel.CRITICAL, IdType.class_, self.current_class_iri,
-                  "Relation with property {} has an untreated restriction "
-                  "{}".format(relation.property_iri, statement))
-
-    def _parse_cardinality(self, graph: rdflib.Graph,
-                           relation: Relation, statement, statements,
-                           treated_statements):
-        """Parse the cardinality of a relation
-
-        Args:
-            graph: underlying ontology graph
-            relation: Relation object into which the information are saved
-            statement: The statement that is actively treated
-            statements: Ontology statements concerning the relation
-            treated_statements: Statements that were already treated
-
-        Returns:
-            None
-        """
-        if Tags.owl_on_class.value in statements:
-            relation.restriction_cardinality = str(statements[statement])
-            target = statements[Tags.owl_on_class.value]
-            self._parse_relation_values(graph, relation, target)
-            treated_statements.append(Tags.owl_on_class.value)
-        elif Tags.owl_on_data_range.value in statements:
-            relation.restriction_cardinality = str(statements[statement])
-            target = statements[Tags.owl_on_data_range.value]
-            self._parse_relation_values(graph, relation, target)
-            treated_statements.append(Tags.owl_on_data_range.value)
-        else:
-            # has From:
-            # in File: owl:maxCardinality "1"^^xsd:nonNegativeInteger
-            # e.g.: {'http://www.w3.org/2002/07/owl#maxCardinality':
-            #        rdflib.term.Literal('1', datatype=
-            #        rdflib.term.URIRef('
-            #        http://www.w3.org/2001/XMLSchema#nonNegativeInteger'))}
-
-            # in this case the file does not state a datarange that is allowed.
-            # Therefore the target gets set to the universal string
-
-            relation.restriction_cardinality = statements[statement].value
-            datatype = "http://www.w3.org/2001/XMLSchema#string"
-            target_statement = TargetStatement(type=StatementType.LEAF,
-                                               target_iri=datatype)
-            relation.target_statement = target_statement
-
-    def _parse_has_value(self, graph: rdflib.Graph, relation: Relation,
-                         node: rdflib.term):
-        """Parse the value of a relation
-
-        Args:
-           graph: underlying ontology graph
-           relation: Relation object into which the information are saved
-           node: (complex) Graph node containing the value
-        
-        Returns:
-           None
-        """
-        self._parse_relation_values(graph, relation, node)
-        # for hasValue only a target-statement that is a leaf is allowed
-        if not relation.target_statement.type == StatementType.LEAF:
-            self._add_logging_information(
-                LogLevel.CRITICAL,
-                IdType.class_,
-                self.current_class_iri,
-                f"In hasValue relation with property {relation.property_iri} "
-                f"target is a complex expression")
-
-    def _parse_relation_values(self, graph: rdflib.Graph,
-                               relation: Relation, node: rdflib.term):
-        """
-        Parse the value of a relation out of a node that can be complex;
-        consisting out of a combination of multiple other nodes
-
-        Args:
-           graph: underlying ontology graph
-           relation: Relation object into which the information are saved
-           node: (complex) Graph node containing the value
-
-        Returns:
-           None
-        """
-        target_statement = TargetStatement()
-        relation.target_statement = target_statement
-
-        queue = [(node, target_statement)]
-        while not len(queue) == 0:
-            current_term, current_statement = queue.pop(0)
-            if isinstance(current_term, rdflib.URIRef):
-                target_iri = get_iri_from_uriref(current_term)
-
-                current_statement.set_target(target_iri=target_iri)
-            else:
-                if rdflib.term.URIRef(Tags.owl_intersection.value) in \
-                        graph.predicates(subject=current_term):
-
-                    current_statement.type = StatementType.AND
-                elif rdflib.term.URIRef(Tags.owl_union.value) in \
-                        graph.predicates(subject=current_term):
-
-                    current_statement.type = StatementType.OR
-                else:
-                    current_statement.set_target(
-                        target_iri="Target statement has no iri",
-                        target_data_value=str(current_term))
-
-                    continue
-
-                child_nodes = self._extract_objects_out_of_single_combination(
-                    graph, current_term, True, True)
-                for child_node in child_nodes:
-                    new_statement = TargetStatement()
-                    current_statement.target_statements.append(new_statement)
-                    queue.append((child_node, new_statement))
-
-    # an intersection/union is a basic list, it consists out of a chain of
-    # bnode, where each bnode has the "first"and "rest" predicate, first
-    # contains our object, rest is a pointer to the next part of the chain.
-    # the list is over if rest points to "NIL"
-    # this methode extracts all objects of a single layered intersection,
-    # if the intersection contains further intersections these are contained in
-    # the result list as BNode
-    def _extract_objects_out_of_single_combination(self, graph: rdflib.Graph,
-                                                   node: rdflib.term.BNode,
-                                                   accept_and: bool,
-                                                   accept_or: bool,
-                                                   accept_one_of: bool = False):
-        """
-        An intersection/union is a basic list, it consits out of a chain of
-        bnode,where each bnode has the "first"and "rest" predicate,
-        first contains our object, rest is a pointer to the next part of the
-        chain. The list is over if rest points to "NIL"
-        This methode extracts all objects of a single layered intersection,
-        if the intersection contains further intersections these are contained
-        in the result list as BNode
-
-        Args:
-            graph: underlying ontology graph
-            node: (complex) Graph node containing the value
-            accept_or (bool): true, if combinations with "or" are allowed to be
-                parsed
-            accept_and (bool): true, if combinations with "and" are allowed
-                to be parsed
-            accept_one_of (bool): true, if ne_of statements are allowed
-                to be parsed
-
-        Returns:
-           None
-        """
-        predicates = list(graph.predicates(subject=node))
-
-        # the passed startnode needs to contain an intersection or a union
-        # both at the same time should not be possible
-        start_node = None
-        if rdflib.term.URIRef(Tags.owl_intersection.value) \
-                in predicates:
-            if accept_and:
-                start_node = next(graph.objects(
-                    subject=node,
-                    predicate=rdflib.term.URIRef(Tags.owl_intersection.value)))
-        elif rdflib.term.URIRef(Tags.owl_union.value) \
-                in predicates:
-            if accept_or:
-                start_node = next(graph.objects(
-                    subject=node,
-                    predicate=rdflib.term.URIRef(Tags.owl_union.value)))
-        elif rdflib.term.URIRef(Tags.owl_one_of.value) \
-                in predicates:
-            if accept_one_of:
-                start_node = next(graph.objects(
-                    subject=node,
-                    predicate=rdflib.term.URIRef(Tags.owl_one_of.value)))
-        else:
-            self._add_logging_information(
-                LogLevel.CRITICAL, IdType.class_, self.current_class_iri,
-                f"Intern Error - invalid {node} passed to list extraction")
-
-        result = []
-        rest = start_node
-        if start_node is None:
-            return []
-
-        while not rest == rdflib.term.URIRef(
-                'http://www.w3.org/1999/02/22-rdf-syntax-ns#nil'):
-
-            first = next(graph.objects(predicate=rdflib.term.URIRef(
-                'http://www.w3.org/1999/02/22-rdf-syntax-ns#first'),
-                subject=rest))
-            result.append(first)
-            rest = next(graph.objects(predicate=rdflib.term.URIRef(
-                        'http://www.w3.org/1999/02/22-rdf-syntax-ns#rest'),
-                                      subject=rest))
-
-        return result
-
-    def _extract_objects_out_of_layered_combination(
-            self, graph: rdflib.Graph, node: rdflib.term.BNode,
-            accept_and: bool, accept_or: bool) -> List[rdflib.term.URIRef]:
-        """Extract all nodes out of a complex combination
-
-        Args:
-            graph: underlying ontology graph
-            node: (complex) Graph node containing the complex combination
-            accept_or (bool): true, if combinations with "or" are allowed to be
-                parsed
-            accept_and (bool): true, if combinations with "and" are allowed
-                to be parsed
-
-        Returns:
-           List[rdflib.term.URIRef], list of terms out of combination
-        """
-        result = []
-        queue = [node]
-
-        while len(queue) > 0:
-            node = queue.pop()
-            if isinstance(node, rdflib.term.URIRef):
-                result.append(node)
-            else:
-                queue.extend(self._extract_objects_out_of_single_combination
-                             (graph, node, accept_and, accept_or))
-        return result
-
+"""Module contains the RDFParser that can create a Vocabulary object out of a
+given ontology"""
+
+import uuid
+from enum import Enum
+from typing import List, Tuple
+
+import rdflib
+
+from filip.models.base import LogLevel
+from filip.semantics.ontology_parser.vocabulary_builder import VocabularyBuilder
+from filip.semantics.vocabulary import Source, IdType, \
+    Vocabulary,RestrictionType, ObjectProperty, DataProperty, Relation, \
+    TargetStatement, StatementType, DatatypeType, Datatype, Class, Individual
+
+
+specifier_base_iris = ["http://www.w3.org/2002/07/owl",
+                       "http://www.w3.org/1999/02/22-rdf-syntax-ns",
+                       "http://www.w3.org/XML/1998/namespace",
+                       "http://www.w3.org/2001/XMLSchema",
+                       "http://www.w3.org/2000/01/rdf-schema"]
+"""
+Defines a set of base iris, that describe elements that belong to the 
+description language not the ontology itself
+"""
+
+
+class Tags(str, Enum):
+    """
+    Collection of tags used as structures in ontologies, that were used more
+    than once in the rdfparser code
+    """
+    rdf_type = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#type',
+    owl_intersection = 'http://www.w3.org/2002/07/owl#intersectionOf',
+    owl_union = 'http://www.w3.org/2002/07/owl#unionOf',
+    owl_one_of = 'http://www.w3.org/2002/07/owl#oneOf',
+    owl_individual = 'http://www.w3.org/2002/07/owl#NamedIndividual',
+    owl_on_class = 'http://www.w3.org/2002/07/owl#onClass',
+    owl_on_data_range = 'http://www.w3.org/2002/07/owl#onDataRange'
+
+
+def get_iri_from_uriref(uriref: rdflib.URIRef) -> str:
+    """Give an Uriref object, returns an iri
+
+    Args:
+        uriref: Object describing the iri
+
+    Returns:
+        str
+    """
+    return str(uriref)
+
+
+def get_base_out_of_iri(iri: str) -> str:
+    """Give an iri, returns an the ontology base name
+
+       Args:
+           iri
+
+       Returns:
+           str
+       """
+    if "#" in iri:
+        index = iri.find("#")
+        return iri[:index]
+    else:
+        # for example if uri looks like:
+        # http://webprotege.stanford.edu/RDwpQ8vbi7HaApq8VoqJUXH
+        index = iri.rfind("/")
+        return iri[:index]
+
+
+class RdfParser:
+    """
+    Class that parses a given source into a vocabulary.
+    """
+    def __init__(self):
+        self.current_source = None
+        """Current source which is parsed, used for Log entries"""
+        self.current_class_iri = None
+        """Iri of class which is currently parsed, used for Log entries"""
+
+    def _add_logging_information(self, level: LogLevel,
+                                 entity_type: IdType, entity_iri: str,
+                                 msg: str):
+        """Add an entry to the parsing log
+
+        Args:
+            level (LogLevel): severe, warning or info
+            entity_type (IdType)
+            entity_iri (str)
+            msg (str): Message to inform the user about the occurred issue
+
+        Returns:
+            None
+        """
+        if self.current_source is not None:
+            self.current_source.add_parsing_log_entry(level, entity_type,
+                                                      entity_iri, msg)
+
+    def parse_source_into_vocabulary(self, source: Source,
+                                     vocabulary: Vocabulary) -> bool:
+        """ Parse a Source into the given vocabulary
+        Args:
+            source (Source)
+            vocabulary (Vocabulary)
+
+        Returns:
+            bool, True if success, False if Error occurred, as an invalid File
+        """
+
+        # if this is the predefined source don't parse it, just pretend it
+        # was successful
+        if source.predefined:
+            return True
+
+        voc_builder = VocabularyBuilder(vocabulary=vocabulary)
+        g = rdflib.Graph()
+
+        # format = rdflib.util.guess_format(source.source_path)
+        voc_builder.add_source(source)
+        voc_builder.set_current_source(source.id)
+
+        g.parse(data=source.content, format="turtle")
+
+        ontology_nodes = list(g.subjects(
+            object=rdflib.term.URIRef("http://www.w3.org/2002/07/owl#Ontology"),
+            predicate=rdflib.term.URIRef(Tags.rdf_type.value)))
+
+        # a source may have no ontology iri defined
+        # if wanted on this place more info about the ontology can be extracted
+        if len(ontology_nodes) > 0:
+            source.ontology_iri = get_iri_from_uriref(ontology_nodes[0])
+
+        self.current_source = source
+
+        self._parse_to_vocabulary(g, voc_builder)
+
+        return True
+
+    def _is_object_defined_by_other_source(self, a: rdflib.term,
+                                           graph: rdflib.Graph) -> bool:
+        """ Test if the term is defined outside the current source
+
+        Args:
+            a (rdflib.term): Term to check
+            graph (rdflib.graph): graph extracted from source
+
+        Returns:
+            bool
+        """
+
+        # if an object is defined by an other source it carries the predicate
+        # ("isDefinedBy"). Then don't parse the object
+        defined_tags = list(graph.objects(
+            subject=a, predicate=rdflib.term.URIRef(
+                "http://www.w3.org/2000/01/rdf-schema#isDefinedBy")))
+        return len(defined_tags) > 0
+
+    def _parse_to_vocabulary(self, graph: rdflib.Graph,
+                             voc_builder: VocabularyBuilder):
+        """Parse an graph that was extracted from a TTL file into the vocabulary
+
+        Args:
+            graph (rdflib.Graph)
+            voc_builder (VocabularyBuilder): Builder object to manipulate a
+                vocabulary
+
+        Returns:
+            None
+        """
+
+        # OWLClasses
+        for a in graph.subjects(
+                object=rdflib.term.URIRef(
+                    "http://www.w3.org/2002/07/owl#Class"),
+                predicate=rdflib.term.URIRef(Tags.rdf_type.value)):
+
+            if isinstance(a, rdflib.term.BNode):
+                pass
+                # owl:Class can also occure in complex target statements of
+                # relations as BNode, ignore it here
+            else:
+
+                # defined in other source -> ignore
+                if self._is_object_defined_by_other_source(a, graph=graph):
+                    continue
+
+                iri, label, comment = self._extract_annotations(graph, a)
+                c = Class(iri=iri, label=label, comment=comment)
+                voc_builder.add_class(class_=c)
+
+        # Class properties
+        found_class_iris = set()
+        for class_node in graph.subjects(
+                predicate=rdflib.term.URIRef(
+                    "http://www.w3.org/2000/01/rdf-schema#subClassOf")):
+
+            class_iri = get_iri_from_uriref(class_node)
+            found_class_iris.add(class_iri)
+
+        for class_iri in found_class_iris:
+            # parent class / relation parsing
+            for sub in graph.objects(
+                    subject=rdflib.term.URIRef(class_iri),
+                    predicate=rdflib.term.URIRef
+                        ('http://www.w3.org/2000/01/rdf-schema#subClassOf')):
+                self.current_class_iri = class_iri  # used only for logging
+                self._parse_subclass_term(graph=graph,
+                                          voc_builder=voc_builder,
+                                          node=sub,
+                                          class_iri=class_iri)
+
+        # OWlObjectProperties
+        for a in graph.subjects(
+                object=rdflib.term.URIRef(
+                    "http://www.w3.org/2002/07/owl#ObjectProperty"),
+                predicate=rdflib.term.URIRef(Tags.rdf_type.value)):
+
+            if isinstance(a, rdflib.term.BNode):
+                self._add_logging_information(LogLevel.WARNING,
+                                              IdType.object_property,
+                                              "unknown",
+                                              "Found unparseable statement")
+
+            else:
+                # defined in other source -> ignore
+                if self._is_object_defined_by_other_source(a, graph):
+                    continue
+
+                iri, label, comment = self._extract_annotations(graph, a)
+
+                obj_prop = ObjectProperty(iri=iri, label=label, comment=comment)
+                voc_builder.add_object_property(obj_prop)
+                # extract inverse properties, it can be multiple but only
+                # URIRefs allowed no union/intersection
+                for inverse_iri_node in graph.objects(subject=a,
+                        predicate=rdflib.term.URIRef(
+                        'http://www.w3.org/2002/07/owl#inverseOf')):
+                    if isinstance(inverse_iri_node, rdflib.term.BNode):
+                        self._add_logging_information(
+                            LogLevel.CRITICAL, IdType.object_property, iri,
+                            "Complex inverseProperty statements aren't allowed")
+                    else:
+                        inverse_iri = get_iri_from_uriref(inverse_iri_node)
+                        obj_prop.add_inverse_property_iri(inverse_iri)
+
+        # OWlDataProperties
+        for a in graph.subjects(
+                object=rdflib.term.URIRef(
+                    "http://www.w3.org/2002/07/owl#DatatypeProperty"),
+                predicate=rdflib.term.URIRef(Tags.rdf_type.value)):
+
+            if isinstance(a, rdflib.term.BNode):
+                self._add_logging_information(LogLevel.WARNING,
+                                              IdType.data_property, "unknown",
+                                             "Found unparseable statement")
+
+            else:
+                # defined in other source -> ignore
+                if self._is_object_defined_by_other_source(a, graph):
+                    continue
+
+                iri, label, comment = self._extract_annotations(graph, a)
+
+                data_prop = DataProperty(iri=iri, label=label, comment=comment)
+                voc_builder.add_data_property(data_prop)
+
+        # OWLDataTypes
+        # only the custom created datatype_catalogue are listed in the file,
+        # the predefined are automatically added at the start
+        # of post processing
+        for a in graph.subjects(
+                object=rdflib.term.URIRef(
+                    "http://www.w3.org/2000/01/rdf-schema#Datatype"),
+                predicate=rdflib.term.URIRef(Tags.rdf_type.value)):
+
+            if isinstance(a, rdflib.term.BNode):
+                # self._add_logging_information(LogLevel.WARNING,
+                #                              IdType.datatype, "unknown",
+                #                              "Found unparseable statement")
+                pass
+                #e.g: :
+                # customDataType4 rdf:type rdfs:Datatype ;
+                # owl:equivalentClass [ rdf:type rdfs:Datatype ;....
+                # the second Datatype triggers this if condition,
+                # but we can ignore this statement
+
+            else:
+                # defined in other source -> ignore
+                if self._is_object_defined_by_other_source(a, graph):
+                    continue
+
+                iri, label, comment = self._extract_annotations(graph, a)
+
+                datatype = Datatype(iri=iri, label=label, comment=comment)
+                voc_builder.add_datatype(datatype=datatype)
+
+                # a datatype can be empty -> use string
+                # a datatype can have multiple equivalent classes
+                # (predefined types) -> ignore for now
+                # a datatype can contain an enum of possible values ->
+                # most interesting
+                # under the predicate owl:equivalentClass is than a
+                # list(first, rest, nil) under the pred.
+                # oneOf with the values
+
+                enum_values = []
+                for equivalent_class in graph.objects(
+                        subject=a,
+                        predicate=rdflib.term.URIRef(
+                            "http://www.w3.org/2002/07/owl#equivalentClass")):
+
+                    if isinstance(equivalent_class, rdflib.term.URIRef):
+                        # points to an other defined datatype, ignore
+                        pass
+                    else:
+                        # is a bNode and points to owl:oneOf
+                        enum_literals = self.\
+                            _extract_objects_out_of_single_combination(
+                                graph, equivalent_class, accept_and=False,
+                                accept_or=False, accept_one_of=True)
+                        for literal in enum_literals:
+                            enum_values.append(str(literal))
+                datatype.enum_values = enum_values
+                if len(enum_values) > 0:
+                    datatype.type = DatatypeType.enum
+                else:
+                    datatype.type = DatatypeType.string
+
+        # OWLIndividuals
+
+        for a in graph.subjects(
+                object=rdflib.term.URIRef(Tags.owl_individual.value),
+                predicate=rdflib.term.URIRef(Tags.rdf_type.value)):
+
+            if isinstance(a, rdflib.term.BNode):
+                self._add_logging_information(LogLevel.WARNING,
+                                              IdType.individual, "unknown",
+                                             "Found unparseable statement")
+
+            else:
+                # defined in other source -> ignore
+                if self._is_object_defined_by_other_source(a, graph):
+                    continue
+
+                iri, label, comment = self._extract_annotations(graph, a)
+                objects = graph.objects(subject=a,
+                                        predicate=
+                                        rdflib.term.URIRef(Tags.rdf_type.value))
+                # superclasses = types
+                types = []
+                for object in objects:
+                    if not object == \
+                           rdflib.term.URIRef(Tags.owl_individual.value):
+                        types.extend(self.
+                            _extract_objects_out_of_layered_combination(
+                                        graph, object, True, False))
+
+                individual = Individual(iri=iri, label=label, comment=comment)
+                for type in types:
+                    individual.parent_class_iris.append(
+                        get_iri_from_uriref(type))
+                voc_builder.add_individual(individual=individual)
+
+        # As seen for example in the bricks ontology an individual can be
+        # declared with :individual1 rdf:type :Class1
+        # this type of declaration is hard to completly detect
+        # we need to see that the object is a class iri and not a specifier iri.
+        # as we may not have loaded all dependencies we can not simply look it
+        # up in vocabulary
+        # -> getbase uri of statement and filter all known specifier uris
+        for sub in graph.subjects(
+                predicate=rdflib.term.URIRef(Tags.rdf_type.value)):
+            for obj in graph.objects(subject=sub,
+                                     predicate=
+                                     rdflib.term.URIRef(Tags.rdf_type.value)):
+
+                if isinstance(obj, rdflib.term.BNode):
+                    continue
+                obj_iri = get_iri_from_uriref(obj)
+
+                obj_base_iri = get_base_out_of_iri(iri=obj_iri)
+                if obj_base_iri not in specifier_base_iris:
+                    iri, label, comment = \
+                        self._extract_annotations(graph, sub)
+                    if not voc_builder.entity_is_known(iri):
+                        iri, label, comment = \
+                            self._extract_annotations(graph, sub)
+                        individual = Individual(iri=iri,
+                                                label=label,
+                                                comment=comment)
+                        individual.parent_class_iris.append(obj_iri)
+                        voc_builder.add_individual(individual)
+
+    def _extract_annotations(self, graph: rdflib.Graph,
+                             node: rdflib.term.URIRef) -> Tuple[str, str, str]:
+        """ Extract out of a node term the owl annotations (iri, label, comment)
+
+        Args:
+            graph (rdflib.graph): Graph describing ontology
+            node (rdflib.term.URIRef): Entity node
+
+        Returns:
+            [str,str,str]: [iri, label, comment]
+        """
+        iri = str(node)
+        label = graph.label(node).title()
+        comment = graph.comment(node).title()
+
+        return iri, label, comment
+
+    def _parse_subclass_term(self, graph: rdflib.Graph,
+                             voc_builder: VocabularyBuilder,
+                             node: rdflib.term, class_iri: str):
+        """Parse a subclass term of the given node and class_iri
+
+        Args:
+            graph (rdflib.graph): Graph describing ontology
+            vocabulary (Vocabulary): Vocabualry to parse into
+            node (rdflib.term)
+            class_iri (str)
+
+        Returns:
+            None
+        """
+
+        # class could have been only defined in other source, than no class
+        # is defined, but as we have found a relation for a class, the class
+        # needs to exist
+        if class_iri not in voc_builder.vocabulary.classes:
+            voc_builder.add_class(class_=Class(iri=class_iri))
+
+        # node can be 1 of 3 things:
+        #   - a parentclass statment -> UriRef
+        #   - a relation statment -> BNode
+        #   - an intersection of parentclasses ,
+        #   relations and intersections -> BNode
+        if isinstance(node, rdflib.term.BNode):
+            # sub has no IRI and is therefore a relation
+
+            # extract the subpredicates and subobjects as statments
+            # if node is a relation:
+            #      in total there should be 3-4 statments:
+            #      rdf:type pointing to owl:Restriction
+            #      owl:onProperty pointing to a data or object property
+            #      1-2 staments which values are exepted, this can point to an
+            #      URIRef or BNode
+
+            # if node is a intersection:
+            #      it has the predicate owl:intersectionOf
+            #      and a set of objects
+
+            predicates = []
+            objects = []
+            for p in graph.predicates(subject=node):
+                predicates.append(p)
+            for o in graph.objects(subject=node):
+                objects.append(o)
+
+            # Combination of statements
+            if rdflib.term.URIRef(Tags.owl_intersection.value) in predicates:
+                objects = self._extract_objects_out_of_single_combination(
+                    graph, node, True, False)
+                for object in objects:
+                    self._parse_subclass_term(graph=graph,
+                                              voc_builder=voc_builder,
+                                              node=object, class_iri=class_iri)
+
+            elif rdflib.term.URIRef(Tags.owl_union.value) in predicates:
+                self._add_logging_information(
+                    LogLevel.CRITICAL, IdType.class_, class_iri,
+                    "Relation statements combined with or")
+
+            elif rdflib.term.URIRef(Tags.owl_one_of.value) in predicates:
+                self._add_logging_information(
+                    LogLevel.CRITICAL, IdType.class_, class_iri,
+                    "Relation statements combined with oneOf")
+
+            # Relation statement
+            else:
+
+                additional_statements = {}
+                rdf_type = ""
+                owl_on_property = ""
+
+                for i in range(len(predicates)):
+                    if predicates[i] == rdflib.term.URIRef(Tags.rdf_type.value):
+                        rdf_type = get_iri_from_uriref(objects[i])
+                    elif predicates[i] == rdflib.term.URIRef(
+                            "http://www.w3.org/2002/07/owl#onProperty"):
+                        owl_on_property = get_iri_from_uriref(objects[i])
+                    else:
+                        additional_statements[
+                            get_iri_from_uriref(predicates[i])] = objects[i]
+
+                relation_is_ok = True
+                if not rdf_type == "http://www.w3.org/2002/07/owl#Restriction":
+                    self._add_logging_information(
+                        LogLevel.CRITICAL, IdType.class_, class_iri,
+                        "Class has an unknown subClass statement")
+                    relation_is_ok = False
+
+                if owl_on_property == "":
+                    self._add_logging_information(
+                        LogLevel.CRITICAL, IdType.class_, class_iri,
+                        "Class has a relation without a property")
+                    relation_is_ok = False
+
+                # object or data relation?
+                if relation_is_ok:
+                    relation = None
+                    id = uuid.uuid4().hex
+                    # this id can and should be random. a class_iri can have a
+                    # property_iri multiple times, to assign always the same id
+                    # for the same relation is not worth the trouble
+
+                    relation = Relation(property_iri=owl_on_property, id=id)
+                    voc_builder.add_relation_for_class(class_iri, relation)
+
+                    # go through the additional statement to figure out the
+                    # targetIRI and the restrictionType/cardinality
+                    self._parse_relation_type(graph, relation,
+                                              additional_statements)
+
+        # parent-class statement or empty list element
+        else:
+            # owlThing is the root object, but it is not declared as a class
+            # in the file to prevent None pointer when looking up parents,
+            # a class that has a parent owlThing simply has no parents
+            if not get_iri_from_uriref(node) == \
+                   "http://www.w3.org/1999/02/22-rdf-syntax-ns#nil":
+                # ignore empty lists
+                if not get_iri_from_uriref(node) == \
+                       "http://www.w3.org/2002/07/owl#Thing":
+                    voc_builder.vocabulary.\
+                        get_class_by_iri(class_iri).parent_class_iris.\
+                        append(get_iri_from_uriref(node))
+
+    def _parse_relation_type(self, graph: rdflib.Graph,
+                             relation: Relation, statements: {}):
+        """
+        Parse the relation type and depending on the result the
+        cardinality or value of relation
+        
+        Args:
+            graph: underlying ontology graph
+            relation: Relation object into which the information are saved
+            statements: Ontology statements concerning the relation
+        
+        Returns:
+            None
+        """
+        treated_statements = []
+        for statement in statements:
+            if statement == "http://www.w3.org/2002/07/owl#someValuesFrom":
+                relation.restriction_type = RestrictionType.some
+                self._parse_relation_values(graph, relation,
+                                            statements[statement])
+            elif statement == "http://www.w3.org/2002/07/owl#allValuesFrom":
+                relation.restriction_type = RestrictionType.only
+                self._parse_relation_values(graph, relation,
+                                            statements[statement])
+            elif statement == "http://www.w3.org/2002/07/owl#hasValue":
+                relation.restriction_type = RestrictionType.value
+                # has Value can only point to a single value
+                self._parse_has_value(graph, relation,
+                                      statements[statement])
+            elif statement == "http://www.w3.org/2002/07/owl#maxCardinality":
+                relation.restriction_type = RestrictionType.max
+                self._parse_cardinality(graph, relation, statement,
+                                        statements, treated_statements)
+            elif statement == "http://www.w3.org/2002/07/owl#minCardinality":
+                relation.restriction_type = RestrictionType.min
+                self._parse_cardinality(graph, relation, statement,
+                                        statements, treated_statements)
+            elif statement == "http://www.w3.org/2002/07/owl#cardinality":
+                relation.restriction_type = RestrictionType.exactly
+                self._parse_cardinality(graph,  relation, statement,
+                                        statements, treated_statements)
+            elif statement == \
+                    "http://www.w3.org/2002/07/owl#maxQualifiedCardinality":
+                relation.restriction_type = RestrictionType.max
+                self._parse_cardinality(graph, relation, statement,
+                                        statements, treated_statements)
+            elif statement == \
+                    "http://www.w3.org/2002/07/owl#minQualifiedCardinality":
+                relation.restriction_type = RestrictionType.min
+                self._parse_cardinality(graph, relation, statement,
+                                        statements, treated_statements)
+            elif statement == \
+                    "http://www.w3.org/2002/07/owl#qualifiedCardinality":
+                relation.restriction_type = RestrictionType.exactly
+                self._parse_cardinality(graph, relation, statement,
+                                        statements, treated_statements)
+
+            treated_statements.append(statement)
+
+        for statement in statements:
+            if statement not in treated_statements:
+                self._add_logging_information(
+                  LogLevel.CRITICAL, IdType.class_, self.current_class_iri,
+                  "Relation with property {} has an untreated restriction "
+                  "{}".format(relation.property_iri, statement))
+
+    def _parse_cardinality(self, graph: rdflib.Graph,
+                           relation: Relation, statement, statements,
+                           treated_statements):
+        """Parse the cardinality of a relation
+
+        Args:
+            graph: underlying ontology graph
+            relation: Relation object into which the information are saved
+            statement: The statement that is actively treated
+            statements: Ontology statements concerning the relation
+            treated_statements: Statements that were already treated
+
+        Returns:
+            None
+        """
+        if Tags.owl_on_class.value in statements:
+            relation.restriction_cardinality = str(statements[statement])
+            target = statements[Tags.owl_on_class.value]
+            self._parse_relation_values(graph, relation, target)
+            treated_statements.append(Tags.owl_on_class.value)
+        elif Tags.owl_on_data_range.value in statements:
+            relation.restriction_cardinality = str(statements[statement])
+            target = statements[Tags.owl_on_data_range.value]
+            self._parse_relation_values(graph, relation, target)
+            treated_statements.append(Tags.owl_on_data_range.value)
+        else:
+            # has From:
+            # in File: owl:maxCardinality "1"^^xsd:nonNegativeInteger
+            # e.g.: {'http://www.w3.org/2002/07/owl#maxCardinality':
+            #        rdflib.term.Literal('1', datatype=
+            #        rdflib.term.URIRef('
+            #        http://www.w3.org/2001/XMLSchema#nonNegativeInteger'))}
+
+            # in this case the file does not state a datarange that is allowed.
+            # Therefore the target gets set to the universal string
+
+            relation.restriction_cardinality = statements[statement].value
+            datatype = "http://www.w3.org/2001/XMLSchema#string"
+            target_statement = TargetStatement(type=StatementType.LEAF,
+                                               target_iri=datatype)
+            relation.target_statement = target_statement
+
+    def _parse_has_value(self, graph: rdflib.Graph, relation: Relation,
+                         node: rdflib.term):
+        """Parse the value of a relation
+
+        Args:
+           graph: underlying ontology graph
+           relation: Relation object into which the information are saved
+           node: (complex) Graph node containing the value
+        
+        Returns:
+           None
+        """
+        self._parse_relation_values(graph, relation, node)
+        # for hasValue only a target-statement that is a leaf is allowed
+        if not relation.target_statement.type == StatementType.LEAF:
+            self._add_logging_information(
+                LogLevel.CRITICAL,
+                IdType.class_,
+                self.current_class_iri,
+                f"In hasValue relation with property {relation.property_iri} "
+                f"target is a complex expression")
+
+    def _parse_relation_values(self, graph: rdflib.Graph,
+                               relation: Relation, node: rdflib.term):
+        """
+        Parse the value of a relation out of a node that can be complex;
+        consisting out of a combination of multiple other nodes
+
+        Args:
+           graph: underlying ontology graph
+           relation: Relation object into which the information are saved
+           node: (complex) Graph node containing the value
+
+        Returns:
+           None
+        """
+        target_statement = TargetStatement()
+        relation.target_statement = target_statement
+
+        queue = [(node, target_statement)]
+        while not len(queue) == 0:
+            current_term, current_statement = queue.pop(0)
+            if isinstance(current_term, rdflib.URIRef):
+                target_iri = get_iri_from_uriref(current_term)
+
+                current_statement.set_target(target_iri=target_iri)
+            else:
+                if rdflib.term.URIRef(Tags.owl_intersection.value) in \
+                        graph.predicates(subject=current_term):
+
+                    current_statement.type = StatementType.AND
+                elif rdflib.term.URIRef(Tags.owl_union.value) in \
+                        graph.predicates(subject=current_term):
+
+                    current_statement.type = StatementType.OR
+                else:
+                    current_statement.set_target(
+                        target_iri="Target statement has no iri",
+                        target_data_value=str(current_term))
+
+                    continue
+
+                child_nodes = self._extract_objects_out_of_single_combination(
+                    graph, current_term, True, True)
+                for child_node in child_nodes:
+                    new_statement = TargetStatement()
+                    current_statement.target_statements.append(new_statement)
+                    queue.append((child_node, new_statement))
+
+    # an intersection/union is a basic list, it consists out of a chain of
+    # bnode, where each bnode has the "first"and "rest" predicate, first
+    # contains our object, rest is a pointer to the next part of the chain.
+    # the list is over if rest points to "NIL"
+    # this methode extracts all objects of a single layered intersection,
+    # if the intersection contains further intersections these are contained in
+    # the result list as BNode
+    def _extract_objects_out_of_single_combination(self, graph: rdflib.Graph,
+                                                   node: rdflib.term.BNode,
+                                                   accept_and: bool,
+                                                   accept_or: bool,
+                                                   accept_one_of: bool = False):
+        """
+        An intersection/union is a basic list, it consits out of a chain of
+        bnode,where each bnode has the "first"and "rest" predicate,
+        first contains our object, rest is a pointer to the next part of the
+        chain. The list is over if rest points to "NIL"
+        This methode extracts all objects of a single layered intersection,
+        if the intersection contains further intersections these are contained
+        in the result list as BNode
+
+        Args:
+            graph: underlying ontology graph
+            node: (complex) Graph node containing the value
+            accept_or (bool): true, if combinations with "or" are allowed to be
+                parsed
+            accept_and (bool): true, if combinations with "and" are allowed
+                to be parsed
+            accept_one_of (bool): true, if ne_of statements are allowed
+                to be parsed
+
+        Returns:
+           None
+        """
+        predicates = list(graph.predicates(subject=node))
+
+        # the passed startnode needs to contain an intersection or a union
+        # both at the same time should not be possible
+        start_node = None
+        if rdflib.term.URIRef(Tags.owl_intersection.value) \
+                in predicates:
+            if accept_and:
+                start_node = next(graph.objects(
+                    subject=node,
+                    predicate=rdflib.term.URIRef(Tags.owl_intersection.value)))
+        elif rdflib.term.URIRef(Tags.owl_union.value) \
+                in predicates:
+            if accept_or:
+                start_node = next(graph.objects(
+                    subject=node,
+                    predicate=rdflib.term.URIRef(Tags.owl_union.value)))
+        elif rdflib.term.URIRef(Tags.owl_one_of.value) \
+                in predicates:
+            if accept_one_of:
+                start_node = next(graph.objects(
+                    subject=node,
+                    predicate=rdflib.term.URIRef(Tags.owl_one_of.value)))
+        else:
+            self._add_logging_information(
+                LogLevel.CRITICAL, IdType.class_, self.current_class_iri,
+                f"Intern Error - invalid {node} passed to list extraction")
+
+        result = []
+        rest = start_node
+        if start_node is None:
+            return []
+
+        while not rest == rdflib.term.URIRef(
+                'http://www.w3.org/1999/02/22-rdf-syntax-ns#nil'):
+
+            first = next(graph.objects(predicate=rdflib.term.URIRef(
+                'http://www.w3.org/1999/02/22-rdf-syntax-ns#first'),
+                subject=rest))
+            result.append(first)
+            rest = next(graph.objects(predicate=rdflib.term.URIRef(
+                        'http://www.w3.org/1999/02/22-rdf-syntax-ns#rest'),
+                                      subject=rest))
+
+        return result
+
+    def _extract_objects_out_of_layered_combination(
+            self, graph: rdflib.Graph, node: rdflib.term.BNode,
+            accept_and: bool, accept_or: bool) -> List[rdflib.term.URIRef]:
+        """Extract all nodes out of a complex combination
+
+        Args:
+            graph: underlying ontology graph
+            node: (complex) Graph node containing the complex combination
+            accept_or (bool): true, if combinations with "or" are allowed to be
+                parsed
+            accept_and (bool): true, if combinations with "and" are allowed
+                to be parsed
+
+        Returns:
+           List[rdflib.term.URIRef], list of terms out of combination
+        """
+        result = []
+        queue = [node]
+
+        while len(queue) > 0:
+            node = queue.pop()
+            if isinstance(node, rdflib.term.URIRef):
+                result.append(node)
+            else:
+                queue.extend(self._extract_objects_out_of_single_combination
+                             (graph, node, accept_and, accept_or))
+        return result
+
```

### Comparing `filip-0.3.0/filip/semantics/ontology_parser/vocabulary_builder.py` & `filip-0.4.0/filip/semantics/ontology_parser/vocabulary_builder.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,285 +1,285 @@
-"""Wrapper module to provide manipulation functions for vocabulary that
-    should later be hidden from the user"""
-import uuid
-from enum import Enum
-
-
-from pydantic import BaseModel, Field
-from typing import Dict
-
-from filip.models.base import LogLevel
-from filip.semantics.vocabulary import *
-
-
-class IdType(str, Enum):
-    class_ = 'Class'
-    object_property = 'Object Property'
-    data_property = 'Data Property'
-    datatype = 'Datatype'
-    relation = 'Relation'
-    combined_relation = 'Combined Relation'
-    individual = 'Individual'
-    source = 'Source'
-
-
-class VocabularyBuilder(BaseModel):
-    """Wrapper class to provide manipulation functions for vocabulary that
-    should later be hidden from the user"""
-
-    vocabulary: Vocabulary = Field(
-        description="Vocabulary to manipulate"
-    )
-
-    current_source: Source = Field(
-        default=None,
-        description="Current source to which entities are added,"
-                    "needed while parsing")
-
-    def clear(self):
-        """Clear all objects form the vocabulary
-
-        Returns:
-            None
-        """
-        self.vocabulary.classes.clear()
-        self.vocabulary.object_properties.clear()
-        self.vocabulary.data_properties.clear()
-        self.vocabulary.datatypes.clear()
-        self.vocabulary.relations.clear()
-        self.vocabulary.combined_object_relations.clear()
-        self.vocabulary.combined_data_relations.clear()
-        self.vocabulary.individuals.clear()
-        self.vocabulary.id_types.clear()
-        for source in self.vocabulary.sources.values():
-            source.clear()
-
-    def add_class(self, class_: Class):
-        """Add a class to the vocabulary
-
-        Args:
-            class_ (Class): class to be added
-
-        Returns:
-            None
-        """
-        self._add_and_merge_entity(class_,
-                                   self.vocabulary.classes,
-                                   IdType.class_)
-
-    def add_object_property(self, obj_prop: ObjectProperty):
-        """Add an ObjectProperty to the vocabulary
-
-        Args:
-            obj_prop (ObjectProperty): ObjectProperty to be added
-
-        Returns:
-            None
-        """
-        self._add_and_merge_entity(
-            obj_prop, self.vocabulary.object_properties, IdType.object_property)
-
-    def add_data_property(self, data_prop: DataProperty):
-        """Add an DataProperty to the vocabulary
-
-        Args:
-            data_prop (DataProperty): DataProperty to be added
-
-        Returns:
-            None
-        """
-        self._add_and_merge_entity(
-            data_prop, self.vocabulary.data_properties, IdType.data_property)
-
-    def add_datatype(self, datatype: Datatype):
-        """Add a DataType to the vocabulary
-
-        Args:
-            datatype (Datatype): Datatype to be added
-
-        Returns:
-            None
-        """
-        self._add_and_merge_entity(
-            datatype, self.vocabulary.datatypes, IdType.datatype)
-
-    def add_predefined_datatype(self, datatype: Datatype):
-        """Add a DataType to the vocabulary, that belongs to the source:
-            Predefined
-
-        Args:
-            datatype (Datatype): Datatype to be added
-
-        Returns:
-            None
-        """
-        self.vocabulary.id_types[datatype.iri] = IdType.datatype
-        self.vocabulary.datatypes[datatype.iri] = datatype
-        datatype.predefined = True
-        datatype.source_ids.add("PREDEFINED")
-
-    def add_individual(self, individual: Individual):
-        """Add an Individual to the vocabulary
-
-        Args:
-            individual (Individual): Individual to be added
-
-        Returns:
-            None
-        """
-        self._add_and_merge_entity(individual,
-                                   self.vocabulary.individuals,
-                                   IdType.individual)
-
-    def add_relation_for_class(self, class_iri: str, rel: Relation):
-        """Add a relation object to a class
-
-        Args:
-            class_iri: Iri of the class to which the relation should be added
-            rel: Relation to add
-
-        Returns:
-            None
-        """
-
-        class_ = self.vocabulary.get_class_by_iri(class_iri)
-
-        # for rel_id in class_.relation_ids:
-        #     ex_rel = self.vocabulary.get_relation_by_id(rel_id)
-        #     if rel.target_statement== rel.target_statement:
-        #         return
-
-        self.vocabulary.relations[rel.id] = rel
-        class_.relation_ids.append(rel.id)
-        self.vocabulary.id_types[rel.id] = IdType.relation
-
-    def add_combined_object_relation_for_class(self, class_iri: str,
-                                               crel: CombinedObjectRelation):
-        """Add a combined object relation object to a class
-
-        Args:
-            class_iri: Iri of the class to which the co-relation should be added
-            crel: CombinedObjectRelation to add
-
-        Returns:
-            None
-        """
-        self.vocabulary.combined_object_relations[crel.id] = crel
-        self.vocabulary.get_class_by_iri(class_iri).\
-            combined_object_relation_ids.append(crel.id)
-        self.vocabulary.id_types[crel.id] = IdType.combined_relation
-
-    def add_combined_data_relation_for_class(self, class_iri: str,
-                                             cdata: CombinedDataRelation):
-        """Add a combined data relation object to a class
-
-        Args:
-            class_iri: Iri of the class to which the cd-relation should be added
-            cdata: CombinedDataRelation to add
-
-        Returns:
-            None
-        """
-        self.vocabulary.combined_data_relations[cdata.id] = cdata
-        self.vocabulary.get_class_by_iri(class_iri).\
-            combined_data_relation_ids.append(cdata.id)
-        self.vocabulary.id_types[cdata.id] = IdType.combined_relation
-
-    def add_source(self, source: Source, id: str = None):
-        """Add a source to the vocabulary
-
-        Args:
-            source: source to add
-            id: id of source, if none is given a random id is generated
-
-        Returns:
-            None
-        """
-        if id is None:
-            source.id = uuid.uuid4().hex
-        else:
-            source.id = id
-        self.vocabulary.id_types[source.id] = IdType.source
-        self.vocabulary.sources[source.id] = source
-        self.current_source = source
-
-    def set_current_source(self, source_id: str):
-        """Set the source of the vocabulary to which new added objects belong
-
-        Args:
-            source_id: id of source to activate
-
-        Returns:
-            None
-        """
-        assert source_id in self.vocabulary.sources
-        self.current_source = self.vocabulary.sources[source_id]
-
-    def _add_and_merge_entity(self,
-                              entity: Entity,
-                              entity_dict: Dict[str, Entity],
-                              id_type: IdType):
-        """Adds an entity to the vocabulary. If an entity with teh same iri
-        already exists the label and comment are "merged" and both sources
-        are noted
-
-        Args:
-            entity: Entity to check
-            entity_dict: Existing entities
-            id_type: Type of entity
-
-        Raises:
-            ParsingError: if Entity of iri exists but has a different IdType
-
-        Returns:
-            None
-        """
-
-        if entity.iri in self.vocabulary.id_types:
-            if not id_type == self.vocabulary.id_types[entity.iri]:
-                self.current_source.add_parsing_log_entry(
-                    LogLevel.CRITICAL, id_type, entity.iri,
-                    f"{entity.iri} from source "
-                    f"{self.current_source.get_name()} "
-                    f"exists multiple times in different catagories. It was "
-                    f"only added for the category "
-                    f"{self.vocabulary.id_types[entity.iri].value}")
-                return
-
-            old_entity = entity_dict[entity.iri]
-
-            def select_from(old: str, new: str, property: str) -> str:
-                """
-                Given two strings, one from the old_entity , one form the new
-                one. It is selected which one to use.
-                """
-                if old == "":
-                    return new
-                elif new == "":
-                    return ""
-                else:
-                    self.current_source.add_parsing_log_entry(
-                        LogLevel.WARNING, id_type, entity.iri,
-                        f"{property} from source "
-                        f"{old_entity.get_source_names(self.vocabulary)} "
-                        f"was overwritten")
-                    return new
-
-            entity.label = select_from(old_entity.label, entity.label, "label")
-            entity.comment = select_from(old_entity.comment, entity.comment,
-                                         "comment")
-
-        self.vocabulary.id_types[entity.iri] = id_type
-        entity.source_ids.add(self.current_source.id)
-        entity_dict[entity.iri] = entity
-
-    def entity_is_known(self, iri: str) -> bool:
-        """Test if the given iri is in vocabulary, if not it belongs to a
-        dependency which is not yet loaded
-
-        Args:
-            iri (str)
-
-        Returns:
-            bool
-        """
-        return iri in self.vocabulary.id_types
+"""Wrapper module to provide manipulation functions for vocabulary that
+    should later be hidden from the user"""
+import uuid
+from enum import Enum
+
+
+from pydantic import BaseModel, Field
+from typing import Dict
+
+from filip.models.base import LogLevel
+from filip.semantics.vocabulary import *
+
+
+class IdType(str, Enum):
+    class_ = 'Class'
+    object_property = 'Object Property'
+    data_property = 'Data Property'
+    datatype = 'Datatype'
+    relation = 'Relation'
+    combined_relation = 'Combined Relation'
+    individual = 'Individual'
+    source = 'Source'
+
+
+class VocabularyBuilder(BaseModel):
+    """Wrapper class to provide manipulation functions for vocabulary that
+    should later be hidden from the user"""
+
+    vocabulary: Vocabulary = Field(
+        description="Vocabulary to manipulate"
+    )
+
+    current_source: Source = Field(
+        default=None,
+        description="Current source to which entities are added,"
+                    "needed while parsing")
+
+    def clear(self):
+        """Clear all objects form the vocabulary
+
+        Returns:
+            None
+        """
+        self.vocabulary.classes.clear()
+        self.vocabulary.object_properties.clear()
+        self.vocabulary.data_properties.clear()
+        self.vocabulary.datatypes.clear()
+        self.vocabulary.relations.clear()
+        self.vocabulary.combined_object_relations.clear()
+        self.vocabulary.combined_data_relations.clear()
+        self.vocabulary.individuals.clear()
+        self.vocabulary.id_types.clear()
+        for source in self.vocabulary.sources.values():
+            source.clear()
+
+    def add_class(self, class_: Class):
+        """Add a class to the vocabulary
+
+        Args:
+            class_ (Class): class to be added
+
+        Returns:
+            None
+        """
+        self._add_and_merge_entity(class_,
+                                   self.vocabulary.classes,
+                                   IdType.class_)
+
+    def add_object_property(self, obj_prop: ObjectProperty):
+        """Add an ObjectProperty to the vocabulary
+
+        Args:
+            obj_prop (ObjectProperty): ObjectProperty to be added
+
+        Returns:
+            None
+        """
+        self._add_and_merge_entity(
+            obj_prop, self.vocabulary.object_properties, IdType.object_property)
+
+    def add_data_property(self, data_prop: DataProperty):
+        """Add an DataProperty to the vocabulary
+
+        Args:
+            data_prop (DataProperty): DataProperty to be added
+
+        Returns:
+            None
+        """
+        self._add_and_merge_entity(
+            data_prop, self.vocabulary.data_properties, IdType.data_property)
+
+    def add_datatype(self, datatype: Datatype):
+        """Add a DataType to the vocabulary
+
+        Args:
+            datatype (Datatype): Datatype to be added
+
+        Returns:
+            None
+        """
+        self._add_and_merge_entity(
+            datatype, self.vocabulary.datatypes, IdType.datatype)
+
+    def add_predefined_datatype(self, datatype: Datatype):
+        """Add a DataType to the vocabulary, that belongs to the source:
+            Predefined
+
+        Args:
+            datatype (Datatype): Datatype to be added
+
+        Returns:
+            None
+        """
+        self.vocabulary.id_types[datatype.iri] = IdType.datatype
+        self.vocabulary.datatypes[datatype.iri] = datatype
+        datatype.predefined = True
+        datatype.source_ids.add("PREDEFINED")
+
+    def add_individual(self, individual: Individual):
+        """Add an Individual to the vocabulary
+
+        Args:
+            individual (Individual): Individual to be added
+
+        Returns:
+            None
+        """
+        self._add_and_merge_entity(individual,
+                                   self.vocabulary.individuals,
+                                   IdType.individual)
+
+    def add_relation_for_class(self, class_iri: str, rel: Relation):
+        """Add a relation object to a class
+
+        Args:
+            class_iri: Iri of the class to which the relation should be added
+            rel: Relation to add
+
+        Returns:
+            None
+        """
+
+        class_ = self.vocabulary.get_class_by_iri(class_iri)
+
+        # for rel_id in class_.relation_ids:
+        #     ex_rel = self.vocabulary.get_relation_by_id(rel_id)
+        #     if rel.target_statement== rel.target_statement:
+        #         return
+
+        self.vocabulary.relations[rel.id] = rel
+        class_.relation_ids.append(rel.id)
+        self.vocabulary.id_types[rel.id] = IdType.relation
+
+    def add_combined_object_relation_for_class(self, class_iri: str,
+                                               crel: CombinedObjectRelation):
+        """Add a combined object relation object to a class
+
+        Args:
+            class_iri: Iri of the class to which the co-relation should be added
+            crel: CombinedObjectRelation to add
+
+        Returns:
+            None
+        """
+        self.vocabulary.combined_object_relations[crel.id] = crel
+        self.vocabulary.get_class_by_iri(class_iri).\
+            combined_object_relation_ids.append(crel.id)
+        self.vocabulary.id_types[crel.id] = IdType.combined_relation
+
+    def add_combined_data_relation_for_class(self, class_iri: str,
+                                             cdata: CombinedDataRelation):
+        """Add a combined data relation object to a class
+
+        Args:
+            class_iri: Iri of the class to which the cd-relation should be added
+            cdata: CombinedDataRelation to add
+
+        Returns:
+            None
+        """
+        self.vocabulary.combined_data_relations[cdata.id] = cdata
+        self.vocabulary.get_class_by_iri(class_iri).\
+            combined_data_relation_ids.append(cdata.id)
+        self.vocabulary.id_types[cdata.id] = IdType.combined_relation
+
+    def add_source(self, source: Source, id: str = None):
+        """Add a source to the vocabulary
+
+        Args:
+            source: source to add
+            id: id of source, if none is given a random id is generated
+
+        Returns:
+            None
+        """
+        if id is None:
+            source.id = uuid.uuid4().hex
+        else:
+            source.id = id
+        self.vocabulary.id_types[source.id] = IdType.source
+        self.vocabulary.sources[source.id] = source
+        self.current_source = source
+
+    def set_current_source(self, source_id: str):
+        """Set the source of the vocabulary to which new added objects belong
+
+        Args:
+            source_id: id of source to activate
+
+        Returns:
+            None
+        """
+        assert source_id in self.vocabulary.sources
+        self.current_source = self.vocabulary.sources[source_id]
+
+    def _add_and_merge_entity(self,
+                              entity: Entity,
+                              entity_dict: Dict[str, Entity],
+                              id_type: IdType):
+        """Adds an entity to the vocabulary. If an entity with teh same iri
+        already exists the label and comment are "merged" and both sources
+        are noted
+
+        Args:
+            entity: Entity to check
+            entity_dict: Existing entities
+            id_type: Type of entity
+
+        Raises:
+            ParsingError: if Entity of iri exists but has a different IdType
+
+        Returns:
+            None
+        """
+
+        if entity.iri in self.vocabulary.id_types:
+            if not id_type == self.vocabulary.id_types[entity.iri]:
+                self.current_source.add_parsing_log_entry(
+                    LogLevel.CRITICAL, id_type, entity.iri,
+                    f"{entity.iri} from source "
+                    f"{self.current_source.get_name()} "
+                    f"exists multiple times in different catagories. It was "
+                    f"only added for the category "
+                    f"{self.vocabulary.id_types[entity.iri].value}")
+                return
+
+            old_entity = entity_dict[entity.iri]
+
+            def select_from(old: str, new: str, property: str) -> str:
+                """
+                Given two strings, one from the old_entity , one form the new
+                one. It is selected which one to use.
+                """
+                if old == "":
+                    return new
+                elif new == "":
+                    return ""
+                else:
+                    self.current_source.add_parsing_log_entry(
+                        LogLevel.WARNING, id_type, entity.iri,
+                        f"{property} from source "
+                        f"{old_entity.get_source_names(self.vocabulary)} "
+                        f"was overwritten")
+                    return new
+
+            entity.label = select_from(old_entity.label, entity.label, "label")
+            entity.comment = select_from(old_entity.comment, entity.comment,
+                                         "comment")
+
+        self.vocabulary.id_types[entity.iri] = id_type
+        entity.source_ids.add(self.current_source.id)
+        entity_dict[entity.iri] = entity
+
+    def entity_is_known(self, iri: str) -> bool:
+        """Test if the given iri is in vocabulary, if not it belongs to a
+        dependency which is not yet loaded
+
+        Args:
+            iri (str)
+
+        Returns:
+            bool
+        """
+        return iri in self.vocabulary.id_types
```

### Comparing `filip-0.3.0/filip/semantics/semantics_manager.py` & `filip-0.4.0/filip/semantics/semantics_manager.py`

 * *Ordering differences only*

 * *Files 24% similar despite different names*

```diff
@@ -1,1251 +1,1251 @@
-"""Manages the local state of the semantic instances"""
-
-import copy
-import json
-import logging
-import uuid
-from math import inf
-
-import requests
-
-from typing import Optional, Dict, Type, List, Any, Union, Set
-from pydantic import BaseModel, Field
-from rapidfuzz import process
-
-from filip.models.base import NgsiVersion
-from filip.models.ngsi_v2.iot import DeviceSettings
-from filip.semantics.vocabulary import Individual
-from filip.models.ngsi_v2.context import ContextEntity
-from filip.clients.ngsi_v2 import ContextBrokerClient, IoTAClient
-from filip.models import FiwareHeader
-from filip.semantics.semantics_models import \
-    InstanceIdentifier, SemanticClass, InstanceHeader, Datatype, DataField, \
-    RelationField, SemanticIndividual, SemanticDeviceClass, CommandField, \
-    Command, DeviceAttributeField, DeviceAttribute
-from filip.utils.simple_ql import QueryString
-
-
-logger = logging.getLogger('semantics')
-
-
-class InstanceRegistry(BaseModel):
-    """
-    Holds all the references to the local SemanticClass instances.
-    The instance registry is a global object, that is directly inject in the
-    SemanticClass constructor over the SemanticsManager
-    """
-    _registry: Dict[InstanceIdentifier, 'SemanticClass'] = {}
-    """ Dict of the references to the local SemanticClass instances. 
-        Instances are saved with their identifier as key """
-
-    _deleted_identifiers: List[InstanceIdentifier] = []
-    """List of all identifiers that were deleted"""
-
-    def delete(self, instance: 'SemanticClass'):
-        """Delete an instance from the registry
-
-        Args:
-            instance(SemanticClass): Instance to remove
-
-        Raises:
-           KeyError, if identifier unknown
-
-        Returns:
-            None
-        """
-        identifier = instance.get_identifier()
-        if not self.contains(identifier):
-            raise KeyError(f"Identifier {identifier} unknown, "
-                           f"can not delete")
-
-        # If instance was loaded from Fiware it has an old_state.
-        # if that is the case, we need to note that we have deleted the instance
-        # to delete it on save, and do not load it again from Fiware
-
-        if instance.old_state.state is not None:
-            self._deleted_identifiers.append(identifier)
-
-        del self._registry[identifier]
-
-    def instance_was_deleted(self, identifier: InstanceIdentifier) -> bool:
-        """
-        Check if an instance was deleted
-
-        Args:
-            identifier (InstanceIdentifier): Identifier of instance to check
-
-        Returns:
-            bool
-        """
-        return identifier in self._deleted_identifiers
-
-    def register(self, instance: 'SemanticClass'):
-        """
-        Register a new instance of a SemanticClass in the registry
-
-        Args:
-            instance(SemanticClass):  Instance to be registered
-        Raises:
-            AttributeError: if Instance is already registered
-        """
-        identifier = instance.get_identifier()
-
-        if identifier in self._registry:
-            raise AttributeError('Instance already exists')
-        else:
-            self._registry[identifier] = instance
-
-    def get(self, identifier: InstanceIdentifier) -> 'SemanticClass':
-        """Retrieve an registered instance with its identifier
-
-        Args:
-            identifier(InstanceIdentifier): identifier belonging to instance
-        Returns:
-            SemanticClass
-        """
-        return self._registry[identifier]
-
-    def contains(self, identifier: InstanceIdentifier) -> bool:
-        """Test if an identifier is registered
-
-        Args:
-            identifier(InstanceIdentifier): identifier belonging to instance
-        Returns:
-            bool, True if registered
-        """
-        return identifier in self._registry
-
-    def get_all(self) -> List['SemanticClass']:
-        """Get all registered instances
-
-        Returns:
-            List[SemanticClass]
-        """
-        return list(self._registry.values())
-
-    def get_all_deleted_identifiers(self) -> List['InstanceIdentifier']:
-        """
-        Get all identifiers that were deleted by the user
-
-        Returns:
-            List[InstanceIdentifier]
-        """
-        return self._deleted_identifiers
-
-    def save(self) -> str:
-        """
-        Save the state of the registry out of a json string.
-
-        Returns:
-             str, json string of registry state
-        """
-        res = {'instances': [], 'deleted_identifiers': []}
-
-        for identifier, instance in self._registry.items():
-            old_state = None
-            if instance.old_state.state is not None:
-                old_state = instance.old_state.state.model_dump_json()
-            instance_dict = {
-                "entity": instance.build_context_entity().model_dump_json(),
-                "header": instance.header.model_dump_json(),
-                "old_state": old_state
-            }
-            res['instances'].append(instance_dict)
-
-        for identifier in self._deleted_identifiers:
-            res['deleted_identifiers'].append(identifier.model_dump_json())
-
-        return json.dumps(res, indent=4)
-
-    def clear(self):
-        """Clear the local state"""
-        self._registry.clear()
-        self._deleted_identifiers.clear()
-
-    def load(self, json_string: str, semantic_manager: 'SemanticsManager'):
-        """
-        Load the state of the registry out of a json string. The current
-        state will be discarded
-
-        Args:
-            json_string (str): State expressed as json string
-            semantic_manager (SemanticsManager): manager to which registry
-                belongs
-        Returns:
-             None
-        """
-        self.clear()
-
-        save = json.loads(json_string)
-        for instance_dict in save['instances']:
-            entity_json = instance_dict['entity']
-            header = InstanceHeader.model_validate(instance_dict['header'])
-
-            context_entity = ContextEntity.model_validate(entity_json)
-
-            instance = semantic_manager._context_entity_to_semantic_class(
-                context_entity, header)
-
-            if instance_dict['old_state'] is not None:
-                instance.old_state.state = \
-                    ContextEntity.model_validate(instance_dict['old_state'])
-
-            self._registry[instance.get_identifier()] = instance
-
-        for identifier in save['deleted_identifiers']:
-            self._deleted_identifiers.append(
-                InstanceIdentifier.model_validate(identifier))
-
-    def __hash__(self):
-        values = (hash(value) for value in self._registry.values())
-
-        return hash((frozenset(values),
-                     frozenset(self._deleted_identifiers)))
-
-
-class SemanticsManager(BaseModel):
-    """
-    The Semantic Manager is a static object that is delivered with
-    each vocabulary model export.
-
-    It provides the interface to interact with the local state and Fiware
-    """
-
-    instance_registry: InstanceRegistry = Field(
-        description="Registry managing the local state"
-    )
-    class_catalogue: Dict[str, Type[SemanticClass]] = Field(
-        default={},
-        description="Register of class names to classes"
-    )
-    datatype_catalogue: Dict[str, Dict[str, str]] = Field(
-        default={},
-        description="Register of datatype names to Dict representation of "
-                    "datatypes"
-    )
-    individual_catalogue: Dict[str, type] = Field(
-        default={},
-        description="Register of individual names to their classes"
-    )
-
-    default_header: InstanceHeader = Field(
-        default=InstanceHeader(),
-        description="Default header that each new instance receives if it "
-                    "does not specify an own header"
-    )
-
-    @staticmethod
-    def get_client(instance_header: InstanceHeader) \
-            -> ContextBrokerClient:
-        """Get the correct ContextBrokerClient to be used with the given header
-
-        Args:
-            instance_header (InstanceHeader): Header to be used with client
-        Returns:
-            ContextBrokerClient
-        """
-        if instance_header.ngsi_version == NgsiVersion.v2:
-            return ContextBrokerClient(
-                url=instance_header.cb_url,
-                fiware_header=instance_header.get_fiware_header())
-        else:
-            # todo LD
-            raise Exception("FiwareVersion not yet supported")
-
-    @staticmethod
-    def get_iota_client(instance_header: InstanceHeader) -> IoTAClient:
-        """Get the correct IotaClient to be used with the given header
-
-        Args:
-            instance_header (InstanceHeader): Header to be used with client
-        Returns:
-            IoTAClient
-        """
-        if instance_header.ngsi_version == NgsiVersion.v2:
-            return IoTAClient(
-                url=instance_header.iota_url,
-                fiware_header=instance_header.get_fiware_header())
-        else:
-            # todo LD
-            raise Exception("FiwareVersion not yet supported")
-
-    def _context_entity_to_semantic_class(
-            self,
-            entity: ContextEntity,
-            header: InstanceHeader) -> SemanticClass:
-
-        """Converts a ContextEntity to a SemanticClass
-
-        Args:
-            entity (ContextEntity): entity to convert
-            header (InstanceHeader): Header of the new instance
-
-        Returns:
-            SemanticClass or SemanticDeviceClass
-        """
-
-        class_name = entity.type
-
-        class_: Type = self.get_class_by_name(class_name)
-
-        if not self.is_class_name_an_device_class(class_name):
-
-            loaded_class: SemanticClass = class_(id=entity.id,
-                                                 header=header,
-                                                 enforce_new=True)
-        else:
-            loaded_class: SemanticDeviceClass = class_(id=entity.id,
-                                                       header=header,
-                                                       enforce_new=True)
-
-        loaded_class.old_state.state = entity
-
-        # load values of class from the context_entity into the instance
-        for field in loaded_class.get_fields():
-            field.clear()  # remove default values, from hasValue relations
-            field_name = field.name
-            entity_attribute = entity.get_attribute(field_name)
-            if entity_attribute is None:
-                raise Exception(
-                    f"The corresponding entity for ({entity.id},{entity.type}) "
-                    f"in Fiware misses a field that "
-                    f"is required by the class_model: {field_name}. The "
-                    f"fiware state and the used vocabulary models are not "
-                    f"compatible")
-
-            entity_field_value = entity.get_attribute(field_name).value
-
-            if isinstance(entity_field_value, List):
-                values = entity_field_value
-            else:
-                values = [entity_field_value]
-
-            for value in values:
-                converted_value = self._convert_value_fitting_for_field(
-                    field, value)
-                if isinstance(field, RelationField):
-                    # we need to bypass the main setter, as it expects an
-                    # instance and we do not want to load the instance if it
-                    # is not used
-                    field._set.add(converted_value)
-                else:
-                    field.add(converted_value)
-
-        # load references into instance
-        references_attribute = entity.get_attribute("referencedBy")
-        references = references_attribute.value
-
-        for identifier_str, prop_list in references.items():
-            for prop in prop_list:
-                loaded_class.add_reference(
-                    InstanceIdentifier.model_validate_json(identifier_str.replace(
-                        "---", ".")), prop)
-
-        # load metadata
-        metadata_dict = entity.get_attribute("metadata").value
-        loaded_class.metadata.name = metadata_dict['name']
-        loaded_class.metadata.comment = metadata_dict['comment']
-
-        # load device_settings into instance, if instance is a device
-        if isinstance(loaded_class, SemanticDeviceClass):
-            settings_attribute = entity.get_attribute("deviceSettings")
-            device_settings = DeviceSettings.model_validate(settings_attribute.value)
-
-            for key, value in device_settings.model_dump().items():
-                loaded_class.device_settings.__setattr__(key, value)
-
-        return loaded_class
-
-    @staticmethod
-    def _convert_value_fitting_for_field(field, value):
-        """
-        Converts a given value into the correct format for the given field
-
-        Args:
-            field: SemanticField
-            value: Value to convert
-
-        Returns:
-            converted value
-        """
-        if isinstance(field, DataField):
-            return value
-        elif isinstance(field, RelationField):
-            # convert json to Identifier, inject identifier in Relation,
-            # the class will be hotloaded if the value in the is
-            # relationship is accessed
-
-            if not isinstance(value, dict):  # is an individual
-                return value
-            else:  # is an instance_identifier
-                # we need to replace back --- with . that we switched,
-                # as a . is not allowed in the dic in Fiware
-                return InstanceIdentifier.model_validate_json(
-                    str(value).replace("---", ".").replace("'", '"'))
-
-        elif isinstance(field, CommandField):
-            if isinstance(value, Command):
-                return value
-            # if loading local state, the wrong string delimters are used,
-            # and the string is not automatically converted to a dict
-            if not isinstance(value, dict):
-                value = json.loads(value.replace("'", '"'))
-
-            return Command(name=value['name'])
-        elif isinstance(field, DeviceAttributeField):
-
-            # if loading local state, the wrong string delimters are used,
-            # and the string is not automatically converted to a dict
-
-            if isinstance(value, DeviceAttribute):
-                return value
-            if not isinstance(value, dict):
-                value = json.loads(value.replace("'", '"'))
-
-            return DeviceAttribute(
-                name=value['name'],
-                attribute_type=value[
-                    "attribute_type"]
-            )
-
-    def get_class_by_name(self, class_name: str) -> Type[SemanticClass]:
-        """
-        Get the class object by its type in string form
-
-        Args:
-            class_name (str)
-
-        Raises:
-            KeyError: if class_name not registered as a SemanticClass
-
-        Returns:
-            Type
-        """
-        return self.class_catalogue[class_name]
-
-    def is_class_name_an_device_class(self, class_name: str) -> bool:
-        """
-        Test if the name/type of a class belongs to a SemanticDeviceClass
-
-        Args:
-            class_name (str): class name to check
-
-        Returns:
-            bool, True if belongs to a SemanticDeviceClass
-        """
-        class_type = self.get_class_by_name(class_name)
-        return isinstance(class_type, SemanticDeviceClass)
-
-    def is_local_state_valid(self, validate_rules: bool = True) -> (bool, str):
-        """
-        Check if the local state is valid and can be saved.
-
-        Args:
-            validate_rules (bool): If true Rulefields are validated
-
-        Returns:
-            (bool, str): (Is valid?, Message)
-        """
-
-        if validate_rules:
-            for instance in self.instance_registry.get_all():
-                if isinstance(instance, Individual):
-                    continue
-                if not instance.are_rule_fields_valid():
-                    return (
-                        False,
-                        f"SemanticEntity {instance.id} of type"
-                        f"{instance.get_type()} has unfulfilled fields " 
-                        f"{[f.name for f in instance.get_invalid_rule_fields()]}."
-                    )
-
-        for instance in self.instance_registry.get_all():
-            if isinstance(instance, SemanticDeviceClass):
-                if instance.device_settings.transport is None:
-                    return (
-                        False,
-                        f"Device {instance.id} of type {instance.get_type()} " 
-                        f"needs to be given an transport setting."
-                    )
-        return True, "State is valid"
-
-    def save_state(self, assert_validity: bool = True):
-        """
-        Save the local state completely to Fiware.
-
-        Args:
-            assert_validity (bool): It true an error is raised if the
-            RuleFields of one instance are invalid
-
-        Raises:
-            AssertionError: If a device endpoint or transport is not defined
-
-        Returns:
-            None
-        """
-        (valid, msg) = self.is_local_state_valid(validate_rules=assert_validity)
-
-        if not valid:
-            raise AssertionError(f"{msg}. Local state was not saved")
-
-        # delete all instance that were loaded from Fiware and then deleted
-        # wrap in try, as the entity could have been deleted by a third party
-        for identifier in self.instance_registry.get_all_deleted_identifiers():
-
-            # we need to handle devices and normal classes with different
-            # clients
-
-            client = self.get_client(instance_header=identifier.header)
-            iota_client = self.get_iota_client(
-                instance_header=identifier.header)
-            try:
-                client.delete_entity(
-                    entity_id=identifier.id,
-                    entity_type=identifier.type,
-                    delete_devices=True,
-                    iota_client=iota_client)
-            except requests.RequestException:
-                raise
-
-            client.close()
-
-        # merge with live state
-        for instance in self.instance_registry.get_all():
-            self.merge_local_and_live_instance_state(instance)
-
-        # save, patch all local instances
-        for instance in self.instance_registry.get_all():
-            cb_client = self.get_client(instance_header=instance.header)
-            if not isinstance(instance, SemanticDeviceClass):
-                # it is important that we patch the values else the
-                # references field would reach an invalid state if we worked
-                # in parallel on an instance
-                cb_client.patch_entity(instance.build_context_entity(),
-                                       instance.old_state.state)
-            else:
-                iota_client = self.get_iota_client(
-                    instance_header=instance.header)
-                iota_client.patch_device(
-                    device=instance.build_context_device(),
-                    patch_entity=True,
-                    cb_client=cb_client)
-                iota_client.close()
-            cb_client.close()
-        # update old_state
-        for instance in self.instance_registry.get_all():
-            instance.old_state.state = instance.build_context_entity()
-
-    def load_instance(self, identifier: InstanceIdentifier) -> SemanticClass:
-        """
-        Get the instance with the given identifier. It is either loaded from
-        local state or retrieved from fiware
-
-        Args:
-            identifier (InstanceIdentifier): Identifier to load
-
-        Returns:
-            SemanticClass
-        """
-
-        if self.instance_registry.contains(identifier=identifier):
-            return self.instance_registry.get(identifier=identifier)
-        else:
-            client = self.get_client(identifier.header)
-
-            entity = client.get_entity(entity_id=identifier.id,
-                                       entity_type=identifier.type)
-            client.close()
-
-            logger.info(f"Instance ({identifier.id}, {identifier.type}) "
-                        f"loaded from Fiware({identifier.header.cb_url}"
-                        f", {identifier.header.service}"
-                        f"{identifier.header.service_path})")
-            return self._context_entity_to_semantic_class(
-                entity=entity,
-                header=identifier.header)
-
-    def does_instance_exists(self, identifier: InstanceIdentifier) -> bool:
-        """
-        Check if an instance with the given identifier already exists in
-        local state or in Fiware
-
-        Args:
-            identifier (InstanceIdentifier): Identifier to check
-
-        Returns:
-            bool, true if exists
-        """
-
-        if self.instance_registry.contains(identifier=identifier):
-            return True
-        elif self.was_instance_deleted(identifier):
-            return False
-        else:
-            client = self.get_client(identifier.header)
-            return client.does_entity_exist(entity_id=identifier.id,
-                                            entity_type=identifier.type)
-
-    def was_instance_deleted(self, identifier: InstanceIdentifier) -> bool:
-        """
-        Check if the instance with the given identifier was deleted.
-
-        Args:
-            identifier (InstanceIdentifier): Identifier to check
-
-        Returns:
-            bool, true if deleted
-        """
-        return self.instance_registry.instance_was_deleted(identifier)
-
-    def get_instance(self, identifier: InstanceIdentifier) -> SemanticClass:
-        """
-        Get the instance with the given identifier. It is either loaded from
-        local state or retrieved from fiware
-
-        Args:
-            identifier (InstanceIdentifier): Identifier to load
-
-        Returns:
-            SemanticClass
-        """
-        return self.load_instance(identifier)
-
-    def get_all_local_instances(self) -> List[SemanticClass]:
-        """
-        Retrieve all SemanticClass instances in the local state
-
-        Returns:
-            List[SemanticClass]
-        """
-        return self.instance_registry.get_all()
-
-    def get_all_local_instances_of_class(self,
-                                         class_: Optional[type] = None,
-                                         class_name: Optional[str] = None,
-                                         get_subclasses: bool = True) \
-            -> List[SemanticClass]:
-        """
-        Retrieve all instances of a SemanitcClass from Local Storage
-
-        Args:
-            class_ (type):
-                Type of classes to retrieve
-            class_name (str):
-                Name of type of classes to retrieve as string
-            get_subclasses (bool):
-                If true also all instances of subclasses
-                of given class are returned
-
-        Raises:
-            AssertionError: If class_ and class_name are both None or non None
-
-        Returns:
-            List[SemanticClass]
-        """
-
-        assert class_ is None or class_name is None, \
-            "Only one parameter is allowed"
-        assert class_ is not None or class_name is not None, \
-            "One parameter is required"
-
-        if class_ is not None:
-            class_name = class_.__name__
-        else:
-            class_ = self.get_class_by_name(class_name)
-
-        res = []
-        for instance in self.instance_registry.get_all():
-            if not get_subclasses:
-                if instance.get_type() == class_name:
-                    res.append(instance)
-            else:
-                if isinstance(instance, class_):
-                    res.append(instance)
-        return res
-
-    def load_instances_from_fiware(
-            self,
-            fiware_header: FiwareHeader,
-            fiware_version: NgsiVersion,
-            cb_url: str,
-            iota_url: str,
-            entity_ids: Optional[List[str]] = None,
-            entity_types: Optional[List[str]] = None,
-            id_pattern: str = None,
-            type_pattern: str = None,
-            q: Union[str, QueryString] = None,
-            limit: int = inf,
-    ) -> List[SemanticClass]:
-        """
-        Loads the instances of given types or ids from Fiware into the local
-        state and returns the loaded instances
-
-        Args:
-            fiware_header (FiwareHeader): Fiware location to load
-            fiware_version (NgsiVersion): Used fiware version
-            cb_url (str): URL of the ContextBroker
-            iota_url (str): URL of the IotaBroker
-            entity_ids (Optional[str]): List of the entities ids that
-                should be loaded
-            entity_types (Optional[str]): List of the entities types that
-                should be loaded
-            id_pattern: A correctly formatted regular expression. Retrieve
-                entities whose ID matches the regular expression. Incompatible
-                with id, e.g. ngsi-ld.* or sensor.*
-            type_pattern: A correctly formatted regular expression. Retrieve
-                entities whose type matches the regular expression.
-                Incompatible with type, e.g. room.*
-            q (SimpleQuery): A query expression, composed of a list of
-                statements separated by ;, i.e.,
-                q=statement1;statement2;statement3. See Simple Query
-                Language specification. Example: temperature>40.
-            limit: Limits the number of entities to be retrieved Example: 20
-
-        Raises:
-           ValueError: if both entity_types and entity_ids are given
-           ValueError: if Retrival of Context-entities fails
-        Returns:
-             List[SemanticClass]
-        """
-
-        header: InstanceHeader = InstanceHeader(
-            service=fiware_header.service,
-            service_path=fiware_header.service_path,
-            cb_url=cb_url,
-            iota_url=iota_url,
-            ngsi_version=fiware_version
-        )
-
-        client = self.get_client(header)
-
-        entities = client.get_entity_list(entity_ids=entity_ids,
-                                          entity_types=entity_types,
-                                          id_pattern=id_pattern,
-                                          type_pattern=type_pattern,
-                                          q=q,
-                                          limit=limit)
-        client.close()
-
-        return [self._context_entity_to_semantic_class(e, header)
-                for e in entities]
-
-    def get_entity_from_fiware(self, instance_identifier: InstanceIdentifier) \
-            -> ContextEntity:
-        """
-        Retrieve the current entry of an instance in Fiware
-
-        Args:
-            instance_identifier (InstanceIdentifier): Identifier to load
-
-        Raises:
-            Exception, if Entity is not present
-
-        Returns:
-              ContextEntity
-        """
-        client = self.get_client(instance_identifier.header)
-
-        return client.get_entity(entity_id=instance_identifier.id,
-                                 entity_type=instance_identifier.type)
-
-    def load_instances(
-            self,
-            identifiers: List[InstanceIdentifier]) -> List[SemanticClass]:
-        """
-        Load all instances, if no local state of it exists it will get taken
-        from Fiware and registered locally
-
-        Args:
-            identifiers List[InstanceIdentifier]: Identifiers of instances
-                that should be loaded
-        Raises:
-            Exception, if one Entity is not present
-
-        Returns:
-           List[SemanticClass]
-        """
-
-        return [self.load_instance(iden) for iden in identifiers]
-
-    def set_default_header(self, header: InstanceHeader):
-        """
-        Set the default header, which all new instance that does not specify a
-        header in the constructor receives
-
-        Args:
-            header (InstanceHeader): new default header
-
-        Returns:
-            None
-        """
-        self.default_header = copy.deepcopy(header)
-
-    def get_default_header(self) -> InstanceHeader:
-        """
-        Instance header is read-only, therefore giving back a copy is
-        theoretically not needed, but it is cleaner that all instance has an
-        own header object that is not shared
-        """
-        return copy.deepcopy(self.default_header)
-
-    def get_datatype(self, datatype_name: str) -> Datatype:
-        """
-        Get a Datatype object with the name as key as specified in the model
-
-        Args:
-            datatype_name (str): key label of the datatype
-
-        Returns:
-            Datatype
-        """
-        return Datatype.model_validate(self.datatype_catalogue[datatype_name])
-
-    def get_individual(self, individual_name: str) -> SemanticIndividual:
-        """
-        Get an individual by its name
-
-        Args:
-            individual_name (str)
-        Raises:
-            KeyError, if name not registered
-        Returns:
-            SemanticIndividual
-        """
-        return self.individual_catalogue[individual_name]()
-
-    def save_local_state_as_json(self) -> str:
-        """
-        Save the local state with all made changes as json string
-
-        Returns:
-            Json String, containing all information about the local state
-        """
-        return self.instance_registry.save()
-
-    def load_local_state_from_json(self, json: str):
-        """
-        Loads the local state from a json string. The current local state gets
-        discarded
-
-        Raises:
-            Error, if not a correct json string
-
-        """
-        self.instance_registry.load(json, self)
-
-    def visualize_local_state(
-            self,
-            display_individuals_rule: str = "ALL"
-            ):
-        """
-        Visualise all instances in the local state in a network graph that
-        shows which instances reference each other over which fields
-
-        On execution of the methode a temporary image file is created and
-        automatically displayed in the standard image viewing software of the
-        system
-
-        Args:
-            display_individuals_rule (rule):
-                If:
-                "USED": Show only Individuals
-                "ALL": Display all known Individuals
-                "NONE": Display no Individuals
-                that are connected to at least one instance
-                else: Show all individuals
-
-        Raises:
-            ValueError: if display_individuals_rule is invalid
-        """
-
-        if not display_individuals_rule == "ALL" and \
-            not display_individuals_rule == "NONE" and \
-            not display_individuals_rule == "USED":
-
-            raise ValueError(f"Invalid parameter {display_individuals_rule}")
-
-        import igraph
-        g = igraph.Graph(directed=True)
-
-        for instance in self.get_all_local_instances():
-            g.add_vertex(name=instance.id,
-                         label=f"\n\n\n {instance.get_type()} \n {instance.id}",
-                         color="green")
-
-        used_individuals_names: Set[str] = set()
-        for instance in self.get_all_local_instances():
-            for field in instance.get_relation_fields():
-                for linked in field.get_all():
-                    if isinstance(linked, SemanticClass):
-                        g.add_edge(instance.id, linked.id, name=field.name)
-                        # g.es[-1]["name"] = field.name
-
-                    elif isinstance(linked, SemanticIndividual):
-                        if not display_individuals_rule == "NONE":
-                            g.add_edge(instance.id, linked.get_name())
-                            used_individuals_names.add(linked.get_name())
-
-        if display_individuals_rule == "ALL":
-            used_individuals_names.update(self.individual_catalogue.keys())
-        for individual in [self.get_individual(name) for name in
-                           used_individuals_names]:
-            g.add_vertex(label=f"\n\n\n{individual.get_name()}",
-                         name=individual.get_name(),
-                         color="blue")
-
-        layout = g.layout("fr")
-        visual_style = {"vertex_size": 20,
-                        "vertex_color": g.vs["color"],
-                        "vertex_label": g.vs["label"],
-                        "edge_label": g.es["name"],
-                        "layout": layout,
-                        "bbox": (len(g.vs) * 50, len(g.vs) * 50)}
-
-        igraph.plot(g, **visual_style)
-
-    def generate_cytoscape_for_local_state(
-            self,
-            display_only_used_individuals: bool = True
-            ):
-        """
-        Generate a graph definition that can be loaded into a cytoscape
-        visualisation tool, that describes the complete current local state.
-
-        For the graph layout COLA is recommended with an edge length of 150
-
-        Args:
-            display_only_used_individuals (bool):
-                If true(default): Show only Individuals that are connected to
-                at least one instance
-                else: Show all individuals
-
-        Returns:
-            Tupel of elements and stylesheet:
-                elements is a dict:
-                {"nodes": NODE_DEFINITIONS, "edges": EDGE_DEFINITIONS}
-                stylesheet is a list containing all the graph styles
-        """
-
-        # graph design
-        stylesheet = [
-            {
-                'selector': 'node',
-                'style': {
-                    'label': 'data(label)',
-                    'z-index': 9999
-                }
-            },
-            {
-                'selector': 'edge',
-                'style': {
-                    'curve-style': 'bezier',
-                    'target-arrow-color': 'black',
-                    'target-arrow-shape': 'triangle',
-                    'line-color': 'black',
-                    "opacity": 0.45,
-                    'z-index': 5000,
-                }
-            },
-            {
-                'selector': '.center',
-                'style': {
-                    'shape': 'rectangle',
-                    'background-color': 'black'
-                }
-            },
-            {
-                'selector': '.individual',
-                'style': {
-                    'shape': 'circle',
-                    'background-color': 'orange'
-                }
-            },
-            {
-                'selector': '.instance',
-                'style': {
-                    'shape': 'circle',
-                    'background-color': 'green'
-                }
-            },
-            {
-                'selector': '.collection',
-                'style': {
-                    'shape': 'triangle',
-                    'background-color': 'gray'
-                }
-            }
-        ]
-
-        nodes = []
-        edges = []
-
-        used_individual_names = set()
-        if not display_only_used_individuals:
-            used_individual_names.update(self.individual_catalogue.keys())
-
-        def get_node_id(item: Union[SemanticClass, SemanticIndividual]) -> str:
-            """
-            Get the id to be used in the graph for an item
-
-            Args:
-                item (Union[SemanticClass, SemanticIndividual]): Item to get
-                                                                    ID for
-
-            Returns:
-                str - ID
-            """
-            if isinstance(item, SemanticIndividual):
-                return item.get_name()
-            else:
-                return item.get_identifier().model_dump_json()
-
-        for instance in self.get_all_local_instances():
-            label = f'({instance.get_type()}){instance.metadata.name}'
-            nodes.append({'data': {'id': get_node_id(instance),
-                                   'label': label,
-                                   'parent_id': '',
-                                   'classes': "instance item"},
-                          'classes': "instance item"})
-
-        for instance in self.get_all_local_instances():
-
-            for rel_field in instance.get_relation_fields():
-
-                values = rel_field.get_all()
-                for v in values:
-                    if isinstance(v, SemanticIndividual):
-                        used_individual_names.add(v.get_name())
-
-                if len(values) == 0:
-                    pass
-                elif len(values) == 1:
-                    edge_id = uuid.uuid4().hex
-                    edges.append({'data': {'id': edge_id,
-                                           'source': get_node_id(instance),
-                                           'target': get_node_id(values[0])}})
-                    edge_name = rel_field.name
-                    stylesheet.append({'selector': '#' + edge_id,
-                                       'style': {'label': edge_name}})
-                else:
-                    edge_id = uuid.uuid4().hex
-                    node_id = uuid.uuid4().hex
-                    nodes.append({'data': {'id': node_id,
-                                           'label': '',
-                                           'parent_id': '',
-                                           'classes': "collection"},
-                                  'classes': "collection"})
-
-                    edges.append({'data': {'id': edge_id,
-                                           'source': get_node_id(instance),
-                                           'target': node_id}})
-                    edge_name = rel_field.name
-                    stylesheet.append({'selector': '#' + edge_id,
-                                       'style': {'label': edge_name}})
-
-                    for value in values:
-                        edge_id = uuid.uuid4().hex
-                        edges.append({'data': {'id': edge_id,
-                                               'source': node_id,
-                                               'target': get_node_id(value)}})
-
-        for individual_name in used_individual_names:
-            nodes.append({'data': {'id': individual_name,
-                                   'label': individual_name, 'parent_id': '',
-                                   'classes': "individual item"},
-                          'classes': "individual item"})
-
-        elements = {'nodes': nodes, 'edges': edges}
-
-        return elements, stylesheet
-
-    def merge_local_and_live_instance_state(self, instance: SemanticClass) ->\
-            None:
-        """
-        The live state of the instance is fetched from Fiware (if it exists)
-        and the two states are merged:
-
-        For each Field:
-        - each added value (compared to old_state) is added to
-        the live state
-        - each deleted value (compared to old_state) is removed from
-        the live state
-
-        For each Device Settings (if instance is device):
-        - If the device setting changed (compared to old_state) the live
-        setting is overwritten
-
-        For each Reference:
-        - each added value (compared to old_state) is added to
-        the live state
-        - each deleted value (compared to old_state) is removed from
-        the live state
-
-        The new state is directly saved in the instance
-
-        Args:
-              instance (SemanticClass): instanced to be treated
-        """
-
-        def converted_attribute_values(field, attribute) -> Set:
-            return {self._convert_value_fitting_for_field(field, value) for
-                    value in attribute.value}
-
-        def _get_added_and_removed_values(
-                old_values: Union[List, Set, Any],
-                current_values: Union[List, Set, Any]) -> (Set, Set):
-
-            old_set = set(old_values)
-            current_set = set(current_values)
-            added_values = set()
-            removed_values = set()
-
-            # remove deleted values from live state, it can be that the value
-            # was also deleted in the live state
-            for value in old_set:
-                if value not in current_set:
-                    removed_values.add(value)
-
-            # add added values
-            for value in current_set:
-                if value not in old_set:
-                    added_values.add(value)
-
-            return added_values, removed_values
-
-        # instance is new. Save it as is
-        client = self.get_client(instance.header)
-        if not client.does_entity_exist(entity_id=instance.id,
-                                        entity_type=instance.get_type()):
-            return
-
-        client = self.get_client(instance.header)
-        live_entity = client.get_entity(entity_id=instance.id,
-                                        entity_type=instance.get_type())
-        client.close()
-
-        current_entity = instance.build_context_entity()
-        old_entity = instance.old_state.state
-
-        # ------merge fields-----------------------------------------------
-        # instance exists already, add all locally added and delete all
-        # locally deleted values to the/from the live_state
-
-        for field in instance.get_fields():
-            # live_values = set(live_entity.get_attribute(field.name).value)
-            live_values = converted_attribute_values(
-                field, live_entity.get_attribute(field.name))
-            old_values = converted_attribute_values(
-                field, old_entity.get_attribute(field.name))
-            current_values = converted_attribute_values(
-                field, current_entity.get_attribute(field.name))
-
-            (added_values, deleted_values) = \
-                _get_added_and_removed_values(
-                    old_values, current_values
-                    # old_entity.get_attribute(field.name).value,
-                    # current_entity.get_attribute(field.name).value
-                )
-
-            for value in added_values:
-                live_values.add(value)
-            for value in deleted_values:
-                if value in live_values:
-                    live_values.remove(value)
-
-            new_values = list(live_values)
-            # update local stated with merged result
-            field._set.clear()  # very important to not use field.clear,
-                                 # as that methode would also delete references
-            for value in new_values:
-                converted_value = self._convert_value_fitting_for_field(
-                    field, value)
-                field._set.add(converted_value)
-
-        # ------merge references-----------------------------------------------
-        merged_references: Dict = live_entity.get_attribute(
-            "referencedBy").value
-        current_references: Dict = current_entity.get_attribute(
-            "referencedBy").value
-        old_references: Dict = old_entity.get_attribute(
-            "referencedBy").value
-
-        keys = set(current_references.keys())
-        keys.update(old_references.keys())
-
-        for key in keys:
-            current_values = []
-            old_values = []
-            if key in current_references:
-                current_values = current_references[key]
-            if key in old_references:
-                old_values = old_references[key]
-
-            (added_values, deleted_values) = _get_added_and_removed_values(
-                current_values=current_values, old_values=old_values)
-
-            # ensure the merged state has each key
-            if key not in merged_references.keys():
-                merged_references[key] = []
-
-            # add, added values that did not exist before
-            for value in added_values:
-                if value not in merged_references[key]:
-                    merged_references[key].append(value)
-
-            # delete deleted values if they were not already deleted
-            for value in deleted_values:
-                if value in merged_references[key]:
-                    merged_references[key].remove(value)
-
-            # delete all keys that point to empty lists
-            keys_to_delete = []
-            for key, value in merged_references.items():
-                if len(value) == 0:
-                    keys_to_delete.append(key)
-            for key in keys_to_delete:
-                del merged_references[key]
-
-        # save merged references
-        instance.references.clear()
-        for key, value in merged_references.items():
-            # replace back the protected . (. not allowed in keys in fiware)
-            instance.references[InstanceIdentifier.model_validate_json(key.replace(
-                "---", "."))] = value
-
-        # ------merge device settings----------------------------------------
-        if isinstance(instance, SemanticDeviceClass):
-            old_settings = old_entity.get_attribute("deviceSettings").value
-            current_settings = \
-                current_entity.get_attribute("deviceSettings").value
-            new_settings = live_entity.get_attribute("deviceSettings").value
-
-            # keys are always the same
-            # override live state with local changes
-            for key in old_settings:
-                if old_settings[key] is not current_settings[key]:
-                    new_settings[key] = current_settings[key]
-                instance.device_settings.__setattr__(key, new_settings[key])
-
-    def find_fitting_model(self, search_term: str, limit: int = 5) -> List[str]:
-        """
-        Find a fitting model by entering a search_term (e.g.: Sensor).
-        The methode returns a selection from up-to [limit] possibly fitting
-        model names. If a model name was selected from the proposition the
-        model can be retrieved with the methode:
-        "get_class_by_name(selectedName)"
-
-        Args:
-            search_term (str): search term to find a model by name
-            limit (int): Max Number of suggested results (default: 5)
-
-        Returns:
-            List[str], containing 0 to [limit] ordered propositions (best first)
-        """
-        class_names = list(self.class_catalogue.keys())
-        suggestions = [item[0] for item in process.extract(
-            query=search_term.casefold(),
-            choices=class_names,
-            score_cutoff=50,
-            limit=limit)]
-
-        return suggestions
+"""Manages the local state of the semantic instances"""
+
+import copy
+import json
+import logging
+import uuid
+from math import inf
+
+import requests
+
+from typing import Optional, Dict, Type, List, Any, Union, Set
+from pydantic import BaseModel, Field
+from rapidfuzz import process
+
+from filip.models.base import NgsiVersion
+from filip.models.ngsi_v2.iot import DeviceSettings
+from filip.semantics.vocabulary import Individual
+from filip.models.ngsi_v2.context import ContextEntity
+from filip.clients.ngsi_v2 import ContextBrokerClient, IoTAClient
+from filip.models import FiwareHeader
+from filip.semantics.semantics_models import \
+    InstanceIdentifier, SemanticClass, InstanceHeader, Datatype, DataField, \
+    RelationField, SemanticIndividual, SemanticDeviceClass, CommandField, \
+    Command, DeviceAttributeField, DeviceAttribute
+from filip.utils.simple_ql import QueryString
+
+
+logger = logging.getLogger('semantics')
+
+
+class InstanceRegistry(BaseModel):
+    """
+    Holds all the references to the local SemanticClass instances.
+    The instance registry is a global object, that is directly inject in the
+    SemanticClass constructor over the SemanticsManager
+    """
+    _registry: Dict[InstanceIdentifier, 'SemanticClass'] = {}
+    """ Dict of the references to the local SemanticClass instances. 
+        Instances are saved with their identifier as key """
+
+    _deleted_identifiers: List[InstanceIdentifier] = []
+    """List of all identifiers that were deleted"""
+
+    def delete(self, instance: 'SemanticClass'):
+        """Delete an instance from the registry
+
+        Args:
+            instance(SemanticClass): Instance to remove
+
+        Raises:
+           KeyError, if identifier unknown
+
+        Returns:
+            None
+        """
+        identifier = instance.get_identifier()
+        if not self.contains(identifier):
+            raise KeyError(f"Identifier {identifier} unknown, "
+                           f"can not delete")
+
+        # If instance was loaded from Fiware it has an old_state.
+        # if that is the case, we need to note that we have deleted the instance
+        # to delete it on save, and do not load it again from Fiware
+
+        if instance.old_state.state is not None:
+            self._deleted_identifiers.append(identifier)
+
+        del self._registry[identifier]
+
+    def instance_was_deleted(self, identifier: InstanceIdentifier) -> bool:
+        """
+        Check if an instance was deleted
+
+        Args:
+            identifier (InstanceIdentifier): Identifier of instance to check
+
+        Returns:
+            bool
+        """
+        return identifier in self._deleted_identifiers
+
+    def register(self, instance: 'SemanticClass'):
+        """
+        Register a new instance of a SemanticClass in the registry
+
+        Args:
+            instance(SemanticClass):  Instance to be registered
+        Raises:
+            AttributeError: if Instance is already registered
+        """
+        identifier = instance.get_identifier()
+
+        if identifier in self._registry:
+            raise AttributeError('Instance already exists')
+        else:
+            self._registry[identifier] = instance
+
+    def get(self, identifier: InstanceIdentifier) -> 'SemanticClass':
+        """Retrieve an registered instance with its identifier
+
+        Args:
+            identifier(InstanceIdentifier): identifier belonging to instance
+        Returns:
+            SemanticClass
+        """
+        return self._registry[identifier]
+
+    def contains(self, identifier: InstanceIdentifier) -> bool:
+        """Test if an identifier is registered
+
+        Args:
+            identifier(InstanceIdentifier): identifier belonging to instance
+        Returns:
+            bool, True if registered
+        """
+        return identifier in self._registry
+
+    def get_all(self) -> List['SemanticClass']:
+        """Get all registered instances
+
+        Returns:
+            List[SemanticClass]
+        """
+        return list(self._registry.values())
+
+    def get_all_deleted_identifiers(self) -> List['InstanceIdentifier']:
+        """
+        Get all identifiers that were deleted by the user
+
+        Returns:
+            List[InstanceIdentifier]
+        """
+        return self._deleted_identifiers
+
+    def save(self) -> str:
+        """
+        Save the state of the registry out of a json string.
+
+        Returns:
+             str, json string of registry state
+        """
+        res = {'instances': [], 'deleted_identifiers': []}
+
+        for identifier, instance in self._registry.items():
+            old_state = None
+            if instance.old_state.state is not None:
+                old_state = instance.old_state.state.model_dump_json()
+            instance_dict = {
+                "entity": instance.build_context_entity().model_dump_json(),
+                "header": instance.header.model_dump_json(),
+                "old_state": old_state
+            }
+            res['instances'].append(instance_dict)
+
+        for identifier in self._deleted_identifiers:
+            res['deleted_identifiers'].append(identifier.model_dump_json())
+
+        return json.dumps(res, indent=4)
+
+    def clear(self):
+        """Clear the local state"""
+        self._registry.clear()
+        self._deleted_identifiers.clear()
+
+    def load(self, json_string: str, semantic_manager: 'SemanticsManager'):
+        """
+        Load the state of the registry out of a json string. The current
+        state will be discarded
+
+        Args:
+            json_string (str): State expressed as json string
+            semantic_manager (SemanticsManager): manager to which registry
+                belongs
+        Returns:
+             None
+        """
+        self.clear()
+
+        save = json.loads(json_string)
+        for instance_dict in save['instances']:
+            entity_json = instance_dict['entity']
+            header = InstanceHeader.model_validate(instance_dict['header'])
+
+            context_entity = ContextEntity.model_validate(entity_json)
+
+            instance = semantic_manager._context_entity_to_semantic_class(
+                context_entity, header)
+
+            if instance_dict['old_state'] is not None:
+                instance.old_state.state = \
+                    ContextEntity.model_validate(instance_dict['old_state'])
+
+            self._registry[instance.get_identifier()] = instance
+
+        for identifier in save['deleted_identifiers']:
+            self._deleted_identifiers.append(
+                InstanceIdentifier.model_validate(identifier))
+
+    def __hash__(self):
+        values = (hash(value) for value in self._registry.values())
+
+        return hash((frozenset(values),
+                     frozenset(self._deleted_identifiers)))
+
+
+class SemanticsManager(BaseModel):
+    """
+    The Semantic Manager is a static object that is delivered with
+    each vocabulary model export.
+
+    It provides the interface to interact with the local state and Fiware
+    """
+
+    instance_registry: InstanceRegistry = Field(
+        description="Registry managing the local state"
+    )
+    class_catalogue: Dict[str, Type[SemanticClass]] = Field(
+        default={},
+        description="Register of class names to classes"
+    )
+    datatype_catalogue: Dict[str, Dict[str, str]] = Field(
+        default={},
+        description="Register of datatype names to Dict representation of "
+                    "datatypes"
+    )
+    individual_catalogue: Dict[str, type] = Field(
+        default={},
+        description="Register of individual names to their classes"
+    )
+
+    default_header: InstanceHeader = Field(
+        default=InstanceHeader(),
+        description="Default header that each new instance receives if it "
+                    "does not specify an own header"
+    )
+
+    @staticmethod
+    def get_client(instance_header: InstanceHeader) \
+            -> ContextBrokerClient:
+        """Get the correct ContextBrokerClient to be used with the given header
+
+        Args:
+            instance_header (InstanceHeader): Header to be used with client
+        Returns:
+            ContextBrokerClient
+        """
+        if instance_header.ngsi_version == NgsiVersion.v2:
+            return ContextBrokerClient(
+                url=instance_header.cb_url,
+                fiware_header=instance_header.get_fiware_header())
+        else:
+            # todo LD
+            raise Exception("FiwareVersion not yet supported")
+
+    @staticmethod
+    def get_iota_client(instance_header: InstanceHeader) -> IoTAClient:
+        """Get the correct IotaClient to be used with the given header
+
+        Args:
+            instance_header (InstanceHeader): Header to be used with client
+        Returns:
+            IoTAClient
+        """
+        if instance_header.ngsi_version == NgsiVersion.v2:
+            return IoTAClient(
+                url=instance_header.iota_url,
+                fiware_header=instance_header.get_fiware_header())
+        else:
+            # todo LD
+            raise Exception("FiwareVersion not yet supported")
+
+    def _context_entity_to_semantic_class(
+            self,
+            entity: ContextEntity,
+            header: InstanceHeader) -> SemanticClass:
+
+        """Converts a ContextEntity to a SemanticClass
+
+        Args:
+            entity (ContextEntity): entity to convert
+            header (InstanceHeader): Header of the new instance
+
+        Returns:
+            SemanticClass or SemanticDeviceClass
+        """
+
+        class_name = entity.type
+
+        class_: Type = self.get_class_by_name(class_name)
+
+        if not self.is_class_name_an_device_class(class_name):
+
+            loaded_class: SemanticClass = class_(id=entity.id,
+                                                 header=header,
+                                                 enforce_new=True)
+        else:
+            loaded_class: SemanticDeviceClass = class_(id=entity.id,
+                                                       header=header,
+                                                       enforce_new=True)
+
+        loaded_class.old_state.state = entity
+
+        # load values of class from the context_entity into the instance
+        for field in loaded_class.get_fields():
+            field.clear()  # remove default values, from hasValue relations
+            field_name = field.name
+            entity_attribute = entity.get_attribute(field_name)
+            if entity_attribute is None:
+                raise Exception(
+                    f"The corresponding entity for ({entity.id},{entity.type}) "
+                    f"in Fiware misses a field that "
+                    f"is required by the class_model: {field_name}. The "
+                    f"fiware state and the used vocabulary models are not "
+                    f"compatible")
+
+            entity_field_value = entity.get_attribute(field_name).value
+
+            if isinstance(entity_field_value, List):
+                values = entity_field_value
+            else:
+                values = [entity_field_value]
+
+            for value in values:
+                converted_value = self._convert_value_fitting_for_field(
+                    field, value)
+                if isinstance(field, RelationField):
+                    # we need to bypass the main setter, as it expects an
+                    # instance and we do not want to load the instance if it
+                    # is not used
+                    field._set.add(converted_value)
+                else:
+                    field.add(converted_value)
+
+        # load references into instance
+        references_attribute = entity.get_attribute("referencedBy")
+        references = references_attribute.value
+
+        for identifier_str, prop_list in references.items():
+            for prop in prop_list:
+                loaded_class.add_reference(
+                    InstanceIdentifier.model_validate_json(identifier_str.replace(
+                        "---", ".")), prop)
+
+        # load metadata
+        metadata_dict = entity.get_attribute("metadata").value
+        loaded_class.metadata.name = metadata_dict['name']
+        loaded_class.metadata.comment = metadata_dict['comment']
+
+        # load device_settings into instance, if instance is a device
+        if isinstance(loaded_class, SemanticDeviceClass):
+            settings_attribute = entity.get_attribute("deviceSettings")
+            device_settings = DeviceSettings.model_validate(settings_attribute.value)
+
+            for key, value in device_settings.model_dump().items():
+                loaded_class.device_settings.__setattr__(key, value)
+
+        return loaded_class
+
+    @staticmethod
+    def _convert_value_fitting_for_field(field, value):
+        """
+        Converts a given value into the correct format for the given field
+
+        Args:
+            field: SemanticField
+            value: Value to convert
+
+        Returns:
+            converted value
+        """
+        if isinstance(field, DataField):
+            return value
+        elif isinstance(field, RelationField):
+            # convert json to Identifier, inject identifier in Relation,
+            # the class will be hotloaded if the value in the is
+            # relationship is accessed
+
+            if not isinstance(value, dict):  # is an individual
+                return value
+            else:  # is an instance_identifier
+                # we need to replace back --- with . that we switched,
+                # as a . is not allowed in the dic in Fiware
+                return InstanceIdentifier.model_validate_json(
+                    str(value).replace("---", ".").replace("'", '"'))
+
+        elif isinstance(field, CommandField):
+            if isinstance(value, Command):
+                return value
+            # if loading local state, the wrong string delimters are used,
+            # and the string is not automatically converted to a dict
+            if not isinstance(value, dict):
+                value = json.loads(value.replace("'", '"'))
+
+            return Command(name=value['name'])
+        elif isinstance(field, DeviceAttributeField):
+
+            # if loading local state, the wrong string delimters are used,
+            # and the string is not automatically converted to a dict
+
+            if isinstance(value, DeviceAttribute):
+                return value
+            if not isinstance(value, dict):
+                value = json.loads(value.replace("'", '"'))
+
+            return DeviceAttribute(
+                name=value['name'],
+                attribute_type=value[
+                    "attribute_type"]
+            )
+
+    def get_class_by_name(self, class_name: str) -> Type[SemanticClass]:
+        """
+        Get the class object by its type in string form
+
+        Args:
+            class_name (str)
+
+        Raises:
+            KeyError: if class_name not registered as a SemanticClass
+
+        Returns:
+            Type
+        """
+        return self.class_catalogue[class_name]
+
+    def is_class_name_an_device_class(self, class_name: str) -> bool:
+        """
+        Test if the name/type of a class belongs to a SemanticDeviceClass
+
+        Args:
+            class_name (str): class name to check
+
+        Returns:
+            bool, True if belongs to a SemanticDeviceClass
+        """
+        class_type = self.get_class_by_name(class_name)
+        return isinstance(class_type, SemanticDeviceClass)
+
+    def is_local_state_valid(self, validate_rules: bool = True) -> (bool, str):
+        """
+        Check if the local state is valid and can be saved.
+
+        Args:
+            validate_rules (bool): If true Rulefields are validated
+
+        Returns:
+            (bool, str): (Is valid?, Message)
+        """
+
+        if validate_rules:
+            for instance in self.instance_registry.get_all():
+                if isinstance(instance, Individual):
+                    continue
+                if not instance.are_rule_fields_valid():
+                    return (
+                        False,
+                        f"SemanticEntity {instance.id} of type"
+                        f"{instance.get_type()} has unfulfilled fields " 
+                        f"{[f.name for f in instance.get_invalid_rule_fields()]}."
+                    )
+
+        for instance in self.instance_registry.get_all():
+            if isinstance(instance, SemanticDeviceClass):
+                if instance.device_settings.transport is None:
+                    return (
+                        False,
+                        f"Device {instance.id} of type {instance.get_type()} " 
+                        f"needs to be given an transport setting."
+                    )
+        return True, "State is valid"
+
+    def save_state(self, assert_validity: bool = True):
+        """
+        Save the local state completely to Fiware.
+
+        Args:
+            assert_validity (bool): It true an error is raised if the
+            RuleFields of one instance are invalid
+
+        Raises:
+            AssertionError: If a device endpoint or transport is not defined
+
+        Returns:
+            None
+        """
+        (valid, msg) = self.is_local_state_valid(validate_rules=assert_validity)
+
+        if not valid:
+            raise AssertionError(f"{msg}. Local state was not saved")
+
+        # delete all instance that were loaded from Fiware and then deleted
+        # wrap in try, as the entity could have been deleted by a third party
+        for identifier in self.instance_registry.get_all_deleted_identifiers():
+
+            # we need to handle devices and normal classes with different
+            # clients
+
+            client = self.get_client(instance_header=identifier.header)
+            iota_client = self.get_iota_client(
+                instance_header=identifier.header)
+            try:
+                client.delete_entity(
+                    entity_id=identifier.id,
+                    entity_type=identifier.type,
+                    delete_devices=True,
+                    iota_client=iota_client)
+            except requests.RequestException:
+                raise
+
+            client.close()
+
+        # merge with live state
+        for instance in self.instance_registry.get_all():
+            self.merge_local_and_live_instance_state(instance)
+
+        # save, patch all local instances
+        for instance in self.instance_registry.get_all():
+            cb_client = self.get_client(instance_header=instance.header)
+            if not isinstance(instance, SemanticDeviceClass):
+                # it is important that we patch the values else the
+                # references field would reach an invalid state if we worked
+                # in parallel on an instance
+                cb_client.patch_entity(instance.build_context_entity(),
+                                       instance.old_state.state)
+            else:
+                iota_client = self.get_iota_client(
+                    instance_header=instance.header)
+                iota_client.patch_device(
+                    device=instance.build_context_device(),
+                    patch_entity=True,
+                    cb_client=cb_client)
+                iota_client.close()
+            cb_client.close()
+        # update old_state
+        for instance in self.instance_registry.get_all():
+            instance.old_state.state = instance.build_context_entity()
+
+    def load_instance(self, identifier: InstanceIdentifier) -> SemanticClass:
+        """
+        Get the instance with the given identifier. It is either loaded from
+        local state or retrieved from fiware
+
+        Args:
+            identifier (InstanceIdentifier): Identifier to load
+
+        Returns:
+            SemanticClass
+        """
+
+        if self.instance_registry.contains(identifier=identifier):
+            return self.instance_registry.get(identifier=identifier)
+        else:
+            client = self.get_client(identifier.header)
+
+            entity = client.get_entity(entity_id=identifier.id,
+                                       entity_type=identifier.type)
+            client.close()
+
+            logger.info(f"Instance ({identifier.id}, {identifier.type}) "
+                        f"loaded from Fiware({identifier.header.cb_url}"
+                        f", {identifier.header.service}"
+                        f"{identifier.header.service_path})")
+            return self._context_entity_to_semantic_class(
+                entity=entity,
+                header=identifier.header)
+
+    def does_instance_exists(self, identifier: InstanceIdentifier) -> bool:
+        """
+        Check if an instance with the given identifier already exists in
+        local state or in Fiware
+
+        Args:
+            identifier (InstanceIdentifier): Identifier to check
+
+        Returns:
+            bool, true if exists
+        """
+
+        if self.instance_registry.contains(identifier=identifier):
+            return True
+        elif self.was_instance_deleted(identifier):
+            return False
+        else:
+            client = self.get_client(identifier.header)
+            return client.does_entity_exist(entity_id=identifier.id,
+                                            entity_type=identifier.type)
+
+    def was_instance_deleted(self, identifier: InstanceIdentifier) -> bool:
+        """
+        Check if the instance with the given identifier was deleted.
+
+        Args:
+            identifier (InstanceIdentifier): Identifier to check
+
+        Returns:
+            bool, true if deleted
+        """
+        return self.instance_registry.instance_was_deleted(identifier)
+
+    def get_instance(self, identifier: InstanceIdentifier) -> SemanticClass:
+        """
+        Get the instance with the given identifier. It is either loaded from
+        local state or retrieved from fiware
+
+        Args:
+            identifier (InstanceIdentifier): Identifier to load
+
+        Returns:
+            SemanticClass
+        """
+        return self.load_instance(identifier)
+
+    def get_all_local_instances(self) -> List[SemanticClass]:
+        """
+        Retrieve all SemanticClass instances in the local state
+
+        Returns:
+            List[SemanticClass]
+        """
+        return self.instance_registry.get_all()
+
+    def get_all_local_instances_of_class(self,
+                                         class_: Optional[type] = None,
+                                         class_name: Optional[str] = None,
+                                         get_subclasses: bool = True) \
+            -> List[SemanticClass]:
+        """
+        Retrieve all instances of a SemanitcClass from Local Storage
+
+        Args:
+            class_ (type):
+                Type of classes to retrieve
+            class_name (str):
+                Name of type of classes to retrieve as string
+            get_subclasses (bool):
+                If true also all instances of subclasses
+                of given class are returned
+
+        Raises:
+            AssertionError: If class_ and class_name are both None or non None
+
+        Returns:
+            List[SemanticClass]
+        """
+
+        assert class_ is None or class_name is None, \
+            "Only one parameter is allowed"
+        assert class_ is not None or class_name is not None, \
+            "One parameter is required"
+
+        if class_ is not None:
+            class_name = class_.__name__
+        else:
+            class_ = self.get_class_by_name(class_name)
+
+        res = []
+        for instance in self.instance_registry.get_all():
+            if not get_subclasses:
+                if instance.get_type() == class_name:
+                    res.append(instance)
+            else:
+                if isinstance(instance, class_):
+                    res.append(instance)
+        return res
+
+    def load_instances_from_fiware(
+            self,
+            fiware_header: FiwareHeader,
+            fiware_version: NgsiVersion,
+            cb_url: str,
+            iota_url: str,
+            entity_ids: Optional[List[str]] = None,
+            entity_types: Optional[List[str]] = None,
+            id_pattern: str = None,
+            type_pattern: str = None,
+            q: Union[str, QueryString] = None,
+            limit: int = inf,
+    ) -> List[SemanticClass]:
+        """
+        Loads the instances of given types or ids from Fiware into the local
+        state and returns the loaded instances
+
+        Args:
+            fiware_header (FiwareHeader): Fiware location to load
+            fiware_version (NgsiVersion): Used fiware version
+            cb_url (str): URL of the ContextBroker
+            iota_url (str): URL of the IotaBroker
+            entity_ids (Optional[str]): List of the entities ids that
+                should be loaded
+            entity_types (Optional[str]): List of the entities types that
+                should be loaded
+            id_pattern: A correctly formatted regular expression. Retrieve
+                entities whose ID matches the regular expression. Incompatible
+                with id, e.g. ngsi-ld.* or sensor.*
+            type_pattern: A correctly formatted regular expression. Retrieve
+                entities whose type matches the regular expression.
+                Incompatible with type, e.g. room.*
+            q (SimpleQuery): A query expression, composed of a list of
+                statements separated by ;, i.e.,
+                q=statement1;statement2;statement3. See Simple Query
+                Language specification. Example: temperature>40.
+            limit: Limits the number of entities to be retrieved Example: 20
+
+        Raises:
+           ValueError: if both entity_types and entity_ids are given
+           ValueError: if Retrival of Context-entities fails
+        Returns:
+             List[SemanticClass]
+        """
+
+        header: InstanceHeader = InstanceHeader(
+            service=fiware_header.service,
+            service_path=fiware_header.service_path,
+            cb_url=cb_url,
+            iota_url=iota_url,
+            ngsi_version=fiware_version
+        )
+
+        client = self.get_client(header)
+
+        entities = client.get_entity_list(entity_ids=entity_ids,
+                                          entity_types=entity_types,
+                                          id_pattern=id_pattern,
+                                          type_pattern=type_pattern,
+                                          q=q,
+                                          limit=limit)
+        client.close()
+
+        return [self._context_entity_to_semantic_class(e, header)
+                for e in entities]
+
+    def get_entity_from_fiware(self, instance_identifier: InstanceIdentifier) \
+            -> ContextEntity:
+        """
+        Retrieve the current entry of an instance in Fiware
+
+        Args:
+            instance_identifier (InstanceIdentifier): Identifier to load
+
+        Raises:
+            Exception, if Entity is not present
+
+        Returns:
+              ContextEntity
+        """
+        client = self.get_client(instance_identifier.header)
+
+        return client.get_entity(entity_id=instance_identifier.id,
+                                 entity_type=instance_identifier.type)
+
+    def load_instances(
+            self,
+            identifiers: List[InstanceIdentifier]) -> List[SemanticClass]:
+        """
+        Load all instances, if no local state of it exists it will get taken
+        from Fiware and registered locally
+
+        Args:
+            identifiers List[InstanceIdentifier]: Identifiers of instances
+                that should be loaded
+        Raises:
+            Exception, if one Entity is not present
+
+        Returns:
+           List[SemanticClass]
+        """
+
+        return [self.load_instance(iden) for iden in identifiers]
+
+    def set_default_header(self, header: InstanceHeader):
+        """
+        Set the default header, which all new instance that does not specify a
+        header in the constructor receives
+
+        Args:
+            header (InstanceHeader): new default header
+
+        Returns:
+            None
+        """
+        self.default_header = copy.deepcopy(header)
+
+    def get_default_header(self) -> InstanceHeader:
+        """
+        Instance header is read-only, therefore giving back a copy is
+        theoretically not needed, but it is cleaner that all instance has an
+        own header object that is not shared
+        """
+        return copy.deepcopy(self.default_header)
+
+    def get_datatype(self, datatype_name: str) -> Datatype:
+        """
+        Get a Datatype object with the name as key as specified in the model
+
+        Args:
+            datatype_name (str): key label of the datatype
+
+        Returns:
+            Datatype
+        """
+        return Datatype.model_validate(self.datatype_catalogue[datatype_name])
+
+    def get_individual(self, individual_name: str) -> SemanticIndividual:
+        """
+        Get an individual by its name
+
+        Args:
+            individual_name (str)
+        Raises:
+            KeyError, if name not registered
+        Returns:
+            SemanticIndividual
+        """
+        return self.individual_catalogue[individual_name]()
+
+    def save_local_state_as_json(self) -> str:
+        """
+        Save the local state with all made changes as json string
+
+        Returns:
+            Json String, containing all information about the local state
+        """
+        return self.instance_registry.save()
+
+    def load_local_state_from_json(self, json: str):
+        """
+        Loads the local state from a json string. The current local state gets
+        discarded
+
+        Raises:
+            Error, if not a correct json string
+
+        """
+        self.instance_registry.load(json, self)
+
+    def visualize_local_state(
+            self,
+            display_individuals_rule: str = "ALL"
+            ):
+        """
+        Visualise all instances in the local state in a network graph that
+        shows which instances reference each other over which fields
+
+        On execution of the methode a temporary image file is created and
+        automatically displayed in the standard image viewing software of the
+        system
+
+        Args:
+            display_individuals_rule (rule):
+                If:
+                "USED": Show only Individuals
+                "ALL": Display all known Individuals
+                "NONE": Display no Individuals
+                that are connected to at least one instance
+                else: Show all individuals
+
+        Raises:
+            ValueError: if display_individuals_rule is invalid
+        """
+
+        if not display_individuals_rule == "ALL" and \
+            not display_individuals_rule == "NONE" and \
+            not display_individuals_rule == "USED":
+
+            raise ValueError(f"Invalid parameter {display_individuals_rule}")
+
+        import igraph
+        g = igraph.Graph(directed=True)
+
+        for instance in self.get_all_local_instances():
+            g.add_vertex(name=instance.id,
+                         label=f"\n\n\n {instance.get_type()} \n {instance.id}",
+                         color="green")
+
+        used_individuals_names: Set[str] = set()
+        for instance in self.get_all_local_instances():
+            for field in instance.get_relation_fields():
+                for linked in field.get_all():
+                    if isinstance(linked, SemanticClass):
+                        g.add_edge(instance.id, linked.id, name=field.name)
+                        # g.es[-1]["name"] = field.name
+
+                    elif isinstance(linked, SemanticIndividual):
+                        if not display_individuals_rule == "NONE":
+                            g.add_edge(instance.id, linked.get_name())
+                            used_individuals_names.add(linked.get_name())
+
+        if display_individuals_rule == "ALL":
+            used_individuals_names.update(self.individual_catalogue.keys())
+        for individual in [self.get_individual(name) for name in
+                           used_individuals_names]:
+            g.add_vertex(label=f"\n\n\n{individual.get_name()}",
+                         name=individual.get_name(),
+                         color="blue")
+
+        layout = g.layout("fr")
+        visual_style = {"vertex_size": 20,
+                        "vertex_color": g.vs["color"],
+                        "vertex_label": g.vs["label"],
+                        "edge_label": g.es["name"],
+                        "layout": layout,
+                        "bbox": (len(g.vs) * 50, len(g.vs) * 50)}
+
+        igraph.plot(g, **visual_style)
+
+    def generate_cytoscape_for_local_state(
+            self,
+            display_only_used_individuals: bool = True
+            ):
+        """
+        Generate a graph definition that can be loaded into a cytoscape
+        visualisation tool, that describes the complete current local state.
+
+        For the graph layout COLA is recommended with an edge length of 150
+
+        Args:
+            display_only_used_individuals (bool):
+                If true(default): Show only Individuals that are connected to
+                at least one instance
+                else: Show all individuals
+
+        Returns:
+            Tupel of elements and stylesheet:
+                elements is a dict:
+                {"nodes": NODE_DEFINITIONS, "edges": EDGE_DEFINITIONS}
+                stylesheet is a list containing all the graph styles
+        """
+
+        # graph design
+        stylesheet = [
+            {
+                'selector': 'node',
+                'style': {
+                    'label': 'data(label)',
+                    'z-index': 9999
+                }
+            },
+            {
+                'selector': 'edge',
+                'style': {
+                    'curve-style': 'bezier',
+                    'target-arrow-color': 'black',
+                    'target-arrow-shape': 'triangle',
+                    'line-color': 'black',
+                    "opacity": 0.45,
+                    'z-index': 5000,
+                }
+            },
+            {
+                'selector': '.center',
+                'style': {
+                    'shape': 'rectangle',
+                    'background-color': 'black'
+                }
+            },
+            {
+                'selector': '.individual',
+                'style': {
+                    'shape': 'circle',
+                    'background-color': 'orange'
+                }
+            },
+            {
+                'selector': '.instance',
+                'style': {
+                    'shape': 'circle',
+                    'background-color': 'green'
+                }
+            },
+            {
+                'selector': '.collection',
+                'style': {
+                    'shape': 'triangle',
+                    'background-color': 'gray'
+                }
+            }
+        ]
+
+        nodes = []
+        edges = []
+
+        used_individual_names = set()
+        if not display_only_used_individuals:
+            used_individual_names.update(self.individual_catalogue.keys())
+
+        def get_node_id(item: Union[SemanticClass, SemanticIndividual]) -> str:
+            """
+            Get the id to be used in the graph for an item
+
+            Args:
+                item (Union[SemanticClass, SemanticIndividual]): Item to get
+                                                                    ID for
+
+            Returns:
+                str - ID
+            """
+            if isinstance(item, SemanticIndividual):
+                return item.get_name()
+            else:
+                return item.get_identifier().model_dump_json()
+
+        for instance in self.get_all_local_instances():
+            label = f'({instance.get_type()}){instance.metadata.name}'
+            nodes.append({'data': {'id': get_node_id(instance),
+                                   'label': label,
+                                   'parent_id': '',
+                                   'classes': "instance item"},
+                          'classes': "instance item"})
+
+        for instance in self.get_all_local_instances():
+
+            for rel_field in instance.get_relation_fields():
+
+                values = rel_field.get_all()
+                for v in values:
+                    if isinstance(v, SemanticIndividual):
+                        used_individual_names.add(v.get_name())
+
+                if len(values) == 0:
+                    pass
+                elif len(values) == 1:
+                    edge_id = uuid.uuid4().hex
+                    edges.append({'data': {'id': edge_id,
+                                           'source': get_node_id(instance),
+                                           'target': get_node_id(values[0])}})
+                    edge_name = rel_field.name
+                    stylesheet.append({'selector': '#' + edge_id,
+                                       'style': {'label': edge_name}})
+                else:
+                    edge_id = uuid.uuid4().hex
+                    node_id = uuid.uuid4().hex
+                    nodes.append({'data': {'id': node_id,
+                                           'label': '',
+                                           'parent_id': '',
+                                           'classes': "collection"},
+                                  'classes': "collection"})
+
+                    edges.append({'data': {'id': edge_id,
+                                           'source': get_node_id(instance),
+                                           'target': node_id}})
+                    edge_name = rel_field.name
+                    stylesheet.append({'selector': '#' + edge_id,
+                                       'style': {'label': edge_name}})
+
+                    for value in values:
+                        edge_id = uuid.uuid4().hex
+                        edges.append({'data': {'id': edge_id,
+                                               'source': node_id,
+                                               'target': get_node_id(value)}})
+
+        for individual_name in used_individual_names:
+            nodes.append({'data': {'id': individual_name,
+                                   'label': individual_name, 'parent_id': '',
+                                   'classes': "individual item"},
+                          'classes': "individual item"})
+
+        elements = {'nodes': nodes, 'edges': edges}
+
+        return elements, stylesheet
+
+    def merge_local_and_live_instance_state(self, instance: SemanticClass) ->\
+            None:
+        """
+        The live state of the instance is fetched from Fiware (if it exists)
+        and the two states are merged:
+
+        For each Field:
+        - each added value (compared to old_state) is added to
+        the live state
+        - each deleted value (compared to old_state) is removed from
+        the live state
+
+        For each Device Settings (if instance is device):
+        - If the device setting changed (compared to old_state) the live
+        setting is overwritten
+
+        For each Reference:
+        - each added value (compared to old_state) is added to
+        the live state
+        - each deleted value (compared to old_state) is removed from
+        the live state
+
+        The new state is directly saved in the instance
+
+        Args:
+              instance (SemanticClass): instanced to be treated
+        """
+
+        def converted_attribute_values(field, attribute) -> Set:
+            return {self._convert_value_fitting_for_field(field, value) for
+                    value in attribute.value}
+
+        def _get_added_and_removed_values(
+                old_values: Union[List, Set, Any],
+                current_values: Union[List, Set, Any]) -> (Set, Set):
+
+            old_set = set(old_values)
+            current_set = set(current_values)
+            added_values = set()
+            removed_values = set()
+
+            # remove deleted values from live state, it can be that the value
+            # was also deleted in the live state
+            for value in old_set:
+                if value not in current_set:
+                    removed_values.add(value)
+
+            # add added values
+            for value in current_set:
+                if value not in old_set:
+                    added_values.add(value)
+
+            return added_values, removed_values
+
+        # instance is new. Save it as is
+        client = self.get_client(instance.header)
+        if not client.does_entity_exist(entity_id=instance.id,
+                                        entity_type=instance.get_type()):
+            return
+
+        client = self.get_client(instance.header)
+        live_entity = client.get_entity(entity_id=instance.id,
+                                        entity_type=instance.get_type())
+        client.close()
+
+        current_entity = instance.build_context_entity()
+        old_entity = instance.old_state.state
+
+        # ------merge fields-----------------------------------------------
+        # instance exists already, add all locally added and delete all
+        # locally deleted values to the/from the live_state
+
+        for field in instance.get_fields():
+            # live_values = set(live_entity.get_attribute(field.name).value)
+            live_values = converted_attribute_values(
+                field, live_entity.get_attribute(field.name))
+            old_values = converted_attribute_values(
+                field, old_entity.get_attribute(field.name))
+            current_values = converted_attribute_values(
+                field, current_entity.get_attribute(field.name))
+
+            (added_values, deleted_values) = \
+                _get_added_and_removed_values(
+                    old_values, current_values
+                    # old_entity.get_attribute(field.name).value,
+                    # current_entity.get_attribute(field.name).value
+                )
+
+            for value in added_values:
+                live_values.add(value)
+            for value in deleted_values:
+                if value in live_values:
+                    live_values.remove(value)
+
+            new_values = list(live_values)
+            # update local stated with merged result
+            field._set.clear()  # very important to not use field.clear,
+                                 # as that methode would also delete references
+            for value in new_values:
+                converted_value = self._convert_value_fitting_for_field(
+                    field, value)
+                field._set.add(converted_value)
+
+        # ------merge references-----------------------------------------------
+        merged_references: Dict = live_entity.get_attribute(
+            "referencedBy").value
+        current_references: Dict = current_entity.get_attribute(
+            "referencedBy").value
+        old_references: Dict = old_entity.get_attribute(
+            "referencedBy").value
+
+        keys = set(current_references.keys())
+        keys.update(old_references.keys())
+
+        for key in keys:
+            current_values = []
+            old_values = []
+            if key in current_references:
+                current_values = current_references[key]
+            if key in old_references:
+                old_values = old_references[key]
+
+            (added_values, deleted_values) = _get_added_and_removed_values(
+                current_values=current_values, old_values=old_values)
+
+            # ensure the merged state has each key
+            if key not in merged_references.keys():
+                merged_references[key] = []
+
+            # add, added values that did not exist before
+            for value in added_values:
+                if value not in merged_references[key]:
+                    merged_references[key].append(value)
+
+            # delete deleted values if they were not already deleted
+            for value in deleted_values:
+                if value in merged_references[key]:
+                    merged_references[key].remove(value)
+
+            # delete all keys that point to empty lists
+            keys_to_delete = []
+            for key, value in merged_references.items():
+                if len(value) == 0:
+                    keys_to_delete.append(key)
+            for key in keys_to_delete:
+                del merged_references[key]
+
+        # save merged references
+        instance.references.clear()
+        for key, value in merged_references.items():
+            # replace back the protected . (. not allowed in keys in fiware)
+            instance.references[InstanceIdentifier.model_validate_json(key.replace(
+                "---", "."))] = value
+
+        # ------merge device settings----------------------------------------
+        if isinstance(instance, SemanticDeviceClass):
+            old_settings = old_entity.get_attribute("deviceSettings").value
+            current_settings = \
+                current_entity.get_attribute("deviceSettings").value
+            new_settings = live_entity.get_attribute("deviceSettings").value
+
+            # keys are always the same
+            # override live state with local changes
+            for key in old_settings:
+                if old_settings[key] is not current_settings[key]:
+                    new_settings[key] = current_settings[key]
+                instance.device_settings.__setattr__(key, new_settings[key])
+
+    def find_fitting_model(self, search_term: str, limit: int = 5) -> List[str]:
+        """
+        Find a fitting model by entering a search_term (e.g.: Sensor).
+        The methode returns a selection from up-to [limit] possibly fitting
+        model names. If a model name was selected from the proposition the
+        model can be retrieved with the methode:
+        "get_class_by_name(selectedName)"
+
+        Args:
+            search_term (str): search term to find a model by name
+            limit (int): Max Number of suggested results (default: 5)
+
+        Returns:
+            List[str], containing 0 to [limit] ordered propositions (best first)
+        """
+        class_names = list(self.class_catalogue.keys())
+        suggestions = [item[0] for item in process.extract(
+            query=search_term.casefold(),
+            choices=class_names,
+            score_cutoff=50,
+            limit=limit)]
+
+        return suggestions
```

### Comparing `filip-0.3.0/filip/semantics/vocabulary/entities.py` & `filip-0.4.0/filip/semantics/vocabulary/entities.py`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,848 +1,848 @@
-"""Vocabulary Models for Ontology Entities"""
-
-from enum import Enum
-from pydantic import BaseModel, Field
-from typing import List, TYPE_CHECKING, Dict, Union, Set, Any
-
-from .source import DependencyStatement
-
-if TYPE_CHECKING:
-    from . import \
-        CombinedObjectRelation, \
-        CombinedDataRelation, \
-        CombinedRelation, \
-        Relation, \
-        Vocabulary, \
-        Source
-
-
-class Entity(BaseModel):
-    """
-    Representing an OWL Entity (Class, Datatype, DataProperty, ObjectProperty,
-                                Individual)
-
-    An Entity is characterised by a unique IRI and originates from a source
-
-    An Entity needs a unique Label (displayname) as it is used in FIWARE as
-    field key. The user can overwrite the given
-    label
-    """
-    iri: str = Field(description="Unique Internationalized Resource Identifier")
-    label: str = Field(
-        default="",
-        description="Label (displayname) extracted from source file "
-                    "(multiple Entities could have the same label)")
-    user_set_label: Any = Field(
-        default="",
-        description="Given by user and overwrites 'label'."
-                    " Needed to make labels unique")
-    comment: str = Field(
-        default="",
-        description="Comment extracted from the ontology/source")
-    source_ids: Set[str] = Field(
-        default=set(),
-        description="IDs of the sources that influenced this class")
-    predefined: bool = Field(
-        default=False,
-        description="Stats if the entity is not extracted from a source, "
-                    "but predefined in the program (Standard Datatypes)")
-
-    def get_label(self) -> str:
-        """ Get the label for the entity.
-        If the user has set a label it is returned, else the label extracted
-        from the source
-
-        Returns:
-             str
-        """
-        if not self.user_set_label == "":
-            return self.user_set_label
-
-        return self.get_original_label()
-
-    def set_label(self, label:str):
-        """ Change the display label of the entity
-
-        Args:
-            label (str): Label that the label should have
-        """
-        self.user_set_label = label
-
-    def get_ontology_iri(self) -> str:
-        """ Get the IRI of the ontology that this entity belongs to
-        (extracted from IRI)
-
-        Returns:
-            str
-        """
-        index = self.iri.find("#")
-        return self.iri[:index]
-
-    def get_source_names(self, vocabulary: 'Vocabulary') -> List[str]:
-        """ Get the names of all the sources
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary of the project
-
-        Returns:
-            str
-        """
-        names = [vocabulary.get_source(id).get_name() for
-                 id in self.source_ids]
-
-        return names
-
-    def get_sources(self, vocabulary: 'Vocabulary') -> List['Source']:
-        """ Get all the source objects that influenced this entity.
-        The sources are sorted according to their names
-
-        Args:
-           vocabulary (Vocabulary): Vocabulary of the project
-
-        Returns:
-           str
-        """
-
-        sources = [vocabulary.get_source(id) for id in self.source_ids]
-
-        sources.sort(key=lambda x: x.source_name, reverse=False)
-        return sources
-
-    def _lists_are_identical(self, a: List, b: List) -> bool:
-        """ Methode to test if to lists contain the same entries
-
-        Args:
-            a (List): first list
-            b (List): second list
-        Returns:
-            bool
-        """
-        return len(set(a).intersection(b)) == len(set(a)) and len(a) == len(b)
-
-    def is_renamed(self) -> bool:
-        """ Check if the entity was renamed by the user
-
-        Returns:
-            bool
-        """
-        return not self.user_set_label == ""
-
-    def get_original_label(self) -> str:
-        """ Get label as defined in the source
-        It can be that the label is empty, then extract the label from the iri
-
-        Returns:
-            str
-        """
-        if not self.label == "":
-            return self.label
-
-        index = self.iri.find("#") + 1
-        return self.iri[index:]
-
-
-class Class(Entity):
-    """
-    Representation of OWL:CLASS
-
-    A class has a set of relations that are combined into CombinedRelations
-
-    Instances are instantiations of a class
-
-    A class can represent Devices, Agents, None or both
-    """
-
-    # The objects whose ids/iris are listed here can be looked up in the
-    # vocabulary of this class
-    child_class_iris: List[str] = Field(
-        default=[],
-        description="All class_iris of classes that inherit from this class")
-    ancestor_class_iris: List[str] = Field(
-        default=[],
-        description="All class_iris of classes from which this class inherits")
-    parent_class_iris: List[str] = Field(
-        default=[],
-        description="All class_iris of classes that are direct parents of this "
-                    "class")
-    relation_ids: List[str] = Field(
-        default=[],
-        description="All ids of relations defined for this class")
-    combined_object_relation_ids: List[str] = Field(
-        default=[],
-        description="All combined_object_relations ids defined for this class")
-    combined_data_relation_ids: List[str] = Field(
-        default=[],
-        description="All combined_data_relations ids defined for this class")
-
-    def get_relation_ids(self) -> List[str]:
-        """Get all ids of relations belonging to this class
-
-        Returns:
-            List[str]
-        """
-        return self.relation_ids
-
-    def get_relations(self, vocabulary: 'Vocabulary') -> List['Relation']:
-        """Get all relations belonging to this class
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary of this project
-
-        Returns:
-            List[Relation]
-        """
-        result = []
-        for id in self.relation_ids:
-            result.append(vocabulary.get_relation_by_id(id))
-
-        return result
-
-    def get_combined_object_relations(self, vocabulary: 'Vocabulary') -> \
-            List['CombinedObjectRelation']:
-        """Get all combined object relations belonging to this class
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary of this project
-
-        Returns:
-            List[CombinedObjectRelation]
-        """
-
-        result = []
-        for id in self.combined_object_relation_ids:
-            result.append(vocabulary.get_combined_object_relation_by_id(id))
-
-        return result
-
-    def get_combined_data_relations(self, vocabulary: 'Vocabulary') -> \
-            List['CombinedDataRelation']:
-        """Get all combined data relations belonging to this class
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary of this project
-
-        Returns:
-            List[CombinedDataRelation]
-        """
-
-        result = []
-        for id in self.combined_data_relation_ids:
-            result.append(vocabulary.get_combined_data_relation_by_id(id))
-
-        return result
-
-    def get_combined_relations(self, vocabulary: 'Vocabulary') -> \
-            List['CombinedRelation']:
-        """Get all combined relations belonging to this class
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary of this project
-
-        Returns:
-            List[CombinedRelation]
-        """
-
-        result = self.get_combined_object_relations(vocabulary)
-        result.extend(self.get_combined_data_relations(vocabulary))
-        return result
-
-    def is_child_of_all_classes(self, target_list: List[str]) -> bool:
-        """Tests if this class is a child class for each of the given classes
-
-        Args:
-            target_list (List[str]): List of ancestor class_iris
-
-        Returns:
-            bool
-        """
-
-        for target in target_list:
-            if not target == self.iri:
-                if target not in self.ancestor_class_iris:
-                    return False
-        return True
-
-    def get_combined_object_relation_with_property_iri(
-            self, obj_prop_iri: str, vocabulary: 'Vocabulary') \
-            -> 'CombinedObjectRelation':
-        """
-        Get the CombinedObjectRelation of this class that combines the
-        relations of the given ObjectProperty
-
-        Args:
-            obj_prop_iri (str): Iri of the ObjectProperty
-            vocabulary (Vocabulary): Vocabulary of this project
-
-        Returns:
-            CombinedObjectRelation
-        """
-        for cor in self.get_combined_object_relations(vocabulary):
-            if cor.property_iri == obj_prop_iri:
-                return cor
-        return None
-
-    def get_combined_data_relation_with_property_iri(self, property_iri,
-                                                     vocabulary):
-        """
-        Get the CombinedDataRelation of this class that combines the
-        relations of the given DataProperty
-
-        Args:
-            property_iri (str): Iri of the DataProperty
-            vocabulary (Vocabulary): Vocabulary of this project
-
-        Returns:
-            CombinedDataRelation
-        """
-        for cdr in self.get_combined_data_relations(vocabulary):
-            if cdr.property_iri == property_iri:
-                return cdr
-        return None
-
-    def get_combined_relation_with_property_iri(self, property_iri, vocabulary)\
-            -> Union['CombinedRelation', None]:
-        """
-        Get the CombinedRelation of this class that combines the relations
-        of the given Property
-
-        If possible use the more specific access functions to save runtime.
-
-        Args:
-            property_iri (str): Iri of the Property
-            vocabulary (Vocabulary): Vocabulary of this project
-
-        Returns:
-            CombinedRelation, None if iri is unknown
-       """
-        for cdr in self.get_combined_data_relations(vocabulary):
-            if cdr.property_iri == property_iri:
-                return cdr
-        for cor in self.get_combined_object_relations(vocabulary):
-            if cor.property_iri == property_iri:
-                return cor
-        return None
-
-    def get_ancestor_classes(self, vocabulary: 'Vocabulary') -> List['Class']:
-        """Get all ancestor classes of this class
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary of this project
-
-        Returns:
-            List[Class]
-        """
-        ancestors = []
-        for ancestor_iri in self.ancestor_class_iris:
-            ancestors.append(vocabulary.get_class_by_iri(ancestor_iri))
-        return ancestors
-
-    def get_parent_classes(self,
-                           vocabulary: 'Vocabulary',
-                           remove_redundancy: bool = False) -> List['Class']:
-        """Get all parent classes of this class
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary of this project
-            remove_redundancy (bool): if true the parents that are child of
-                other parents are not included
-
-        Returns:
-            List[Class]
-        """
-        parents = []
-
-        for parent_iri in self.parent_class_iris:
-            parents.append(vocabulary.get_class_by_iri(parent_iri))
-
-        if remove_redundancy:
-            child_iris = set()
-            for parent in parents:
-                child_iris.update(parent.child_class_iris)
-            for parent in parents:
-                if parent.iri in child_iris:
-                    parents.remove(parent)
-
-        return parents
-
-    def treat_dependency_statements(self, vocabulary: 'Vocabulary') -> \
-            List[DependencyStatement]:
-        """
-        Purge and list all pointers/iris that are not contained in
-        the vocabulary
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary of this project
-
-        Returns:
-            List[Dict[str, str]]: List of purged statements dicts with keys:
-            Parent Class, class, dependency, fulfilled
-        """
-
-        statements = []
-        # parent classes:
-        parents_to_purge = []
-        for parent_iri in self.parent_class_iris:
-            found = parent_iri in vocabulary.classes
-            statements.append(DependencyStatement(type="Parent Class",
-                                                  class_iri=self.iri,
-                                                  dependency_iri=parent_iri,
-                                                  fulfilled=found
-                                                  ))
-            if not found:
-                parents_to_purge.append(parent_iri)
-        for iri in parents_to_purge:
-            self.parent_class_iris.remove(iri)
-
-        # relations
-        relation_ids_to_purge = set()
-        for relation in self.get_relations(vocabulary):
-
-            relation_statements = relation.get_dependency_statements(
-                vocabulary, self.get_ontology_iri(), self.iri)
-            for statement in relation_statements:
-                if statement.fulfilled == False:
-                    relation_ids_to_purge.add(relation.id)
-            statements.extend(relation_statements)
-
-        for id in relation_ids_to_purge:
-            self.relation_ids.remove(id)
-            del vocabulary.relations[id]
-
-        return statements
-
-    def get_next_combined_relation_id(self, current_cr_id: str,
-                                      object_relations: bool) -> str:
-        """Get the alphabetically(Property label) next CombinedRelation.
-
-        If no CR is after the given one, the first is returned
-
-        Args:
-            current_cr_id (str): ID of the CombinedRelation of which the next
-                should be found
-            object_relations (bool):
-                True if Searching for  CombinedObjectRelations
-
-        Returns:
-            str: ID of next CR
-        """
-        list_ = self.combined_data_relation_ids
-        if object_relations:
-            list_ = self.combined_object_relation_ids
-
-        current_index = list_.index(current_cr_id)
-        res_index = current_index+1
-        if res_index >= len(list_):
-            res_index = 0
-        return list_[res_index]
-
-    def get_previous_combined_relation_id(self, current_cr_id: str,
-                                          object_relations: bool) -> str:
-        """Get the alphabetically(Property label) previous CombinedRelation.
-
-        If no CR is before the given one, the last is returned
-
-        Args:
-            current_cr_id (str): ID of the CombinedRelation of which the
-                previous should be found
-            object_relations (bool): True if Searching for
-                CombinedObjectRelations
-
-        Returns:
-            str: ID of previous CR
-        """
-
-        list_ = self.combined_data_relation_ids
-        if object_relations:
-            list_ = self.combined_object_relation_ids
-
-        current_index = list_.index(current_cr_id)
-        res_index = current_index - 1
-        if res_index < 0:
-            res_index = len(list_)-1
-        return list_[res_index]
-
-    def is_logically_equivalent_to(self, class_: 'Class',
-                                   vocabulary: 'Vocabulary',
-                                   old_vocabulary: 'Vocabulary') -> bool:
-        """Test if a class is logically equivalent in two vocabularies.
-
-        Args:
-            class_ (Class): Class to be tested against, from the old_vocabulary
-            vocabulary (Vocabulary): New project vocabulary
-            old_vocabulary (Vocabulary): Old project vocabulary
-
-        Returns:
-            bool
-        """
-
-        # test if parent classes are identical
-        if not self._lists_are_identical(class_.parent_class_iris,
-                                         self.parent_class_iris):
-            return False
-
-        # test if combined object relation ids are identical
-        if not self._lists_are_identical(class_.combined_object_relation_ids,
-                                         self.combined_object_relation_ids):
-            return False
-
-        # test if combined data  relation ids are identical
-        if not self._lists_are_identical(class_.combined_data_relation_ids,
-                                         self.combined_data_relation_ids):
-            return False
-
-        # test if combined relations are identical
-        for cr in self.get_combined_relations(vocabulary):
-            old_cr = old_vocabulary.get_combined_relation_by_id(cr.id)
-
-            relation_strings = []
-            for relation in cr.get_relations(vocabulary):
-                relation_strings.append(relation.to_string(vocabulary))
-
-            old_relation_strings = []
-            for old_relation in old_cr.get_relations(old_vocabulary):
-                old_relation_strings.append(old_relation.to_string(vocabulary))
-
-            if not self._lists_are_identical(relation_strings,
-                                             old_relation_strings):
-
-                return False
-
-        return True
-
-    def is_iot_class(self, vocabulary: 'Vocabulary') -> bool:
-        """
-        A class is an iot/device class if it contains one CDR, where the
-        relation is marked as a device relation: DeviceAttribute/Command
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary of the project
-
-        Returns:
-            bool
-        """
-
-        for cdr_id in self.combined_data_relation_ids:
-            cdr = vocabulary.get_combined_data_relation_by_id(cdr_id)
-            prop = vocabulary.get_data_property(cdr.property_iri)
-            if not prop.field_type == DataFieldType.simple:
-                return True
-        return False
-
-
-class DatatypeType(str, Enum):
-    """
-    Types of a Datatype
-    """
-    string = 'string'
-    number = 'number'
-    date = 'date'
-    enum = 'enum'
-
-
-class DatatypeFields(BaseModel):
-    """Key Fields describing a Datatype"""
-    type: DatatypeType = Field(default=DatatypeType.string,
-                               description="Type of the datatype")
-    number_has_range: Any = Field(
-        default=False,
-        description="If Type==Number: Does the datatype define a range")
-    number_range_min: Union[int, str] = Field(
-        default="/",
-        description="If Type==Number: Min value of the datatype range, "
-                    "if a range is defined")
-    number_range_max: Union[int, str] = Field(
-        default="/",
-        description="If Type==Number: Max value of the datatype range, "
-                    "if a range is defined")
-    number_decimal_allowed: bool = Field(
-        default=False,
-        description="If Type==Number: Are decimal numbers allowed?")
-    forbidden_chars: List[str] = Field(
-        default=[],
-        description="If Type==String: Blacklisted chars")
-    allowed_chars: List[str] = Field(
-        default=[],
-        description="If Type==String: Whitelisted chars")
-    enum_values: List[str] = Field(
-        default=[],
-        description="If Type==Enum: Enum values")
-
-
-class Datatype(Entity, DatatypeFields):
-    """
-    Represents OWL:Datatype
-
-    A Datatype is the target of a DataRelation. The Datatype stats a set of
-    values that are valid.
-    This can be an ENUM, a number range, or a check for black/whitelisted chars
-
-    In the Parsing PostProcesseor predefined datatype_catalogue are added to the
-    vocabulary
-    """
-
-    def export(self) -> Dict[str,str]:
-        """ Export datatype as dict
-
-        Returns:
-            Dict[str,str]
-        """
-        res = self.model_dump(include={'type', 'number_has_range',
-                                 'number_range_min', 'number_range_max',
-                                 'number_decimal_allowed', 'forbidden_chars',
-                                 'allowed_chars', 'enum_values'},
-                              exclude_defaults=True)
-        res['type'] = self.type.value
-        return res
-
-    def value_is_valid(self, value: str) -> bool:
-        """Test if value is valid for this datatype.
-        Numbers are also given as strings
-
-        Args:
-            value (str): value to be tested
-
-        Returns:
-            bool
-        """
-
-        if self.type == DatatypeType.string:
-            if len(self.allowed_chars) > 0:
-                # if allowed chars is empty all chars are allowed
-                for char in value:
-                    if char not in self.allowed_chars:
-                        return False
-            for char in self.forbidden_chars:
-                if char in value:
-                    return False
-            return True
-
-        if self.type == DatatypeType.number:
-
-            if self.number_decimal_allowed:
-                try:
-                    number = float(value)
-                except:
-                    return False
-            else:
-                try:
-                    number = int(value)
-                except:
-                    return False
-
-            if not self.number_range_min == "/":
-                if number < self.number_range_min:
-                    return False
-            if not self.number_range_max == "/":
-                if number > self.number_range_max:
-                    return False
-
-            return True
-
-        if self.type == DatatypeType.enum:
-            return value in self.enum_values
-
-        if self.type == DatatypeType.date:
-            try:
-                from dateutil.parser import parse
-                parse(value, fuzzy=False)
-                return True
-
-            except ValueError:
-                return False
-
-        return True
-
-    def is_logically_equivalent_to(self, datatype:'Datatype',
-                                   vocabulary: 'Vocabulary',
-                                   old_vocabulary: 'Vocabulary') -> bool:
-        """Test if this datatype is logically equivalent to the given datatype
-
-        Args:
-            datatype (Datatype): Datatype to compare against
-            vocabulary (Vocabulary): Not used, but needed to keep signature the
-                same as other entities
-            old_vocabulary (Vocabulary): Not used, but needed to keep signature
-                the same as other entities
-        Returns:
-            bool
-        """
-
-        if not self.type == datatype.type:
-            return False
-        if not self.number_has_range == datatype.number_has_range:
-            return False
-        if not self.enum_values == datatype.enum_values:
-            return False
-
-        return True
-
-
-class Individual(Entity):
-    """
-    Represents OWL:Individual
-
-    An individual is a predefined "instance" of a class
-    But they are here only used as values for Relations
-
-    They are not instances, no value can be assigned to them, they are no
-    agents or devices
-    """
-
-    parent_class_iris: List[str] = Field(
-        default=[],
-        description="List of all parent class iris, "
-                    "an individual can have multiple parents")
-
-    def to_string(self) -> str:
-        """Get a string representation of the Individual
-
-        Returns:
-            str
-        """
-        return "(Individual)"+self.get_label()
-
-    def get_ancestor_iris(self, vocabulary: 'Vocabulary') -> List[str]:
-        """ Get all iris of ancestor classes
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary of the project
-
-        Returns:
-            List[str]
-        """
-        ancestor_iris = set()
-        for parent_iri in self.parent_class_iris:
-            ancestor_iris.add(parent_iri)
-            ancestor_iris.update(vocabulary.get_class_by_iri(parent_iri).
-                                 ancestor_class_iris)
-
-        return list(ancestor_iris)
-
-    def get_parent_classes(self, vocabulary: 'Vocabulary') -> List['Class']:
-        """ Get all parent class objects
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary of the project
-
-        Returns:
-            List[Class]
-        """
-        parents = []
-        for parent_iri in self.parent_class_iris:
-            parents.append(vocabulary.get_class_by_iri(parent_iri))
-        return parents
-
-    def is_logically_equivalent_to(self, individual: 'Individual',
-                                   vocabulary: 'Vocabulary',
-                                   old_vocabulary: 'Vocabulary') -> bool:
-        """Test if this individal is logically equivalent in two vocabularies.
-
-        Args:
-            individual (Individual): Individual to be tested against, from the
-                old vocabulary
-            vocabulary (Vocabulary): New project vocabulary, not used but needed
-                to keep signature the same
-            old_vocabulary (Vocabulary): Old project vocabulary, not used but
-                needed to keep signature the same
-
-        Returns:
-            bool
-        """
-
-        if not self._lists_are_identical(self.parent_class_iris,
-                                         individual.parent_class_iris):
-            return False
-        return True
-
-    def treat_dependency_statements(self, vocabulary: 'Vocabulary') -> \
-            List[DependencyStatement]:
-        """ Purge and list all pointers/iris that are not contained in the
-        vocabulary
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary of this project
-
-        Returns:
-            List[Dict[str, str]]: List of purged statements dicts with keys:
-            Parent Class, class, dependency, fulfilled
-        """
-        statements = []
-
-        for parent_iri in self.parent_class_iris:
-            found = parent_iri in vocabulary.classes
-            statements.append(DependencyStatement(type="Parent Class",
-                                                  class_iri=self.iri,
-                                                  dependency_iri=parent_iri,
-                                                  fulfilled=found
-                                                  ))
-
-            if not found:
-                self.parent_class_iris.remove(parent_iri)
-
-        return statements
-
-
-class DataFieldType(str, Enum):
-    """Type of the field that represents the DataProperty"""
-    command = "command"
-    device_attribute = "device_attribute"
-    simple = "simple"
-
-
-class DataProperty(Entity):
-    """
-    Representation of OWL:DataProperty
-    """
-
-    field_type: DataFieldType = Field(
-        default=DataFieldType.simple,
-        description="Type of the dataproperty; set by the user while "
-                    "configuring the vocabulary"
-    )
-
-
-class ObjectProperty(Entity):
-    """
-    Representation of OWL:ObjectProperty
-    """
-
-    inverse_property_iris: Set[str] = Field(
-        default=set(),
-        description="List of property iris that are inverse:Of; "
-                    "If an instance i2 is added in an instance i1 "
-                    "for this property. Then i1 is added to i2 under the"
-                    " inverseProperty (if the class has that property)")
-
-    def add_inverse_property_iri(self, iri: str):
-        """Add an inverse property
-
-        Args:
-            iri (str): Iri of the inverse objectProperty
-
-        Returns:
-            None
-        """
-        self.inverse_property_iris.add(iri)
-
-    def is_logically_equivalent_to(self, object_property: 'ObjectProperty',
-                                   vocabulary: 'Vocabulary',
-                                   old_vocabulary: 'Vocabulary') -> bool:
-        """Test if this Property in the new_vocabulary is logically equivalent
-        to the object_property in the old_vocabulary
-
-        Args:
-            object_property (ObjectProperty): ObjectProperty to be tested
-                against, from the old vocabulary
-            vocabulary (Vocabulary): New project vocabulary, not used but
-                needed to keep signature the same
-            old_vocabulary (Vocabulary): Old project vocabulary, not used but
-                needed to keep signature the same
-
-        Returns:
-            bool
-        """
-        if not self.inverse_property_iris == \
-                object_property.inverse_property_iris:
-            return False
-
-        return True
+"""Vocabulary Models for Ontology Entities"""
+
+from enum import Enum
+from pydantic import BaseModel, Field
+from typing import List, TYPE_CHECKING, Dict, Union, Set, Any
+
+from .source import DependencyStatement
+
+if TYPE_CHECKING:
+    from . import \
+        CombinedObjectRelation, \
+        CombinedDataRelation, \
+        CombinedRelation, \
+        Relation, \
+        Vocabulary, \
+        Source
+
+
+class Entity(BaseModel):
+    """
+    Representing an OWL Entity (Class, Datatype, DataProperty, ObjectProperty,
+                                Individual)
+
+    An Entity is characterised by a unique IRI and originates from a source
+
+    An Entity needs a unique Label (displayname) as it is used in FIWARE as
+    field key. The user can overwrite the given
+    label
+    """
+    iri: str = Field(description="Unique Internationalized Resource Identifier")
+    label: str = Field(
+        default="",
+        description="Label (displayname) extracted from source file "
+                    "(multiple Entities could have the same label)")
+    user_set_label: Any = Field(
+        default="",
+        description="Given by user and overwrites 'label'."
+                    " Needed to make labels unique")
+    comment: str = Field(
+        default="",
+        description="Comment extracted from the ontology/source")
+    source_ids: Set[str] = Field(
+        default=set(),
+        description="IDs of the sources that influenced this class")
+    predefined: bool = Field(
+        default=False,
+        description="Stats if the entity is not extracted from a source, "
+                    "but predefined in the program (Standard Datatypes)")
+
+    def get_label(self) -> str:
+        """ Get the label for the entity.
+        If the user has set a label it is returned, else the label extracted
+        from the source
+
+        Returns:
+             str
+        """
+        if not self.user_set_label == "":
+            return self.user_set_label
+
+        return self.get_original_label()
+
+    def set_label(self, label:str):
+        """ Change the display label of the entity
+
+        Args:
+            label (str): Label that the label should have
+        """
+        self.user_set_label = label
+
+    def get_ontology_iri(self) -> str:
+        """ Get the IRI of the ontology that this entity belongs to
+        (extracted from IRI)
+
+        Returns:
+            str
+        """
+        index = self.iri.find("#")
+        return self.iri[:index]
+
+    def get_source_names(self, vocabulary: 'Vocabulary') -> List[str]:
+        """ Get the names of all the sources
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary of the project
+
+        Returns:
+            str
+        """
+        names = [vocabulary.get_source(id).get_name() for
+                 id in self.source_ids]
+
+        return names
+
+    def get_sources(self, vocabulary: 'Vocabulary') -> List['Source']:
+        """ Get all the source objects that influenced this entity.
+        The sources are sorted according to their names
+
+        Args:
+           vocabulary (Vocabulary): Vocabulary of the project
+
+        Returns:
+           str
+        """
+
+        sources = [vocabulary.get_source(id) for id in self.source_ids]
+
+        sources.sort(key=lambda x: x.source_name, reverse=False)
+        return sources
+
+    def _lists_are_identical(self, a: List, b: List) -> bool:
+        """ Methode to test if to lists contain the same entries
+
+        Args:
+            a (List): first list
+            b (List): second list
+        Returns:
+            bool
+        """
+        return len(set(a).intersection(b)) == len(set(a)) and len(a) == len(b)
+
+    def is_renamed(self) -> bool:
+        """ Check if the entity was renamed by the user
+
+        Returns:
+            bool
+        """
+        return not self.user_set_label == ""
+
+    def get_original_label(self) -> str:
+        """ Get label as defined in the source
+        It can be that the label is empty, then extract the label from the iri
+
+        Returns:
+            str
+        """
+        if not self.label == "":
+            return self.label
+
+        index = self.iri.find("#") + 1
+        return self.iri[index:]
+
+
+class Class(Entity):
+    """
+    Representation of OWL:CLASS
+
+    A class has a set of relations that are combined into CombinedRelations
+
+    Instances are instantiations of a class
+
+    A class can represent Devices, Agents, None or both
+    """
+
+    # The objects whose ids/iris are listed here can be looked up in the
+    # vocabulary of this class
+    child_class_iris: List[str] = Field(
+        default=[],
+        description="All class_iris of classes that inherit from this class")
+    ancestor_class_iris: List[str] = Field(
+        default=[],
+        description="All class_iris of classes from which this class inherits")
+    parent_class_iris: List[str] = Field(
+        default=[],
+        description="All class_iris of classes that are direct parents of this "
+                    "class")
+    relation_ids: List[str] = Field(
+        default=[],
+        description="All ids of relations defined for this class")
+    combined_object_relation_ids: List[str] = Field(
+        default=[],
+        description="All combined_object_relations ids defined for this class")
+    combined_data_relation_ids: List[str] = Field(
+        default=[],
+        description="All combined_data_relations ids defined for this class")
+
+    def get_relation_ids(self) -> List[str]:
+        """Get all ids of relations belonging to this class
+
+        Returns:
+            List[str]
+        """
+        return self.relation_ids
+
+    def get_relations(self, vocabulary: 'Vocabulary') -> List['Relation']:
+        """Get all relations belonging to this class
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary of this project
+
+        Returns:
+            List[Relation]
+        """
+        result = []
+        for id in self.relation_ids:
+            result.append(vocabulary.get_relation_by_id(id))
+
+        return result
+
+    def get_combined_object_relations(self, vocabulary: 'Vocabulary') -> \
+            List['CombinedObjectRelation']:
+        """Get all combined object relations belonging to this class
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary of this project
+
+        Returns:
+            List[CombinedObjectRelation]
+        """
+
+        result = []
+        for id in self.combined_object_relation_ids:
+            result.append(vocabulary.get_combined_object_relation_by_id(id))
+
+        return result
+
+    def get_combined_data_relations(self, vocabulary: 'Vocabulary') -> \
+            List['CombinedDataRelation']:
+        """Get all combined data relations belonging to this class
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary of this project
+
+        Returns:
+            List[CombinedDataRelation]
+        """
+
+        result = []
+        for id in self.combined_data_relation_ids:
+            result.append(vocabulary.get_combined_data_relation_by_id(id))
+
+        return result
+
+    def get_combined_relations(self, vocabulary: 'Vocabulary') -> \
+            List['CombinedRelation']:
+        """Get all combined relations belonging to this class
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary of this project
+
+        Returns:
+            List[CombinedRelation]
+        """
+
+        result = self.get_combined_object_relations(vocabulary)
+        result.extend(self.get_combined_data_relations(vocabulary))
+        return result
+
+    def is_child_of_all_classes(self, target_list: List[str]) -> bool:
+        """Tests if this class is a child class for each of the given classes
+
+        Args:
+            target_list (List[str]): List of ancestor class_iris
+
+        Returns:
+            bool
+        """
+
+        for target in target_list:
+            if not target == self.iri:
+                if target not in self.ancestor_class_iris:
+                    return False
+        return True
+
+    def get_combined_object_relation_with_property_iri(
+            self, obj_prop_iri: str, vocabulary: 'Vocabulary') \
+            -> 'CombinedObjectRelation':
+        """
+        Get the CombinedObjectRelation of this class that combines the
+        relations of the given ObjectProperty
+
+        Args:
+            obj_prop_iri (str): Iri of the ObjectProperty
+            vocabulary (Vocabulary): Vocabulary of this project
+
+        Returns:
+            CombinedObjectRelation
+        """
+        for cor in self.get_combined_object_relations(vocabulary):
+            if cor.property_iri == obj_prop_iri:
+                return cor
+        return None
+
+    def get_combined_data_relation_with_property_iri(self, property_iri,
+                                                     vocabulary):
+        """
+        Get the CombinedDataRelation of this class that combines the
+        relations of the given DataProperty
+
+        Args:
+            property_iri (str): Iri of the DataProperty
+            vocabulary (Vocabulary): Vocabulary of this project
+
+        Returns:
+            CombinedDataRelation
+        """
+        for cdr in self.get_combined_data_relations(vocabulary):
+            if cdr.property_iri == property_iri:
+                return cdr
+        return None
+
+    def get_combined_relation_with_property_iri(self, property_iri, vocabulary)\
+            -> Union['CombinedRelation', None]:
+        """
+        Get the CombinedRelation of this class that combines the relations
+        of the given Property
+
+        If possible use the more specific access functions to save runtime.
+
+        Args:
+            property_iri (str): Iri of the Property
+            vocabulary (Vocabulary): Vocabulary of this project
+
+        Returns:
+            CombinedRelation, None if iri is unknown
+       """
+        for cdr in self.get_combined_data_relations(vocabulary):
+            if cdr.property_iri == property_iri:
+                return cdr
+        for cor in self.get_combined_object_relations(vocabulary):
+            if cor.property_iri == property_iri:
+                return cor
+        return None
+
+    def get_ancestor_classes(self, vocabulary: 'Vocabulary') -> List['Class']:
+        """Get all ancestor classes of this class
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary of this project
+
+        Returns:
+            List[Class]
+        """
+        ancestors = []
+        for ancestor_iri in self.ancestor_class_iris:
+            ancestors.append(vocabulary.get_class_by_iri(ancestor_iri))
+        return ancestors
+
+    def get_parent_classes(self,
+                           vocabulary: 'Vocabulary',
+                           remove_redundancy: bool = False) -> List['Class']:
+        """Get all parent classes of this class
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary of this project
+            remove_redundancy (bool): if true the parents that are child of
+                other parents are not included
+
+        Returns:
+            List[Class]
+        """
+        parents = []
+
+        for parent_iri in self.parent_class_iris:
+            parents.append(vocabulary.get_class_by_iri(parent_iri))
+
+        if remove_redundancy:
+            child_iris = set()
+            for parent in parents:
+                child_iris.update(parent.child_class_iris)
+            for parent in parents:
+                if parent.iri in child_iris:
+                    parents.remove(parent)
+
+        return parents
+
+    def treat_dependency_statements(self, vocabulary: 'Vocabulary') -> \
+            List[DependencyStatement]:
+        """
+        Purge and list all pointers/iris that are not contained in
+        the vocabulary
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary of this project
+
+        Returns:
+            List[Dict[str, str]]: List of purged statements dicts with keys:
+            Parent Class, class, dependency, fulfilled
+        """
+
+        statements = []
+        # parent classes:
+        parents_to_purge = []
+        for parent_iri in self.parent_class_iris:
+            found = parent_iri in vocabulary.classes
+            statements.append(DependencyStatement(type="Parent Class",
+                                                  class_iri=self.iri,
+                                                  dependency_iri=parent_iri,
+                                                  fulfilled=found
+                                                  ))
+            if not found:
+                parents_to_purge.append(parent_iri)
+        for iri in parents_to_purge:
+            self.parent_class_iris.remove(iri)
+
+        # relations
+        relation_ids_to_purge = set()
+        for relation in self.get_relations(vocabulary):
+
+            relation_statements = relation.get_dependency_statements(
+                vocabulary, self.get_ontology_iri(), self.iri)
+            for statement in relation_statements:
+                if statement.fulfilled == False:
+                    relation_ids_to_purge.add(relation.id)
+            statements.extend(relation_statements)
+
+        for id in relation_ids_to_purge:
+            self.relation_ids.remove(id)
+            del vocabulary.relations[id]
+
+        return statements
+
+    def get_next_combined_relation_id(self, current_cr_id: str,
+                                      object_relations: bool) -> str:
+        """Get the alphabetically(Property label) next CombinedRelation.
+
+        If no CR is after the given one, the first is returned
+
+        Args:
+            current_cr_id (str): ID of the CombinedRelation of which the next
+                should be found
+            object_relations (bool):
+                True if Searching for  CombinedObjectRelations
+
+        Returns:
+            str: ID of next CR
+        """
+        list_ = self.combined_data_relation_ids
+        if object_relations:
+            list_ = self.combined_object_relation_ids
+
+        current_index = list_.index(current_cr_id)
+        res_index = current_index+1
+        if res_index >= len(list_):
+            res_index = 0
+        return list_[res_index]
+
+    def get_previous_combined_relation_id(self, current_cr_id: str,
+                                          object_relations: bool) -> str:
+        """Get the alphabetically(Property label) previous CombinedRelation.
+
+        If no CR is before the given one, the last is returned
+
+        Args:
+            current_cr_id (str): ID of the CombinedRelation of which the
+                previous should be found
+            object_relations (bool): True if Searching for
+                CombinedObjectRelations
+
+        Returns:
+            str: ID of previous CR
+        """
+
+        list_ = self.combined_data_relation_ids
+        if object_relations:
+            list_ = self.combined_object_relation_ids
+
+        current_index = list_.index(current_cr_id)
+        res_index = current_index - 1
+        if res_index < 0:
+            res_index = len(list_)-1
+        return list_[res_index]
+
+    def is_logically_equivalent_to(self, class_: 'Class',
+                                   vocabulary: 'Vocabulary',
+                                   old_vocabulary: 'Vocabulary') -> bool:
+        """Test if a class is logically equivalent in two vocabularies.
+
+        Args:
+            class_ (Class): Class to be tested against, from the old_vocabulary
+            vocabulary (Vocabulary): New project vocabulary
+            old_vocabulary (Vocabulary): Old project vocabulary
+
+        Returns:
+            bool
+        """
+
+        # test if parent classes are identical
+        if not self._lists_are_identical(class_.parent_class_iris,
+                                         self.parent_class_iris):
+            return False
+
+        # test if combined object relation ids are identical
+        if not self._lists_are_identical(class_.combined_object_relation_ids,
+                                         self.combined_object_relation_ids):
+            return False
+
+        # test if combined data  relation ids are identical
+        if not self._lists_are_identical(class_.combined_data_relation_ids,
+                                         self.combined_data_relation_ids):
+            return False
+
+        # test if combined relations are identical
+        for cr in self.get_combined_relations(vocabulary):
+            old_cr = old_vocabulary.get_combined_relation_by_id(cr.id)
+
+            relation_strings = []
+            for relation in cr.get_relations(vocabulary):
+                relation_strings.append(relation.to_string(vocabulary))
+
+            old_relation_strings = []
+            for old_relation in old_cr.get_relations(old_vocabulary):
+                old_relation_strings.append(old_relation.to_string(vocabulary))
+
+            if not self._lists_are_identical(relation_strings,
+                                             old_relation_strings):
+
+                return False
+
+        return True
+
+    def is_iot_class(self, vocabulary: 'Vocabulary') -> bool:
+        """
+        A class is an iot/device class if it contains one CDR, where the
+        relation is marked as a device relation: DeviceAttribute/Command
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary of the project
+
+        Returns:
+            bool
+        """
+
+        for cdr_id in self.combined_data_relation_ids:
+            cdr = vocabulary.get_combined_data_relation_by_id(cdr_id)
+            prop = vocabulary.get_data_property(cdr.property_iri)
+            if not prop.field_type == DataFieldType.simple:
+                return True
+        return False
+
+
+class DatatypeType(str, Enum):
+    """
+    Types of a Datatype
+    """
+    string = 'string'
+    number = 'number'
+    date = 'date'
+    enum = 'enum'
+
+
+class DatatypeFields(BaseModel):
+    """Key Fields describing a Datatype"""
+    type: DatatypeType = Field(default=DatatypeType.string,
+                               description="Type of the datatype")
+    number_has_range: Any = Field(
+        default=False,
+        description="If Type==Number: Does the datatype define a range")
+    number_range_min: Union[int, str] = Field(
+        default="/",
+        description="If Type==Number: Min value of the datatype range, "
+                    "if a range is defined")
+    number_range_max: Union[int, str] = Field(
+        default="/",
+        description="If Type==Number: Max value of the datatype range, "
+                    "if a range is defined")
+    number_decimal_allowed: bool = Field(
+        default=False,
+        description="If Type==Number: Are decimal numbers allowed?")
+    forbidden_chars: List[str] = Field(
+        default=[],
+        description="If Type==String: Blacklisted chars")
+    allowed_chars: List[str] = Field(
+        default=[],
+        description="If Type==String: Whitelisted chars")
+    enum_values: List[str] = Field(
+        default=[],
+        description="If Type==Enum: Enum values")
+
+
+class Datatype(Entity, DatatypeFields):
+    """
+    Represents OWL:Datatype
+
+    A Datatype is the target of a DataRelation. The Datatype stats a set of
+    values that are valid.
+    This can be an ENUM, a number range, or a check for black/whitelisted chars
+
+    In the Parsing PostProcesseor predefined datatype_catalogue are added to the
+    vocabulary
+    """
+
+    def export(self) -> Dict[str,str]:
+        """ Export datatype as dict
+
+        Returns:
+            Dict[str,str]
+        """
+        res = self.model_dump(include={'type', 'number_has_range',
+                                 'number_range_min', 'number_range_max',
+                                 'number_decimal_allowed', 'forbidden_chars',
+                                 'allowed_chars', 'enum_values'},
+                              exclude_defaults=True)
+        res['type'] = self.type.value
+        return res
+
+    def value_is_valid(self, value: str) -> bool:
+        """Test if value is valid for this datatype.
+        Numbers are also given as strings
+
+        Args:
+            value (str): value to be tested
+
+        Returns:
+            bool
+        """
+
+        if self.type == DatatypeType.string:
+            if len(self.allowed_chars) > 0:
+                # if allowed chars is empty all chars are allowed
+                for char in value:
+                    if char not in self.allowed_chars:
+                        return False
+            for char in self.forbidden_chars:
+                if char in value:
+                    return False
+            return True
+
+        if self.type == DatatypeType.number:
+
+            if self.number_decimal_allowed:
+                try:
+                    number = float(value)
+                except:
+                    return False
+            else:
+                try:
+                    number = int(value)
+                except:
+                    return False
+
+            if not self.number_range_min == "/":
+                if number < self.number_range_min:
+                    return False
+            if not self.number_range_max == "/":
+                if number > self.number_range_max:
+                    return False
+
+            return True
+
+        if self.type == DatatypeType.enum:
+            return value in self.enum_values
+
+        if self.type == DatatypeType.date:
+            try:
+                from dateutil.parser import parse
+                parse(value, fuzzy=False)
+                return True
+
+            except ValueError:
+                return False
+
+        return True
+
+    def is_logically_equivalent_to(self, datatype:'Datatype',
+                                   vocabulary: 'Vocabulary',
+                                   old_vocabulary: 'Vocabulary') -> bool:
+        """Test if this datatype is logically equivalent to the given datatype
+
+        Args:
+            datatype (Datatype): Datatype to compare against
+            vocabulary (Vocabulary): Not used, but needed to keep signature the
+                same as other entities
+            old_vocabulary (Vocabulary): Not used, but needed to keep signature
+                the same as other entities
+        Returns:
+            bool
+        """
+
+        if not self.type == datatype.type:
+            return False
+        if not self.number_has_range == datatype.number_has_range:
+            return False
+        if not self.enum_values == datatype.enum_values:
+            return False
+
+        return True
+
+
+class Individual(Entity):
+    """
+    Represents OWL:Individual
+
+    An individual is a predefined "instance" of a class
+    But they are here only used as values for Relations
+
+    They are not instances, no value can be assigned to them, they are no
+    agents or devices
+    """
+
+    parent_class_iris: List[str] = Field(
+        default=[],
+        description="List of all parent class iris, "
+                    "an individual can have multiple parents")
+
+    def to_string(self) -> str:
+        """Get a string representation of the Individual
+
+        Returns:
+            str
+        """
+        return "(Individual)"+self.get_label()
+
+    def get_ancestor_iris(self, vocabulary: 'Vocabulary') -> List[str]:
+        """ Get all iris of ancestor classes
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary of the project
+
+        Returns:
+            List[str]
+        """
+        ancestor_iris = set()
+        for parent_iri in self.parent_class_iris:
+            ancestor_iris.add(parent_iri)
+            ancestor_iris.update(vocabulary.get_class_by_iri(parent_iri).
+                                 ancestor_class_iris)
+
+        return list(ancestor_iris)
+
+    def get_parent_classes(self, vocabulary: 'Vocabulary') -> List['Class']:
+        """ Get all parent class objects
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary of the project
+
+        Returns:
+            List[Class]
+        """
+        parents = []
+        for parent_iri in self.parent_class_iris:
+            parents.append(vocabulary.get_class_by_iri(parent_iri))
+        return parents
+
+    def is_logically_equivalent_to(self, individual: 'Individual',
+                                   vocabulary: 'Vocabulary',
+                                   old_vocabulary: 'Vocabulary') -> bool:
+        """Test if this individal is logically equivalent in two vocabularies.
+
+        Args:
+            individual (Individual): Individual to be tested against, from the
+                old vocabulary
+            vocabulary (Vocabulary): New project vocabulary, not used but needed
+                to keep signature the same
+            old_vocabulary (Vocabulary): Old project vocabulary, not used but
+                needed to keep signature the same
+
+        Returns:
+            bool
+        """
+
+        if not self._lists_are_identical(self.parent_class_iris,
+                                         individual.parent_class_iris):
+            return False
+        return True
+
+    def treat_dependency_statements(self, vocabulary: 'Vocabulary') -> \
+            List[DependencyStatement]:
+        """ Purge and list all pointers/iris that are not contained in the
+        vocabulary
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary of this project
+
+        Returns:
+            List[Dict[str, str]]: List of purged statements dicts with keys:
+            Parent Class, class, dependency, fulfilled
+        """
+        statements = []
+
+        for parent_iri in self.parent_class_iris:
+            found = parent_iri in vocabulary.classes
+            statements.append(DependencyStatement(type="Parent Class",
+                                                  class_iri=self.iri,
+                                                  dependency_iri=parent_iri,
+                                                  fulfilled=found
+                                                  ))
+
+            if not found:
+                self.parent_class_iris.remove(parent_iri)
+
+        return statements
+
+
+class DataFieldType(str, Enum):
+    """Type of the field that represents the DataProperty"""
+    command = "command"
+    device_attribute = "device_attribute"
+    simple = "simple"
+
+
+class DataProperty(Entity):
+    """
+    Representation of OWL:DataProperty
+    """
+
+    field_type: DataFieldType = Field(
+        default=DataFieldType.simple,
+        description="Type of the dataproperty; set by the user while "
+                    "configuring the vocabulary"
+    )
+
+
+class ObjectProperty(Entity):
+    """
+    Representation of OWL:ObjectProperty
+    """
+
+    inverse_property_iris: Set[str] = Field(
+        default=set(),
+        description="List of property iris that are inverse:Of; "
+                    "If an instance i2 is added in an instance i1 "
+                    "for this property. Then i1 is added to i2 under the"
+                    " inverseProperty (if the class has that property)")
+
+    def add_inverse_property_iri(self, iri: str):
+        """Add an inverse property
+
+        Args:
+            iri (str): Iri of the inverse objectProperty
+
+        Returns:
+            None
+        """
+        self.inverse_property_iris.add(iri)
+
+    def is_logically_equivalent_to(self, object_property: 'ObjectProperty',
+                                   vocabulary: 'Vocabulary',
+                                   old_vocabulary: 'Vocabulary') -> bool:
+        """Test if this Property in the new_vocabulary is logically equivalent
+        to the object_property in the old_vocabulary
+
+        Args:
+            object_property (ObjectProperty): ObjectProperty to be tested
+                against, from the old vocabulary
+            vocabulary (Vocabulary): New project vocabulary, not used but
+                needed to keep signature the same
+            old_vocabulary (Vocabulary): Old project vocabulary, not used but
+                needed to keep signature the same
+
+        Returns:
+            bool
+        """
+        if not self.inverse_property_iris == \
+                object_property.inverse_property_iris:
+            return False
+
+        return True
```

### Comparing `filip-0.3.0/filip/semantics/vocabulary/relation.py` & `filip-0.4.0/filip/semantics/vocabulary/relation.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,556 +1,556 @@
-"""Vocabulary Models for Relations"""
-
-from typing import Set, Dict, TYPE_CHECKING, Optional
-
-if TYPE_CHECKING:
-    from . import Vocabulary
-
-from aenum import Enum
-from typing import List, TYPE_CHECKING
-
-from pydantic import BaseModel, Field
-
-from .source import DependencyStatement
-
-if TYPE_CHECKING:
-    from . import Vocabulary, IdType
-
-
-class StatementType(str, Enum):
-    """
-    A statement is either a leaf and holds an iri/label or it is a combination
-    of leafs with or / and
-    """
-    OR = 'or'
-    AND = 'and'
-    LEAF = 'leaf'
-
-
-class TargetStatement(BaseModel):
-    """
-    A target statement is the statement the sits in a relation statement behind
-    the restrictionType:
-    E.g: consists_of some Device or Sensor.
-    here Device or Sensor is the targetstatement as it sits behind "some"
-
-    A targetstatement is build recursively: It is either a Leaf: str or a union
-    (or) or an intersection(and) of targetstatements
-
-    the combination of statements is purely logical and not numerical: device
-        and device is true as soon as one device is given,
-        it does not need two separate devices.
-    """
-
-    target_data_value: Optional[str] = Field(
-        default=None,
-        description="Holds the value if the relation is a hasValue (LEAF only)")
-    target_iri: str = Field(
-        default="",
-        description="The IRI of the target (LEAF only)")
-    target_statements: List['TargetStatement'] = Field(
-        default=[],
-        description="The targetstatements that are combined with this "
-                    "targetstatement (and/or only)"
-    )
-    type: StatementType = Field(default=StatementType.LEAF,
-                                description="Statement types")
-
-    def set_target(self, target_iri: str, target_data_value: str = None):
-        """ Set target for this statement and make it a LEAF statement
-
-        Args:
-            target_iri (str): iri of the target (class or datatype iri)
-            target_data_value (str): Value of the targetstatment if no IRI but
-             a fixed default value is given
-
-        Returns:
-            None
-        """
-        self.type = StatementType.LEAF
-        self.target_iri = target_iri
-        self.target_data_value = target_data_value
-
-    def get_all_targets(self) -> List[List[str]]:
-        """Extract possible targets out of statements
-        interpretation: [[a,b], [c]]-> (a and b) or c -> the target needs to
-        have ancestors(or be): (both a anb b) or c
-
-        items inside the inner brackets are connected via and the innerbrackets
-        are all connect over or
-
-        Returns:
-            List[List[str]]
-        """
-        if self.type == StatementType.LEAF:
-            if self.target_data_value is not None:
-                return [[]]
-            else:
-                return [[self.target_iri]]
-        else:
-            collection = []  # form: [ [[]], [[],[]], ..]
-            for statement in self.target_statements:
-                collection.append(statement.get_all_targets())
-
-            if self.type == StatementType.OR:
-                result = []
-                for sublist in collection:  # sublist form: [[],[],...]
-                    result.extend(sublist)
-                return result
-
-            else:  # AND
-                # with and we distribute our lists
-                # example: col= [ [[1],[2]], [[3,4]] ] => [[1,3,4], [2,3,4]]
-                # we build the results in an all in one way, we compute the
-                # number of entries in the final solution
-                # for each list li we fill the i-th position of all results
-
-                # example: col= [ [[a,b]], [[c],[d]] , [[e],[f]] ] =>
-                # statement: (a and b) and (c or d) and (e or f)
-                # 0 : res = [[], [], [], []]
-                # 1 : res = [[a,b], [a,b], [a,b], [a,b]]
-                # 2 : res = [[a,b,c], [a,b,c], [a,b,d], [a,b,d]]
-                # 3 : res = [[a,b,c,e], [a,b,c,f], [a,b,d,e], [a,b,d,f]]
-
-                result = []  # result form: [[],[],...]
-                lengths = []
-                number_of_entries = 1
-                for sublist in collection:  # sublist form: [[],[],...]
-                    number_of_entries = number_of_entries * len(sublist)
-                    lengths.append(len(sublist))
-
-                # init with empty lists
-                for empty in range(number_of_entries):
-                    result.append([])
-
-                for i in range(0, len(collection)):
-                    mod = 1
-                    for j in range(i + 1, len(lengths)):
-                        mod = mod * lengths[j]
-
-                    counter = 0
-                    while counter < number_of_entries:
-                        for sublist in collection[i]:
-                            for entry in sublist:
-                                for j in range(mod):
-                                    result[counter].append(entry)
-                                    counter += 1
-                return result
-
-    def to_string(self, vocabulary: 'Vocabulary') -> str:
-        """Get a string representation of the targetstatment
-
-        Args:
-            vocabulary (Vocabulary): vocabulary of the project
-
-        Returns:
-            str
-        """
-
-        if self.type == StatementType.LEAF:
-            label = self.retrieve_label(vocabulary)
-            if label == "":
-                return self.target_iri
-            return label
-        else:
-            result = "(" + self.target_statements[0].to_string(vocabulary)
-            for statement in self.target_statements[1:]:
-                result += " " + self.type + " "
-                result += statement.to_string(vocabulary) + ")"
-
-            return result
-
-    def is_fulfilled_by_iri_value(self, value: str, ancestor_values: List[str]) \
-            -> bool:
-        """
-        Test if a set of values fulfills the targetstatement;
-        Only for objectRelations
-
-        Args:
-            value (str): value to check: Class_iri of instance/individual
-            ancestor_values(List[List[str]]): List containing the ancestors iris
-                for each value (linked over index)
-        Returns:
-            bool
-        """
-
-        targets = self.get_all_targets()
-
-        values = ancestor_values
-        values.append(value)
-
-        # one sublist of targets needs to be fulfilled targets:
-        # [(a and b) or c or (d and a),....]
-        for sublist in targets:
-            sublist_fulfilled = True
-            for item in sublist:
-                if item not in values:
-                    sublist_fulfilled = False
-
-            if sublist_fulfilled:
-                return True
-        return False
-
-    def is_fulfilled_by_data_value(self, value: str, vocabulary: 'Vocabulary') \
-            -> bool:
-        """
-        Test if a set of values fulfills the targetstatement;
-        Only for dataRelations
-
-        Args:
-            value (List[str]):  value to check
-            vocabulary (Vocabulary)
-        Returns:
-            bool
-        """
-
-        # a data target_statement theoraticly only has one statement
-        if self.target_data_value is not None:
-            return value == self.target_data_value
-
-        from .vocabulary import IdType
-        if not vocabulary.is_id_of_type(self.target_iri, IdType.datatype):
-            return False
-        else:
-            datatype = vocabulary.get_datatype(self.target_iri)
-            return datatype.value_is_valid(value)
-
-    def retrieve_label(self, vocabulary: 'Vocabulary') -> str:
-        """Get the label of the target_iri. Only logical for Leaf statements
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary of the project
-
-        Returns:
-            str
-        """
-        if self.type == StatementType.LEAF:
-            if self.target_data_value is not None:
-                return self.target_data_value
-            else:
-                return vocabulary.get_label_for_entity_iri(self.target_iri)
-        return ""
-
-    def get_dependency_statements(
-            self,
-            vocabulary: 'Vocabulary',
-            ontology_iri: str,
-            class_iri: str) -> List[DependencyStatement]:
-        """
-        Get a list of all pointers/iris that are not contained in the
-        vocabulary. Purging is done in class
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary of this project
-            ontology_iri (str): IRI of the source ontology
-            class_iri (str): IRI of class (legacy)
-
-        Returns:
-            List[Dict[str, str]]: List of purged statements dicts with keys:
-            Parent Class, class, dependency, fulfilled
-        """
-        statements = []
-        if self.type == StatementType.LEAF:
-
-            # if we have a given data value, we do not have an iri
-            if self.target_data_value is None:
-                # check if predefined datatype
-                if not vocabulary.iri_is_predefined_datatype(self.target_iri):
-                    found = self.target_iri in vocabulary.classes or \
-                            self.target_iri in vocabulary.datatypes or \
-                            self.target_iri in vocabulary.individuals
-                    statements.append(
-                        DependencyStatement(
-                            type="Relation Target",
-                            class_iri=class_iri,
-                            dependency_iri=self.target_iri,
-                            fulfilled=found)
-                    )
-        else:
-            for target_statement in self.target_statements:
-                statements.extend(
-                    target_statement.get_dependency_statements(
-                        vocabulary, ontology_iri, class_iri))
-        return statements
-
-
-# target_statements is a forward reference, so that the class can refer to
-# itself this forward reference need to be resolved after the class has fully
-# loaded
-TargetStatement.model_rebuild()
-
-
-class RestrictionType(str, Enum):
-    """RestrictionTypes, as defined for OWL"""
-    _init_ = 'value __doc__'
-
-    some = 'some', 'at least 1 value of that target'
-    only = 'only', 'only value of that target'
-    min = 'min', 'min n values of that target'
-    max = 'max', 'max n values of that target'
-    exactly = 'exactly', 'exactly n values of that target'
-    value = 'value', 'predefined value'
-
-
-class Relation(BaseModel):
-    """
-    A Relation is defined in the source for a class.
-    It has the form: RestrictionType property target_statement
-
-    It defines a set of allowed/required values which each instance of this
-    class can/should have under this property
-
-    A Relation is defined in a OWL:class, but all child classes of that class
-    inherit it
-    """
-
-    id: str = Field(description="Unique generated Relation ID, "
-                                "for internal use")
-    restriction_type: RestrictionType = Field(
-        default=None,
-        description="Restriction type of this relation")
-    restriction_cardinality: int = Field(
-        default=-1,
-        description="Only needed for min, max, equaly states the 'n'")
-    property_iri: str = Field(
-        default="",
-        description="IRI of the property (data- or object-)")
-    target_statement: TargetStatement = Field(
-        default=None,
-        description="Complex statement which classes/datatype_catalogue "
-                    "are allowed/required")
-
-    def get_targets(self) -> List[List[str]]:
-        """Get all targets specified in the target statement in AND-OR Notation
-
-        Returns:
-            List[List[str]]: [[a,b],[c]] either a and b needs to present, or c
-        """
-        return self.target_statement.get_all_targets()
-
-    def to_string(self, vocabulary: 'Vocabulary') -> str:
-        """ Get a string representation of the relation
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary of this project
-
-        Returns:
-            str
-        """
-
-        if self.restriction_cardinality == -1:
-            return "{} {}".format(self.restriction_type, self.target_statement.
-                                  to_string(vocabulary))
-        else:
-            return self.restriction_type + " " + \
-                   str(self.restriction_cardinality) + " " \
-                   + self.target_statement.to_string(vocabulary)
-
-    def is_restriction_fulfilled(self, number_of_fulfilling_values: int,
-                                 total_number_of_values: int) -> bool:
-        """Test if the restriction type is fulfilled by comparing the number of
-        fulfilling values against the total
-        number of values given
-
-        Args:
-            number_of_fulfilling_values (int): Number of values that fulfill the
-                relation
-            total_number_of_values (int): the number of values given for this
-                relation
-
-        Returns:
-            bool
-        """
-
-        if self.restriction_type == RestrictionType.some:
-            return number_of_fulfilling_values >= 1
-        if self.restriction_type == RestrictionType.only:
-            return number_of_fulfilling_values == total_number_of_values
-        if self.restriction_type == RestrictionType.min:
-            return number_of_fulfilling_values >= \
-                   (int)(self.restriction_cardinality)
-        if self.restriction_type == RestrictionType.max:
-            return number_of_fulfilling_values <= \
-                   (int)(self.restriction_cardinality)
-        if self.restriction_type == RestrictionType.exactly:
-            return number_of_fulfilling_values == \
-                   (int)(self.restriction_cardinality)
-        if self.restriction_type == RestrictionType.value:
-            return number_of_fulfilling_values >= 1
-
-    def get_dependency_statements(
-            self, vocabulary: 'Vocabulary', ontology_iri: str, class_iri: str) \
-            -> List[DependencyStatement]:
-        """ Get a list of all pointers/iris that are not contained in the
-            vocabulary
-            Purging is done in class
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary of this project
-            ontology_iri (str): IRI of the source ontology
-            class_iri (str): IRI of class (legacy)
-
-        Returns:
-            List[Dict[str, str]]: List of purged statements dicts with keys:
-                Parent Class, class, dependency, fulfilled
-        """
-        statements = []
-
-        found = self.property_iri in vocabulary.object_properties or \
-                self.property_iri in vocabulary.data_properties
-
-        statements.append(DependencyStatement(type="Relation Property",
-                                              class_iri=class_iri,
-                                              dependency_iri=self.property_iri,
-                                              fulfilled=found))
-
-        statements.extend(self.target_statement.get_dependency_statements(
-            vocabulary, ontology_iri, class_iri))
-
-        return statements
-
-    def is_fulfilled_with_iris(
-            self, vocabulary: 'Vocabulary', values: List[str],
-            ancestor_values: List[List[str]]) -> bool:
-        """Test if a set of values fulfills the rules of the relation
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary of the project
-            values (List[str]):  List of values to check
-            ancestor_values(List[List[str]]): List containing the ancestors iris
-                for each value (linked over index)
-        Returns:
-            bool
-        """
-        number_of_fulfilling_values = 0
-        for i in range(len(values)):
-            if self.target_statement.is_fulfilled_by_iri_value(
-                    values[i], ancestor_values[i]):
-                number_of_fulfilling_values += 1
-
-        return self.is_restriction_fulfilled(number_of_fulfilling_values,
-                                             len(values))
-
-    def is_fulfilled_with_values(self, vocabulary: 'Vocabulary',
-                                 values: List[str]) -> bool:
-        """Test if a set of values fulfills the rules of the relation.
-        Used if property is a data property
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary of the project
-            values (List[str]):  List of values to check
-
-        Returns:
-            bool
-        """
-        number_of_fulfilling_values = 0
-
-        for i in range(len(values)):
-            if self.target_statement.is_fulfilled_by_data_value(values[i],
-                                                                vocabulary):
-                number_of_fulfilling_values += 1
-
-        return self.is_restriction_fulfilled(number_of_fulfilling_values,
-                                             len(values))
-
-    def get_all_possible_target_class_iris(self, vocabulary: 'Vocabulary') \
-            -> Set[str]:
-        """Get a set of class iris that are possible values for an
-        objectRelation
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary of this project
-
-        Returns:
-            Set[str]: class_iris
-        """
-
-        # if the relation is of type value it only defines that this relation
-        # has the given values
-        # not that it could have some more
-        if self.restriction_type == RestrictionType.value:
-            return set()
-
-        possible_class_iris = set()
-        targets = self.get_targets()
-        for target_list in targets:
-            for class_ in vocabulary.get_classes():
-                if class_.is_child_of_all_classes(target_list):
-                    possible_class_iris.add(class_.iri)
-                    children = vocabulary.get_class_by_iri(class_.iri). \
-                        child_class_iris
-                    possible_class_iris.update(children)
-
-        return possible_class_iris
-
-    def get_possible_enum_target_values(self, vocabulary: 'Vocabulary') -> \
-            List[str]:
-        """Get all allowed enum target values for a data relation
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary of this project
-
-        Returns:
-            List[str]
-        """
-        targets: List[List[str]] = self.target_statement.get_all_targets()
-
-        from .vocabulary import IdType
-        # methode only makes sense for data relations
-        if not vocabulary.is_id_of_type(self.property_iri,
-                                        IdType.data_property):
-            return []
-
-        res = []
-        # as it is a datarelation the targets should only contain single lists,
-        # to be flexible with changes we loop also
-        # these lists
-        for list in targets:
-            for entry_iri in list:
-                if vocabulary.is_id_of_type(entry_iri, IdType.datatype):
-                    datatype = vocabulary.get_datatype(entry_iri)
-                    res.extend(datatype.enum_values)
-
-        return res
-
-    def get_all_target_iris(self) -> Set[str]:
-        """Get all iris of targets
-
-        Returns:
-            Set(str)
-        """
-        iris = set()
-
-        statements = [self.target_statement]
-
-        while len(statements) > 0:
-            statement = statements.pop()
-            if statement.type == StatementType.LEAF:
-                if not statement.target_iri == "":
-                    iris.add(statement.target_iri)
-            else:
-                statements.extend(statement.target_statements)
-
-        return iris
-
-    def export_rule(self, vocabulary: 'Vocabulary') -> (str, str):
-        """Get the rule as string
-
-        Args:
-           vocabulary (Vocabulary): Vocabulary of the project
-
-        Returns:
-           str
-        """
-        targets = []
-        for inner_list in self.get_targets():
-            new_list = []
-            targets.append(new_list)
-            for iri in inner_list:
-                new_list.append(vocabulary.get_label_for_entity_iri(iri))
-
-        if (int)(self.restriction_cardinality) > 0:
-            return f'"{self.restriction_type.value}|' \
-                   f'{self.restriction_cardinality}"', targets
-        else:
-            return f'"{self.restriction_type.value}"', targets
-
+"""Vocabulary Models for Relations"""
+
+from typing import Set, Dict, TYPE_CHECKING, Optional
+
+if TYPE_CHECKING:
+    from . import Vocabulary
+
+from aenum import Enum
+from typing import List, TYPE_CHECKING
+
+from pydantic import BaseModel, Field
+
+from .source import DependencyStatement
+
+if TYPE_CHECKING:
+    from . import Vocabulary, IdType
+
+
+class StatementType(str, Enum):
+    """
+    A statement is either a leaf and holds an iri/label or it is a combination
+    of leafs with or / and
+    """
+    OR = 'or'
+    AND = 'and'
+    LEAF = 'leaf'
+
+
+class TargetStatement(BaseModel):
+    """
+    A target statement is the statement the sits in a relation statement behind
+    the restrictionType:
+    E.g: consists_of some Device or Sensor.
+    here Device or Sensor is the targetstatement as it sits behind "some"
+
+    A targetstatement is build recursively: It is either a Leaf: str or a union
+    (or) or an intersection(and) of targetstatements
+
+    the combination of statements is purely logical and not numerical: device
+        and device is true as soon as one device is given,
+        it does not need two separate devices.
+    """
+
+    target_data_value: Optional[str] = Field(
+        default=None,
+        description="Holds the value if the relation is a hasValue (LEAF only)")
+    target_iri: str = Field(
+        default="",
+        description="The IRI of the target (LEAF only)")
+    target_statements: List['TargetStatement'] = Field(
+        default=[],
+        description="The targetstatements that are combined with this "
+                    "targetstatement (and/or only)"
+    )
+    type: StatementType = Field(default=StatementType.LEAF,
+                                description="Statement types")
+
+    def set_target(self, target_iri: str, target_data_value: str = None):
+        """ Set target for this statement and make it a LEAF statement
+
+        Args:
+            target_iri (str): iri of the target (class or datatype iri)
+            target_data_value (str): Value of the targetstatment if no IRI but
+             a fixed default value is given
+
+        Returns:
+            None
+        """
+        self.type = StatementType.LEAF
+        self.target_iri = target_iri
+        self.target_data_value = target_data_value
+
+    def get_all_targets(self) -> List[List[str]]:
+        """Extract possible targets out of statements
+        interpretation: [[a,b], [c]]-> (a and b) or c -> the target needs to
+        have ancestors(or be): (both a anb b) or c
+
+        items inside the inner brackets are connected via and the innerbrackets
+        are all connect over or
+
+        Returns:
+            List[List[str]]
+        """
+        if self.type == StatementType.LEAF:
+            if self.target_data_value is not None:
+                return [[]]
+            else:
+                return [[self.target_iri]]
+        else:
+            collection = []  # form: [ [[]], [[],[]], ..]
+            for statement in self.target_statements:
+                collection.append(statement.get_all_targets())
+
+            if self.type == StatementType.OR:
+                result = []
+                for sublist in collection:  # sublist form: [[],[],...]
+                    result.extend(sublist)
+                return result
+
+            else:  # AND
+                # with and we distribute our lists
+                # example: col= [ [[1],[2]], [[3,4]] ] => [[1,3,4], [2,3,4]]
+                # we build the results in an all in one way, we compute the
+                # number of entries in the final solution
+                # for each list li we fill the i-th position of all results
+
+                # example: col= [ [[a,b]], [[c],[d]] , [[e],[f]] ] =>
+                # statement: (a and b) and (c or d) and (e or f)
+                # 0 : res = [[], [], [], []]
+                # 1 : res = [[a,b], [a,b], [a,b], [a,b]]
+                # 2 : res = [[a,b,c], [a,b,c], [a,b,d], [a,b,d]]
+                # 3 : res = [[a,b,c,e], [a,b,c,f], [a,b,d,e], [a,b,d,f]]
+
+                result = []  # result form: [[],[],...]
+                lengths = []
+                number_of_entries = 1
+                for sublist in collection:  # sublist form: [[],[],...]
+                    number_of_entries = number_of_entries * len(sublist)
+                    lengths.append(len(sublist))
+
+                # init with empty lists
+                for empty in range(number_of_entries):
+                    result.append([])
+
+                for i in range(0, len(collection)):
+                    mod = 1
+                    for j in range(i + 1, len(lengths)):
+                        mod = mod * lengths[j]
+
+                    counter = 0
+                    while counter < number_of_entries:
+                        for sublist in collection[i]:
+                            for entry in sublist:
+                                for j in range(mod):
+                                    result[counter].append(entry)
+                                    counter += 1
+                return result
+
+    def to_string(self, vocabulary: 'Vocabulary') -> str:
+        """Get a string representation of the targetstatment
+
+        Args:
+            vocabulary (Vocabulary): vocabulary of the project
+
+        Returns:
+            str
+        """
+
+        if self.type == StatementType.LEAF:
+            label = self.retrieve_label(vocabulary)
+            if label == "":
+                return self.target_iri
+            return label
+        else:
+            result = "(" + self.target_statements[0].to_string(vocabulary)
+            for statement in self.target_statements[1:]:
+                result += " " + self.type + " "
+                result += statement.to_string(vocabulary) + ")"
+
+            return result
+
+    def is_fulfilled_by_iri_value(self, value: str, ancestor_values: List[str]) \
+            -> bool:
+        """
+        Test if a set of values fulfills the targetstatement;
+        Only for objectRelations
+
+        Args:
+            value (str): value to check: Class_iri of instance/individual
+            ancestor_values(List[List[str]]): List containing the ancestors iris
+                for each value (linked over index)
+        Returns:
+            bool
+        """
+
+        targets = self.get_all_targets()
+
+        values = ancestor_values
+        values.append(value)
+
+        # one sublist of targets needs to be fulfilled targets:
+        # [(a and b) or c or (d and a),....]
+        for sublist in targets:
+            sublist_fulfilled = True
+            for item in sublist:
+                if item not in values:
+                    sublist_fulfilled = False
+
+            if sublist_fulfilled:
+                return True
+        return False
+
+    def is_fulfilled_by_data_value(self, value: str, vocabulary: 'Vocabulary') \
+            -> bool:
+        """
+        Test if a set of values fulfills the targetstatement;
+        Only for dataRelations
+
+        Args:
+            value (List[str]):  value to check
+            vocabulary (Vocabulary)
+        Returns:
+            bool
+        """
+
+        # a data target_statement theoraticly only has one statement
+        if self.target_data_value is not None:
+            return value == self.target_data_value
+
+        from .vocabulary import IdType
+        if not vocabulary.is_id_of_type(self.target_iri, IdType.datatype):
+            return False
+        else:
+            datatype = vocabulary.get_datatype(self.target_iri)
+            return datatype.value_is_valid(value)
+
+    def retrieve_label(self, vocabulary: 'Vocabulary') -> str:
+        """Get the label of the target_iri. Only logical for Leaf statements
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary of the project
+
+        Returns:
+            str
+        """
+        if self.type == StatementType.LEAF:
+            if self.target_data_value is not None:
+                return self.target_data_value
+            else:
+                return vocabulary.get_label_for_entity_iri(self.target_iri)
+        return ""
+
+    def get_dependency_statements(
+            self,
+            vocabulary: 'Vocabulary',
+            ontology_iri: str,
+            class_iri: str) -> List[DependencyStatement]:
+        """
+        Get a list of all pointers/iris that are not contained in the
+        vocabulary. Purging is done in class
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary of this project
+            ontology_iri (str): IRI of the source ontology
+            class_iri (str): IRI of class (legacy)
+
+        Returns:
+            List[Dict[str, str]]: List of purged statements dicts with keys:
+            Parent Class, class, dependency, fulfilled
+        """
+        statements = []
+        if self.type == StatementType.LEAF:
+
+            # if we have a given data value, we do not have an iri
+            if self.target_data_value is None:
+                # check if predefined datatype
+                if not vocabulary.iri_is_predefined_datatype(self.target_iri):
+                    found = self.target_iri in vocabulary.classes or \
+                            self.target_iri in vocabulary.datatypes or \
+                            self.target_iri in vocabulary.individuals
+                    statements.append(
+                        DependencyStatement(
+                            type="Relation Target",
+                            class_iri=class_iri,
+                            dependency_iri=self.target_iri,
+                            fulfilled=found)
+                    )
+        else:
+            for target_statement in self.target_statements:
+                statements.extend(
+                    target_statement.get_dependency_statements(
+                        vocabulary, ontology_iri, class_iri))
+        return statements
+
+
+# target_statements is a forward reference, so that the class can refer to
+# itself this forward reference need to be resolved after the class has fully
+# loaded
+TargetStatement.model_rebuild()
+
+
+class RestrictionType(str, Enum):
+    """RestrictionTypes, as defined for OWL"""
+    _init_ = 'value __doc__'
+
+    some = 'some', 'at least 1 value of that target'
+    only = 'only', 'only value of that target'
+    min = 'min', 'min n values of that target'
+    max = 'max', 'max n values of that target'
+    exactly = 'exactly', 'exactly n values of that target'
+    value = 'value', 'predefined value'
+
+
+class Relation(BaseModel):
+    """
+    A Relation is defined in the source for a class.
+    It has the form: RestrictionType property target_statement
+
+    It defines a set of allowed/required values which each instance of this
+    class can/should have under this property
+
+    A Relation is defined in a OWL:class, but all child classes of that class
+    inherit it
+    """
+
+    id: str = Field(description="Unique generated Relation ID, "
+                                "for internal use")
+    restriction_type: RestrictionType = Field(
+        default=None,
+        description="Restriction type of this relation")
+    restriction_cardinality: int = Field(
+        default=-1,
+        description="Only needed for min, max, equaly states the 'n'")
+    property_iri: str = Field(
+        default="",
+        description="IRI of the property (data- or object-)")
+    target_statement: TargetStatement = Field(
+        default=None,
+        description="Complex statement which classes/datatype_catalogue "
+                    "are allowed/required")
+
+    def get_targets(self) -> List[List[str]]:
+        """Get all targets specified in the target statement in AND-OR Notation
+
+        Returns:
+            List[List[str]]: [[a,b],[c]] either a and b needs to present, or c
+        """
+        return self.target_statement.get_all_targets()
+
+    def to_string(self, vocabulary: 'Vocabulary') -> str:
+        """ Get a string representation of the relation
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary of this project
+
+        Returns:
+            str
+        """
+
+        if self.restriction_cardinality == -1:
+            return "{} {}".format(self.restriction_type, self.target_statement.
+                                  to_string(vocabulary))
+        else:
+            return self.restriction_type + " " + \
+                   str(self.restriction_cardinality) + " " \
+                   + self.target_statement.to_string(vocabulary)
+
+    def is_restriction_fulfilled(self, number_of_fulfilling_values: int,
+                                 total_number_of_values: int) -> bool:
+        """Test if the restriction type is fulfilled by comparing the number of
+        fulfilling values against the total
+        number of values given
+
+        Args:
+            number_of_fulfilling_values (int): Number of values that fulfill the
+                relation
+            total_number_of_values (int): the number of values given for this
+                relation
+
+        Returns:
+            bool
+        """
+
+        if self.restriction_type == RestrictionType.some:
+            return number_of_fulfilling_values >= 1
+        if self.restriction_type == RestrictionType.only:
+            return number_of_fulfilling_values == total_number_of_values
+        if self.restriction_type == RestrictionType.min:
+            return number_of_fulfilling_values >= \
+                   (int)(self.restriction_cardinality)
+        if self.restriction_type == RestrictionType.max:
+            return number_of_fulfilling_values <= \
+                   (int)(self.restriction_cardinality)
+        if self.restriction_type == RestrictionType.exactly:
+            return number_of_fulfilling_values == \
+                   (int)(self.restriction_cardinality)
+        if self.restriction_type == RestrictionType.value:
+            return number_of_fulfilling_values >= 1
+
+    def get_dependency_statements(
+            self, vocabulary: 'Vocabulary', ontology_iri: str, class_iri: str) \
+            -> List[DependencyStatement]:
+        """ Get a list of all pointers/iris that are not contained in the
+            vocabulary
+            Purging is done in class
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary of this project
+            ontology_iri (str): IRI of the source ontology
+            class_iri (str): IRI of class (legacy)
+
+        Returns:
+            List[Dict[str, str]]: List of purged statements dicts with keys:
+                Parent Class, class, dependency, fulfilled
+        """
+        statements = []
+
+        found = self.property_iri in vocabulary.object_properties or \
+                self.property_iri in vocabulary.data_properties
+
+        statements.append(DependencyStatement(type="Relation Property",
+                                              class_iri=class_iri,
+                                              dependency_iri=self.property_iri,
+                                              fulfilled=found))
+
+        statements.extend(self.target_statement.get_dependency_statements(
+            vocabulary, ontology_iri, class_iri))
+
+        return statements
+
+    def is_fulfilled_with_iris(
+            self, vocabulary: 'Vocabulary', values: List[str],
+            ancestor_values: List[List[str]]) -> bool:
+        """Test if a set of values fulfills the rules of the relation
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary of the project
+            values (List[str]):  List of values to check
+            ancestor_values(List[List[str]]): List containing the ancestors iris
+                for each value (linked over index)
+        Returns:
+            bool
+        """
+        number_of_fulfilling_values = 0
+        for i in range(len(values)):
+            if self.target_statement.is_fulfilled_by_iri_value(
+                    values[i], ancestor_values[i]):
+                number_of_fulfilling_values += 1
+
+        return self.is_restriction_fulfilled(number_of_fulfilling_values,
+                                             len(values))
+
+    def is_fulfilled_with_values(self, vocabulary: 'Vocabulary',
+                                 values: List[str]) -> bool:
+        """Test if a set of values fulfills the rules of the relation.
+        Used if property is a data property
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary of the project
+            values (List[str]):  List of values to check
+
+        Returns:
+            bool
+        """
+        number_of_fulfilling_values = 0
+
+        for i in range(len(values)):
+            if self.target_statement.is_fulfilled_by_data_value(values[i],
+                                                                vocabulary):
+                number_of_fulfilling_values += 1
+
+        return self.is_restriction_fulfilled(number_of_fulfilling_values,
+                                             len(values))
+
+    def get_all_possible_target_class_iris(self, vocabulary: 'Vocabulary') \
+            -> Set[str]:
+        """Get a set of class iris that are possible values for an
+        objectRelation
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary of this project
+
+        Returns:
+            Set[str]: class_iris
+        """
+
+        # if the relation is of type value it only defines that this relation
+        # has the given values
+        # not that it could have some more
+        if self.restriction_type == RestrictionType.value:
+            return set()
+
+        possible_class_iris = set()
+        targets = self.get_targets()
+        for target_list in targets:
+            for class_ in vocabulary.get_classes():
+                if class_.is_child_of_all_classes(target_list):
+                    possible_class_iris.add(class_.iri)
+                    children = vocabulary.get_class_by_iri(class_.iri). \
+                        child_class_iris
+                    possible_class_iris.update(children)
+
+        return possible_class_iris
+
+    def get_possible_enum_target_values(self, vocabulary: 'Vocabulary') -> \
+            List[str]:
+        """Get all allowed enum target values for a data relation
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary of this project
+
+        Returns:
+            List[str]
+        """
+        targets: List[List[str]] = self.target_statement.get_all_targets()
+
+        from .vocabulary import IdType
+        # methode only makes sense for data relations
+        if not vocabulary.is_id_of_type(self.property_iri,
+                                        IdType.data_property):
+            return []
+
+        res = []
+        # as it is a datarelation the targets should only contain single lists,
+        # to be flexible with changes we loop also
+        # these lists
+        for list in targets:
+            for entry_iri in list:
+                if vocabulary.is_id_of_type(entry_iri, IdType.datatype):
+                    datatype = vocabulary.get_datatype(entry_iri)
+                    res.extend(datatype.enum_values)
+
+        return res
+
+    def get_all_target_iris(self) -> Set[str]:
+        """Get all iris of targets
+
+        Returns:
+            Set(str)
+        """
+        iris = set()
+
+        statements = [self.target_statement]
+
+        while len(statements) > 0:
+            statement = statements.pop()
+            if statement.type == StatementType.LEAF:
+                if not statement.target_iri == "":
+                    iris.add(statement.target_iri)
+            else:
+                statements.extend(statement.target_statements)
+
+        return iris
+
+    def export_rule(self, vocabulary: 'Vocabulary') -> (str, str):
+        """Get the rule as string
+
+        Args:
+           vocabulary (Vocabulary): Vocabulary of the project
+
+        Returns:
+           str
+        """
+        targets = []
+        for inner_list in self.get_targets():
+            new_list = []
+            targets.append(new_list)
+            for iri in inner_list:
+                new_list.append(vocabulary.get_label_for_entity_iri(iri))
+
+        if (int)(self.restriction_cardinality) > 0:
+            return f'"{self.restriction_type.value}|' \
+                   f'{self.restriction_cardinality}"', targets
+        else:
+            return f'"{self.restriction_type.value}"', targets
+
```

### Comparing `filip-0.3.0/filip/semantics/vocabulary/source.py` & `filip-0.4.0/filip/semantics/vocabulary/source.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,227 +1,227 @@
-"""Vocabulary Models for Ontology Sources"""
-
-import datetime
-from typing import TYPE_CHECKING, List, Optional
-
-from pydantic import ConfigDict, BaseModel, Field
-
-from ...models.base import LogLevel
-
-if TYPE_CHECKING:
-    from . import Vocabulary, IdType, LoggingLevel
-
-
-class DependencyStatement(BaseModel):
-    """Information about one dependency statement in the source
-    A dependency is a reference of one iri in an other entity definition
-    """
-    source_iri: str = Field(
-        default="",
-        description="Iri of the source containing the statement")
-    source_name: str = Field(
-        default="",
-        description="Name of the source containing the statement")
-    type: str = Field(
-        description="Possible types: Parent Class, Relation Property, "
-                    "Relation Target")
-    class_iri: str = Field(
-        description="Iri of the class containing the statement")
-    dependency_iri: str = Field(description="Entity Iri of the dependency")
-    fulfilled: bool = Field(
-        description="True if the dependency_iri is registered in the "
-                    "vocabulary")
-
-
-class ParsingError(BaseModel):
-    """Object represents one issue that arose while parsing a source,
-       and holds all relevant details for that issue"""
-    model_config = ConfigDict(use_enum_values=True)
-    level: LogLevel = Field(description="Severity of error")
-    source_iri: str = Field(description=
-                            "Iri of the source containing the error")
-    source_name: Optional[str] = Field(
-        default=None,
-        description="Name of the source, only set in get_function"
-    )
-    entity_type: str = Field(
-        description="Type of the problematic entity: Class, Individual,.."
-                    "ID_type in string form"
-    )
-    entity_iri: str = Field(description="Iri of the problematic entity")
-    entity_label: Optional[str] = Field(
-        default=None,
-        description="Name of the source, only set in get_function"
-    )
-    message: str = Field(
-        description="Message describing the error"
-    )
-
-
-class Source(BaseModel):
-    """
-    A source represent one file that was provided via file upload or link to the
-    project and is parsed into the
-    vocabulary
-    """
-
-    id: str = Field(default="",
-                    description="unique ID of the source; for internal use")
-    source_name: str = Field(default="",
-                             description="Name of the source ")
-    content: str = Field(
-        default="",
-        description="File content of the provided ontology file")
-    parsing_log: List['ParsingError'] = Field(
-        default=[],
-        description="Log containing all issues that were discovered while "
-                    "parsing")
-    dependency_statements: List[DependencyStatement] = Field(
-        default=[],
-        description="List of all statements in source")
-    timestamp: datetime.datetime = Field(
-        description="timestamp when the source was added to the project")
-    ontology_iri: str = Field(
-        default=None,
-        description="Iri of the ontology of the source")
-    predefined: bool = Field(
-        default=False,
-        description="Stating if the source is a predefined source; "
-                    "a predefined source is added to each project containing "
-                    "owl:Thing and predefined Datatypes")
-
-    def get_number_of_id_type(self, vocabulary: 'Vocabulary',
-                              id_type: 'IdType') -> int:
-        """Get the number how many entities of a given type are created by or
-        influenced by this source
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary of this project
-            id_type (IdType): Idtype that should be counted
-
-        Returns:
-            int
-        """
-
-        from . import IdType
-        id_func = "/"
-        iri_list = []
-
-        if id_type is IdType.class_:
-            id_func = vocabulary.get_class_by_iri
-            iri_list = vocabulary.classes
-        elif id_type is IdType.object_property:
-            id_func = vocabulary.get_object_property
-            iri_list = vocabulary.object_properties
-        elif id_type is IdType.data_property:
-            id_func = vocabulary.get_data_property
-            iri_list = vocabulary.data_properties
-        elif id_type is IdType.individual:
-            id_func = vocabulary.get_individual
-            iri_list = vocabulary.individuals
-        elif id_type is IdType.datatype:
-            id_func = vocabulary.get_datatype
-            iri_list = vocabulary.datatypes
-
-        if id_func == "/":
-            return -1
-
-        counter = 0
-        for iri in iri_list:
-            entity = id_func(iri)
-            if self.id in entity.source_ids:
-                counter += 1
-        return counter
-
-    def get_name(self) -> str:
-        """Get the name of the source
-
-        Returns:
-            str
-        """
-        return self.source_name
-
-    def treat_dependency_statements(self, vocabulary: 'Vocabulary'):
-        """
-        Log and purge all pointers/iris in entities that are not contained
-        in the vocabulary
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary of this project
-
-        Returns:
-            None
-        """
-        dependency_statements = []
-
-        for class_ in vocabulary.get_classes():
-            if self.id in class_.source_ids:
-                dependency_statements.extend(
-                    class_.treat_dependency_statements(vocabulary))
-
-        for individual_iri in vocabulary.individuals:
-            individual = vocabulary.get_individual(individual_iri)
-            if self.id in individual.source_ids:
-                dependency_statements.extend(
-                    individual.treat_dependency_statements(vocabulary))
-
-        for statement in dependency_statements:
-            statement.source_iri = self.ontology_iri
-            statement.source_name = self.source_name
-
-        self.dependency_statements = dependency_statements
-
-    def add_parsing_log_entry(self, level: 'LoggingLevel', entity_type: 'IdType',
-                              entity_iri: str,  msg: str):
-        """
-        Add a parsing log entry for an entity, if an issue in parsing
-        was discovered
-
-        Args:
-            level (LoggingLevel): Logging level of the entry
-            entity_type (IdType): Type of the enitity (Class, Individual,..)
-            entity_iri (str): iri of the entity
-            msg (str): message to display in log
-
-        Returns:
-            None
-        """
-
-        from . import ParsingError
-        self.parsing_log.append(ParsingError(
-            level=level,
-            entity_type=str(entity_type),
-            entity_iri=entity_iri,
-            message=msg,
-            source_iri=self.ontology_iri
-        ))
-
-    def get_parsing_log(self, vocabulary: 'Vocabulary') -> List['ParsingError']:
-        """Get the Parsinglog, where the labels of the entities are filled in
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary of this project
-
-        Returns:
-            List[Dict[str, Union[LoggingLevel,'IdType',str]]]
-        """
-        for entry in self.parsing_log:
-
-            entry.source_name = self.source_name
-            try:
-                label = vocabulary.get_label_for_entity_iri(entry.entity_iri)
-                entry.entity_label = label
-            except Exception:
-                pass
-
-        return self.parsing_log
-
-    def clear(self):
-        """Clear all logging and dependency data of the source
-
-        Returns:
-            None
-        """
-        self.parsing_log = []
-        self.dependency_statements = []
-
-
+"""Vocabulary Models for Ontology Sources"""
+
+import datetime
+from typing import TYPE_CHECKING, List, Optional
+
+from pydantic import ConfigDict, BaseModel, Field
+
+from ...models.base import LogLevel
+
+if TYPE_CHECKING:
+    from . import Vocabulary, IdType, LoggingLevel
+
+
+class DependencyStatement(BaseModel):
+    """Information about one dependency statement in the source
+    A dependency is a reference of one iri in an other entity definition
+    """
+    source_iri: str = Field(
+        default="",
+        description="Iri of the source containing the statement")
+    source_name: str = Field(
+        default="",
+        description="Name of the source containing the statement")
+    type: str = Field(
+        description="Possible types: Parent Class, Relation Property, "
+                    "Relation Target")
+    class_iri: str = Field(
+        description="Iri of the class containing the statement")
+    dependency_iri: str = Field(description="Entity Iri of the dependency")
+    fulfilled: bool = Field(
+        description="True if the dependency_iri is registered in the "
+                    "vocabulary")
+
+
+class ParsingError(BaseModel):
+    """Object represents one issue that arose while parsing a source,
+       and holds all relevant details for that issue"""
+    model_config = ConfigDict(use_enum_values=True)
+    level: LogLevel = Field(description="Severity of error")
+    source_iri: str = Field(description=
+                            "Iri of the source containing the error")
+    source_name: Optional[str] = Field(
+        default=None,
+        description="Name of the source, only set in get_function"
+    )
+    entity_type: str = Field(
+        description="Type of the problematic entity: Class, Individual,.."
+                    "ID_type in string form"
+    )
+    entity_iri: str = Field(description="Iri of the problematic entity")
+    entity_label: Optional[str] = Field(
+        default=None,
+        description="Name of the source, only set in get_function"
+    )
+    message: str = Field(
+        description="Message describing the error"
+    )
+
+
+class Source(BaseModel):
+    """
+    A source represent one file that was provided via file upload or link to the
+    project and is parsed into the
+    vocabulary
+    """
+
+    id: str = Field(default="",
+                    description="unique ID of the source; for internal use")
+    source_name: str = Field(default="",
+                             description="Name of the source ")
+    content: str = Field(
+        default="",
+        description="File content of the provided ontology file")
+    parsing_log: List['ParsingError'] = Field(
+        default=[],
+        description="Log containing all issues that were discovered while "
+                    "parsing")
+    dependency_statements: List[DependencyStatement] = Field(
+        default=[],
+        description="List of all statements in source")
+    timestamp: datetime.datetime = Field(
+        description="timestamp when the source was added to the project")
+    ontology_iri: str = Field(
+        default=None,
+        description="Iri of the ontology of the source")
+    predefined: bool = Field(
+        default=False,
+        description="Stating if the source is a predefined source; "
+                    "a predefined source is added to each project containing "
+                    "owl:Thing and predefined Datatypes")
+
+    def get_number_of_id_type(self, vocabulary: 'Vocabulary',
+                              id_type: 'IdType') -> int:
+        """Get the number how many entities of a given type are created by or
+        influenced by this source
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary of this project
+            id_type (IdType): Idtype that should be counted
+
+        Returns:
+            int
+        """
+
+        from . import IdType
+        id_func = "/"
+        iri_list = []
+
+        if id_type is IdType.class_:
+            id_func = vocabulary.get_class_by_iri
+            iri_list = vocabulary.classes
+        elif id_type is IdType.object_property:
+            id_func = vocabulary.get_object_property
+            iri_list = vocabulary.object_properties
+        elif id_type is IdType.data_property:
+            id_func = vocabulary.get_data_property
+            iri_list = vocabulary.data_properties
+        elif id_type is IdType.individual:
+            id_func = vocabulary.get_individual
+            iri_list = vocabulary.individuals
+        elif id_type is IdType.datatype:
+            id_func = vocabulary.get_datatype
+            iri_list = vocabulary.datatypes
+
+        if id_func == "/":
+            return -1
+
+        counter = 0
+        for iri in iri_list:
+            entity = id_func(iri)
+            if self.id in entity.source_ids:
+                counter += 1
+        return counter
+
+    def get_name(self) -> str:
+        """Get the name of the source
+
+        Returns:
+            str
+        """
+        return self.source_name
+
+    def treat_dependency_statements(self, vocabulary: 'Vocabulary'):
+        """
+        Log and purge all pointers/iris in entities that are not contained
+        in the vocabulary
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary of this project
+
+        Returns:
+            None
+        """
+        dependency_statements = []
+
+        for class_ in vocabulary.get_classes():
+            if self.id in class_.source_ids:
+                dependency_statements.extend(
+                    class_.treat_dependency_statements(vocabulary))
+
+        for individual_iri in vocabulary.individuals:
+            individual = vocabulary.get_individual(individual_iri)
+            if self.id in individual.source_ids:
+                dependency_statements.extend(
+                    individual.treat_dependency_statements(vocabulary))
+
+        for statement in dependency_statements:
+            statement.source_iri = self.ontology_iri
+            statement.source_name = self.source_name
+
+        self.dependency_statements = dependency_statements
+
+    def add_parsing_log_entry(self, level: 'LoggingLevel', entity_type: 'IdType',
+                              entity_iri: str,  msg: str):
+        """
+        Add a parsing log entry for an entity, if an issue in parsing
+        was discovered
+
+        Args:
+            level (LoggingLevel): Logging level of the entry
+            entity_type (IdType): Type of the enitity (Class, Individual,..)
+            entity_iri (str): iri of the entity
+            msg (str): message to display in log
+
+        Returns:
+            None
+        """
+
+        from . import ParsingError
+        self.parsing_log.append(ParsingError(
+            level=level,
+            entity_type=str(entity_type),
+            entity_iri=entity_iri,
+            message=msg,
+            source_iri=self.ontology_iri
+        ))
+
+    def get_parsing_log(self, vocabulary: 'Vocabulary') -> List['ParsingError']:
+        """Get the Parsinglog, where the labels of the entities are filled in
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary of this project
+
+        Returns:
+            List[Dict[str, Union[LoggingLevel,'IdType',str]]]
+        """
+        for entry in self.parsing_log:
+
+            entry.source_name = self.source_name
+            try:
+                label = vocabulary.get_label_for_entity_iri(entry.entity_iri)
+                entry.entity_label = label
+            except Exception:
+                pass
+
+        return self.parsing_log
+
+    def clear(self):
+        """Clear all logging and dependency data of the source
+
+        Returns:
+            None
+        """
+        self.parsing_log = []
+        self.dependency_statements = []
+
+
```

### Comparing `filip-0.3.0/filip/semantics/vocabulary_configurator.py` & `filip-0.4.0/filip/semantics/vocabulary_configurator.py`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,875 +1,875 @@
-"""Module providing an interface to manipulate the sources of a vocabulary,
-and to ability to export it to models"""
-
-import copy
-import io
-import keyword
-import os
-from datetime import datetime
-from string import ascii_letters, digits
-from typing import List, Optional, Dict, Tuple, Set
-
-import pathlib
-import requests
-import wget
-
-from filip.semantics.ontology_parser.post_processer import PostProcessor
-from filip.semantics.ontology_parser.rdfparser import RdfParser
-from filip.semantics.vocabulary import \
-    LabelSummary, \
-    Vocabulary, \
-    Source, \
-    Entity, \
-    RestrictionType, \
-    Class, \
-    ParsingError, \
-    CombinedRelation, \
-    DataFieldType, \
-    DependencyStatement, \
-    VocabularySettings
-
-# Blacklist containing all labels that are forbidden for entities to have
-label_blacklist = list(keyword.kwlist)
-label_blacklist.extend(["referencedBy", "deviceSettings"])
-label_blacklist.extend(["references", "device_settings", "header",
-                        "old_state", "", "semantic_manager", "delete",
-                        "metadata"])
-label_blacklist.extend(["id", "type", "class"])
-label_blacklist.extend(["str", "int", "float", "complex", "list", "tuple",
-                        "range", "dict", "list", "set", "frozenset", "bool",
-                        "bytes", "bytearray", "memoryview"])
-
-# Whitelist containing all chars that an entity label can consist of
-label_char_whitelist = ascii_letters + digits + "_"
-
-
-class VocabularyConfigurator:
-    """
-    Class that provides static interfaces to manipulate the sources of a
-    vocabulary, validate and save it.
-    """
-
-    @classmethod
-    def create_vocabulary(cls,
-                          settings: VocabularySettings = VocabularySettings()) \
-            -> Vocabulary:
-        """
-        Create a new blank vocabulary with given settings
-
-        Args:
-            settings: VocabularySettings
-
-        Returns:
-            Vocabulary
-        """
-
-        return Vocabulary(settings=settings)
-
-    @classmethod
-    def delete_source_from_vocabulary(cls, vocabulary: Vocabulary,
-                                      source_id: str) -> Vocabulary:
-        """
-        Delete a source from the vocabulary
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary from which the source should
-            be removed
-            source_id (str): Id of source to remove
-
-        Raises:
-            ValueError:  If no source with given Id exists in Vocabulary
-
-        Returns:
-            New Vocabulary without the given source
-        """
-        new_vocabulary = Vocabulary(settings=copy.copy(vocabulary.settings))
-        parser = RdfParser()
-        found = False
-        for source in vocabulary.sources.values():
-            if not source_id == source.id:
-                parser.parse_source_into_vocabulary(
-                    source=copy.deepcopy(source), vocabulary=new_vocabulary)
-            else:
-                found = True
-
-        PostProcessor.post_process_vocabulary(
-            vocabulary=new_vocabulary, old_vocabulary=vocabulary)
-
-        if not found:
-            raise ValueError(
-                f"Source with source_id {source_id} not in vocabulary")
-
-        PostProcessor.transfer_settings(
-            new_vocabulary=new_vocabulary, old_vocabulary=vocabulary)
-
-        return new_vocabulary
-
-    @classmethod
-    def add_ontology_to_vocabulary_as_link(
-            cls,
-            vocabulary: Vocabulary,
-            link: str,
-            source_name: Optional[str] = None) -> Vocabulary:
-        """
-        Add a source to the vocabulary with via a weblink. Source name will
-        be extracted from link, if no name is given
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary to which the source should
-            be added
-            link (str): Weblink to the source
-            source_name (Optional[str]): Name for the source
-
-        Raises:
-            ParsingException:  If the given source was not valid and could not
-            be parsed
-
-        Returns:
-            New Vocabulary with the given source added to it
-        """
-
-        downloaded_obj = requests.get(link)
-        file_bytes = io.BytesIO(downloaded_obj.content)
-        if source_name is None:
-            source_name = wget.filename_from_url(link)
-
-        file_str = io.TextIOWrapper(file_bytes, encoding='utf-8').read()
-
-        return cls.add_ontology_to_vocabulary_as_string(vocabulary=vocabulary,
-                                                        source_name=source_name,
-                                                        source_content=file_str)
-
-    @classmethod
-    def add_ontology_to_vocabulary_as_file(
-            cls,
-            vocabulary: Vocabulary,
-            path_to_file: str,
-            source_name: Optional[str] = None) -> Vocabulary:
-        """
-        Add a source to the vocabulary with via a file path. Source name will
-        be extracted from path, if no name is given
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary to which the source should
-            be added
-            path_to_file (str): Path to the source file
-            source_name (Optional[str]): Name for the source
-
-        Raises:
-            ParsingException:  If the given source was not valid and could not
-            be parsed
-
-        Returns:
-            New Vocabulary with the given source added to it
-        """
-
-        with open(path_to_file, 'r') as file:
-            data = file.read()
-
-        if source_name is None:
-            source_name = os.path.basename(path_to_file).split(".")[0]
-
-        source = Source(source_name=source_name,
-                        content=data,
-                        timestamp=datetime.now())
-
-        return VocabularyConfigurator._parse_sources_into_vocabulary(
-            vocabulary=vocabulary, sources=[source])
-
-    @classmethod
-    def add_ontology_to_vocabulary_as_string(cls, vocabulary: Vocabulary,
-                                             source_name: str,
-                                             source_content: str) -> Vocabulary:
-        """
-        Add a source to the vocabulary by giving the source content as string.
-        Source name needs to be given
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary to which the source should
-            be added
-            source_content (str): Content of source
-            source_name (str): Name for the source
-
-        Raises:
-            ParsingException:  If the given source was not valid and could not
-            be parsed
-
-        Returns:
-            New Vocabulary with the given source added to it
-        """
-        source = Source(source_name=source_name,
-                        content=source_content,
-                        timestamp=datetime.now())
-
-        return VocabularyConfigurator._parse_sources_into_vocabulary(
-            vocabulary=vocabulary, sources=[source])
-
-    @classmethod
-    def _parse_sources_into_vocabulary(cls, vocabulary: Vocabulary,
-                                       sources: List[Source]) -> Vocabulary:
-        """
-        Parse the given source objects into the vocabulary
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary to which the source should
-            be added
-            sources (List[Source]): Source objects to be added
-
-        Raises:
-            ParsingException:  If the given source was not valid and could not
-            be parsed
-
-        Returns:
-            New Vocabulary with the given sources added to it
-        """
-
-        # create a new vocabulary by reparsing the existing sources
-        new_vocabulary = Vocabulary(settings=copy.copy(vocabulary.settings))
-        parser = RdfParser()
-        for source in vocabulary.sources.values():
-            source_copy = copy.deepcopy(source)
-            source_copy.clear()
-            parser.parse_source_into_vocabulary(source=source_copy,
-                                                vocabulary=new_vocabulary)
-
-        # try to parse in the new sources and post_process
-        try:
-            for source in sources:
-                parser.parse_source_into_vocabulary(source=source,
-                                                    vocabulary=new_vocabulary)
-            PostProcessor.post_process_vocabulary(
-                vocabulary=new_vocabulary, old_vocabulary=vocabulary)
-        except Exception as e:
-            raise ParsingException(e.args)
-
-        return new_vocabulary
-
-    @classmethod
-    def is_label_blacklisted(cls, label: str) -> bool:
-        """Checks if the given label is forbidden for an entity to possess
-
-        Args:
-            label (str): label to check
-
-        Returns:
-            bool
-        """
-        return label in label_blacklist
-
-    @classmethod
-    def is_label_illegal(cls, label: str) -> bool:
-        """Checks if the given label contains a forbidden char
-
-        Args:
-            label (str): label to check
-
-        Returns:
-            bool, True if label forbidden
-        """
-        for c in label:
-            if c not in label_char_whitelist:
-                return True
-        return False
-
-    @classmethod
-    def get_label_conflicts_in_vocabulary(cls, vocabulary: Vocabulary) -> \
-            LabelSummary:
-        """
-        Compute a summary for all labels present in the vocabulary.
-        The summary contains all naming clashes and illegal labels.
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary to analyse
-
-        Returns:
-            LabelSummary
-        """
-
-        def get_conflicts_in_group(entities_to_check: List[Dict]):
-            # maps label to list of entities with that label
-            used_labels: Dict[str, List[Entity]] = {}
-            duplicate_labels = set()
-
-            # process entities to find conflicts
-            for entity_list in entities_to_check:
-                for entity in entity_list.values():
-                    label = entity.get_label()
-                    if label in used_labels:
-                        duplicate_labels.add(label)
-                        used_labels[label].append(entity)
-                    else:
-                        used_labels[label] = [entity]
-
-            # sort duplicate_labels to have alphabetical order in list
-            dup_list = list(duplicate_labels)
-            dup_list = sorted(dup_list, key=str.casefold)
-
-            result: Dict[str, List[Entity]] = {}
-            # store and log findings
-            for label in dup_list:
-                result[label] = used_labels[label]
-
-            return result
-
-        def get_blacklisted_labels(entities_to_check: List[Dict]):
-            result: List[Tuple[str, Entity]] = []
-            for entity_list in entities_to_check:
-                for entity in entity_list.values():
-                    label = entity.get_label()
-                    if cls.is_label_blacklisted(label):
-                        result.append((label, entity))
-
-            return result
-
-        def get_illegal_labels(entities_to_check: List[Dict]):
-            result: List[Tuple[str, Entity]] = []
-            for entity_list in entities_to_check:
-                for entity in entity_list.values():
-                    label = entity.get_label()
-                    if cls.is_label_illegal(label):
-                        result.append((label, entity))
-
-            return result
-
-        summary = LabelSummary(
-            class_label_duplicates=get_conflicts_in_group(
-                [vocabulary.classes, vocabulary.individuals,
-                 vocabulary.get_enum_dataytypes()]),
-            field_label_duplicates=get_conflicts_in_group(
-                [vocabulary.data_properties, vocabulary.object_properties]),
-            datatype_label_duplicates=get_conflicts_in_group(
-                [vocabulary.datatypes]),
-            blacklisted_labels=get_blacklisted_labels([
-                vocabulary.classes, vocabulary.individuals,
-                vocabulary.data_properties, vocabulary.object_properties
-            ]),
-            labels_with_illegal_chars=get_illegal_labels([
-                vocabulary.classes, vocabulary.individuals,
-                vocabulary.data_properties, vocabulary.object_properties,
-                vocabulary.datatypes
-            ]),
-        )
-
-        return summary
-
-    @classmethod
-    def is_vocabulary_valid(cls, vocabulary: Vocabulary) -> bool:
-        """
-        Test if the given vocabulary is valid -> all labels are unique and
-        correct
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary to analyse
-
-        Returns:
-            bool
-        """
-        return VocabularyConfigurator.get_label_conflicts_in_vocabulary(
-            vocabulary).is_valid()
-
-    @classmethod
-    def get_missing_dependency_statements(cls, vocabulary: Vocabulary) -> \
-            List[DependencyStatement]:
-        """
-        Get a list of all Dependencies that are currently missing in the
-        vocabulary in form of DependencyStatements
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary to analyse
-
-        Returns:
-            List[DependencyStatement]
-        """
-        missing_dependencies: List[DependencyStatement] = []
-        for source in vocabulary.get_source_list():
-            for statement in source.dependency_statements:
-                if not statement.fulfilled:
-                    missing_dependencies.append(statement)
-        return missing_dependencies
-
-    @classmethod
-    def get_missing_dependencies(cls, vocabulary: Vocabulary) -> List[str]:
-        """
-        Get a list of all Dependencies that are currently missing in the
-        vocabulary in form of iris
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary to analyse
-
-        Returns:
-            List[str]: List of missing iris
-        """
-
-        missing_dependencies: Set[str] = set()
-        for source in vocabulary.get_source_list():
-            for statement in source.dependency_statements:
-                if not statement.fulfilled:
-                    missing_dependencies.add(statement.dependency_iri)
-        return list(missing_dependencies)
-
-    @classmethod
-    def get_parsing_logs(cls, vocabulary: Vocabulary) -> List[ParsingError]:
-        """
-        Get the parsing logs of a vocabulary
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary to analyse
-
-        Returns:
-            List[ParsingError]
-        """
-        res = []
-        for source in vocabulary.sources.values():
-            res.extend(source.get_parsing_log(vocabulary))
-        return res
-
-    @classmethod
-    def generate_vocabulary_models(
-            cls,
-            vocabulary: Vocabulary,
-            path: Optional[str] = None,
-            filename: Optional[str] = None,
-            alternative_manager_name: Optional[str] = None) ->  \
-            Optional[str]:
-        """
-        Export the given vocabulary as python model file.
-        All vocabulary classes will be converted to python classes,
-        with their CRs as property fields.
-        If path and filename are given, the generated file will be saved,
-        else the file content is returned as string.
-
-        Args:
-            vocabulary (Vocabulary): Vocabulary to export
-            path (Optional[str]): Path where the file should be saved
-            filename (Optional[str]): Name of the file
-            alternative_manager_name (Optional[str]): alternative name for
-                the semantic_manager. The manager of the model can than also
-                be referenced over the object with this name
-
-        Raises:
-            Exception: if file can not be saved as specified with path and
-                       filename
-            Exception: if vocabulary has label conflicts and is thus not valid
-
-        Returns:
-            Optional[str], generated content if path or filename not given
-        """
-
-        if not cls.is_vocabulary_valid(vocabulary):
-            raise Exception(
-                "Vocabulary was not valid. Label conflicts "
-                "prevented the generation of models. Check for conflicts with: "
-                "VocabularyConfigurator."
-                "get_label_conflicts_in_vocabulary(vocabulary)"
-                )
-
-        def split_string_into_lines(string: str, limit: int) -> [str]:
-            """Helper methode, takes a long string and splits it into
-            multiple parts that each represent one line
-
-            Args:
-                string: value to split
-                limit: line limit
-            Returns:
-                [str], string separated into lines
-            """
-            last_space_index = 0
-            last_split_index = 0
-            current_index = 0
-            result = []
-
-            for char in string:
-                if char == " ":
-                    last_space_index = current_index
-                if current_index-last_split_index > limit:
-                    result.append(string[last_split_index: last_space_index])
-                    last_split_index = last_space_index+1
-                current_index += 1
-
-            # add the remaining part, if the last character of the string was
-            # not a space at the perfect position
-            if not last_split_index == len(string):
-                result.append(string[last_split_index:current_index])
-            return result
-
-        content: str = '"""\nAutogenerated Models for the vocabulary ' \
-                       'described ' \
-                       'by the ontologies:\n'
-        for source in vocabulary.sources.values():
-            if not source.predefined:
-                content += f'\t{source.ontology_iri} ({source.source_name})\n'
-        content += '"""\n\n'
-
-        # imports
-        content += "from enum import Enum\n"
-        content += "from typing import Dict, Union, List\n"
-        content += "from filip.semantics.semantics_models import\\" \
-                   "\n\tSemanticClass,\\" \
-                   "\n\tSemanticIndividual,\\" \
-                   "\n\tRelationField,\\" \
-                   "\n\tDataField,\\" \
-                   "\n\tSemanticDeviceClass,\\" \
-                   "\n\tDeviceAttributeField,\\" \
-                   "\n\tCommandField"
-        content += "\n"
-        content += "from filip.semantics.semantics_manager import\\" \
-                   "\n\tSemanticsManager,\\" \
-                   "\n\tInstanceRegistry"
-
-        content += "\n\n\n"
-        content += f"semantic_manager: SemanticsManager = SemanticsManager("
-        content += "\n\t"
-        content += "instance_registry=InstanceRegistry(),"
-        content += "\n"
-        content += ")"
-        content += "\n\n"
-        if alternative_manager_name is not None:
-            content += f"{alternative_manager_name}: SemanticsManager"
-            content += f"= semantic_manager"
-            content += "\n\n"
-        content += "# ---------CLASSES--------- #"
-
-        # the classes need to be added in order, so that the parents are
-        # defined, the moment the children are added
-        classes: List[Class] = vocabulary.get_classes_sorted_by_label()
-        class_order: List[Class] = []
-        children: Dict[str, Set] = {}
-        added_class_iris = set()
-
-        # set up data for computation of order
-        iri_queue = ["http://www.w3.org/2002/07/owl#Thing"]
-        for class_ in classes:
-            if class_.iri not in children:
-                children[class_.iri] = set()
-
-                if class_.label == "Currency":
-                    print(class_.get_parent_classes(vocabulary))
-
-            for parent in class_.get_parent_classes(vocabulary):
-                if parent.iri not in children:
-                    children[parent.iri] = set()
-                children[parent.iri].add(class_.iri)
-
-        # compute class order, in the queue are always the classes, that have
-        # all parents already defined (starting with Thing).
-        # It is added from the queue and all children who are now fully
-        # defined are added to the queue
-        while len(iri_queue) > 0:
-            # remove from queue
-            parent_iri = iri_queue[0]
-            del iri_queue[0]
-
-            # add to class_order
-            parent = vocabulary.classes[parent_iri]
-            class_order.append(parent)
-            added_class_iris.add(parent_iri)
-
-            # check children
-            child_iris = children[parent_iri]
-            for child_iri in child_iris:
-                child = vocabulary.classes[child_iri]
-
-                # all parents added, add child to queue
-                if len([p for p in child.parent_class_iris
-                        if p in added_class_iris]) == len(
-                        child.parent_class_iris):
-
-                    if not child_iri in added_class_iris:
-                        iri_queue.append(child_iri)
-
-        for class_ in class_order:
-
-            content += "\n\n\n"
-            # Parent Classes
-            parent_class_string = ""
-            parents = class_.get_parent_classes(vocabulary,
-                                                remove_redundancy=True)
-
-            # Device Class, only add if this is a device class and it was not
-            # added for a parent
-            if class_.is_iot_class(vocabulary):
-                if True not in [p.is_iot_class(vocabulary) for p in
-                                parents]:
-                    parent_class_string = " ,SemanticDeviceClass"
-
-            for parent in parents:
-                parent_class_string += f", {parent.get_label()}"
-
-            parent_class_string = parent_class_string[
-                                  2:]  # remove first comma and space
-            if parent_class_string == "":
-                parent_class_string = "SemanticClass"
-
-            content += f"class {class_.get_label()}({parent_class_string}):"
-
-            # add class docstring
-            content += f'\n\t"""'
-            for line in split_string_into_lines(class_.comment, 75):
-                content += f"\n\t{line}"
-            if class_.comment == "":
-                content += "\n\tGenerated SemanticClass without description"
-            content += f"\n\n\t"
-            content += f"Source(s): \n\t\t"
-
-            for source_id in class_.source_ids:
-                content += f"{vocabulary.sources[source_id].ontology_iri} " \
-                           f"({vocabulary.sources[source_id].source_name})"
-            content += f'\n\t"""'
-
-            # ------Constructors------
-            if class_.get_label() == "Thing":
-                content += "\n\n\t"
-                content += "def __new__(cls, *args, **kwargs):"
-                content += "\n\t\t"
-                content += f"kwargs['semantic_manager'] = semantic_manager"
-                content += "\n\t\t"
-                content += "return super().__new__(cls, *args, **kwargs)"
-
-                content += "\n\n\t"
-                content += "def __init__(self, *args, **kwargs):"
-                content += "\n\t\t"
-                content += f"kwargs['semantic_manager'] = semantic_manager"
-                content += "\n\t\t"
-                content += "is_initialised = 'id' in self.__dict__"
-                content += "\n\t\t"
-                content += "super().__init__(*args, **kwargs)"
-
-            else:
-                content += "\n\n\t"
-                content += "def __init__(self, *args, **kwargs):"
-                content += "\n\t\t"
-                content += "is_initialised = 'id' in self.__dict__"
-                content += "\n\t\t"
-                content += "super().__init__(*args, **kwargs)"
-
-            # ------Init Fields------
-            content += "\n\t\t"
-            content += "if not is_initialised:"
-            # Only initialise values once
-            for cdr in class_.get_combined_data_relations(vocabulary):
-                if not cdr.is_device_relation(vocabulary):
-                    content += "\n\t\t\t"
-                    content += \
-                        f"self." \
-                        f"{cdr.get_property_label(vocabulary)}._rules = " \
-                        f"{cdr.export_rule(vocabulary, stringify_fields=True)}"
-
-            if len(class_.get_combined_object_relations(vocabulary)) > 0:
-                content += "\n"
-            for cor in class_.get_combined_object_relations(vocabulary):
-                content += "\n\t\t\t"
-                content += f"self." \
-                           f"{cor.get_property_label(vocabulary)}._rules = " \
-                           f"{cor.export_rule(vocabulary, stringify_fields=False)}"
-
-            if len(class_.get_combined_relations(vocabulary)) > 0:
-                content += "\n"
-            for cr in class_.get_combined_relations(vocabulary):
-                content += "\n\t\t\t"
-                content += f"self.{cr.get_property_label(vocabulary)}" \
-                           f"._instance_identifier = " \
-                           f"self.get_identifier()"
-
-            # ------Add preset Values------
-            for cdr in class_.get_combined_data_relations(vocabulary):
-                # Add fixed values to fields, for CDRs these values need to be
-                # strings. Only add the statement on the uppermost occurring
-                # class
-                if not cdr.is_device_relation(vocabulary):
-                    for rel in cdr.get_relations(vocabulary):
-                        if rel.id in class_.relation_ids:
-                            # only reinitialise the fields if this child class
-                            # changed them
-                            if rel.restriction_type == RestrictionType.value:
-                                content += "\n\t\t\t"
-                                content += \
-                                    f"self." \
-                                    f"{cdr.get_property_label(vocabulary)}" \
-                                    f".add(" \
-                                    f"'{rel.target_statement.target_data_value}')"
-
-            if len(class_.get_combined_object_relations(vocabulary)) > 0:
-                content += "\n"
-            for cor in class_.get_combined_object_relations(vocabulary):
-                # Add fixed values to fields, for CORs these values need to be
-                # Individuals.
-                # Only add the statement on the uppermost occurring class
-                for rel in cor.get_relations(vocabulary):
-                    if rel.id in class_.relation_ids:
-                        i = vocabulary. \
-                            get_label_for_entity_iri(
-                            rel.get_targets()[0][0])
-                        if rel.restriction_type == RestrictionType.value:
-                            content += "\n\t\t\t"
-                            content += f"self." \
-                                       f"{cor.get_property_label(vocabulary)}" \
-                                       f".add({i}())"
-
-            # if no content was added af the not initialised if, removed it
-            # again, and its preceding \n
-            if content[-22:] == "if not is_initialised:":
-                content = content[:-25]
-
-            # make space the same for each case above
-            if "\n" in content[-2:]:
-                content = content[:-1]
-
-            def build_field_comment(cr: CombinedRelation) -> str:
-                comment = vocabulary.get_entity_by_iri(cr.property_iri).comment
-                res = ""
-                if comment != "":
-                    res += f'\n\t"""'
-                    for line in split_string_into_lines(comment, 75):
-                        res += f'\n\t{line}'
-                    res += f'\n\t"""'
-                return res
-
-            # ------Add Data Fields------
-            if len(class_.get_combined_data_relations(vocabulary)) > 0:
-                content += "\n\n\t"
-                content += "# Data fields"
-            for cdr in class_.get_combined_data_relations(vocabulary):
-                cdr_type = cdr.get_field_type(vocabulary)
-                if cdr_type == DataFieldType.simple:
-                    content += "\n\n\t"
-                    label = cdr.get_property_label(vocabulary)
-                    content += f"{label}: DataField = DataField("
-                    content += "\n\t\t"
-                    content += f"name='{label}',"
-                    content += "\n\t\t"
-                    content += \
-                        f"rule='" \
-                        f"{cdr.get_all_targetstatements_as_string(vocabulary)}',"
-                    content += "\n\t\t"
-                    content += f"semantic_manager=semantic_manager)"
-                    content += build_field_comment(cdr)
-
-                elif cdr_type == DataFieldType.command:
-                    content += "\n\n\t"
-                    label = cdr.get_property_label(vocabulary)
-                    content += f"{label}: CommandField = CommandField("
-                    content += "\n\t\t"
-                    content += f"name='{label}',"
-                    content += "\n\t\t"
-                    content += f"semantic_manager=semantic_manager)"
-                    content += build_field_comment(cdr)
-
-                elif cdr_type == DataFieldType.device_attribute:
-                    content += "\n\n\t"
-                    label = cdr.get_property_label(vocabulary)
-                    content += f"{label}: DeviceAttributeField " \
-                               f"= DeviceAttributeField("
-                    content += "\n\t\t"
-                    content += f"name='{label}',"
-                    content += "\n\t\t"
-                    content += f"semantic_manager=semantic_manager)"
-                    content += build_field_comment(cdr)
-
-            # ------Add Relation Fields------
-            if len(class_.get_combined_object_relations(vocabulary)) > 0:
-                content += "\n\n\t"
-                content += "# Relation fields"
-            for cor in class_.get_combined_object_relations(vocabulary):
-                content += "\n\n\t"
-                label = cor.get_property_label(vocabulary)
-                content += f"{label}: RelationField = RelationField("
-                content += "\n\t\t"
-                content += f"name='{label}',"
-                content += "\n\t\t"
-                content += f"rule='" \
-                           f"{cor.get_all_targetstatements_as_string(vocabulary)}',"
-                content += "\n\t\t"
-                if not len(cor.get_inverse_of_labels(vocabulary)) == 0:
-                    content += "inverse_of="
-                    content += str(cor.get_inverse_of_labels(vocabulary))
-                    content += ",\n\t\t"
-
-                content += f"semantic_manager=semantic_manager)"
-                content += build_field_comment(cor)
-
-        content += "\n\n\n"
-        content += "# ---------Individuals--------- #"
-
-        for individual in vocabulary.individuals.values():
-            content += "\n\n\n"
-
-            parent_class_string = ""
-            for parent in individual.get_parent_classes(vocabulary):
-                parent_class_string += f", {parent.get_label()}"
-            parent_class_string = parent_class_string[2:]
-
-            content += f"class {individual.get_label()}(SemanticIndividual):"
-            content += "\n\t"
-            content += f"_parent_classes: List[type] = [{parent_class_string}]"
-
-        content += "\n\n\n"
-
-        content += "# ---------Datatypes--------- #"
-        content += "\n"
-
-        # Datatypes catalogue
-        content += f"semantic_manager.datatype_catalogue = "
-        content += "{"
-        for name, datatype in vocabulary.datatypes.items():
-            definition = datatype.export()
-            content += "\n\t"
-            # content += f"'{datatype.get_label()}': \t {definition},"
-            content += f"'{datatype.get_label()}': "
-            content += "{\n"
-            for key, value in definition.items():
-                string_value = f"'{value}'" if type(value) == str else value
-                content += f"\t\t'{key}': {string_value},\n"
-            content += "\t},"
-
-        content += "\n"
-        content += "}"
-
-        # Build datatypes with enums as Enums
-        content += "\n\n\n"
-        for datatype in vocabulary.get_enum_dataytypes().values():
-            content += f"class {datatype.get_label()}(str, Enum):"
-            for value in datatype.enum_values:
-                content += f"\n\tvalue_{value} = '{value}'"
-            content += "\n\n\n"
-
-        content += "# ---------Class Dict--------- #"
-
-        # build class dict
-        content += "\n\n"
-        content += f"semantic_manager.class_catalogue = "
-        content += "{"
-        for class_ in vocabulary.get_classes_sorted_by_label():
-            content += "\n\t"
-            content += f"'{class_.get_label()}': {class_.get_label()},"
-        content += "\n\t}"
-        content += "\n"
-
-        # build individual dict
-        content += "\n\n"
-        content += f"semantic_manager.individual_catalogue = "
-        content += "{"
-        for individual in vocabulary.individuals.values():
-            content += "\n\t"
-            content += f"'{individual.get_label()}': {individual.get_label()},"
-        content += "\n\t}"
-        content += "\n"
-
-        if path is None or filename is None:
-            return content
-        else:
-            path = pathlib.Path(path).joinpath(filename).with_suffix(".py")
-
-            with open(path, "w", encoding ="utf-8") as text_file:
-                text_file.write(content)
-
-
-class ParsingException(Exception):
-    """Error Class that is raised if parsing of an ontology was unsuccessful"""
-
-    # Constructor or Initializer
-    def __init__(self, value):
-        self.value = value
-
-    # __str__ is to print() the value
-    def __str__(self):
-        return repr(self.value)
+"""Module providing an interface to manipulate the sources of a vocabulary,
+and to ability to export it to models"""
+
+import copy
+import io
+import keyword
+import os
+from datetime import datetime
+from string import ascii_letters, digits
+from typing import List, Optional, Dict, Tuple, Set
+
+import pathlib
+import requests
+import wget
+
+from filip.semantics.ontology_parser.post_processer import PostProcessor
+from filip.semantics.ontology_parser.rdfparser import RdfParser
+from filip.semantics.vocabulary import \
+    LabelSummary, \
+    Vocabulary, \
+    Source, \
+    Entity, \
+    RestrictionType, \
+    Class, \
+    ParsingError, \
+    CombinedRelation, \
+    DataFieldType, \
+    DependencyStatement, \
+    VocabularySettings
+
+# Blacklist containing all labels that are forbidden for entities to have
+label_blacklist = list(keyword.kwlist)
+label_blacklist.extend(["referencedBy", "deviceSettings"])
+label_blacklist.extend(["references", "device_settings", "header",
+                        "old_state", "", "semantic_manager", "delete",
+                        "metadata"])
+label_blacklist.extend(["id", "type", "class"])
+label_blacklist.extend(["str", "int", "float", "complex", "list", "tuple",
+                        "range", "dict", "list", "set", "frozenset", "bool",
+                        "bytes", "bytearray", "memoryview"])
+
+# Whitelist containing all chars that an entity label can consist of
+label_char_whitelist = ascii_letters + digits + "_"
+
+
+class VocabularyConfigurator:
+    """
+    Class that provides static interfaces to manipulate the sources of a
+    vocabulary, validate and save it.
+    """
+
+    @classmethod
+    def create_vocabulary(cls,
+                          settings: VocabularySettings = VocabularySettings()) \
+            -> Vocabulary:
+        """
+        Create a new blank vocabulary with given settings
+
+        Args:
+            settings: VocabularySettings
+
+        Returns:
+            Vocabulary
+        """
+
+        return Vocabulary(settings=settings)
+
+    @classmethod
+    def delete_source_from_vocabulary(cls, vocabulary: Vocabulary,
+                                      source_id: str) -> Vocabulary:
+        """
+        Delete a source from the vocabulary
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary from which the source should
+            be removed
+            source_id (str): Id of source to remove
+
+        Raises:
+            ValueError:  If no source with given Id exists in Vocabulary
+
+        Returns:
+            New Vocabulary without the given source
+        """
+        new_vocabulary = Vocabulary(settings=copy.copy(vocabulary.settings))
+        parser = RdfParser()
+        found = False
+        for source in vocabulary.sources.values():
+            if not source_id == source.id:
+                parser.parse_source_into_vocabulary(
+                    source=copy.deepcopy(source), vocabulary=new_vocabulary)
+            else:
+                found = True
+
+        PostProcessor.post_process_vocabulary(
+            vocabulary=new_vocabulary, old_vocabulary=vocabulary)
+
+        if not found:
+            raise ValueError(
+                f"Source with source_id {source_id} not in vocabulary")
+
+        PostProcessor.transfer_settings(
+            new_vocabulary=new_vocabulary, old_vocabulary=vocabulary)
+
+        return new_vocabulary
+
+    @classmethod
+    def add_ontology_to_vocabulary_as_link(
+            cls,
+            vocabulary: Vocabulary,
+            link: str,
+            source_name: Optional[str] = None) -> Vocabulary:
+        """
+        Add a source to the vocabulary with via a weblink. Source name will
+        be extracted from link, if no name is given
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary to which the source should
+            be added
+            link (str): Weblink to the source
+            source_name (Optional[str]): Name for the source
+
+        Raises:
+            ParsingException:  If the given source was not valid and could not
+            be parsed
+
+        Returns:
+            New Vocabulary with the given source added to it
+        """
+
+        downloaded_obj = requests.get(link)
+        file_bytes = io.BytesIO(downloaded_obj.content)
+        if source_name is None:
+            source_name = wget.filename_from_url(link)
+
+        file_str = io.TextIOWrapper(file_bytes, encoding='utf-8').read()
+
+        return cls.add_ontology_to_vocabulary_as_string(vocabulary=vocabulary,
+                                                        source_name=source_name,
+                                                        source_content=file_str)
+
+    @classmethod
+    def add_ontology_to_vocabulary_as_file(
+            cls,
+            vocabulary: Vocabulary,
+            path_to_file: str,
+            source_name: Optional[str] = None) -> Vocabulary:
+        """
+        Add a source to the vocabulary with via a file path. Source name will
+        be extracted from path, if no name is given
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary to which the source should
+            be added
+            path_to_file (str): Path to the source file
+            source_name (Optional[str]): Name for the source
+
+        Raises:
+            ParsingException:  If the given source was not valid and could not
+            be parsed
+
+        Returns:
+            New Vocabulary with the given source added to it
+        """
+
+        with open(path_to_file, 'r') as file:
+            data = file.read()
+
+        if source_name is None:
+            source_name = os.path.basename(path_to_file).split(".")[0]
+
+        source = Source(source_name=source_name,
+                        content=data,
+                        timestamp=datetime.now())
+
+        return VocabularyConfigurator._parse_sources_into_vocabulary(
+            vocabulary=vocabulary, sources=[source])
+
+    @classmethod
+    def add_ontology_to_vocabulary_as_string(cls, vocabulary: Vocabulary,
+                                             source_name: str,
+                                             source_content: str) -> Vocabulary:
+        """
+        Add a source to the vocabulary by giving the source content as string.
+        Source name needs to be given
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary to which the source should
+            be added
+            source_content (str): Content of source
+            source_name (str): Name for the source
+
+        Raises:
+            ParsingException:  If the given source was not valid and could not
+            be parsed
+
+        Returns:
+            New Vocabulary with the given source added to it
+        """
+        source = Source(source_name=source_name,
+                        content=source_content,
+                        timestamp=datetime.now())
+
+        return VocabularyConfigurator._parse_sources_into_vocabulary(
+            vocabulary=vocabulary, sources=[source])
+
+    @classmethod
+    def _parse_sources_into_vocabulary(cls, vocabulary: Vocabulary,
+                                       sources: List[Source]) -> Vocabulary:
+        """
+        Parse the given source objects into the vocabulary
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary to which the source should
+            be added
+            sources (List[Source]): Source objects to be added
+
+        Raises:
+            ParsingException:  If the given source was not valid and could not
+            be parsed
+
+        Returns:
+            New Vocabulary with the given sources added to it
+        """
+
+        # create a new vocabulary by reparsing the existing sources
+        new_vocabulary = Vocabulary(settings=copy.copy(vocabulary.settings))
+        parser = RdfParser()
+        for source in vocabulary.sources.values():
+            source_copy = copy.deepcopy(source)
+            source_copy.clear()
+            parser.parse_source_into_vocabulary(source=source_copy,
+                                                vocabulary=new_vocabulary)
+
+        # try to parse in the new sources and post_process
+        try:
+            for source in sources:
+                parser.parse_source_into_vocabulary(source=source,
+                                                    vocabulary=new_vocabulary)
+            PostProcessor.post_process_vocabulary(
+                vocabulary=new_vocabulary, old_vocabulary=vocabulary)
+        except Exception as e:
+            raise ParsingException(e.args)
+
+        return new_vocabulary
+
+    @classmethod
+    def is_label_blacklisted(cls, label: str) -> bool:
+        """Checks if the given label is forbidden for an entity to possess
+
+        Args:
+            label (str): label to check
+
+        Returns:
+            bool
+        """
+        return label in label_blacklist
+
+    @classmethod
+    def is_label_illegal(cls, label: str) -> bool:
+        """Checks if the given label contains a forbidden char
+
+        Args:
+            label (str): label to check
+
+        Returns:
+            bool, True if label forbidden
+        """
+        for c in label:
+            if c not in label_char_whitelist:
+                return True
+        return False
+
+    @classmethod
+    def get_label_conflicts_in_vocabulary(cls, vocabulary: Vocabulary) -> \
+            LabelSummary:
+        """
+        Compute a summary for all labels present in the vocabulary.
+        The summary contains all naming clashes and illegal labels.
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary to analyse
+
+        Returns:
+            LabelSummary
+        """
+
+        def get_conflicts_in_group(entities_to_check: List[Dict]):
+            # maps label to list of entities with that label
+            used_labels: Dict[str, List[Entity]] = {}
+            duplicate_labels = set()
+
+            # process entities to find conflicts
+            for entity_list in entities_to_check:
+                for entity in entity_list.values():
+                    label = entity.get_label()
+                    if label in used_labels:
+                        duplicate_labels.add(label)
+                        used_labels[label].append(entity)
+                    else:
+                        used_labels[label] = [entity]
+
+            # sort duplicate_labels to have alphabetical order in list
+            dup_list = list(duplicate_labels)
+            dup_list = sorted(dup_list, key=str.casefold)
+
+            result: Dict[str, List[Entity]] = {}
+            # store and log findings
+            for label in dup_list:
+                result[label] = used_labels[label]
+
+            return result
+
+        def get_blacklisted_labels(entities_to_check: List[Dict]):
+            result: List[Tuple[str, Entity]] = []
+            for entity_list in entities_to_check:
+                for entity in entity_list.values():
+                    label = entity.get_label()
+                    if cls.is_label_blacklisted(label):
+                        result.append((label, entity))
+
+            return result
+
+        def get_illegal_labels(entities_to_check: List[Dict]):
+            result: List[Tuple[str, Entity]] = []
+            for entity_list in entities_to_check:
+                for entity in entity_list.values():
+                    label = entity.get_label()
+                    if cls.is_label_illegal(label):
+                        result.append((label, entity))
+
+            return result
+
+        summary = LabelSummary(
+            class_label_duplicates=get_conflicts_in_group(
+                [vocabulary.classes, vocabulary.individuals,
+                 vocabulary.get_enum_dataytypes()]),
+            field_label_duplicates=get_conflicts_in_group(
+                [vocabulary.data_properties, vocabulary.object_properties]),
+            datatype_label_duplicates=get_conflicts_in_group(
+                [vocabulary.datatypes]),
+            blacklisted_labels=get_blacklisted_labels([
+                vocabulary.classes, vocabulary.individuals,
+                vocabulary.data_properties, vocabulary.object_properties
+            ]),
+            labels_with_illegal_chars=get_illegal_labels([
+                vocabulary.classes, vocabulary.individuals,
+                vocabulary.data_properties, vocabulary.object_properties,
+                vocabulary.datatypes
+            ]),
+        )
+
+        return summary
+
+    @classmethod
+    def is_vocabulary_valid(cls, vocabulary: Vocabulary) -> bool:
+        """
+        Test if the given vocabulary is valid -> all labels are unique and
+        correct
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary to analyse
+
+        Returns:
+            bool
+        """
+        return VocabularyConfigurator.get_label_conflicts_in_vocabulary(
+            vocabulary).is_valid()
+
+    @classmethod
+    def get_missing_dependency_statements(cls, vocabulary: Vocabulary) -> \
+            List[DependencyStatement]:
+        """
+        Get a list of all Dependencies that are currently missing in the
+        vocabulary in form of DependencyStatements
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary to analyse
+
+        Returns:
+            List[DependencyStatement]
+        """
+        missing_dependencies: List[DependencyStatement] = []
+        for source in vocabulary.get_source_list():
+            for statement in source.dependency_statements:
+                if not statement.fulfilled:
+                    missing_dependencies.append(statement)
+        return missing_dependencies
+
+    @classmethod
+    def get_missing_dependencies(cls, vocabulary: Vocabulary) -> List[str]:
+        """
+        Get a list of all Dependencies that are currently missing in the
+        vocabulary in form of iris
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary to analyse
+
+        Returns:
+            List[str]: List of missing iris
+        """
+
+        missing_dependencies: Set[str] = set()
+        for source in vocabulary.get_source_list():
+            for statement in source.dependency_statements:
+                if not statement.fulfilled:
+                    missing_dependencies.add(statement.dependency_iri)
+        return list(missing_dependencies)
+
+    @classmethod
+    def get_parsing_logs(cls, vocabulary: Vocabulary) -> List[ParsingError]:
+        """
+        Get the parsing logs of a vocabulary
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary to analyse
+
+        Returns:
+            List[ParsingError]
+        """
+        res = []
+        for source in vocabulary.sources.values():
+            res.extend(source.get_parsing_log(vocabulary))
+        return res
+
+    @classmethod
+    def generate_vocabulary_models(
+            cls,
+            vocabulary: Vocabulary,
+            path: Optional[str] = None,
+            filename: Optional[str] = None,
+            alternative_manager_name: Optional[str] = None) ->  \
+            Optional[str]:
+        """
+        Export the given vocabulary as python model file.
+        All vocabulary classes will be converted to python classes,
+        with their CRs as property fields.
+        If path and filename are given, the generated file will be saved,
+        else the file content is returned as string.
+
+        Args:
+            vocabulary (Vocabulary): Vocabulary to export
+            path (Optional[str]): Path where the file should be saved
+            filename (Optional[str]): Name of the file
+            alternative_manager_name (Optional[str]): alternative name for
+                the semantic_manager. The manager of the model can than also
+                be referenced over the object with this name
+
+        Raises:
+            Exception: if file can not be saved as specified with path and
+                       filename
+            Exception: if vocabulary has label conflicts and is thus not valid
+
+        Returns:
+            Optional[str], generated content if path or filename not given
+        """
+
+        if not cls.is_vocabulary_valid(vocabulary):
+            raise Exception(
+                "Vocabulary was not valid. Label conflicts "
+                "prevented the generation of models. Check for conflicts with: "
+                "VocabularyConfigurator."
+                "get_label_conflicts_in_vocabulary(vocabulary)"
+                )
+
+        def split_string_into_lines(string: str, limit: int) -> [str]:
+            """Helper methode, takes a long string and splits it into
+            multiple parts that each represent one line
+
+            Args:
+                string: value to split
+                limit: line limit
+            Returns:
+                [str], string separated into lines
+            """
+            last_space_index = 0
+            last_split_index = 0
+            current_index = 0
+            result = []
+
+            for char in string:
+                if char == " ":
+                    last_space_index = current_index
+                if current_index-last_split_index > limit:
+                    result.append(string[last_split_index: last_space_index])
+                    last_split_index = last_space_index+1
+                current_index += 1
+
+            # add the remaining part, if the last character of the string was
+            # not a space at the perfect position
+            if not last_split_index == len(string):
+                result.append(string[last_split_index:current_index])
+            return result
+
+        content: str = '"""\nAutogenerated Models for the vocabulary ' \
+                       'described ' \
+                       'by the ontologies:\n'
+        for source in vocabulary.sources.values():
+            if not source.predefined:
+                content += f'\t{source.ontology_iri} ({source.source_name})\n'
+        content += '"""\n\n'
+
+        # imports
+        content += "from enum import Enum\n"
+        content += "from typing import Dict, Union, List\n"
+        content += "from filip.semantics.semantics_models import\\" \
+                   "\n\tSemanticClass,\\" \
+                   "\n\tSemanticIndividual,\\" \
+                   "\n\tRelationField,\\" \
+                   "\n\tDataField,\\" \
+                   "\n\tSemanticDeviceClass,\\" \
+                   "\n\tDeviceAttributeField,\\" \
+                   "\n\tCommandField"
+        content += "\n"
+        content += "from filip.semantics.semantics_manager import\\" \
+                   "\n\tSemanticsManager,\\" \
+                   "\n\tInstanceRegistry"
+
+        content += "\n\n\n"
+        content += f"semantic_manager: SemanticsManager = SemanticsManager("
+        content += "\n\t"
+        content += "instance_registry=InstanceRegistry(),"
+        content += "\n"
+        content += ")"
+        content += "\n\n"
+        if alternative_manager_name is not None:
+            content += f"{alternative_manager_name}: SemanticsManager"
+            content += f"= semantic_manager"
+            content += "\n\n"
+        content += "# ---------CLASSES--------- #"
+
+        # the classes need to be added in order, so that the parents are
+        # defined, the moment the children are added
+        classes: List[Class] = vocabulary.get_classes_sorted_by_label()
+        class_order: List[Class] = []
+        children: Dict[str, Set] = {}
+        added_class_iris = set()
+
+        # set up data for computation of order
+        iri_queue = ["http://www.w3.org/2002/07/owl#Thing"]
+        for class_ in classes:
+            if class_.iri not in children:
+                children[class_.iri] = set()
+
+                if class_.label == "Currency":
+                    print(class_.get_parent_classes(vocabulary))
+
+            for parent in class_.get_parent_classes(vocabulary):
+                if parent.iri not in children:
+                    children[parent.iri] = set()
+                children[parent.iri].add(class_.iri)
+
+        # compute class order, in the queue are always the classes, that have
+        # all parents already defined (starting with Thing).
+        # It is added from the queue and all children who are now fully
+        # defined are added to the queue
+        while len(iri_queue) > 0:
+            # remove from queue
+            parent_iri = iri_queue[0]
+            del iri_queue[0]
+
+            # add to class_order
+            parent = vocabulary.classes[parent_iri]
+            class_order.append(parent)
+            added_class_iris.add(parent_iri)
+
+            # check children
+            child_iris = children[parent_iri]
+            for child_iri in child_iris:
+                child = vocabulary.classes[child_iri]
+
+                # all parents added, add child to queue
+                if len([p for p in child.parent_class_iris
+                        if p in added_class_iris]) == len(
+                        child.parent_class_iris):
+
+                    if not child_iri in added_class_iris:
+                        iri_queue.append(child_iri)
+
+        for class_ in class_order:
+
+            content += "\n\n\n"
+            # Parent Classes
+            parent_class_string = ""
+            parents = class_.get_parent_classes(vocabulary,
+                                                remove_redundancy=True)
+
+            # Device Class, only add if this is a device class and it was not
+            # added for a parent
+            if class_.is_iot_class(vocabulary):
+                if True not in [p.is_iot_class(vocabulary) for p in
+                                parents]:
+                    parent_class_string = " ,SemanticDeviceClass"
+
+            for parent in parents:
+                parent_class_string += f", {parent.get_label()}"
+
+            parent_class_string = parent_class_string[
+                                  2:]  # remove first comma and space
+            if parent_class_string == "":
+                parent_class_string = "SemanticClass"
+
+            content += f"class {class_.get_label()}({parent_class_string}):"
+
+            # add class docstring
+            content += f'\n\t"""'
+            for line in split_string_into_lines(class_.comment, 75):
+                content += f"\n\t{line}"
+            if class_.comment == "":
+                content += "\n\tGenerated SemanticClass without description"
+            content += f"\n\n\t"
+            content += f"Source(s): \n\t\t"
+
+            for source_id in class_.source_ids:
+                content += f"{vocabulary.sources[source_id].ontology_iri} " \
+                           f"({vocabulary.sources[source_id].source_name})"
+            content += f'\n\t"""'
+
+            # ------Constructors------
+            if class_.get_label() == "Thing":
+                content += "\n\n\t"
+                content += "def __new__(cls, *args, **kwargs):"
+                content += "\n\t\t"
+                content += f"kwargs['semantic_manager'] = semantic_manager"
+                content += "\n\t\t"
+                content += "return super().__new__(cls, *args, **kwargs)"
+
+                content += "\n\n\t"
+                content += "def __init__(self, *args, **kwargs):"
+                content += "\n\t\t"
+                content += f"kwargs['semantic_manager'] = semantic_manager"
+                content += "\n\t\t"
+                content += "is_initialised = 'id' in self.__dict__"
+                content += "\n\t\t"
+                content += "super().__init__(*args, **kwargs)"
+
+            else:
+                content += "\n\n\t"
+                content += "def __init__(self, *args, **kwargs):"
+                content += "\n\t\t"
+                content += "is_initialised = 'id' in self.__dict__"
+                content += "\n\t\t"
+                content += "super().__init__(*args, **kwargs)"
+
+            # ------Init Fields------
+            content += "\n\t\t"
+            content += "if not is_initialised:"
+            # Only initialise values once
+            for cdr in class_.get_combined_data_relations(vocabulary):
+                if not cdr.is_device_relation(vocabulary):
+                    content += "\n\t\t\t"
+                    content += \
+                        f"self." \
+                        f"{cdr.get_property_label(vocabulary)}._rules = " \
+                        f"{cdr.export_rule(vocabulary, stringify_fields=True)}"
+
+            if len(class_.get_combined_object_relations(vocabulary)) > 0:
+                content += "\n"
+            for cor in class_.get_combined_object_relations(vocabulary):
+                content += "\n\t\t\t"
+                content += f"self." \
+                           f"{cor.get_property_label(vocabulary)}._rules = " \
+                           f"{cor.export_rule(vocabulary, stringify_fields=False)}"
+
+            if len(class_.get_combined_relations(vocabulary)) > 0:
+                content += "\n"
+            for cr in class_.get_combined_relations(vocabulary):
+                content += "\n\t\t\t"
+                content += f"self.{cr.get_property_label(vocabulary)}" \
+                           f"._instance_identifier = " \
+                           f"self.get_identifier()"
+
+            # ------Add preset Values------
+            for cdr in class_.get_combined_data_relations(vocabulary):
+                # Add fixed values to fields, for CDRs these values need to be
+                # strings. Only add the statement on the uppermost occurring
+                # class
+                if not cdr.is_device_relation(vocabulary):
+                    for rel in cdr.get_relations(vocabulary):
+                        if rel.id in class_.relation_ids:
+                            # only reinitialise the fields if this child class
+                            # changed them
+                            if rel.restriction_type == RestrictionType.value:
+                                content += "\n\t\t\t"
+                                content += \
+                                    f"self." \
+                                    f"{cdr.get_property_label(vocabulary)}" \
+                                    f".add(" \
+                                    f"'{rel.target_statement.target_data_value}')"
+
+            if len(class_.get_combined_object_relations(vocabulary)) > 0:
+                content += "\n"
+            for cor in class_.get_combined_object_relations(vocabulary):
+                # Add fixed values to fields, for CORs these values need to be
+                # Individuals.
+                # Only add the statement on the uppermost occurring class
+                for rel in cor.get_relations(vocabulary):
+                    if rel.id in class_.relation_ids:
+                        i = vocabulary. \
+                            get_label_for_entity_iri(
+                            rel.get_targets()[0][0])
+                        if rel.restriction_type == RestrictionType.value:
+                            content += "\n\t\t\t"
+                            content += f"self." \
+                                       f"{cor.get_property_label(vocabulary)}" \
+                                       f".add({i}())"
+
+            # if no content was added af the not initialised if, removed it
+            # again, and its preceding \n
+            if content[-22:] == "if not is_initialised:":
+                content = content[:-25]
+
+            # make space the same for each case above
+            if "\n" in content[-2:]:
+                content = content[:-1]
+
+            def build_field_comment(cr: CombinedRelation) -> str:
+                comment = vocabulary.get_entity_by_iri(cr.property_iri).comment
+                res = ""
+                if comment != "":
+                    res += f'\n\t"""'
+                    for line in split_string_into_lines(comment, 75):
+                        res += f'\n\t{line}'
+                    res += f'\n\t"""'
+                return res
+
+            # ------Add Data Fields------
+            if len(class_.get_combined_data_relations(vocabulary)) > 0:
+                content += "\n\n\t"
+                content += "# Data fields"
+            for cdr in class_.get_combined_data_relations(vocabulary):
+                cdr_type = cdr.get_field_type(vocabulary)
+                if cdr_type == DataFieldType.simple:
+                    content += "\n\n\t"
+                    label = cdr.get_property_label(vocabulary)
+                    content += f"{label}: DataField = DataField("
+                    content += "\n\t\t"
+                    content += f"name='{label}',"
+                    content += "\n\t\t"
+                    content += \
+                        f"rule='" \
+                        f"{cdr.get_all_targetstatements_as_string(vocabulary)}',"
+                    content += "\n\t\t"
+                    content += f"semantic_manager=semantic_manager)"
+                    content += build_field_comment(cdr)
+
+                elif cdr_type == DataFieldType.command:
+                    content += "\n\n\t"
+                    label = cdr.get_property_label(vocabulary)
+                    content += f"{label}: CommandField = CommandField("
+                    content += "\n\t\t"
+                    content += f"name='{label}',"
+                    content += "\n\t\t"
+                    content += f"semantic_manager=semantic_manager)"
+                    content += build_field_comment(cdr)
+
+                elif cdr_type == DataFieldType.device_attribute:
+                    content += "\n\n\t"
+                    label = cdr.get_property_label(vocabulary)
+                    content += f"{label}: DeviceAttributeField " \
+                               f"= DeviceAttributeField("
+                    content += "\n\t\t"
+                    content += f"name='{label}',"
+                    content += "\n\t\t"
+                    content += f"semantic_manager=semantic_manager)"
+                    content += build_field_comment(cdr)
+
+            # ------Add Relation Fields------
+            if len(class_.get_combined_object_relations(vocabulary)) > 0:
+                content += "\n\n\t"
+                content += "# Relation fields"
+            for cor in class_.get_combined_object_relations(vocabulary):
+                content += "\n\n\t"
+                label = cor.get_property_label(vocabulary)
+                content += f"{label}: RelationField = RelationField("
+                content += "\n\t\t"
+                content += f"name='{label}',"
+                content += "\n\t\t"
+                content += f"rule='" \
+                           f"{cor.get_all_targetstatements_as_string(vocabulary)}',"
+                content += "\n\t\t"
+                if not len(cor.get_inverse_of_labels(vocabulary)) == 0:
+                    content += "inverse_of="
+                    content += str(cor.get_inverse_of_labels(vocabulary))
+                    content += ",\n\t\t"
+
+                content += f"semantic_manager=semantic_manager)"
+                content += build_field_comment(cor)
+
+        content += "\n\n\n"
+        content += "# ---------Individuals--------- #"
+
+        for individual in vocabulary.individuals.values():
+            content += "\n\n\n"
+
+            parent_class_string = ""
+            for parent in individual.get_parent_classes(vocabulary):
+                parent_class_string += f", {parent.get_label()}"
+            parent_class_string = parent_class_string[2:]
+
+            content += f"class {individual.get_label()}(SemanticIndividual):"
+            content += "\n\t"
+            content += f"_parent_classes: List[type] = [{parent_class_string}]"
+
+        content += "\n\n\n"
+
+        content += "# ---------Datatypes--------- #"
+        content += "\n"
+
+        # Datatypes catalogue
+        content += f"semantic_manager.datatype_catalogue = "
+        content += "{"
+        for name, datatype in vocabulary.datatypes.items():
+            definition = datatype.export()
+            content += "\n\t"
+            # content += f"'{datatype.get_label()}': \t {definition},"
+            content += f"'{datatype.get_label()}': "
+            content += "{\n"
+            for key, value in definition.items():
+                string_value = f"'{value}'" if type(value) == str else value
+                content += f"\t\t'{key}': {string_value},\n"
+            content += "\t},"
+
+        content += "\n"
+        content += "}"
+
+        # Build datatypes with enums as Enums
+        content += "\n\n\n"
+        for datatype in vocabulary.get_enum_dataytypes().values():
+            content += f"class {datatype.get_label()}(str, Enum):"
+            for value in datatype.enum_values:
+                content += f"\n\tvalue_{value} = '{value}'"
+            content += "\n\n\n"
+
+        content += "# ---------Class Dict--------- #"
+
+        # build class dict
+        content += "\n\n"
+        content += f"semantic_manager.class_catalogue = "
+        content += "{"
+        for class_ in vocabulary.get_classes_sorted_by_label():
+            content += "\n\t"
+            content += f"'{class_.get_label()}': {class_.get_label()},"
+        content += "\n\t}"
+        content += "\n"
+
+        # build individual dict
+        content += "\n\n"
+        content += f"semantic_manager.individual_catalogue = "
+        content += "{"
+        for individual in vocabulary.individuals.values():
+            content += "\n\t"
+            content += f"'{individual.get_label()}': {individual.get_label()},"
+        content += "\n\t}"
+        content += "\n"
+
+        if path is None or filename is None:
+            return content
+        else:
+            path = pathlib.Path(path).joinpath(filename).with_suffix(".py")
+
+            with open(path, "w", encoding ="utf-8") as text_file:
+                text_file.write(content)
+
+
+class ParsingException(Exception):
+    """Error Class that is raised if parsing of an ontology was unsuccessful"""
+
+    # Constructor or Initializer
+    def __init__(self, value):
+        self.value = value
+
+    # __str__ is to print() the value
+    def __str__(self):
+        return repr(self.value)
```

### Comparing `filip-0.3.0/filip/utils/datetime.py` & `filip-0.4.0/filip/utils/datetime.py`

 * *Ordering differences only*

 * *Files 25% similar despite different names*

```diff
@@ -1,30 +1,30 @@
-from datetime import datetime, timezone
-
-
-def transform_to_utc_datetime(dt: datetime) -> datetime:
-    """
-    Converts datetime object to utc datetime object with zone
-
-    Args:
-        dt:
-
-    Returns:
-
-    """
-    return dt.astimezone(tz=timezone.utc)
-
-
-def convert_datetime_to_iso_8601_with_z_suffix(dt: datetime) -> str:
-    """
-    Converts datetime object to iso8601 notation with z-suffix
-
-    Args:
-        dt: datetime object
-
-    Returns:
-        String in iso 8601 notation with z-suffix
-    """
-    dt = transform_to_utc_datetime(dt)
-    return dt.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3]+'Z'
-
-
+from datetime import datetime, timezone
+
+
+def transform_to_utc_datetime(dt: datetime) -> datetime:
+    """
+    Converts datetime object to utc datetime object with zone
+
+    Args:
+        dt:
+
+    Returns:
+
+    """
+    return dt.astimezone(tz=timezone.utc)
+
+
+def convert_datetime_to_iso_8601_with_z_suffix(dt: datetime) -> str:
+    """
+    Converts datetime object to iso8601 notation with z-suffix
+
+    Args:
+        dt: datetime object
+
+    Returns:
+        String in iso 8601 notation with z-suffix
+    """
+    dt = transform_to_utc_datetime(dt)
+    return dt.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3]+'Z'
+
+
```

### Comparing `filip-0.3.0/filip/utils/filter.py` & `filip-0.4.0/filip/utils/filter.py`

 * *Ordering differences only*

 * *Files 26% similar despite different names*

```diff
@@ -1,124 +1,124 @@
-"""
-Filter functions to keep client code clean and easy to use.
-"""
-from typing import List, Union
-from filip.clients.ngsi_v2 import ContextBrokerClient
-from filip.models import FiwareHeader
-from filip.models.ngsi_v2.iot import Device, ServiceGroup
-from filip.models.ngsi_v2.subscriptions import Subscription
-from requests.exceptions import RequestException
-
-
-def filter_device_list(devices: List[Device],
-                       device_ids: Union[str, List[str]] = None,
-                       entity_names: Union[str, List[str]] = None,
-                       entity_types: Union[str, List[str]] = None) -> List[Device]:
-    """
-    Filter the given device list based on conditions
-
-    Args:
-        devices: device list that need to be filtered
-        device_ids: A list of device_id as filter condition
-        entity_names: A list of entity_name (e.g. entity_id) as filter condition.
-        entity_types: A list of entity_type as filter condition
-
-    Returns:
-        List of matching devices
-    """
-    if device_ids:
-        if isinstance(device_ids, (list, str)):
-            if isinstance(device_ids, str):
-                device_ids = [device_ids]
-            devices = [device for device in devices if device.device_id in device_ids]
-        else:
-            raise TypeError('device_ids must be a string or a list of strings!')
-
-    if entity_names:
-        if isinstance(entity_names, (list, str)):
-            if isinstance(entity_names, str):
-                entity_names = [entity_names]
-            devices = [device for device in devices if device.entity_name in entity_names]
-        else:
-            raise TypeError('entity_names must be a string or a list of strings!')
-
-    if entity_types:
-        if isinstance(entity_types, (list, str)):
-            if isinstance(entity_types, str):
-                entity_types = [entity_types]
-            devices = [device for device in devices if device.entity_type in entity_types]
-        else:
-            raise TypeError('entity_types must be a string or a list of strings!')
-
-    return devices
-
-
-def filter_subscriptions_by_entity(entity_id: str,
-                                   entity_type: str,
-                                   url: str = None,
-                                   fiware_header: FiwareHeader = None,
-                                   subscriptions: List[Subscription] = None,
-                                   ) -> List[Subscription]:
-    """
-    Function that filters subscriptions based on the entity id or id pattern
-    and entity type or type pattern. The function can be used in two ways,
-    wither pass list of subscriptions to filter based on entity or directly pass
-    client information to filter subscriptions in a single request.
-
-    Args:
-        entity_id: Id of the entity to be matched
-        entity_type: Type of the entity to be matched
-        url: Url of the context broker service
-        fiware_header: Fiware header of the tenant
-        subscriptions: List of subscriptions to filter
-    Returns:
-        list of subscriptions by entity
-    """
-    if not subscriptions:
-        client = ContextBrokerClient(url=url, fiware_header=fiware_header)
-        subscriptions = client.get_subscription_list()
-    filtered_subscriptions = []
-    for subscription in subscriptions:
-        for entity in subscription.subject.entities:
-            if entity.id == entity_id or (
-                    entity.idPattern is not None
-                    and entity.idPattern.match(entity_id)):
-                if entity.type == entity_type or \
-                        (entity.typePattern is not None and
-                         entity.typePattern.match(entity_type)):
-                    filtered_subscriptions.append(subscription)
-    return filtered_subscriptions
-
-
-def filter_group_list(group_list: List[ServiceGroup],
-                      resources: Union[str, List[str]] = None,
-                      apikeys: Union[str, List[str]] = None
-                      ) -> List[ServiceGroup]:
-    """
-    Filter service group based on resource and apikey.
-
-    Args:
-        group_list: The list of service groups that need to be filtered
-        resources: see ServiceGroup model
-        apikeys: see ServiceGroup
-
-    Returns: a single service group or Not Found Error
-    """
-    if resources:
-        if isinstance(resources, (list, str)):
-            if isinstance(resources, str):
-                resources = [resources]
-            group_list = [group for group in group_list if group.resource in resources]
-        else:
-            raise TypeError('resources must be a string or a list of strings!')
-
-    if apikeys:
-        if isinstance(apikeys, (list, str)):
-            if isinstance(apikeys, str):
-                apikeys = [apikeys]
-            group_list = [group for group in group_list if group.apikey in apikeys]
-        else:
-            raise TypeError('apikeys must be a string or a list of strings!')
-
-    return group_list
-
-
+"""
+Filter functions to keep client code clean and easy to use.
+"""
+from typing import List, Union
+from filip.clients.ngsi_v2 import ContextBrokerClient
+from filip.models import FiwareHeader
+from filip.models.ngsi_v2.iot import Device, ServiceGroup
+from filip.models.ngsi_v2.subscriptions import Subscription
+from requests.exceptions import RequestException
+
+
+def filter_device_list(devices: List[Device],
+                       device_ids: Union[str, List[str]] = None,
+                       entity_names: Union[str, List[str]] = None,
+                       entity_types: Union[str, List[str]] = None) -> List[Device]:
+    """
+    Filter the given device list based on conditions
+
+    Args:
+        devices: device list that need to be filtered
+        device_ids: A list of device_id as filter condition
+        entity_names: A list of entity_name (e.g. entity_id) as filter condition.
+        entity_types: A list of entity_type as filter condition
+
+    Returns:
+        List of matching devices
+    """
+    if device_ids:
+        if isinstance(device_ids, (list, str)):
+            if isinstance(device_ids, str):
+                device_ids = [device_ids]
+            devices = [device for device in devices if device.device_id in device_ids]
+        else:
+            raise TypeError('device_ids must be a string or a list of strings!')
+
+    if entity_names:
+        if isinstance(entity_names, (list, str)):
+            if isinstance(entity_names, str):
+                entity_names = [entity_names]
+            devices = [device for device in devices if device.entity_name in entity_names]
+        else:
+            raise TypeError('entity_names must be a string or a list of strings!')
+
+    if entity_types:
+        if isinstance(entity_types, (list, str)):
+            if isinstance(entity_types, str):
+                entity_types = [entity_types]
+            devices = [device for device in devices if device.entity_type in entity_types]
+        else:
+            raise TypeError('entity_types must be a string or a list of strings!')
+
+    return devices
+
+
+def filter_subscriptions_by_entity(entity_id: str,
+                                   entity_type: str,
+                                   url: str = None,
+                                   fiware_header: FiwareHeader = None,
+                                   subscriptions: List[Subscription] = None,
+                                   ) -> List[Subscription]:
+    """
+    Function that filters subscriptions based on the entity id or id pattern
+    and entity type or type pattern. The function can be used in two ways,
+    wither pass list of subscriptions to filter based on entity or directly pass
+    client information to filter subscriptions in a single request.
+
+    Args:
+        entity_id: Id of the entity to be matched
+        entity_type: Type of the entity to be matched
+        url: Url of the context broker service
+        fiware_header: Fiware header of the tenant
+        subscriptions: List of subscriptions to filter
+    Returns:
+        list of subscriptions by entity
+    """
+    if not subscriptions:
+        client = ContextBrokerClient(url=url, fiware_header=fiware_header)
+        subscriptions = client.get_subscription_list()
+    filtered_subscriptions = []
+    for subscription in subscriptions:
+        for entity in subscription.subject.entities:
+            if entity.id == entity_id or (
+                    entity.idPattern is not None
+                    and entity.idPattern.match(entity_id)):
+                if entity.type == entity_type or \
+                        (entity.typePattern is not None and
+                         entity.typePattern.match(entity_type)):
+                    filtered_subscriptions.append(subscription)
+    return filtered_subscriptions
+
+
+def filter_group_list(group_list: List[ServiceGroup],
+                      resources: Union[str, List[str]] = None,
+                      apikeys: Union[str, List[str]] = None
+                      ) -> List[ServiceGroup]:
+    """
+    Filter service group based on resource and apikey.
+
+    Args:
+        group_list: The list of service groups that need to be filtered
+        resources: see ServiceGroup model
+        apikeys: see ServiceGroup
+
+    Returns: a single service group or Not Found Error
+    """
+    if resources:
+        if isinstance(resources, (list, str)):
+            if isinstance(resources, str):
+                resources = [resources]
+            group_list = [group for group in group_list if group.resource in resources]
+        else:
+            raise TypeError('resources must be a string or a list of strings!')
+
+    if apikeys:
+        if isinstance(apikeys, (list, str)):
+            if isinstance(apikeys, str):
+                apikeys = [apikeys]
+            group_list = [group for group in group_list if group.apikey in apikeys]
+        else:
+            raise TypeError('apikeys must be a string or a list of strings!')
+
+    return group_list
+
+
```

### Comparing `filip-0.3.0/filip/utils/iot.py` & `filip-0.4.0/filip/utils/iot.py`

 * *Ordering differences only*

 * *Files 26% similar despite different names*

```diff
@@ -1,32 +1,32 @@
-"""
-Helper functions to handle the devices related with the IoT Agent
-"""
-import warnings
-from typing import List, Union
-from filip.models.ngsi_v2.iot import Device
-from filip.utils.filter import filter_device_list as filter_device_list_new
-
-def filter_device_list(devices: List[Device],
-                       device_ids: Union[str, List[str]] = None,
-                       entity_names: Union[str, List[str]] = None,
-                       entity_types: Union[str, List[str]] = None) -> List[Device]:
-    """
-    Filter the given device list based on conditions
-
-    Args:
-        devices: device list that need to be filtered
-        device_ids: A list of device_id as filter condition
-        entity_names: A list of entity_name (e.g. entity_id) as filter condition.
-        entity_types: A list of entity_type as filter condition
-
-    Returns:
-        List of matching devices
-    """
-    warnings.warn("This function has been moved to 'filip.utils.filter' "
-                  "and will be removed from this module in future releases!",
-                  DeprecationWarning)
-
-    return filter_device_list_new(devices=devices,
-                                  device_ids=device_ids,
-                                  entity_names=entity_names,
-                                  entity_types=entity_types)
+"""
+Helper functions to handle the devices related with the IoT Agent
+"""
+import warnings
+from typing import List, Union
+from filip.models.ngsi_v2.iot import Device
+from filip.utils.filter import filter_device_list as filter_device_list_new
+
+def filter_device_list(devices: List[Device],
+                       device_ids: Union[str, List[str]] = None,
+                       entity_names: Union[str, List[str]] = None,
+                       entity_types: Union[str, List[str]] = None) -> List[Device]:
+    """
+    Filter the given device list based on conditions
+
+    Args:
+        devices: device list that need to be filtered
+        device_ids: A list of device_id as filter condition
+        entity_names: A list of entity_name (e.g. entity_id) as filter condition.
+        entity_types: A list of entity_type as filter condition
+
+    Returns:
+        List of matching devices
+    """
+    warnings.warn("This function has been moved to 'filip.utils.filter' "
+                  "and will be removed from this module in future releases!",
+                  DeprecationWarning)
+
+    return filter_device_list_new(devices=devices,
+                                  device_ids=device_ids,
+                                  entity_names=entity_names,
+                                  entity_types=entity_types)
```

### Comparing `filip-0.3.0/filip/utils/model_generation.py` & `filip-0.4.0/filip/utils/model_generation.py`

 * *Ordering differences only*

 * *Files 20% similar despite different names*

```diff
@@ -1,156 +1,156 @@
-"""
-Code generator for data models from schema.json descriptions
-"""
-import json
-import shutil
-from pathlib import Path
-from tempfile import TemporaryDirectory
-from typing import Union, Dict, Any, Type
-from urllib import parse
-from uuid import uuid4
-from datamodel_code_generator import InputFileType, generate, ParseResult
-from pydantic import create_model
-
-from filip.models.ngsi_v2.context import ContextAttribute, ContextEntity
-
-
-def create_data_model_file(*,
-                           path: Union[Path, str],
-                           url: str = None,
-                           schema: Union[Path, str, ParseResult] = None,
-                           schema_type: Union[str, InputFileType] =
-                     InputFileType.JsonSchema,
-                           class_name: str = None
-                           ) -> None:
-    """
-    This will create a data model from data model definitions. The schemas
-    can either downloaded from a url or passed as str or dict. Allowed input
-    types are defined but the underlying toolbox.
-
-    Many data models suited for FIWARE are located here:
-    https://github.com/smart-data-models/data-models
-
-    Args:
-        path:
-            path where the generated code should saved
-        url:
-            url to download the definition from
-        schema_type (str):
-            `auto`, `openapi`, `jsonschema`, `json`, `yaml`, `dict`, `csv`
-        class_name:
-            classname for the model class
-
-    Returns:
-        None
-
-    Examples::
-
-        {
-            "type": "object",
-            "properties": {
-                "number": {
-                    "type": "number"
-                    },
-                "street_name": {
-                    "type": "string"
-                   },
-                "street_type": {
-                    "type": "string",
-                    "enum": ["Street", "Avenue", "Boulevard"]
-                }
-            }
-        }
-    """
-    if isinstance(path, str):
-        path = Path(path)
-    path.parent.mkdir(parents=True, exist_ok=True)
-
-    if isinstance(schema_type, str):
-        schema_type = InputFileType(schema_type)
-
-    with TemporaryDirectory() as temp:
-        temp = Path(temp)
-        output = Path(temp).joinpath(f'{uuid4()}.py')
-
-        if url:
-            schema = parse.urlparse(url)
-        if not schema:
-            raise ValueError("Missing argument! Either 'url' or 'schema' "
-                             "must be provided")
-
-        generate(
-            input_=schema,
-            input_file_type=schema_type,
-            output=output,
-            class_name=class_name)
-
-        # move temporary file to output directory
-        shutil.move(str(output), str(path))
-
-
-def create_context_entity_model(name: str = None,
-                                data: Dict = None,
-                                validators: Dict[str, Any] = None,
-                                path: Union[Path, str] = None) -> \
-        Type['ContextEntity']:
-    r"""
-    Creates a ContextEntity-Model from a dict:
-
-    Args:
-        name:
-            name of the model
-        data:
-            dictionary containing the data structure
-        validators (optional):
-            validators for the new model
-        path:
-            if present the model will written to *.py file if file ending
-            *.py is used and to json-schema if *.json is used.
-
-    Example:
-
-        >>> def username_alphanumeric(cls, value):
-                assert v.value.isalnum(), 'must be numeric'
-                return value
-
-        >>> model = create_context_entity_model(
-                        name='MyModel',
-                        data={
-                            'id': 'MyId',
-                            'type':'MyType',
-                            'temp': 'MyProperty'}
-                        {'validate_test': validator('temperature')(
-                            username_alphanumeric)})
-
-    Returns:
-        ContextEntity
-
-    """
-    properties = {key: (ContextAttribute, ...) for key in data.keys() if
-                  key not in ContextEntity.model_fields}
-    model = create_model(
-        __model_name=name or 'GeneratedContextEntity',
-        __base__=ContextEntity,
-        __validators__=validators or {},
-        **properties
-    )
-
-    # if path exits a file will be generated that contains the model
-    if path:
-        if isinstance(path, str):
-            path=Path(path)
-
-        with TemporaryDirectory() as temp:
-            temp = Path(temp)
-            output = Path(temp).joinpath(f'{uuid4()}.json')
-            output.touch(exist_ok=True)
-            with output.open('w') as f:
-                json.dump(model.model_json_schema(), f, indent=2)
-            if path.suffix == '.json':
-                # move temporary file to output directory
-                shutil.move(str(output), str(path))
-            elif path.suffix == '.py':
-                create_data_model_file(path=path,
-                                       schema=output,
-                                       class_name=name)
-    return model
+"""
+Code generator for data models from schema.json descriptions
+"""
+import json
+import shutil
+from pathlib import Path
+from tempfile import TemporaryDirectory
+from typing import Union, Dict, Any, Type
+from urllib import parse
+from uuid import uuid4
+from datamodel_code_generator import InputFileType, generate, ParseResult
+from pydantic import create_model
+
+from filip.models.ngsi_v2.context import ContextAttribute, ContextEntity
+
+
+def create_data_model_file(*,
+                           path: Union[Path, str],
+                           url: str = None,
+                           schema: Union[Path, str, ParseResult] = None,
+                           schema_type: Union[str, InputFileType] =
+                     InputFileType.JsonSchema,
+                           class_name: str = None
+                           ) -> None:
+    """
+    This will create a data model from data model definitions. The schemas
+    can either downloaded from a url or passed as str or dict. Allowed input
+    types are defined but the underlying toolbox.
+
+    Many data models suited for FIWARE are located here:
+    https://github.com/smart-data-models/data-models
+
+    Args:
+        path:
+            path where the generated code should saved
+        url:
+            url to download the definition from
+        schema_type (str):
+            `auto`, `openapi`, `jsonschema`, `json`, `yaml`, `dict`, `csv`
+        class_name:
+            classname for the model class
+
+    Returns:
+        None
+
+    Examples::
+
+        {
+            "type": "object",
+            "properties": {
+                "number": {
+                    "type": "number"
+                    },
+                "street_name": {
+                    "type": "string"
+                   },
+                "street_type": {
+                    "type": "string",
+                    "enum": ["Street", "Avenue", "Boulevard"]
+                }
+            }
+        }
+    """
+    if isinstance(path, str):
+        path = Path(path)
+    path.parent.mkdir(parents=True, exist_ok=True)
+
+    if isinstance(schema_type, str):
+        schema_type = InputFileType(schema_type)
+
+    with TemporaryDirectory() as temp:
+        temp = Path(temp)
+        output = Path(temp).joinpath(f'{uuid4()}.py')
+
+        if url:
+            schema = parse.urlparse(url)
+        if not schema:
+            raise ValueError("Missing argument! Either 'url' or 'schema' "
+                             "must be provided")
+
+        generate(
+            input_=schema,
+            input_file_type=schema_type,
+            output=output,
+            class_name=class_name)
+
+        # move temporary file to output directory
+        shutil.move(str(output), str(path))
+
+
+def create_context_entity_model(name: str = None,
+                                data: Dict = None,
+                                validators: Dict[str, Any] = None,
+                                path: Union[Path, str] = None) -> \
+        Type['ContextEntity']:
+    r"""
+    Creates a ContextEntity-Model from a dict:
+
+    Args:
+        name:
+            name of the model
+        data:
+            dictionary containing the data structure
+        validators (optional):
+            validators for the new model
+        path:
+            if present the model will written to *.py file if file ending
+            *.py is used and to json-schema if *.json is used.
+
+    Example:
+
+        >>> def username_alphanumeric(cls, value):
+                assert v.value.isalnum(), 'must be numeric'
+                return value
+
+        >>> model = create_context_entity_model(
+                        name='MyModel',
+                        data={
+                            'id': 'MyId',
+                            'type':'MyType',
+                            'temp': 'MyProperty'}
+                        {'validate_test': validator('temperature')(
+                            username_alphanumeric)})
+
+    Returns:
+        ContextEntity
+
+    """
+    properties = {key: (ContextAttribute, ...) for key in data.keys() if
+                  key not in ContextEntity.model_fields}
+    model = create_model(
+        __model_name=name or 'GeneratedContextEntity',
+        __base__=ContextEntity,
+        __validators__=validators or {},
+        **properties
+    )
+
+    # if path exits a file will be generated that contains the model
+    if path:
+        if isinstance(path, str):
+            path=Path(path)
+
+        with TemporaryDirectory() as temp:
+            temp = Path(temp)
+            output = Path(temp).joinpath(f'{uuid4()}.json')
+            output.touch(exist_ok=True)
+            with output.open('w') as f:
+                json.dump(model.model_json_schema(), f, indent=2)
+            if path.suffix == '.json':
+                # move temporary file to output directory
+                shutil.move(str(output), str(path))
+            elif path.suffix == '.py':
+                create_data_model_file(path=path,
+                                       schema=output,
+                                       class_name=name)
+    return model
```

### Comparing `filip-0.3.0/filip/utils/validators.py` & `filip-0.4.0/filip/utils/validators.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,168 +1,168 @@
-"""
-Helper functions to prohibit boiler plate code
-"""
-import logging
-import re
-from aenum import Enum
-from typing import Dict, Any, List
-from pydantic import AnyHttpUrl, validate_call
-from pydantic_core import PydanticCustomError
-from filip.custom_types import AnyMqttUrl
-
-
-logger = logging.getLogger(name=__name__)
-
-
-class FiwareRegex(str, Enum):
-    """
-    Collection of Regex expression used to check if the value of a Pydantic
-    field, can be used in the related Fiware field.
-    """
-    _init_ = 'value __doc__'
-
-    standard = r"(^((?![?&#/\"' ])[\x00-\x7F])*$)", \
-               "Prevents any string that contains at least one of the " \
-               "symbols: ? & # / ' \" or a whitespace"
-    string_protect = r"(?!^id$)(?!^type$)(?!^geo:location$)" \
-                     r"(^((?![?&#/\"' ])[\x00-\x7F])*$)",\
-                     "Prevents any string that contains at least one of " \
-                     "the symbols: ? & # / ' \" or a whitespace." \
-                     "AND the strings: id, type, geo:location"
-
-
-@validate_call
-def validate_http_url(url: AnyHttpUrl) -> str:
-    """
-    Function checks whether the host has "http" added in case of http as
-    protocol.
-
-    Args:
-        url (AnyHttpUrl): the url for the host / port
-
-    Returns:
-        validated url
-    """
-    return str(url) if url else url
-
-
-@validate_call
-def validate_mqtt_url(url: AnyMqttUrl) -> str:
-    """
-    Function that checks whether a url is valid mqtt endpoint
-
-    Args:
-        url: the url for the target endpoint
-
-    Returns:
-       validated url
-    """
-    return str(url) if url else url
-
-
-def validate_escape_character_free(value: Any) -> Any:
-    """
-    Function that checks whether a value contains a string part that starts
-    or end with ' or ".
-    the function iterates to break down each complex data-structure to its
-    fundamental string parts.
-    Each value of a list is examined
-    Of dictionaries each value is examined, keys are skipped, as they are ok
-    for Fiware
-
-    Args:
-        value: the string to check
-
-    Returns:
-       validated string
-    """
-
-    if not isinstance(value, List):
-        values = [value]
-    else:
-        values = value
-
-    for value in values:
-        if isinstance(value, Dict):
-            for key, dict_value in value.items():
-                validate_escape_character_free(dict_value)
-                # it seems Fiware has no problem if the keys contain ' or "
-                # validate_escape_character_free(key)
-        elif isinstance(value, List):
-            for inner_list in value:
-                validate_escape_character_free(inner_list)
-        else:
-            # if a value here is not a string, it will also not contain ' or "
-            value = str(value)
-            if '"' == value[-1:] or '"' == value[0:1]:
-                raise ValueError(f"The value {value} contains "
-                                 f"the forbidden char \"")
-            if "'" == value[-1:] or "'" == value[0:1]:
-                raise ValueError(f"The value {value} contains "
-                                 f"the forbidden char '")
-    return values
-
-
-def match_regex(value: str, pattern: str):
-    regex = re.compile(pattern)
-    if not regex.match(value):
-        raise PydanticCustomError(
-            'string_pattern_mismatch',
-            "String should match pattern '{pattern}'",
-            {'pattern': pattern},
-        )
-    return value
-
-
-def ignore_none_input(func):
-    def wrapper(arg):
-        if arg is None:
-            return arg
-        return func(arg)
-    return wrapper
-
-
-def validate_fiware_standard_regex(vale: str):
-    return match_regex(vale, FiwareRegex.standard.value)
-
-
-def validate_fiware_string_protect_regex(vale: str):
-    return match_regex(vale, FiwareRegex.string_protect.value)
-
-
-@ignore_none_input
-def validate_mqtt_topic(topic: str):
-    return match_regex(topic, r'^((?![\'\"#+,])[\x00-\x7F])*$')
-
-
-@ignore_none_input
-def validate_fiware_datatype_standard(_type):
-    from filip.models.base import DataType
-    if isinstance(_type, DataType):
-        return _type
-    elif isinstance(_type, str):
-        return validate_fiware_standard_regex(_type)
-    else:
-        raise TypeError(f"Invalid type {type(_type)}")
-
-
-@ignore_none_input
-def validate_fiware_datatype_string_protect(_type):
-    from filip.models.base import DataType
-    if isinstance(_type, DataType):
-        return _type
-    elif isinstance(_type, str):
-        return validate_fiware_string_protect_regex(_type)
-    else:
-        raise TypeError(f"Invalid type {type(_type)}")
-
-
-@ignore_none_input
-def validate_fiware_service_path(service_path):
-    return match_regex(service_path,
-                       r'^((\/\w*)|(\/\#))*(\,((\/\w*)|(\/\#)))*$')
-
-
-@ignore_none_input
-def validate_fiware_service(service):
-    return match_regex(service,
-                       r"\w*$")
+"""
+Helper functions to prohibit boiler plate code
+"""
+import logging
+import re
+from aenum import Enum
+from typing import Dict, Any, List
+from pydantic import AnyHttpUrl, validate_call
+from pydantic_core import PydanticCustomError
+from filip.custom_types import AnyMqttUrl
+
+
+logger = logging.getLogger(name=__name__)
+
+
+class FiwareRegex(str, Enum):
+    """
+    Collection of Regex expression used to check if the value of a Pydantic
+    field, can be used in the related Fiware field.
+    """
+    _init_ = 'value __doc__'
+
+    standard = r"(^((?![?&#/\"' ])[\x00-\x7F])*$)", \
+               "Prevents any string that contains at least one of the " \
+               "symbols: ? & # / ' \" or a whitespace"
+    string_protect = r"(?!^id$)(?!^type$)(?!^geo:location$)" \
+                     r"(^((?![?&#/\"' ])[\x00-\x7F])*$)",\
+                     "Prevents any string that contains at least one of " \
+                     "the symbols: ? & # / ' \" or a whitespace." \
+                     "AND the strings: id, type, geo:location"
+
+
+@validate_call
+def validate_http_url(url: AnyHttpUrl) -> str:
+    """
+    Function checks whether the host has "http" added in case of http as
+    protocol.
+
+    Args:
+        url (AnyHttpUrl): the url for the host / port
+
+    Returns:
+        validated url
+    """
+    return str(url) if url else url
+
+
+@validate_call
+def validate_mqtt_url(url: AnyMqttUrl) -> str:
+    """
+    Function that checks whether a url is valid mqtt endpoint
+
+    Args:
+        url: the url for the target endpoint
+
+    Returns:
+       validated url
+    """
+    return str(url) if url else url
+
+
+def validate_escape_character_free(value: Any) -> Any:
+    """
+    Function that checks whether a value contains a string part that starts
+    or end with ' or ".
+    the function iterates to break down each complex data-structure to its
+    fundamental string parts.
+    Each value of a list is examined
+    Of dictionaries each value is examined, keys are skipped, as they are ok
+    for Fiware
+
+    Args:
+        value: the string to check
+
+    Returns:
+       validated string
+    """
+
+    if not isinstance(value, List):
+        values = [value]
+    else:
+        values = value
+
+    for value in values:
+        if isinstance(value, Dict):
+            for key, dict_value in value.items():
+                validate_escape_character_free(dict_value)
+                # it seems Fiware has no problem if the keys contain ' or "
+                # validate_escape_character_free(key)
+        elif isinstance(value, List):
+            for inner_list in value:
+                validate_escape_character_free(inner_list)
+        else:
+            # if a value here is not a string, it will also not contain ' or "
+            value = str(value)
+            if '"' == value[-1:] or '"' == value[0:1]:
+                raise ValueError(f"The value {value} contains "
+                                 f"the forbidden char \"")
+            if "'" == value[-1:] or "'" == value[0:1]:
+                raise ValueError(f"The value {value} contains "
+                                 f"the forbidden char '")
+    return values
+
+
+def match_regex(value: str, pattern: str):
+    regex = re.compile(pattern)
+    if not regex.match(value):
+        raise PydanticCustomError(
+            'string_pattern_mismatch',
+            "String should match pattern '{pattern}'",
+            {'pattern': pattern},
+        )
+    return value
+
+
+def ignore_none_input(func):
+    def wrapper(arg):
+        if arg is None:
+            return arg
+        return func(arg)
+    return wrapper
+
+
+def validate_fiware_standard_regex(vale: str):
+    return match_regex(vale, FiwareRegex.standard.value)
+
+
+def validate_fiware_string_protect_regex(vale: str):
+    return match_regex(vale, FiwareRegex.string_protect.value)
+
+
+@ignore_none_input
+def validate_mqtt_topic(topic: str):
+    return match_regex(topic, r'^((?![\'\"#+,])[\x00-\x7F])*$')
+
+
+@ignore_none_input
+def validate_fiware_datatype_standard(_type):
+    from filip.models.base import DataType
+    if isinstance(_type, DataType):
+        return _type
+    elif isinstance(_type, str):
+        return validate_fiware_standard_regex(_type)
+    else:
+        raise TypeError(f"Invalid type {type(_type)}")
+
+
+@ignore_none_input
+def validate_fiware_datatype_string_protect(_type):
+    from filip.models.base import DataType
+    if isinstance(_type, DataType):
+        return _type
+    elif isinstance(_type, str):
+        return validate_fiware_string_protect_regex(_type)
+    else:
+        raise TypeError(f"Invalid type {type(_type)}")
+
+
+@ignore_none_input
+def validate_fiware_service_path(service_path):
+    return match_regex(service_path,
+                       r'^((\/\w*)|(\/\#))*(\,((\/\w*)|(\/\#)))*$')
+
+
+@ignore_none_input
+def validate_fiware_service(service):
+    return match_regex(service,
+                       r"\w*$")
```

### Comparing `filip-0.3.0/filip.egg-info/PKG-INFO` & `filip-0.4.0/filip.egg-info/PKG-INFO`

 * *Files 14% similar despite different names*

```diff
@@ -1,335 +1,340 @@
-Metadata-Version: 2.1
-Name: filip
-Version: 0.3.0
-Summary: [FI]WARE [Li]brary for [P]ython
-Home-page: https://github.com/RWTH-EBC/filip
-Download-URL: https://github.com/RWTH-EBC/FiLiP/archive/refs/tags/v0.3.0.tar.gz
-Author: RWTH Aachen University, E.ON Energy Research Center, Institute        of Energy Efficient Buildings and Indoor Climate
-Author-email: tstorek@eonerc.rwth-aachen.de
-Project-URL: Documentation, https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/docs/index.html
-Project-URL: Source, https://github.com/RWTH-EBC/filip
-Project-URL: Download, https://github.com/RWTH-EBC/FiLiP/archive/refs/tags/v0.3.0.tar.gz
-Keywords: iot,fiware,semantic
-Classifier: Development Status :: 3 - Alpha
-Classifier: Topic :: Scientific/Engineering
-Classifier: Intended Audience :: Science/Research
-Classifier: Programming Language :: Python :: 3.7
-Classifier: Programming Language :: Python :: 3.8
-Classifier: Programming Language :: Python :: 3.9
-Classifier: License :: OSI Approved :: BSD License
-Requires-Python: >=3.7
-Description-Content-Type: text/markdown
-License-File: LICENSE.md
-Requires-Dist: aenum~=3.1.15
-Requires-Dist: datamodel_code_generator[http]~=0.25.0
-Requires-Dist: paho-mqtt~=1.6.1
-Requires-Dist: pandas~=1.3.5
-Requires-Dist: pandas_datapackage_reader~=0.18.0
-Requires-Dist: pydantic~=2.5.2
-Requires-Dist: pydantic-settings~=2.0.0
-Requires-Dist: stringcase>=1.2.0
-Requires-Dist: rdflib~=6.0.0
-Requires-Dist: regex~=2023.10.3
-Requires-Dist: requests~=2.31.0
-Requires-Dist: rapidfuzz~=3.4.0
-Requires-Dist: wget~=3.2
-Provides-Extra: semantics
-Requires-Dist: igraph~=0.9.8; extra == "semantics"
-
-![E.ON EBC RWTH Aachen University](https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/logos/EBC_Logo.png)
-
-# FiLiP
-
-[![pylint](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/pylint/pylint.svg)](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/pylint/pylint.html)
-[![Documentation](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/docs/doc.svg)](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/docs/index.html)
-[![coverage](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/coverage/badge.svg)](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/coverage)
-[![License](https://img.shields.io/badge/License-BSD%203--Clause-blue.svg)](https://opensource.org/licenses/BSD-3-Clause)
-[![build](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/build/build.svg)](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/build/build.svg)
-
-FiLiP (Fiware Library for Python) is a python software development kit (SDK) for 
-accelerating the development of web services that use Fiware's Generic 
-Enablers (GEs) as backend.
-
-It is mainly based on the [Pydantic](https://pydantic-docs.helpmanual.io/) 
-package which is a sophisticated library for data validation and settings 
-management using python type annotations.
-Pydantic enforces type hints at runtime, and provides user friendly errors 
-when data is invalid.
-We mainly use the Pydantic model to build our own data model structure required 
-for efficient data model parsing and validation and interaction with FIWARE 
-services' RestAPIs.
-
-For API interaction, FiLiP relies on the well-known 
-[requests](https://docs.python-requests.org/en/latest/) package. 
-It is important to understand that we do not in any way restrict any 
-features of requests.
-
-Furthermore, FiLiP is designed to help with the fast development of FIWARE-based 
-applications and avoid hundreds of lines of boilerplate, but it cannot 
-substitute learning the basic concepts behind the used FIWARE components.
-
-## General Motivation
-
-Why implement a client library when clients can be auto-generated 
-from openapi documentation? 
-A general prerequisite to do so is that the documentation is in depth and of 
-good quality. 
-While FIWARE generally provides 
-[openapi documentation](https://github.com/FIWARE/specifications),
-here are some thoughts on the challenges of auto-generating client code from 
-these documents:
-
-- Auto-generated code tends to become rather bulky and its quality strongly
-  depends on the provided input data.
-- Manipulating generated code can result in a big hassle for maintenance if 
-  additional features need to be integrated.
-- The underlying NGSI (Next Generation Service Interface) for FIWARE is a
-  rather generic specification.
-  Hence, generated models may also be of generic types as lists
-  and dicts in Python. So there is no real benefit.
-  Furthermore, there is no chance for reasonable validation and error handling.
-
-## Getting started
-
-The following section shortly describes how to use the library.
-
-### Prerequisites
-
-Since FiLiP is designed as a client library, it requires a server that provides 
-the target Service-APIs.
-Hence, if you do not yet have a running instance of a FIWARE based platform, 
-using docker is the most convenient way to set it up. 
-Please check [here](https://github.com/N5GEH/n5geh.platform) for a tutorial 
-on this.
-If this is not an option for you, FIWARE also provides a testing server.
-You can register for a testing account 
-[here](https://www.fiware.org/developers/fiware-lab/).
-> **Note**: FiLiP is now compatible to [Pydantic V2](https://docs.pydantic.dev/latest/migration/). If your program still require Pydantic V1.x for some reason, please use release [v0.2.5](https://github.com/RWTH-EBC/FiLiP/releases/tag/v0.2.5) or earlier version of FiLiP. Besides, we recommended to use `pydantic~=1.10` in the `requirements.txt`
-
-### Installation
-
-The easiest way to install the library is via pip:
-
-````
-pip install -U filip
-````
-
-If you want to benefit from the latest changes, use the following command 
-(This will install the current master branch from this repository):
-
-```
-pip install -U git+git://github.com/RWTH-EBC/filip
-```
-
-#### Install semantics module (optional)
-
-If you want to use the optional [semantics module](filip/semantics), use the following command (This will install the libraries that only required for the semantics module):
-````
-pip install -U filip[semantics]
-````
-
-### Introduction to FIWARE
-
-The following section introduces FIWARE. If you are already familiar with 
-FIWARE, you can skip this section and go straight to [Getting Started](#getting-started).
-
-#### What is FIWARE?
-
-FIWARE is a framework of open-source cloud platform components, created 
-to facilitate the development of smart solutions within various application 
-domains. 
-At the moment, the FIWARE 
-[catalogue](https://www.fiware.org/developers/catalogue/) contains over 30 
-interoperable software modules, so-called Generic Enablers 
-(GE) for developing and providing customized IoT platform solutions.
-
-To get familiar with the APIs of the different modules we highly recommend 
-checking the 
-[step-by-step tutorial](https://fiware-tutorials.readthedocs.io/en/latest/). 
-It provides a good overview on FIWARE and its basic usage.
-Whereas the tutorial helps to understand most of the general concepts, 
-for a deep dive, where you can learn about the components in more detail, 
-FIWARE also offers extended lessons through their 
-[academy](https://fiware-academy.readthedocs.io/en/latest/index.html/).
-
-However, usually one only requires a small set of components. 
-Hence, we recommend using the cited pages only as needed.
-
-#### How to set up a FIWARE platform?
-
-The easiest way to set up a FIWARE platform is by using docker as all GEs are 
-open-source and distributed as docker containers on dockerhub.
-
-However, as mentioned before, for most use cases only a subset of GEs is required.
-Hence, we wrote a small [tutorial](https://github.com/N5GEH/n5geh.platform) 
-explaining how to set up a platform suited for most use cases within the energy 
-domain. 
-
-#### FIWARE GEs covered by FiLiP
-
-FiLiP is a library developed on demand.
-Hence, we do not aim to cover the APIs of all GEs that are included in the 
-[catalogue](https://www.fiware.org/developers/catalogue/). 
-This would mean an unnecessary development overhead. 
-Therefore, FiLiP currently only covers the APIs of the following GEs:
-
-- NGSIv2 Context Broker for managing context data. We use its 
-  reference implementation ORION for testing.
-    - [documentation](https://fiware-orion.readthedocs.io/en/master/)
-    - [github](https://github.com/telefonicaid/fiware-orion)
-    - [swagger](https://swagger.lab.fiware.org/)
-    - [NGSI v2 specifications](https://github.com/FIWARE/specifications/tree/master/OpenAPI/ngsiv2)
-    
-    
-- IoT-Agents for managing IoT Devices. IoT agents are implemented using 
-  the FIWARE IoT Agent Node Lib as a common framework.
-    - [documentation](https://iotagent-node-lib.readthedocs.io/en/latest/)
-    - [github](https://github.com/telefonicaid/iotagent-node-lib)
-
-    
-- IoT-Agent-JSON for managing devices using a JSON message payload protocol 
-  format.  
-    - [documentation](https://fiware-iotagent-json.readthedocs.io/en/latest/)
-    - [github](https://github.com/telefonicaid/iotagent-json)
-    - [apiary](https://telefonicaiotiotagents.docs.apiary.io/) 
-    (*partly deprecated*)
-
-  Example payload:
-  
-        {
-            "humidity": "45%",
-            "temperature": "23",
-            "luminosity": "1570"
-        }  
-
-- IoT-Agent-Ultralight for managing devices using an Ultralight 2.0 message 
-  payload protocol.
-  
-    - [documentation](https://fiware-iotagent-ul.readthedocs.io/en/latest/)
-    - [github](https://github.com/telefonicaid/iotagent-ul)
-    - [apiary](https://telefonicaiotiotagents.docs.apiary.io/) 
-      (*partly deprecated*)
-    
-    Example payload:
-  
-        humidity|45%|temperature|23|luminosity|1570
-        
-- QuantumLeap for the management of time series data
-  
-    - [documentation](https://quantumleap.readthedocs.io/en/latest/)
-    - [github](https://github.com/FIWARE-GEs/quantum-leap)
-    - [swagger](https://app.swaggerhub.com/apis/smartsdk/ngsi-tsdb/0.8.3)
-
-## Structure of FiLiP
-
-![Library Structure](https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/diagrams/out/architecture.png)
-
-
-## Documentation
-
-We are still working on the documentation.
-You can find our current documentation 
-[here](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/docs/index.html).
-
-## Running examples
-
-Once you have installed the library, you can check the [examples](/examples)
-to learn how to use the different components. 
-
-Currently, we provide basic examples for the usage of FiLiP for the FIWARE 
-GEs mentioned above.
-We suggest to start in the right order to first understand the 
-configuration of clients.
-Afterwards, you can start modelling context data and interacting with the context 
-broker and use its functionalities before you learn how to connect 
-IoT Devices and store historic data.
-
-## Testing
-
-We use unittests to write our test cases.
-To test the source code of the library in our CI workflow, the CI 
-executes all tests located in the `tests`-directory and prefixed with `test_` .
-
-## How to contribute
-
-Please see our [contribution guide](./CONTRIBUTING.md) for more details on 
-how you can contribute to this project.
-
-## Authors
-
-* [Thomas Storek](https://www.ebc.eonerc.rwth-aachen.de/cms/E-ON-ERC-EBC/Das-Institut/Mitarbeiter/Team2/~lhda/Thomas-Storek/?lidx=1) 
-* [Junsong Du](https://www.ebc.eonerc.rwth-aachen.de/cms/E-ON-ERC-EBC/Das-Institut/Mitarbeiter/Digitale-Energie-Quartiere/~trcib/Du-Junsong/lidx/1/) (corresponding)
-* [Saira Bano](https://www.ebc.eonerc.rwth-aachen.de/cms/E-ON-ERC-EBC/Das-Institut/Mitarbeiter/Systemadministration/~ohhca/Bano-Saira/)
-
-## Alumni
-
-* Jeff Reding
-* Felix Rehmann
-* Daniel Nikolay
-
-## References
-
-We presented or applied the library in the following publications:
-
-- Haghgoo, M., Dognini, A., Storek, T., Plamanescu, R, Rahe, U., 
-  Gheorghe, S, Albu, M., Monti, A., MÃ¼ller, D. (2021) A cloud-based service-oriented architecture to unlock smart energy services
-  https://www.doi.org/10.1186/s42162-021-00143-x
-
-- Baranski, M., Storek, T. P. B., KÃ¼mpel, A., Blechmann, S., Streblow, R., 
-MÃ¼ller, D. et al.,
-(2020). National 5G Energy Hub : Application of the Open-Source Cloud Platform 
-FIWARE for Future Energy Management Systems. 
-https://doi.org/10.18154/RWTH-2020-07876
-
-- T. Storek, J. LohmÃ¶ller, A. KÃ¼mpel, M. Baranski & D. MÃ¼ller (2019). 
-Application of the open-source cloud platform FIWARE for future building 
-energy management systems. 
-Journal of Physics: 
-Conference Series, 1343, 12063. https://doi.org/10.1088/1742-6596/1343/1/012063
-
-## License
-
-This project is licensed under the BSD License - see the [LICENSE](LICENSE) file for details.
-
-## Copyright
-
-<a href="https://www.ebc.eonerc.rwth-aachen.de/"> <img alt="EBC" src="https://www.ebc.eonerc.rwth-aachen.de/global/show_picture.asp?id=aaaaaaaaaakevlz" height="100"> </a>
-
-2021-2022, RWTH Aachen University, E.ON Energy Research Center, Institute for Energy 
-Efficient Buildings and Indoor Climate
-
-[Institute for Energy Efficient Buildings and Indoor Climate (EBC)](https://www.ebc.eonerc.rwth-aachen.de)  
-[E.ON Energy Research Center (E.ON ERC)](https://www.eonerc.rwth-aachen.de)  
-[RWTH University Aachen, Germany](https://www.rwth-aachen.de)
-
-## Disclaimer
-
-This project is part of the cooperation between the RWTH Aachen University and 
-the Research Centre JÃ¼lich.
-
-<a href="https://www.jara.org/de/forschung/jara-energy"> <img alt="JARA 
-ENERGY" src="https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/logos/LogoJARAEnergy.jpg" height="100"> </a>
-
-## Related projects
-
-<a href="https://n5geh.de/"> <img alt="National 5G Energy Hub" 
-src="https://avatars.githubusercontent.com/u/43948851?s=200&v=4" height="100"></a>
-
-<a href="https://fismep.de/"> <img alt="FISMEP" 
-src="https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/logos/FISMEP.png" 
-height="100"></a>
-
-
-## Acknowledgments
-
-We gratefully acknowledge the financial support of the Federal Ministry <br /> 
-for Economic Affairs and Climate Action (BMWK), promotional references 
-03ET1495A, 03ET1551A, 0350018A, 03ET1561B.
-
-<a href="https://www.bmwi.de/Navigation/EN/Home/home.html"> <img alt="BMWK" 
-src="https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/logos/bmwi_logo_en.png" height="100"> </a>
-
-This project has received funding in the framework of the joint programming initiative ERA-Net Smart Grids Plus, with support from the European Unionâ€™s Horizon 2020 research and innovation programme.
-
-<a href="https://www.eranet-smartgridsplus.eu/"> <img alt="ERANET" 
-src="https://fismep.de/wp-content/uploads/2017/09/SmartGridsPlus_rgb-300x55.jpg" height="100"> </a>
+Metadata-Version: 2.1
+Name: filip
+Version: 0.4.0
+Summary: [FI]WARE [Li]brary for [P]ython
+Home-page: https://github.com/RWTH-EBC/filip
+Download-URL: https://github.com/RWTH-EBC/FiLiP/archive/refs/tags/v0.4.0.tar.gz
+Author: RWTH Aachen University, E.ON Energy Research Center, Institute        of Energy Efficient Buildings and Indoor Climate
+Author-email: tstorek@eonerc.rwth-aachen.de
+Project-URL: Documentation, https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/docs/index.html
+Project-URL: Source, https://github.com/RWTH-EBC/filip
+Project-URL: Download, https://github.com/RWTH-EBC/FiLiP/archive/refs/tags/v0.4.0.tar.gz
+Keywords: iot,fiware,semantic
+Classifier: Development Status :: 3 - Alpha
+Classifier: Topic :: Scientific/Engineering
+Classifier: Intended Audience :: Science/Research
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3.9
+Classifier: Programming Language :: Python :: 3.10
+Classifier: Programming Language :: Python :: 3.11
+Classifier: License :: OSI Approved :: BSD License
+Requires-Python: >=3.8
+Description-Content-Type: text/markdown
+License-File: LICENSE.md
+Requires-Dist: aenum~=3.1.15
+Requires-Dist: datamodel_code_generator[http]~=0.25.0
+Requires-Dist: paho-mqtt~=1.6.1
+Requires-Dist: pandas_datapackage_reader~=0.18.0
+Requires-Dist: pydantic~=2.5.2
+Requires-Dist: pydantic-settings~=2.0.0
+Requires-Dist: stringcase>=1.2.0
+Requires-Dist: rdflib~=6.0.0
+Requires-Dist: regex~=2023.10.3
+Requires-Dist: requests~=2.31.0
+Requires-Dist: rapidfuzz~=3.4.0
+Requires-Dist: wget~=3.2
+Provides-Extra: semantics
+Requires-Dist: igraph~=0.11.2; extra == "semantics"
+Requires-Dist: pandas~=1.3.5; python_version < "3.9"
+Requires-Dist: pandas~=2.1.4; python_version >= "3.9"
+
+![E.ON EBC RWTH Aachen University](https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/logos/EBC_Logo.png)
+
+# FiLiP
+
+[![pylint](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/pylint/pylint.svg)](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/pylint/pylint.html)
+[![Documentation](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/docs/doc.svg)](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/docs/index.html)
+[![coverage](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/coverage/badge.svg)](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/coverage)
+[![License](https://img.shields.io/badge/License-BSD%203--Clause-blue.svg)](https://opensource.org/licenses/BSD-3-Clause)
+[![build](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/build/build.svg)](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/build/build.svg)
+
+FiLiP (Fiware Library for Python) is a python software development kit (SDK) for 
+accelerating the development of web services that use Fiware's Generic 
+Enablers (GEs) as backend.
+
+It is mainly based on the [Pydantic](https://pydantic-docs.helpmanual.io/) 
+package which is a sophisticated library for data validation and settings 
+management using python type annotations.
+Pydantic enforces type hints at runtime, and provides user friendly errors 
+when data is invalid.
+We mainly use the Pydantic model to build our own data model structure required 
+for efficient data model parsing and validation and interaction with FIWARE 
+services' RestAPIs. 
+
+For API interaction, FiLiP relies on the well-known 
+[requests](https://docs.python-requests.org/en/latest/) package. 
+It is important to understand that we do not in any way restrict any 
+features of requests.
+
+Furthermore, FiLiP is designed to help with the fast development of FIWARE-based 
+applications and avoid hundreds of lines of boilerplate, but it cannot 
+substitute learning the basic concepts behind the used FIWARE components.
+
+## General Motivation
+
+Why implement a client library when clients can be auto-generated 
+from openapi documentation? 
+A general prerequisite to do so is that the documentation is in depth and of 
+good quality. 
+While FIWARE generally provides 
+[openapi documentation](https://github.com/FIWARE/specifications),
+here are some thoughts on the challenges of auto-generating client code from 
+these documents:
+
+- Auto-generated code tends to become rather bulky and its quality strongly
+  depends on the provided input data.
+- Manipulating generated code can result in a big hassle for maintenance if 
+  additional features need to be integrated.
+- The underlying NGSI (Next Generation Service Interface) for FIWARE is a
+  rather generic specification.
+  Hence, generated models may also be of generic types as lists
+  and dicts in Python. So there is no real benefit.
+  Furthermore, there is no chance for reasonable validation and error handling.
+
+## Getting started
+
+The following section shortly describes how to use the library.
+
+### Prerequisites
+
+Since FiLiP is designed as a client library, it requires a server that provides 
+the target Service-APIs.
+Hence, if you do not yet have a running instance of a FIWARE based platform, 
+using docker is the most convenient way to set it up. 
+Please check [here](https://github.com/N5GEH/n5geh.platform) for a tutorial 
+on this.
+If this is not an option for you, FIWARE also provides a testing server.
+You can register for a testing account 
+[here](https://www.fiware.org/developers/fiware-lab/).
+> **Note**: FiLiP is now compatible to [Pydantic V2](https://docs.pydantic.dev/latest/migration/). If your program still require Pydantic V1.x for some reason, please use release [v0.2.5](https://github.com/RWTH-EBC/FiLiP/releases/tag/v0.2.5) or earlier version of FiLiP. Besides, we recommended to use `pydantic~=1.10` in the `requirements.txt`
+
+### Installation
+
+The easiest way to install the library is via pip:
+
+````
+pip install -U filip
+````
+
+If you want to benefit from the latest changes, use the following command 
+(This will install the current master branch from this repository):
+
+```
+pip install -U git+git://github.com/RWTH-EBC/filip
+```
+
+#### Install semantics module (optional)
+
+If you want to use the optional [semantics module](filip/semantics), use the following command (This will install the libraries that only required for the semantics module):
+````
+pip install -U filip[semantics]
+````
+
+### Introduction to FIWARE
+
+The following section introduces FIWARE. If you are already familiar with 
+FIWARE, you can skip this section and go straight to [Getting Started](#getting-started).
+
+#### What is FIWARE?
+
+FIWARE is a framework of open-source cloud platform components, created 
+to facilitate the development of smart solutions within various application 
+domains. 
+At the moment, the FIWARE 
+[catalogue](https://www.fiware.org/developers/catalogue/) contains over 30 
+interoperable software modules, so-called Generic Enablers 
+(GE) for developing and providing customized IoT platform solutions.
+
+To get familiar with the APIs of the different modules we highly recommend 
+checking the 
+[step-by-step tutorial](https://fiware-tutorials.readthedocs.io/en/latest/). 
+It provides a good overview on FIWARE and its basic usage.
+Whereas the tutorial helps to understand most of the general concepts, 
+for a deep dive, where you can learn about the components in more detail, 
+FIWARE also offers extended lessons through their 
+[academy](https://fiware-academy.readthedocs.io/en/latest/index.html/).
+
+However, usually one only requires a small set of components. 
+Hence, we recommend using the cited pages only as needed.
+
+#### How to set up a FIWARE platform?
+
+The easiest way to set up a FIWARE platform is by using docker as all GEs are 
+open-source and distributed as docker containers on dockerhub.
+
+However, as mentioned before, for most use cases only a subset of GEs is required.
+Hence, we wrote a small [tutorial](https://github.com/N5GEH/n5geh.platform) 
+explaining how to set up a platform suited for most use cases within the energy 
+domain. 
+
+#### FIWARE GEs covered by FiLiP
+
+FiLiP is a library developed on demand.
+Hence, we do not aim to cover the APIs of all GEs that are included in the 
+[catalogue](https://www.fiware.org/developers/catalogue/). 
+This would mean an unnecessary development overhead. 
+Therefore, FiLiP currently only covers the APIs of the following GEs:
+
+- NGSIv2 Context Broker for managing context data. We use its 
+  reference implementation ORION for testing.
+    - [documentation](https://fiware-orion.readthedocs.io/en/master/)
+    - [github](https://github.com/telefonicaid/fiware-orion)
+    - [swagger](https://swagger.lab.fiware.org/)
+    - [NGSI v2 specifications](https://github.com/FIWARE/specifications/tree/master/OpenAPI/ngsiv2)
+    
+    
+- IoT-Agents for managing IoT Devices. IoT agents are implemented using 
+  the FIWARE IoT Agent Node Lib as a common framework.
+    - [documentation](https://iotagent-node-lib.readthedocs.io/en/latest/)
+    - [github](https://github.com/telefonicaid/iotagent-node-lib)
+
+    
+- IoT-Agent-JSON for managing devices using a JSON message payload protocol 
+  format.  
+    - [documentation](https://fiware-iotagent-json.readthedocs.io/en/latest/)
+    - [github](https://github.com/telefonicaid/iotagent-json)
+    - [apiary](https://telefonicaiotiotagents.docs.apiary.io/) 
+    (*partly deprecated*)
+
+  Example payload:
+  
+        {
+            "humidity": "45%",
+            "temperature": "23",
+            "luminosity": "1570"
+        }  
+
+- IoT-Agent-Ultralight for managing devices using an Ultralight 2.0 message 
+  payload protocol.
+  
+    - [documentation](https://fiware-iotagent-ul.readthedocs.io/en/latest/)
+    - [github](https://github.com/telefonicaid/iotagent-ul)
+    - [apiary](https://telefonicaiotiotagents.docs.apiary.io/) 
+      (*partly deprecated*)
+    
+    Example payload:
+  
+        humidity|45%|temperature|23|luminosity|1570
+        
+- QuantumLeap for the management of time series data
+  
+    - [documentation](https://quantumleap.readthedocs.io/en/latest/)
+    - [github](https://github.com/FIWARE-GEs/quantum-leap)
+    - [swagger](https://app.swaggerhub.com/apis/smartsdk/ngsi-tsdb/0.8.3)
+
+## Structure of FiLiP
+
+![Library Structure](https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/diagrams/out/architecture.png)
+
+
+## Documentation
+
+We are still working on the documentation.
+You can find our current documentation 
+[here](https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/docs/index.html).
+
+## Running examples
+
+Once you have installed the library, you can check the [examples](/examples)
+to learn how to use the different components. 
+
+Currently, we provide basic examples for the usage of FiLiP for the FIWARE 
+GEs mentioned above.
+We suggest to start in the right order to first understand the 
+configuration of clients.
+Afterwards, you can start modelling context data and interacting with the context 
+broker and use its functionalities before you learn how to connect 
+IoT Devices and store historic data.
+
+## Testing
+
+We use unittests to write our test cases.
+To test the source code of the library in our CI workflow, the CI 
+executes all tests located in the `tests`-directory and prefixed with `test_` .
+
+## How to contribute
+
+Please see our [contribution guide](./CONTRIBUTING.md) for more details on 
+how you can contribute to this project.
+
+## Authors
+
+* [Thomas Storek](https://github.com/tstorek) 
+* [Junsong Du](https://www.ebc.eonerc.rwth-aachen.de/cms/E-ON-ERC-EBC/Das-Institut/Mitarbeiter/Digitale-Energie-Quartiere/~trcib/Du-Junsong/lidx/1/) (corresponding)
+* [Saira Bano](https://www.ebc.eonerc.rwth-aachen.de/cms/E-ON-ERC-EBC/Das-Institut/Mitarbeiter/Systemadministration/~ohhca/Bano-Saira/)
+* [Sebastian Blechmann](https://www.ebc.eonerc.rwth-aachen.de/cms/E-ON-ERC-EBC/Das-Institut/Mitarbeiter/Team2/~carjd/Blechmann-Sebastian/)
+
+## Alumni
+
+* Jeff Reding
+* Felix Rehmann
+* Daniel Nikolay
+
+## References
+
+We presented or applied the library in the following publications:
+
+- S. Blechmann, I. Sowa, M. H. Schraven, R. Streblow, D. Müller & A. Monti. Open source platform application for smart building and smart grid controls. Automation in Construction 145 (2023), 104622. ISSN: 0926-5805. https://doi.org/10.1016/j.autcon.2022.104622        
+
+- Haghgoo, M., Dognini, A., Storek, T., Plamanescu, R, Rahe, U., 
+  Gheorghe, S, Albu, M., Monti, A., Müller, D. (2021) A cloud-based service-oriented architecture to unlock smart energy services
+  https://www.doi.org/10.1186/s42162-021-00143-x      
+
+- Baranski, M., Storek, T. P. B., Kümpel, A., Blechmann, S., Streblow, R., 
+Müller, D. et al.,
+(2020). National 5G Energy Hub : Application of the Open-Source Cloud Platform 
+FIWARE for Future Energy Management Systems. 
+https://doi.org/10.18154/RWTH-2020-07876      
+
+- T. Storek, J. Lohmöller, A. Kümpel, M. Baranski & D. Müller (2019). 
+Application of the open-source cloud platform FIWARE for future building 
+energy management systems. 
+Journal of Physics: 
+Conference Series, 1343, 12063. https://doi.org/10.1088/1742-6596/1343/1/012063     
+
+## License
+
+This project is licensed under the BSD License - see the [LICENSE](LICENSE) file for details.
+
+## Copyright
+
+<a href="https://www.ebc.eonerc.rwth-aachen.de/"> <img alt="EBC" src="https://www.ebc.eonerc.rwth-aachen.de/global/show_picture.asp?id=aaaaaaaaaakevlz" height="100"> </a>
+
+2021-2024, RWTH Aachen University, E.ON Energy Research Center, Institute for Energy 
+Efficient Buildings and Indoor Climate
+
+[Institute for Energy Efficient Buildings and Indoor Climate (EBC)](https://www.ebc.eonerc.rwth-aachen.de)  
+[E.ON Energy Research Center (E.ON ERC)](https://www.eonerc.rwth-aachen.de)  
+[RWTH University Aachen, Germany](https://www.rwth-aachen.de)
+
+## Disclaimer
+
+This project is part of the cooperation between the RWTH Aachen University and 
+the Research Centre Jülich.
+
+<a href="https://www.jara.org/de/forschung/jara-energy"> <img alt="JARA 
+ENERGY" src="https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/logos/LogoJARAEnergy.jpg" height="100"> </a>
+
+## Related projects
+
+<a href="https://n5geh.de/"> <img alt="National 5G Energy Hub" 
+src="https://avatars.githubusercontent.com/u/43948851?s=200&v=4" height="100"></a>
+
+<a href="https://fismep.de/"> <img alt="FISMEP" 
+src="https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/logos/FISMEP.png" 
+height="100"></a>
+
+
+## Acknowledgments
+
+We gratefully acknowledge the financial support of the Federal Ministry <br /> 
+for Economic Affairs and Climate Action (BMWK), promotional references 
+03ET1495A, 03ET1551A, 0350018A, 03ET1561B.
+
+<a href="https://www.bmwi.de/Navigation/EN/Home/home.html"> <img alt="BMWK" 
+src="https://raw.githubusercontent.com/RWTH-EBC/FiLiP/master/docs/logos/bmwi_logo_en.png" height="100"> </a>
+
+This project has received funding in the framework of the joint programming initiative ERA-Net Smart Grids Plus, with support from the European Union’s Horizon 2020 research and innovation programme.
+
+<a href="https://www.eranet-smartgridsplus.eu/"> <img alt="ERANET" 
+src="https://fismep.de/wp-content/uploads/2017/09/SmartGridsPlus_rgb-300x55.jpg" height="100"> </a>
```

### Comparing `filip-0.3.0/filip.egg-info/SOURCES.txt` & `filip-0.4.0/filip.egg-info/SOURCES.txt`

 * *Files identical despite different names*

### Comparing `filip-0.3.0/setup.py` & `filip-0.4.0/setup.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,70 +1,72 @@
-"""Setup.py script for the FiLiP-Library"""
-
-import setuptools
-
-# read the contents of your README file
-from pathlib import Path
-readme_path = Path(__file__).parent.joinpath("README.md")
-LONG_DESCRIPTION = readme_path.read_text()
-
-INSTALL_REQUIRES = ['aenum~=3.1.15',
-                    'datamodel_code_generator[http]~=0.25.0',
-                    'paho-mqtt~=1.6.1',
-                    'pandas~=1.3.5',
-                    'pandas_datapackage_reader~=0.18.0',
-                    'pydantic~=2.5.2',
-                    'pydantic-settings~=2.0.0',
-                    'stringcase>=1.2.0',
-                    'rdflib~=6.0.0',
-                    'regex~=2023.10.3',
-                    'requests~=2.31.0',
-                    'rapidfuzz~=3.4.0',
-                    'wget~=3.2']
-
-SETUP_REQUIRES = INSTALL_REQUIRES.copy()
-
-VERSION = '0.3.0'
-
-setuptools.setup(
-    name='filip',
-    version=VERSION,
-    author='RWTH Aachen University, E.ON Energy Research Center, Institute\
-        of Energy Efficient Buildings and Indoor Climate',
-    author_email='tstorek@eonerc.rwth-aachen.de',
-    description='[FI]WARE [Li]brary for [P]ython',
-    long_description=LONG_DESCRIPTION,
-    long_description_content_type="text/markdown",
-    url="https://github.com/RWTH-EBC/filip",
-    download_url=f"https://github.com/RWTH-EBC/FiLiP/archive/refs/tags/v{VERSION}.tar.gz",
-    project_urls={
-        "Documentation":
-            "https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/docs/index.html",
-        "Source":
-            "https://github.com/RWTH-EBC/filip",
-        "Download":
-            f"https://github.com/RWTH-EBC/FiLiP/archive/refs/tags/v{VERSION}.tar.gz"},
-    # Specify the Python versions you support here. In particular, ensure
-    # that you indicate whether you support Python 2, Python 3 or both.
-    classifiers=['Development Status :: 3 - Alpha',
-                 'Topic :: Scientific/Engineering',
-                 'Intended Audience :: Science/Research',
-                 'Programming Language :: Python :: 3.7',
-                 'Programming Language :: Python :: 3.8',
-                 'Programming Language :: Python :: 3.9',
-                 "License :: OSI Approved :: BSD License"],
-    keywords=['iot', 'fiware', 'semantic'],
-    packages=setuptools.find_packages(exclude=['tests',
-                                               'tests.*',
-                                               'img',
-                                               'tutorials.*',
-                                               'tutorials']),
-    package_data={'filip': ['data/unece-units/*.csv']},
-    setup_requires=SETUP_REQUIRES,
-    # optional modules
-    extras_require={
-        "semantics": ["igraph~=0.9.8"]
-    },
-    install_requires=INSTALL_REQUIRES,
-    python_requires=">=3.7",
-
-)
+"""Setup.py script for the FiLiP-Library"""
+
+import setuptools
+
+# read the contents of your README file
+from pathlib import Path
+readme_path = Path(__file__).parent.joinpath("README.md")
+LONG_DESCRIPTION = readme_path.read_text()
+
+INSTALL_REQUIRES = ['aenum~=3.1.15',
+                    'datamodel_code_generator[http]~=0.25.0',
+                    'paho-mqtt~=1.6.1',
+                    'pandas_datapackage_reader~=0.18.0',
+                    'pydantic~=2.5.2',
+                    'pydantic-settings~=2.0.0',
+                    'stringcase>=1.2.0',
+                    'rdflib~=6.0.0',
+                    'regex~=2023.10.3',
+                    'requests~=2.31.0',
+                    'rapidfuzz~=3.4.0',
+                    'wget~=3.2']
+
+SETUP_REQUIRES = INSTALL_REQUIRES.copy()
+
+VERSION = '0.4.0'
+
+setuptools.setup(
+    name='filip',
+    version=VERSION,
+    author='RWTH Aachen University, E.ON Energy Research Center, Institute\
+        of Energy Efficient Buildings and Indoor Climate',
+    author_email='tstorek@eonerc.rwth-aachen.de',
+    description='[FI]WARE [Li]brary for [P]ython',
+    long_description=LONG_DESCRIPTION,
+    long_description_content_type="text/markdown",
+    url="https://github.com/RWTH-EBC/filip",
+    download_url=f"https://github.com/RWTH-EBC/FiLiP/archive/refs/tags/v{VERSION}.tar.gz",
+    project_urls={
+        "Documentation":
+            "https://ebc.pages.rwth-aachen.de/EBC_all/github_ci/FiLiP/master/docs/index.html",
+        "Source":
+            "https://github.com/RWTH-EBC/filip",
+        "Download":
+            f"https://github.com/RWTH-EBC/FiLiP/archive/refs/tags/v{VERSION}.tar.gz"},
+    # Specify the Python versions you support here. In particular, ensure
+    # that you indicate whether you support Python 2, Python 3 or both.
+    classifiers=['Development Status :: 3 - Alpha',
+                 'Topic :: Scientific/Engineering',
+                 'Intended Audience :: Science/Research',
+                 'Programming Language :: Python :: 3.8',
+                 'Programming Language :: Python :: 3.9',
+                 'Programming Language :: Python :: 3.10',
+                 'Programming Language :: Python :: 3.11',
+                 "License :: OSI Approved :: BSD License"],
+    keywords=['iot', 'fiware', 'semantic'],
+    packages=setuptools.find_packages(exclude=['tests',
+                                               'tests.*',
+                                               'img',
+                                               'tutorials.*',
+                                               'tutorials']),
+    package_data={'filip': ['data/unece-units/*.csv']},
+    setup_requires=SETUP_REQUIRES,
+    # optional modules
+    extras_require={
+        "semantics": ["igraph~=0.11.2"],
+        ":python_version < '3.9'": ["pandas~=1.3.5"],
+        ":python_version >= '3.9'": ["pandas~=2.1.4"]
+    },
+    install_requires=INSTALL_REQUIRES,
+    python_requires=">=3.8",
+
+)
```

### Comparing `filip-0.3.0/tests/test_config.py` & `filip-0.4.0/tests/test_config.py`

 * *Ordering differences only*

 * *Files 15% similar despite different names*

```diff
@@ -1,51 +1,51 @@
-"""
-Test module for configuration functions
-"""
-import os
-import unittest
-from filip.config import Settings
-import json
-from pydantic import AnyHttpUrl
-
-
-class TestSettings(unittest.TestCase):
-    """
-    Test case for loading settings
-    """
-    def setUp(self) -> None:
-
-        # Test if the testcase was run directly or over in a global test-run.
-        # Match the needed path to the config file in both cases
-        if os.getcwd().split("\\")[-1] == "tests":
-            self.settings_parsing = Settings(_env_file='test_config.env')
-        else:
-            self.settings_parsing = \
-                Settings(_env_file='./tests/test_config.env')
-
-        for key, value in json.loads(self.settings_parsing.model_dump_json()).items():
-            os.environ[key] = value
-        self.settings_dotenv = Settings()
-
-    def test_load_dotenv(self):
-        """
-        Tests loading form dotenv file
-
-        Returns:
-            None
-        """
-        self.assertEqual(str(self.settings_parsing.IOTA_URL), str(AnyHttpUrl("http://myHost:4041/")))
-        self.assertEqual(str(self.settings_parsing.CB_URL), str(AnyHttpUrl("http://myHost:1026/")))
-        self.assertEqual(str(self.settings_parsing.QL_URL), str(AnyHttpUrl("http://myHost:8668/")))
-
-    def test_example_dotenv(self):
-        """
-        Tests to parse settings
-
-        Returns:
-            None
-        """
-        self.assertEqual(self.settings_parsing, self.settings_dotenv)
-
-    def tearDown(self) -> None:
-        for k in self.settings_parsing.model_dump().keys():
-            del os.environ[k]
+"""
+Test module for configuration functions
+"""
+import os
+import unittest
+from filip.config import Settings
+import json
+from pydantic import AnyHttpUrl
+
+
+class TestSettings(unittest.TestCase):
+    """
+    Test case for loading settings
+    """
+    def setUp(self) -> None:
+
+        # Test if the testcase was run directly or over in a global test-run.
+        # Match the needed path to the config file in both cases
+        if os.getcwd().split("\\")[-1] == "tests":
+            self.settings_parsing = Settings(_env_file='test_config.env')
+        else:
+            self.settings_parsing = \
+                Settings(_env_file='./tests/test_config.env')
+
+        for key, value in json.loads(self.settings_parsing.model_dump_json()).items():
+            os.environ[key] = value
+        self.settings_dotenv = Settings()
+
+    def test_load_dotenv(self):
+        """
+        Tests loading form dotenv file
+
+        Returns:
+            None
+        """
+        self.assertEqual(str(self.settings_parsing.IOTA_URL), str(AnyHttpUrl("http://myHost:4041/")))
+        self.assertEqual(str(self.settings_parsing.CB_URL), str(AnyHttpUrl("http://myHost:1026/")))
+        self.assertEqual(str(self.settings_parsing.QL_URL), str(AnyHttpUrl("http://myHost:8668/")))
+
+    def test_example_dotenv(self):
+        """
+        Tests to parse settings
+
+        Returns:
+            None
+        """
+        self.assertEqual(self.settings_parsing, self.settings_dotenv)
+
+    def tearDown(self) -> None:
+        for k in self.settings_parsing.model_dump().keys():
+            del os.environ[k]
```

### Comparing `filip-0.3.0/tests/test_logging.py` & `filip-0.4.0/tests/test_logging.py`

 * *Ordering differences only*

 * *Files 20% similar despite different names*

```diff
@@ -1,77 +1,77 @@
-"""
-Test module for logging functionality
-"""
-import logging
-from unittest import TestCase
-
-
-class TestLoggingConfig(TestCase):
-    """
-    Test case for logging functionality
-    """
-    def setUp(self) -> None:
-        self.logger = logging.getLogger(
-            name=f"{__package__}.{self.__class__.__name__}")
-
-    def test_overwrite_config(self):
-        """
-        Tests to overwrite the logger configurations
-
-        Returns:
-            None
-        """
-
-        # Try to set logging level before calling logging.basisConfig()
-        # Since no handler is configured this will fail
-        self.logger = logging.getLogger(
-            name=f"{__package__}.{self.__class__.__name__}")
-        self.logger.warning("Trying to set log_level to '%s' via settings "
-                            "before calling basicConfig. This will fail "
-                            "because no handler is added to the logger",
-                            logging.DEBUG)
-        self.logger.setLevel(level=logging.DEBUG)
-        # The next line will not show up!
-        self.logger.info("Current LOG_LEVEL is '%s'", self.logger.level)
-
-        # Try to set logging level before calling logging.basisConfig()
-        # but adding a handler before.
-        self.logger.handlers.clear()
-        handler = logging.StreamHandler()
-        formatter = logging.Formatter(fmt='Custom Logging Stream %(asctime)s - '
-                                          '%(name)s - '
-                                          '%(levelname)s : %(message)s')
-        handler.setFormatter(formatter)
-        self.logger.info("Set LOG_LEVEL to '%s' via settings and adding a "
-                         "handler before. ",
-                         logging.DEBUG)
-        self.logger.addHandler(handler)
-        self.logger.setLevel(level=logging.DEBUG)
-        self.logger.info("Current LOG_LEVEL has changed to '%s'",
-                         self.logger.level)
-        # The next line will not show up!
-        self.logger.debug("Current LOG_LEVEL is '%s'", self.logger.level)
-
-        # Try to set loglevel via basicConfig
-        new_loglevel = logging.WARNING
-        self.logger.info("Set LOG_LEVEL to '%s' via basicConfig", new_loglevel)
-        # logging.basicConfig(level=new_loglevel,
-        #                    format='%(asctime)s : %(name)s : %(levelname)s : '
-        #                           '%(message)s')
-        logger = logging.getLogger()
-        handler = logging.StreamHandler()
-        formatter = logging.Formatter(fmt='Root Stream %(asctime)s - '
-                                          '%(name)s - '
-                                          '%(levelname)s : %(message)s')
-        handler.setFormatter(formatter)
-        logger.addHandler(handler)
-        logger.setLevel('DEBUG')
-        logger.debug('Initialize root logger')
-        # This message will show up twice because now a handler is configured
-        # in the root logger and all messages will be forwarded
-        # but it does because the
-        # loggers are detached and we need to delete the handler first
-        self.logger.info("Current LOG_LEVEL '%s' (this will appear twice)",
-                         self.logger.level)
-
-    def tearDown(self) -> None:
-        pass
+"""
+Test module for logging functionality
+"""
+import logging
+from unittest import TestCase
+
+
+class TestLoggingConfig(TestCase):
+    """
+    Test case for logging functionality
+    """
+    def setUp(self) -> None:
+        self.logger = logging.getLogger(
+            name=f"{__package__}.{self.__class__.__name__}")
+
+    def test_overwrite_config(self):
+        """
+        Tests to overwrite the logger configurations
+
+        Returns:
+            None
+        """
+
+        # Try to set logging level before calling logging.basisConfig()
+        # Since no handler is configured this will fail
+        self.logger = logging.getLogger(
+            name=f"{__package__}.{self.__class__.__name__}")
+        self.logger.warning("Trying to set log_level to '%s' via settings "
+                            "before calling basicConfig. This will fail "
+                            "because no handler is added to the logger",
+                            logging.DEBUG)
+        self.logger.setLevel(level=logging.DEBUG)
+        # The next line will not show up!
+        self.logger.info("Current LOG_LEVEL is '%s'", self.logger.level)
+
+        # Try to set logging level before calling logging.basisConfig()
+        # but adding a handler before.
+        self.logger.handlers.clear()
+        handler = logging.StreamHandler()
+        formatter = logging.Formatter(fmt='Custom Logging Stream %(asctime)s - '
+                                          '%(name)s - '
+                                          '%(levelname)s : %(message)s')
+        handler.setFormatter(formatter)
+        self.logger.info("Set LOG_LEVEL to '%s' via settings and adding a "
+                         "handler before. ",
+                         logging.DEBUG)
+        self.logger.addHandler(handler)
+        self.logger.setLevel(level=logging.DEBUG)
+        self.logger.info("Current LOG_LEVEL has changed to '%s'",
+                         self.logger.level)
+        # The next line will not show up!
+        self.logger.debug("Current LOG_LEVEL is '%s'", self.logger.level)
+
+        # Try to set loglevel via basicConfig
+        new_loglevel = logging.WARNING
+        self.logger.info("Set LOG_LEVEL to '%s' via basicConfig", new_loglevel)
+        # logging.basicConfig(level=new_loglevel,
+        #                    format='%(asctime)s : %(name)s : %(levelname)s : '
+        #                           '%(message)s')
+        logger = logging.getLogger()
+        handler = logging.StreamHandler()
+        formatter = logging.Formatter(fmt='Root Stream %(asctime)s - '
+                                          '%(name)s - '
+                                          '%(levelname)s : %(message)s')
+        handler.setFormatter(formatter)
+        logger.addHandler(handler)
+        logger.setLevel('DEBUG')
+        logger.debug('Initialize root logger')
+        # This message will show up twice because now a handler is configured
+        # in the root logger and all messages will be forwarded
+        # but it does because the
+        # loggers are detached and we need to delete the handler first
+        self.logger.info("Current LOG_LEVEL '%s' (this will appear twice)",
+                         self.logger.level)
+
+    def tearDown(self) -> None:
+        pass
```

