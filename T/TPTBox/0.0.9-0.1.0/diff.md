# Comparing `tmp/tptbox-0.0.9-py3-none-any.whl.zip` & `tmp/tptbox-0.1.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,19 +1,19 @@
-Zip file size: 1139685 bytes, number of entries: 58
+Zip file size: 1140001 bytes, number of entries: 58
 -rwxr-xr-x  2.0 unx     1119 b- defN 80-Jan-01 00:00 TPTBox/__init__.py
 -rwxr-xr-x  2.0 unx      619 b- defN 80-Jan-01 00:00 TPTBox/core/__init__.py
 -rwxr-xr-x  2.0 unx     3972 b- defN 80-Jan-01 00:00 TPTBox/core/bids_constants.py
--rwxr-xr-x  2.0 unx    55059 b- defN 80-Jan-01 00:00 TPTBox/core/bids_files.py
--rwxr-xr-x  2.0 unx    63805 b- defN 80-Jan-01 00:00 TPTBox/core/nii_wrapper.py
+-rwxr-xr-x  2.0 unx    55801 b- defN 80-Jan-01 00:00 TPTBox/core/bids_files.py
+-rwxr-xr-x  2.0 unx    64166 b- defN 80-Jan-01 00:00 TPTBox/core/nii_wrapper.py
 -rwxr-xr-x  2.0 unx     9151 b- defN 80-Jan-01 00:00 TPTBox/core/nii_wrapper_math.py
--rwxr-xr-x  2.0 unx    37266 b- defN 80-Jan-01 00:00 TPTBox/core/np_utils.py
+-rwxr-xr-x  2.0 unx    37507 b- defN 80-Jan-01 00:00 TPTBox/core/np_utils.py
 -rwxr-xr-x  2.0 unx    69391 b- defN 80-Jan-01 00:00 TPTBox/core/poi.py
 -rwxr-xr-x  2.0 unx    28688 b- defN 80-Jan-01 00:00 TPTBox/core/poi_abstract.py
 -rwxr-xr-x  2.0 unx     2907 b- defN 80-Jan-01 00:00 TPTBox/core/poi_global.py
--rwxr-xr-x  2.0 unx    18098 b- defN 80-Jan-01 00:00 TPTBox/core/sitk_utils.py
+-rwxr-xr-x  2.0 unx    18197 b- defN 80-Jan-01 00:00 TPTBox/core/sitk_utils.py
 -rwxr-xr-x  2.0 unx     7861 b- defN 80-Jan-01 00:00 TPTBox/core/vert_constants.py
 -rwxr-xr-x  2.0 unx    45577 b- defN 80-Jan-01 00:00 TPTBox/core/vertebra_pois_non_centroids.py
 -rwxr-xr-x  2.0 unx      207 b- defN 80-Jan-01 00:00 TPTBox/docker/__init__.py
 -rwxr-xr-x  2.0 unx    36551 b- defN 80-Jan-01 00:00 TPTBox/docker/docker.py
 -rwxr-xr-x  2.0 unx     1392 b- defN 80-Jan-01 00:00 TPTBox/docker/docker_run.py
 -rwxr-xr-x  2.0 unx      165 b- defN 80-Jan-01 00:00 TPTBox/logger/__init__.py
 -rwxr-xr-x  2.0 unx     5063 b- defN 80-Jan-01 00:00 TPTBox/logger/log_constants.py
@@ -21,24 +21,24 @@
 -rw-r--r--  2.0 unx     4836 b- defN 80-Jan-01 00:00 TPTBox/mesh3D/mesh.py
 -rwxr-xr-x  2.0 unx     4633 b- defN 80-Jan-01 00:00 TPTBox/mesh3D/mesh_colors.py
 -rwxr-xr-x  2.0 unx      418 b- defN 80-Jan-01 00:00 TPTBox/registration/__init__.py
 -rwxr-xr-x  2.0 unx    13413 b- defN 80-Jan-01 00:00 TPTBox/registration/_deepali/test.py
 -rwxr-xr-x  2.0 unx     3715 b- defN 80-Jan-01 00:00 TPTBox/registration/ridged_intensity/register.py
 -rwxr-xr-x  2.0 unx      144 b- defN 80-Jan-01 00:00 TPTBox/registration/ridged_points/__init__.py
 -rwxr-xr-x  2.0 unx    11219 b- defN 80-Jan-01 00:00 TPTBox/registration/ridged_points/point_registration.py
--rwxr-xr-x  2.0 unx     7029 b- defN 80-Jan-01 00:00 TPTBox/registration/script_ax2sag.py
--rwxr-xr-x  2.0 unx    13829 b- defN 80-Jan-01 00:00 TPTBox/registration/script_ax2sag_v2.py
+-rwxr-xr-x  2.0 unx     7039 b- defN 80-Jan-01 00:00 TPTBox/registration/script_ax2sag.py
+-rwxr-xr-x  2.0 unx    13839 b- defN 80-Jan-01 00:00 TPTBox/registration/script_ax2sag_v2.py
 -rwxr-xr-x  2.0 unx     8053 b- defN 80-Jan-01 00:00 TPTBox/spine/POI_plotter.py
 -rw-r--r--  2.0 unx      835 b- defN 80-Jan-01 00:00 TPTBox/spine/mesh3D/vert_mesh_colors.py
 -rwxr-xr-x  2.0 unx      221 b- defN 80-Jan-01 00:00 TPTBox/spine/snapshot2D/__init__.py
 -rwxr-xr-x  2.0 unx    33768 b- defN 80-Jan-01 00:00 TPTBox/spine/snapshot2D/snapshot_modular.py
--rwxr-xr-x  2.0 unx    15584 b- defN 80-Jan-01 00:00 TPTBox/spine/snapshot2D/snapshot_templates.py
+-rwxr-xr-x  2.0 unx    15619 b- defN 80-Jan-01 00:00 TPTBox/spine/snapshot2D/snapshot_templates.py
 -rwxr-xr-x  2.0 unx     2156 b- defN 80-Jan-01 00:00 TPTBox/spine/spinal_cord_segmentation/__count_segmented.py
 -rwxr-xr-x  2.0 unx        1 b- defN 80-Jan-01 00:00 TPTBox/spine/spinal_cord_segmentation/__init__.py
--rwxr-xr-x  2.0 unx    19705 b- defN 80-Jan-01 00:00 TPTBox/spine/spinal_cord_segmentation/seg_spinalcordtoolbox.py
+-rwxr-xr-x  2.0 unx    19735 b- defN 80-Jan-01 00:00 TPTBox/spine/spinal_cord_segmentation/seg_spinalcordtoolbox.py
 -rw-r--r--  2.0 unx     2256 b- defN 80-Jan-01 00:00 TPTBox/stitching/README.md
 -rwxr-xr-x  2.0 unx       86 b- defN 80-Jan-01 00:00 TPTBox/stitching/__init__.py
 -rwxr-xr-x  2.0 unx    11308 b- defN 80-Jan-01 00:00 TPTBox/stitching/__stitching_reg.py
 -rwxr-xr-x  2.0 unx    10048 b- defN 80-Jan-01 00:00 TPTBox/stitching/__stitching_vertical.py
 -rw-r--r--  2.0 unx   326043 b- defN 80-Jan-01 00:00 TPTBox/stitching/stitching.jpg
 -rwxr-xr-x  2.0 unx    22293 b- defN 80-Jan-01 00:00 TPTBox/stitching/stitching.py
 -rwxr-xr-x  2.0 unx     4427 b- defN 80-Jan-01 00:00 TPTBox/stitching/stitching_tools.py
@@ -49,12 +49,12 @@
 -rw-r--r--  2.0 unx   259999 b- defN 80-Jan-01 00:00 TPTBox/tests/sample_mri/sub-mri_label-6_T2w.nii.gz
 -rw-r--r--  2.0 unx    12846 b- defN 80-Jan-01 00:00 TPTBox/tests/sample_mri/sub-mri_seg-subreg_label-6_msk.nii.gz
 -rw-r--r--  2.0 unx    12144 b- defN 80-Jan-01 00:00 TPTBox/tests/sample_mri/sub-mri_seg-vert_label-6_msk.nii.gz
 -rwxr-xr-x  2.0 unx     1756 b- defN 80-Jan-01 00:00 TPTBox/tests/speedtest.py
 -rw-r--r--  2.0 unx     2871 b- defN 80-Jan-01 00:00 TPTBox/tests/speedtest_cc3d.py
 -rw-r--r--  2.0 unx     1045 b- defN 80-Jan-01 00:00 TPTBox/tests/speedtest_morphological.py
 -rw-r--r--  2.0 unx    11959 b- defN 80-Jan-01 00:00 TPTBox/tests/test_utils.py
--rw-r--r--  2.0 unx    34523 b- defN 80-Jan-01 00:00 tptbox-0.0.9.dist-info/LICENSE
--rw-r--r--  2.0 unx     4337 b- defN 80-Jan-01 00:00 tptbox-0.0.9.dist-info/METADATA
--rw-r--r--  2.0 unx       88 b- defN 80-Jan-01 00:00 tptbox-0.0.9.dist-info/WHEEL
-?rw-r--r--  2.0 unx     5279 b- defN 16-Jan-01 00:00 tptbox-0.0.9.dist-info/RECORD
-58 files, 1649802 bytes uncompressed, 1131227 bytes compressed:  31.4%
+-rw-r--r--  2.0 unx    34523 b- defN 80-Jan-01 00:00 tptbox-0.1.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     4337 b- defN 80-Jan-01 00:00 tptbox-0.1.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       88 b- defN 80-Jan-01 00:00 tptbox-0.1.0.dist-info/WHEEL
+?rw-r--r--  2.0 unx     5279 b- defN 16-Jan-01 00:00 tptbox-0.1.0.dist-info/RECORD
+58 files, 1651330 bytes uncompressed, 1131543 bytes compressed:  31.5%
```

## zipnote {}

```diff
@@ -156,20 +156,20 @@
 
 Filename: TPTBox/tests/speedtest_morphological.py
 Comment: 
 
 Filename: TPTBox/tests/test_utils.py
 Comment: 
 
-Filename: tptbox-0.0.9.dist-info/LICENSE
+Filename: tptbox-0.1.0.dist-info/LICENSE
 Comment: 
 
-Filename: tptbox-0.0.9.dist-info/METADATA
+Filename: tptbox-0.1.0.dist-info/METADATA
 Comment: 
 
-Filename: tptbox-0.0.9.dist-info/WHEEL
+Filename: tptbox-0.1.0.dist-info/WHEEL
 Comment: 
 
-Filename: tptbox-0.0.9.dist-info/RECORD
+Filename: tptbox-0.1.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## TPTBox/core/bids_files.py

```diff
@@ -99,83 +99,79 @@
             "fat-outphase",
             "water-outphase",
             "r2s",
         ]
         if key in entity_parts and value not in parts:
             print(f'[!] value for {key} must be in {parts}. This name "{name}" is invalid, with value {value}')
             return False
-
-        return True
+        else:
+            return True
     except Exception as e:
         print(e)
         return False
 
 
 def get_values_from_name(path: Path | str, verbose) -> tuple[str, dict[str, str], str, str]:
     name = Path(path).name
-    BIDS_key, file_type = name.split(".", maxsplit=1)
+    bids_key, file_type = name.split(".", maxsplit=1)
 
-    keys = BIDS_key.split("_")
-    format = keys[-1]
-    if format not in formats_relaxed and verbose:
-        print(f"[!] Unknown format {format} in file {name}", formats)
-        formats_relaxed.append(format)
+    keys = bids_key.split("_")
+    bids_format = keys[-1]
+    if bids_format not in formats_relaxed and verbose:
+        print(f"[!] Unknown format {bids_format} in file {name}", formats)
+        formats_relaxed.append(bids_format)
     if file_type not in file_types and verbose:
         print(f"[!] Unknown file_type {file_type} in file {name}")
 
     dic = {}
     for idx, s in enumerate(keys[:-1]):
         try:
             key, value = s.split("-", maxsplit=1)
             if idx == 0 and key != "sub" and verbose:
                 print(f"[!] First key must be sub not {key}. This name '{name}' is invalid")
             if idx != 1 and key == "ses" and verbose:
                 print(f"[!] Session must be second key. This name '{name}' is invalid")
 
             if key in dic and verbose:
-                print(f"[!] {BIDS_key} contains copies of the same key twice. This name '{name}' is invalid")
+                print(f"[!] {bids_key} contains copies of the same key twice. This name '{name}' is invalid")
 
             validate_entities(key, value, name, verbose)
             dic[key] = value
-        except:
+        except Exception:
             if verbose:
                 print(f'[!] "{s}" is not a valid key/value pair. Expected "KEY-VALUE" in {name}')
-    return format, dic, BIDS_key, file_type
-
-
-global_bids_list: dict = {}
+    return bids_format, dic, bids_key, file_type
 
 
 class BIDS_Global_info:
     def __init__(
         self,
         datasets: Sequence[Path] | Sequence[str],
         parents: Sequence[str] = ["rawdata", "derivatives"],
         additional_key: Sequence[str] = ["sequ", "seg", "ovl"],
-        verbose=True,
-        clear=True,
+        verbose: bool = True,
         file_name_manipulation: typing.Callable[[str], str] | None = None,
     ):
         """This Objects creates a datastructures reflecting BIDS-folders.
 
         Args:
             datasets (typing.List[str]): List of dataset paths
             parents (typing.List[str]): List of parents (like ["rawdata","sourcedata","derivatives"])
             additional_key (list, optional): Additional keys that are not in the default BIDS but should not raise a warning. Defaults to ["sequ", "seg", "ovl"].
         """
         assert isinstance(datasets, Sequence), "datasets is not a list"
         assert isinstance(parents, Sequence), "parents is not a list"
+        self.__bids_list: dict = {}
 
         self.file_name_manipulation = file_name_manipulation
-        if clear:
-            global_bids_list.clear()
         # Validate
         for ds in datasets:
-            if not os.path.basename(ds).startswith("dataset-"):
-                print(f"[!] Dataset {os.path.basename(ds)} does not start with 'dataset-'")
+            ds_path = Path(ds) if isinstance(ds, str) else ds
+            if not ds_path.name.startswith("dataset-"):
+                print(f"[!] Dataset {ds_path.name} does not start with 'dataset-'")
         for ps in parents:
             if not any(ps.startswith(lp) for lp in parents):
                 print(f"[!] Parentfolder {ps} is not a legal name")
 
         self.datasets = datasets
         self.parents = parents
         self.subjects: dict[str, Subject_Container] = {}
@@ -214,25 +210,25 @@
     def add_file_2_subject(self, bids: BIDS_FILE | Path, ds=None) -> None:
         if isinstance(bids, Path) and "DS_Store" in bids.name:
             return
         if ds is None:
             if isinstance(bids, BIDS_FILE):
                 ds = bids.dataset
             else:
-                assert False, "Dataset-path required"
+                raise AssertionError("Dataset-path required")
         if isinstance(bids, Path):
             try:
-                BIDS_key, file_type = bids.name.split(".", maxsplit=1)
+                bids_key, file_type = bids.name.split(".", maxsplit=1)
             except Exception:
                 print("[!] skip file with out a type declaration:", bids.name)
                 # raise e
                 return
 
-            if BIDS_key in global_bids_list:
-                global_bids_list[BIDS_key].add_file(bids)
+            if bids_key in self._global_bids_list:
+                self._global_bids_list[bids_key].add_file(bids)
                 return
             bids = BIDS_FILE(
                 bids,
                 ds,
                 verbose=self.verbose,
                 file_name_manipulation=self.file_name_manipulation,
             )
@@ -255,16 +251,17 @@
 
     def __len__(self):
         return len(self.subjects)
 
     def __str__(self):
         return "BIDS_Global_info: parents=" + str(self.parents) + f"\nDatasets = {self.datasets}"
 
+    @property
     def _global_bids_list(self):
-        return global_bids_list
+        return self.__bids_list
 
 
 class Subject_Container:
     def __init__(self, name) -> None:
         self.name = name
         self.sequences: dict[str, list[BIDS_FILE]] = {}
 
@@ -361,14 +358,15 @@
 
 class BIDS_FILE:
     def __init__(
         self,
         file: Path | str,
         dataset: Path | str,
         verbose=True,
+        bids_ds: BIDS_Global_info | None = None,
         file_name_manipulation: typing.Callable[[str], str] | None = None,
     ):
         """A multi-file representation. It holds the path to Bids-files with the same identifier (filename excluding the file type).
         It can hold the reference to the nii.gz, json, etc at the same time.
 
         The following fields are imported and can be accessed.
         self.format (str): The last value determining its use/modalities like T1w, msk, dixon
@@ -392,26 +390,27 @@
             if "WS_" in str(file):
                 file.rename(file.parent / Path(file_name_manipulation(file.name)))
             name = file_name_manipulation(file.name)
         else:
             name = file.name
         self.format, self.info, self.BIDS_key, file_type = get_values_from_name(name, verbose)
 
-        global_bids_list[self.BIDS_key] = self
+        if bids_ds is not None:
+            bids_ds.add_file_2_subject(bids=self, ds=self.dataset)
         self.file = {
             file_type: Path(file),
         }
-        BIDS_key, _ = Path(file).name.split(".", maxsplit=1)
+        bids_key, _ = Path(file).name.split(".", maxsplit=1)
         for file_type in ["nii.gz", "json", "png"]:
             if file_type in self.file:
                 continue
-            p = Path(Path(file).parent, BIDS_key + "." + file_type)
+            p = Path(Path(file).parent, bids_key + "." + file_type)
             if p.exists():
                 self.file[file_type] = p
-        self.file = {key: value for key, value in sorted(self.file.items())}
+        self.file = dict(sorted(self.file.items()))
 
     def __str__(self) -> str:
         s = f"{self.BIDS_key}.{list(self.file.keys())}\t parent = {self.get_parent()}"
         return s
 
     def __repr__(self):
         return str(self)
@@ -441,35 +440,40 @@
     def set_subject(self, sub: Subject_Container):
         self.subject = sub
 
     def set(self, key, value):
         validate_entities(key, value, f"..._{key}-{value}_...", self.verbose)
         self.info[key] = value
 
-    def get(self, key, default: str | None = None) -> str:
+    def get(self, key, default: str | None = None) -> str | None:
         if key in self.info:
             return self.info[key]
         return default
 
     def loop_keys(self):
         return self.info.items()
 
     def remove(self, key):
         assert key != "sub", "not allowed to remove subject name"
         return self.info.pop(key)
 
-    def add_file(self, path: Path):
-        BIDS_key, file_type = Path(path).name.split(".", maxsplit=1)
+    def add_file(
+        self,
+        path: Path,
+        bids_ds: BIDS_Global_info | None = None,
+    ):
+        bids_key, file_type = Path(path).name.split(".", maxsplit=1)
 
-        assert BIDS_key == self.BIDS_key, f"only aligned data aka same name different file type: {BIDS_key} != {self.BIDS_key}"
+        assert bids_key == self.BIDS_key, f"only aligned data aka same name different file type: {bids_key} != {self.BIDS_key}"
         bids_dic_file = self.file
         if file_type not in self.file:
             bids_dic_file[file_type] = path
-            global_bids_list[BIDS_key].file = {key: value for key, value in sorted(bids_dic_file.items())}
-        self.file = {key: value for key, value in sorted(bids_dic_file.items())}
+            if bids_ds is not None:
+                bids_ds._global_bids_list[bids_key].file = dict(sorted(bids_dic_file.items()))
+        self.file = dict(sorted(bids_dic_file.items()))
 
     def rename_files(self, path: Path | str, ending=".nii.gz"):
         path = str(path)
         assert path.endswith(ending), f"set 'ending' to the part after the '.'\n {path} does not end with {ending}"
         path = path.replace(ending, "")
         for key, value in self.file.items():
             p = Path(path + "." + key)
@@ -487,32 +491,29 @@
 
     def get_parent(self, file_type=None):
         return self.get_path_decomposed(file_type)[1]
 
     def get_changed_bids(
         self,
         file_type: str | None = "nii.gz",
-        format: str | None = None,
+        bids_format: str | None = None,
         parent: str = "derivatives",
         path: str | None = None,
         info: dict | None = None,
         from_info=False,
         auto_add_run_id=False,
         additional_folder: str | None = None,
         dataset_path: str | None = None,
         make_parent=True,
     ):
-        if dataset_path is not None:
-            ds = dataset_path
-        else:
-            ds = self.get_path_decomposed()[0]
+        ds = dataset_path if dataset_path is not None else self.get_path_decomposed()[0]
         return BIDS_FILE(
             self.get_changed_path(
                 file_type=file_type,
-                format=format,
+                bids_format=bids_format,
                 parent=parent,
                 path=path,
                 info=info,
                 from_info=from_info,
                 auto_add_run_id=auto_add_run_id,
                 additional_folder=additional_folder,
                 dataset_path=dataset_path,
@@ -520,15 +521,15 @@
             ),
             ds,
         )
 
     def get_changed_path(
         self,
         file_type: str | None = "nii.gz",
-        format: str | None = None,
+        bids_format: str | None = None,
         parent: str = "derivatives",
         path: str | None = None,
         info: dict | None = None,
         from_info=False,
         auto_add_run_id=False,
         additional_folder: str | None = None,
         dataset_path: str | None = None,
@@ -579,28 +580,32 @@
             )  # Oder of keys is deterministic for python >3.7
         while True:
             file_name = ""
             ## Info
             final_info = {}
             for key, value in same_info.items():
                 if key in info:
-                    value = info[key]
+                    value = info[key]  # noqa: PLW2901
                 if value is not None:
                     # file_name += f"{key}-{value}_"
                     if non_strict_mode:
                         validate_entities(key, value, f"..._{key}-{value}_...", verbose=True)
                     else:
                         assert validate_entities(key, value, f"..._{key}-{value}_...", verbose=True)
                     final_info[key] = value
             for key, value in info.items():
                 # New Keys are getting checked!
                 if non_strict_mode:
-                    print(
-                        f"[!] {key} is not in list of legal keys. This name '{key}' is invalid. Legal keys are: {list(entities_keys.keys())}. \nFor use see https://bids-specification.readthedocs.io/en/stable/99-appendices/09-entities.html"
-                    ) if key not in entities_keys else None
+                    (
+                        print(
+                            f"[!] {key} is not in list of legal keys. This name '{key}' is invalid. Legal keys are: {list(entities_keys.keys())}. \nFor use see https://bids-specification.readthedocs.io/en/stable/99-appendices/09-entities.html"
+                        )
+                        if key not in entities_keys
+                        else None
+                    )
                 else:
                     assert (
                         key in entities_keys
                     ), f"[!] {key} is not in list of legal keys. This name '{key}' is invalid. Legal keys are: {list(entities_keys.keys())}. \nFor use see https://bids-specification.readthedocs.io/en/stable/99-appendices/09-entities.html"
                 # validate_entities(key, value, f"..._{key}-{value}_...", self.verbose)
                 if key in same_info:
                     continue
@@ -613,24 +618,24 @@
             keys_sorted = sorted(
                 final_info.keys(),
                 key=lambda x: entity_keys.index(x) if x in entity_keys else list(final_info.keys()).index(x) + len(entity_keys),
             )
             for key in keys_sorted:
                 file_name += f"{key}-{final_info[key]}_"
             # End Info
-            format = format if format is not None else same_format
+            bids_format = bids_format if bids_format is not None else same_format
             file_type = file_type if file_type is not None else same_filetype
             assert (
                 file_type in file_types
             ), f"[!] {file_type} is not in list of file types. Legal file types are: {list(file_types)}. \nFor use see https://bids-specification.readthedocs.io/en/stable/99-appendices/09-entities.html"
-            if format not in formats:
+            if bids_format not in formats:
                 raise ValueError(
-                    f"[!] {format} is not in list of formats. Legal formats are: {list(formats)}. \nFor use see https://bids-specification.readthedocs.io/en/stable/99-appendices/09-entities.html"
+                    f"[!] {bids_format} is not in list of formats. Legal formats are: {list(formats)}. \nFor use see https://bids-specification.readthedocs.io/en/stable/99-appendices/09-entities.html"
                 )
-            file_name += f"{format}.{file_type}"
+            file_name += f"{bids_format}.{file_type}"
 
             out_path = Path(
                 dataset_path if dataset_path is not None else ds_path,
                 parent if parent is not None else same_parent,
                 path if path is not None else same_path,
                 additional_folder if additional_folder is not None else "",
                 file_name,
@@ -644,45 +649,46 @@
             if "run" in info:
                 info["run"] += 1
             else:
                 info["run"] = 2
 
     def save_changed_path(
         self,
-        format: str | None = None,
+        bids_format: str | None = None,
         parent: str = "derivatives",
         path: str | None = None,
         info: dict | None = None,
         from_info=False,
         auto_add_run_id=False,
         additional_folder: str | None = None,
         dataset_path: str | None = None,
         non_strict_mode: bool = False,
     ) -> None:
         import shutil
 
         for key, value in self.file.items():
             out = self.get_changed_path(
                 key,
-                format=format,
+                bids_format=bids_format,
                 parent=parent,
                 path=path,
                 from_info=from_info,
                 info=info,
                 auto_add_run_id=auto_add_run_id,
                 additional_folder=additional_folder,
                 dataset_path=dataset_path,
                 make_parent=True,
                 non_strict_mode=non_strict_mode,
             )
             shutil.copy2(value, out)
 
     def find_changed_path(
         self,
-        format: str | None = None,
+        bids_ds: BIDS_Global_info,
+        bids_format: str | None = None,
         info: dict | None = None,
         from_info=False,
     ) -> BIDS_FILE | None:
         if info is None:
             info = {}
 
         if from_info:
@@ -690,39 +696,39 @@
             same_format = self.format
         else:
             _, _, _, old_filename = self.get_path_decomposed()
             same_format, same_info, _, _ = get_values_from_name(old_filename, self.verbose)  # Oder of keys is deterministic for python >3.7
         file_name = ""
         for key, value in same_info.items():
             if key in info:
-                value = info[key]
+                value = info[key]  # noqa: PLW2901
             file_name += f"{key}-{value}_"
         for key, value in info.items():
             validate_entities(key, value, f"..._{key}-{value}_...", self.verbose)
             if key in same_info:
                 continue
             file_name += f"{key}-{value}_"
 
-        file_name += f"{format if format is not None else same_format}"
-        return global_bids_list.get(file_name)
+        file_name += f"{bids_format if bids_format is not None else same_format}"
+        return bids_ds._global_bids_list.get(file_name)
 
     def insert_info_into_path(self, path):
         """Helper function. Automatically replaces {key} with  values from the self.info dict in a string. Like:
         f"sub-{sub}" --> "sub-patient001"
         f"{sub}/ses-{ses}/sub-{sub}_ses-{ses}_label-heart_msk.nii.gz" --> "sub-patient001"
         """
         if path is None:
             return None
         path = str(path)
         while "{" in path:
             left, right = path.split("{", maxsplit=1)
             middle, right = right.split("}", maxsplit=1)
-            a = self.info[middle] if middle in self.info else None
+            a = self.info.get(middle, None)
             if a is None:
-                warn(f"{middle} not found in {self}")
+                warn(f"{middle} not found in {self}", stacklevel=3)
                 a = middle
             path = left + a + right
         return path
 
     def get_sequence_files(
         self,
         key_transform: typing.Callable[[BIDS_FILE], str | None] | None = None,
@@ -761,14 +767,15 @@
                 if nii is None:
                     p = Path(str(self.file["json"]).replace("ctd.json", "msk.nii.gz"))
                     nii = p if p.exists() else nii
                 assert (
                     nii is not None
                 ), "This file has no zoom info. Use open_ctd(self, nii) with a image reference (BIDS_FILE/PATH) with the same nii"
                 nii = TPTBox.to_nii(nii)
+                assert isinstance(nii, TPTBox.NII)
                 cdt.zoom = nii.zoom
                 cdt.shape = nii.shape
                 cdt.rotation = nii.rotation
                 cdt.origin = nii.origin
                 cdt.orientation = nii.orientation
         except KeyError as e:
             raise ValueError(f"json not present. Found only {self.file.keys()}\t{self.file}\n\n{self}") from e
@@ -896,35 +903,35 @@
         # query.candidates = dic.copy()
         return query
 
     def _filter_fam_id(self, fam: BIDS_Family):
         self.unflatten()
         dic = fam.data_dict
         any_file = dic[next(iter(dic.keys()))][0]
-        id = any_file.subject.get_sequence_name(any_file)
+        subject_id = any_file.subject.get_sequence_name(any_file)
         c = self.candidates
         self.candidates = {}
-        self.candidates[id] = c[id]
+        self.candidates[subject_id] = c[subject_id]  # type: ignore
 
     def copy(self):
         copy = Searchquery(self.subject, self._flatten)
         copy.candidates = self.candidates.copy()
         return copy
 
     def flatten(self):
         """
         Transform from multi-file-mode to single file-mode
         """
         if self._flatten:
             return
         a: list[BIDS_FILE] = []
         assert isinstance(self.candidates, dict)
-        for _, value_lists in self.candidates.items():
+        for value_lists in self.candidates.values():
             for value in value_lists:
-                a.append(value)
+                a.append(value)  # noqa: PERF402
         self.candidates = a
         self._flatten = True
 
     def unflatten(self):
         """
         Transforms from single file-mode to multi-file-mode. Filtered Objects are still removed
         """
@@ -985,15 +992,15 @@
 
     def filter_filetype(self, filter_fun: str | typing.Callable[[str | object], bool], required=True):
         return self.filter("filetype", filter_fun=filter_fun, required=required)
 
     def filter_non_existence(
         self,
         key: str,
-        filter_fun: str | typing.Callable[[str | object], bool] = lambda x: True,
+        filter_fun: str | typing.Callable[[str | object], bool] = lambda x: True,  # noqa: ARG005
         required=True,
     ) -> None:
         """Remove family/file from the Searchquery if:
 
             (unflatten-mode) ANY single file exist in the family returns True
 
             (unflatten-mode) the filter_fun returns True
@@ -1018,56 +1025,65 @@
             assert isinstance(self.candidates, dict)
             for sequences, bids_files in self.candidates.copy().items():
                 # print(sequences, list(bids_file.do_filter(key, filter_fun, required=required) for bids_file in bids_files))
                 if any(bids_file.do_filter(key, filter_fun, required=required) for bids_file in bids_files):
                     self.candidates.pop(sequences)
 
     def filter_dixon_only_inphase(self):
-        json_filter = lambda x: "ImageType" not in x or (
-            "W" not in x["ImageType"]
-            and "F" not in x["ImageType"]
-            and "FAT" not in x["ImageType"]
-            and "WATER" not in x["ImageType"]
-            and "OP" not in x["ImageType"]
-        )
-        lam_filter = (
-            lambda x: x.upper() != "W"
-            and x.upper() != "F"
-            and x.upper() != "FAT"
-            and x.upper() != "WATER"
-            and x.upper() != "OP"
-            and x.upper() != "OPP"
-            and x.upper() != "OUTPHASE"
-        )
+        def json_filter(x):
+            return (
+                "ImageType" not in x
+                or "W" not in x["ImageType"]
+                and "F" not in x["ImageType"]
+                and "FAT" not in x["ImageType"]
+                and "WATER" not in x["ImageType"]
+                and "OP" not in x["ImageType"]
+            )
+
+        def lam_filter(x):
+            return (
+                x.upper() != "W"
+                and x.upper() != "F"
+                and x.upper() != "FAT"
+                and x.upper() != "WATER"
+                and x.upper() != "OP"
+                and x.upper() != "OPP"
+                and x.upper() != "OUTPHASE"
+            )
+
         self.filter_json(json_filter, required=False)
         self.filter("rec", lam_filter, required=False)  # type: ignore DEPRECATED
         self.filter("part", lam_filter, required=False)  # type: ignore
         self.filter("acq", lam_filter, required=False)  # type: ignore DEPRECATED
 
     def filter_dixon_water(self, _keys=None):
         if _keys is None:
             _keys = ["W", "WATER"]
         assert self._flatten
-        json_filter = lambda x: "ImageType" not in x or all(k in x["ImageType"] for k in _keys)
 
-        lam_filter = lambda x: any(k == x.upper() for k in _keys)
+        def json_filter(x):
+            return "ImageType" not in x or all(k in x["ImageType"] for k in _keys)
+
+        def lam_filter(x):
+            return any(k == x.upper() for k in _keys)
+
         self.filter_json(json_filter, required=False)
         self.filter("rec", lam_filter, required=False)  # type: ignore
         self.filter("part", lam_filter, required=False)  # type: ignore
 
     def filter_dixon_fat(self):
         self.filter_dixon_water(_keys=["F", "FAT"])
 
     def filter_dixon_outphase(self):
         self.filter_dixon_water(_keys=["OP", "OPP", "OUTPHASE"])
 
     def action(
         self,
         action_fun: typing.Callable[[BIDS_FILE], None],
-        filter_fun: str | typing.Callable[[str | object], bool] = lambda x: True,
+        filter_fun: str | typing.Callable[[str | object], bool] = lambda x: True,  # noqa: ARG005
         key: str = "",
         required: bool = True,
         all_in_sequence=False,
     ):
         """When the filter_function is True the action_fun is applied on the BIDS_File
 
         Args:
@@ -1084,16 +1100,16 @@
         if self._flatten:
             assert isinstance(self.candidates, list)
             for bids_file in self.candidates.copy():
                 if bids_file.do_filter(key, filter_fun, required=required):
                     action_fun(bids_file)
         else:
             assert isinstance(self.candidates, dict)
-            for sequences, bids_files in self.candidates.copy().items():
-                if all_in_sequence:
+            for bids_files in self.candidates.copy().values():
+                if all_in_sequence:  # noqa: SIM102
                     if any(bids_file.do_filter(key, filter_fun, required=required) for bids_file in bids_files):
                         for bids_file in bids_files:
                             action_fun(bids_file)
 
                 for bids_file in bids_files:
                     if bids_file.do_filter(key, filter_fun, required=required):
                         action_fun(bids_file)
@@ -1124,21 +1140,21 @@
             sort (bool, optional): Sort alphabetically. Defaults to False.
 
         Returns:
             typing.Iterator[BIDS_FILE]: _description_
         """
         assert isinstance(self.candidates, list), "call flatten() before looping as a list"
         if sort:
-            return sorted(list(self.candidates.__iter__()))  # type: ignore
+            return sorted(self.candidates.__iter__())  # type: ignore
         return self.candidates.__iter__()
 
     def loop_dict(
         self,
         sort=False,
-        key_transform: typing.Callable[[BIDS_FILE], str | None] = None,
+        key_transform: typing.Callable[[BIDS_FILE], str | None] | None = None,
         key_addendum: list[str] | None = None,  # type: ignore
     ) -> typing.Iterator[BIDS_Family]:
         """Returns an iterator. Flatten must be False: it iterates over all families, where the return is the dict from the get_sequence_files function
 
         Args:
             sort (bool, optional): Sort alphabetically. Defaults to False.
             key_transform (typing.Callable[[BIDS_FILE], str | None]): provide alternative dict name for certain fils, if default should be used return None
@@ -1234,20 +1250,20 @@
 
     def get_key_len(self) -> dict[str, int]:
         return {k: len(v) for k, v in self}
 
     def get_format_len(self):
         format_len = {}
         for k, v in self:
-            format = k.split("_")[0]
-            if format not in format_len:
-                format_len[format] = (0, 0)
-            format_len[format] = (
-                format_len[format][0] + 1,
-                format_len[format][1] + len(v),
+            bids_format = k.split("_")[0]
+            if bids_format not in format_len:
+                format_len[bids_format] = (0, 0)
+            format_len[bids_format] = (
+                format_len[bids_format][0] + 1,
+                format_len[bids_format][1] + len(v),
             )
         return format_len
 
     def get_files_with_multiples(self):
         return self.get_files(key=[k for k, v in self.get_key_len().items() if v > 1])
 
     def get_files(self, key: list[str] | str | None = None):
@@ -1287,15 +1303,15 @@
 
 
 if __name__ == "__main__":
     global_info = BIDS_Global_info(
         ["/media/robert/Expansion/dataset-Testset"],
         ["sourcedata", "rawdata", "rawdata_ct", "rawdata_dixon", "derivatives"],  #
     )
-    for subj_name, subject in global_info.enumerate_subjects():
+    for _, subject in global_info.enumerate_subjects():
         query = subject.new_query()
         # It must exist a dixon and a msk
         query.filter("format", "dixon")
         # A nii.gz must exist
         query.filter("Filetype", "nii.gz")
         query.filter("format", "msk")
         # Example of lamda function filtering
```

## TPTBox/core/nii_wrapper.py

```diff
@@ -12,26 +12,28 @@
 import numpy as np
 from nibabel import Nifti1Header, Nifti1Image  # type: ignore
 from typing_extensions import Self
 
 from TPTBox.core.nii_wrapper_math import NII_Math
 from TPTBox.core.np_utils import (
     np_calc_boundary_mask,
+    np_center_of_mass,
     np_connected_components,
     np_count_nonzero,
     np_dilate_msk,
     np_erode_msk,
     np_fill_holes,
     np_get_connected_components_center_of_mass,
     np_get_largest_k_connected_components,
     np_map_labels,
     np_unique,
     np_unique_withoutzero,
     np_volume,
 )
+from TPTBox.core.vert_constants import Coordinate
 
 from . import bids_files
 from . import vert_constants as vc
 from .vert_constants import Sentinel
 
 AFFINE = np.ndarray
 _unpacked_nii = tuple[np.ndarray, AFFINE, nib.nifti1.Nifti1Header]
@@ -981,20 +983,20 @@
         Returns:
             _type_: _description_
         """
         arr = self.get_seg_array()
         return np_get_connected_components_center_of_mass(arr, label=label, connectivity=connectivity, sort_by_axis=sort_by_axis)
 
 
-    def get_largest_k_segmentation_connected_components(self, k: int, labels: int | list[int] | None = None, connectivity: int = 1, return_original_labels: bool = True):
+    def get_largest_k_segmentation_connected_components(self, k: int | None, labels: int | list[int] | None = None, connectivity: int = 1, return_original_labels: bool = True):
         """Finds the largest k connected components in a given array (does NOT work with zero as label!)
 
         Args:
             arr (np.ndarray): input array
-            k (int): finds the k-largest components
+            k (int | None): finds the k-largest components. If k is None, will find all connected components and still sort them by size
             labels (int | list[int] | None, optional): Labels that the algorithm should be applied to. If none, applies on all labels found in this NII. Defaults to None.
             return_original_labels (bool): If set to False, will label the components from 1 to k. Defaults to True
         """
         return self.set_array(np_get_largest_k_connected_components(self.get_seg_array(), k=k, label_ref=labels, connectivity=connectivity, return_original_labels=return_original_labels))
 
 
     def get_segmentation_difference_to(self, mask_gt: Self, ignore_background_tp: bool = False) -> Self:
@@ -1185,17 +1187,21 @@
     def unique(self,verbose:logging=False):
         '''Returns all integer labels WITHOUT 0. Must be performed only on a segmentation nii'''
         out = np_unique_withoutzero(self.get_seg_array())
         log.print(out,verbose=verbose)
         return out
 
     def volumes(self, include_zero: bool = False) -> dict[int, int]:
-        '''Returns a dict stating how many pixels are present for each label (including zero!)'''
+        '''Returns a dict stating how many pixels are present for each label'''
         return np_volume(self.get_seg_array(), include_zero=include_zero)
 
+    def center_of_masses(self) -> dict[int, Coordinate]:
+        '''Returns a dict stating the center of mass for each present label (not including zero!)'''
+        return np_center_of_mass(self.get_seg_array())
+
     def assert_affine(
             self,
             other: Self | "POI" | None = None,
             affine: AFFINE | None = None,
             zoom: Zooms | None = None,
             orientation: Ax_Codes | None = None,
             rotation: ROTATION | None = None,
```

## TPTBox/core/np_utils.py

```diff
@@ -103,15 +103,19 @@
 
     Args:
         arr (np.ndarray): _description_
 
     Returns:
         list[int]: _description_
     """
-    return [idx for idx, i in enumerate(cc3dstatistics(arr)["voxel_counts"]) if i > 0 and idx != 0]
+    try:
+        return [idx for idx, i in enumerate(cc3dstatistics(arr)["voxel_counts"]) if i > 0 and idx != 0]
+    except Exception:
+        pass
+    return [i for i in np.unique(arr) if i != 0]
 
 
 def np_center_of_mass(arr: UINTARRAY) -> dict[int, Coordinate]:
     """Calculates center of mass, mapping label in array to a coordinate (float) (exluding zero)
 
     Args:
         arr (np.ndarray): _description_
@@ -504,45 +508,47 @@
             {i: subreg_cc_n[i] for i in labels},
         )
     return subreg_cc, subreg_cc_n
 
 
 def np_get_largest_k_connected_components(
     arr: UINTARRAY,
-    k: int,
+    k: int | None = None,
     label_ref: Label_Reference = None,
     connectivity: int = 3,
     return_original_labels: bool = True,
 ) -> UINTARRAY:
     """finds the largest k connected components in a given array (does NOT work with zero as label!)
 
     Args:
         arr (np.ndarray): input array
-        k (int): finds the k-largest components
+        k (int | None): finds the k-largest components. If k is None, will find all connected components and still sort them by size
         labels (int | list[int] | None, optional): Labels that the algorithm should be applied to. If none, applies on all labels found in arr. Defaults to None.
         connectivity: in range [1,3]. For 2D images, 2 and 3 is the same.
         return_original_labels (bool): If set to False, will label the components from 1 to k. Defaults to True
 
     Returns:
         np.ndarray: array with the largest k connected components
     """
 
-    assert k > 0
+    assert k is None or k > 0
     assert 2 <= arr.ndim <= 3, f"expected 2D or 3D, but got {arr.ndim}"
     assert 1 <= connectivity <= 3, f"expected connectivity in [1,3], but got {connectivity}"
     if arr.ndim == 2:  # noqa: SIM108
         connectivity = min(connectivity * 2, 8)  # 1:4, 2:8, 3:8
     else:
         connectivity = 6 if connectivity == 1 else 18 if connectivity == 2 else 26
 
     arr2 = arr.copy()
     labels: Sequence[int] = _to_labels(arr, label_ref)
     arr2[np.isin(arr, labels, invert=True)] = 0  # type:ignore
 
     labels_out, n = connected_components(arr, connectivity=connectivity, return_N=True)
+    if k is None:
+        k = n
     k = min(k, n)  # if k > N, will return all N but still sorted
     label_volume_pairs = [(i, ct) for i, ct in np_volume(labels_out).items() if ct > 0]
     label_volume_pairs.sort(key=lambda x: x[1], reverse=True)
     preserve: list[int] = [x[0] for x in label_volume_pairs[:k]]
 
     cc_out = np.zeros(arr.shape, dtype=arr.dtype)
     for i, preserve_label in enumerate(preserve):
```

## TPTBox/core/sitk_utils.py

```diff
@@ -1,11 +1,11 @@
 from typing import TYPE_CHECKING
 
 import numpy as np
-import SimpleITK as sitk
+import SimpleITK as sitk  # noqa: N813
 
 if TYPE_CHECKING:
     from nibabel import Nifti1Image
 
     from TPTBox import NII, POI
 
 
@@ -84,27 +84,27 @@
     https://programmer.ink/think/resample-method-and-code-notes-of-python-simpleitk-library.html
     use itk Method to convert the original image resample To be consistent with the target image
     :param ori_img: Original alignment required itk image
     :param target_img: Target to align itk image
     :param resample_method: itk interpolation method : sitk.sitkLinear-linear  sitk.sitkNearestNeighbor-Nearest neighbor
     :return:img_res_itk: Resampling okay itk image
     """
-    target_Size = target_img.GetSize()  # Target image size [x,y,z]
-    target_Spacing = target_img.GetSpacing()  # Voxel block size of the target [x,y,z]
+    target_size = target_img.GetSize()  # Target image size [x,y,z]
+    target_spacing = target_img.GetSpacing()  # Voxel block size of the target [x,y,z]
     target_origin = target_img.GetOrigin()  # Starting point of target [x,y,z]
     target_direction = target_img.GetDirection()  # Target direction [crown, sagittal, transverse] = [z,y,x]
 
     # The method of itk is resample
     resampler = sitk.ResampleImageFilter()
     resampler.SetReferenceImage(ori_img)  # Target image to resample
     # Set the information of the target image
-    resampler.SetSize(target_Size)  # Target image size
+    resampler.SetSize(target_size)  # Target image size
     resampler.SetOutputOrigin(target_origin)
     resampler.SetOutputDirection(target_direction)
-    resampler.SetOutputSpacing(target_Spacing)
+    resampler.SetOutputSpacing(target_spacing)
     # Set different type according to the need to resample the image
     if resample_method == sitk.sitkNearestNeighbor:
         resampler.SetOutputPixelType(sitk.sitkUInt16)  # Nearest neighbor interpolation is used for mask, and uint16 is saved
     else:
         resampler.SetOutputPixelType(sitk.sitkFloat32)  # Linear interpolation is used for PET/CT/MRI and the like, and float32 is saved
     resampler.SetTransform(sitk.Transform(3, sitk.sitkIdentity))
     resampler.SetInterpolator(resample_method)
@@ -119,45 +119,45 @@
         image0_min_extent = image.GetOrigin()[index]
         image0_max_extent = image.GetOrigin()[index] + image.GetSize()[index] * image.GetSpacing()[index]
         min_extent = min(image0_min_extent, ref_img.GetOrigin()[index])
         max_extent = max(image0_max_extent, ref_img.GetOrigin()[index] + ref_img.GetSize()[index] * ref_img.GetSpacing()[index])
         lower.append(int((image0_min_extent - min_extent) / image.GetSpacing()[index] + 1))
         upper.append(int((max_extent - image0_max_extent) / image.GetSpacing()[index] + 1))
 
-    filter = sitk.ConstantPadImageFilter()
+    sitk_filter = sitk.ConstantPadImageFilter()
     #  filter->SetInput(input);
     print(lower, upper)
-    filter.SetPadLowerBound(lower)
-    filter.SetPadUpperBound(upper)
-    filter.SetConstant(default_value)
-    return filter.Execute(image)
+    sitk_filter.SetPadLowerBound(lower)
+    sitk_filter.SetPadUpperBound(upper)
+    sitk_filter.SetConstant(default_value)
+    return sitk_filter.Execute(image)
 
 
 def padZ(image: sitk.Image, pad_min_z, pad_max_z, unique_value) -> sitk.Image:
-    filter = sitk.ConstantPadImageFilter()
+    sitk_filter = sitk.ConstantPadImageFilter()
     #  filter->SetInput(input);
-    filter.SetPadLowerBound([0, 0, pad_min_z])
-    filter.SetPadUpperBound([0, 0, pad_max_z])
-    filter.SetConstant(unique_value)
-    return filter.Execute(image)
+    sitk_filter.SetPadLowerBound([0, 0, pad_min_z])
+    sitk_filter.SetPadUpperBound([0, 0, pad_max_z])
+    sitk_filter.SetConstant(unique_value)
+    return sitk_filter.Execute(image)
 
 
 def cropZ(image: sitk.Image, pad_min_z, pad_max_z, verbose=True, z_index=2) -> sitk.Image:
     if verbose:
         print("[*] crop ", pad_min_z, abs(pad_max_z), "pixels")
-    filter = sitk.CropImageFilter()
-    filter.SetLowerBoundaryCropSize([abs(pad_min_z) if i == z_index else 0 for i in range(3)])
-    filter.SetUpperBoundaryCropSize([abs(pad_max_z) if i == z_index else 0 for i in range(3)])
-    return filter.Execute(image)
+    sitk_filter = sitk.CropImageFilter()
+    sitk_filter.SetLowerBoundaryCropSize([abs(pad_min_z) if i == z_index else 0 for i in range(3)])
+    sitk_filter.SetUpperBoundaryCropSize([abs(pad_max_z) if i == z_index else 0 for i in range(3)])
+    return sitk_filter.Execute(image)
 
 
 def divide_by_max(img: sitk.Image) -> sitk.Image:
-    filter = sitk.MinimumMaximumImageFilter()
-    filter.Execute(img)
-    maximum = filter.GetMaximum()
+    sitk_filter = sitk.MinimumMaximumImageFilter()
+    sitk_filter.Execute(img)
+    maximum = sitk_filter.GetMaximum()
     if maximum == 0:
         print("[!] Warning the max of this image is 0. It is probably empty ")
         return img
     return sitk.Divide(img, maximum)
 
 
 def affine_registration_transform(moving_image, fixed_image: sitk.Image, transform=None, verbose=True) -> sitk.Transform:
```

## TPTBox/registration/script_ax2sag.py

```diff
@@ -43,20 +43,20 @@
             q2.filter("ses", str(session))
             ax_files = list(q2.loop_list())
             ## MAKE AXIAL Stich resituated on Sagittal
             out_ax = ax_files[0].get_changed_path(parent=out_folder, info={"sequ": "stitched", "chunk": None})
             out_ax_cord = ax_files[0].get_changed_path(
                 parent=out_folder,
                 info={"sequ": "stitched", "seg": "spinalcord", "chunk": None},
-                format="msk",
+                bids_format="msk",
             )
             out_ax_ms = ax_files[0].get_changed_path(
                 parent=out_folder,
                 info={"sequ": "stitched", "label": "lesions", "chunk": None},
-                format="msk",
+                bids_format="msk",
             )
 
             # out_ax2 = ax_files[0].get_changed_path(parent=out_folder, info={"sequ": "stitchedxxx", "chunk": None})
             if not out_ax.exists():
                 reg_ax_files = []
                 stitched_sag = to_nii(out_sag)
                 for ax_f in ax_files:
```

## TPTBox/registration/script_ax2sag_v2.py

```diff
@@ -242,20 +242,20 @@
             q2.filter("ses", str(session))
             ax_files = list(q2.loop_list())
             ## MAKE AXIAL Stich resituated on Sagittal
             out_ax = ax_files[0].get_changed_path(parent=out_folder, info={"sequ": "stitched", "chunk": None})
             out_ax_cord = ax_files[0].get_changed_path(
                 parent=out_folder,
                 info={"sequ": "stitched", "seg": "spinalcord", "chunk": None},
-                format="msk",
+                bids_format="msk",
             )
             out_ax_ms = ax_files[0].get_changed_path(
                 parent=out_folder,
                 info={"sequ": "stitched", "label": "lesions", "chunk": None},
-                format="msk",
+                bids_format="msk",
             )
 
             find_best_fit(
                 ax_files,
                 T2w_sag,
                 T2w_sag_vert,
                 T2w_sag_spinalcord,
```

## TPTBox/spine/snapshot2D/snapshot_templates.py

```diff
@@ -71,15 +71,15 @@
                 crop_msk=True,
                 cor_savgol_filter=False,
                 # cmap="viridis",#ListedColormap(cmap),
             )
         )
 
     if out_path is None:
-        out_path = ct_ref.get_changed_path(file_type="png", format="snp", info={"desc": "mip"})
+        out_path = ct_ref.get_changed_path(file_type="png", bids_format="snp", info={"desc": "mip"})
     create_snapshot(snp_path=[out_path], frames=frames)
     # print("[ ]saved snapshot into:", out_path)
 
 
 def sacrum_shot(
     ct_ref: BIDS_FILE,
     vert_msk: Image_Reference,
@@ -136,15 +136,15 @@
                 visualization_type=Visualization_Type.Maximum_Intensity_Colored_Depth,
                 image_threshold=100,
                 denoise_threshold=150,
                 only_mask_area=False,
             )
         )
     if out_path is None:
-        out_path = ct_ref.get_changed_path(file_type="png", format="snp", info={"desc": "sacrum"})
+        out_path = ct_ref.get_changed_path(file_type="png", bids_format="snp", info={"desc": "sacrum"})
     create_snapshot(snp_path=[out_path], frames=frames)
     # print("[ ]saved snapshot into:", out_path)
 
 
 def spline_shot(
     ct_ref: BIDS_FILE,
     vert_msk: Image_Reference,
@@ -173,15 +173,15 @@
             axial=False,
             crop_msk=False,
         ),
     ]
     if out_path is None:
         out_path = ct_ref.get_changed_path(
             file_type="png",
-            format="snp",
+            bids_format="snp",
             info={"desc": f"spline-interpolation-{add_info}"},
         )
     create_snapshot(snp_path=[out_path], frames=frames)
     # print("[ ]saved snapshot into:", out_path)
 
 
 def mri_snapshot(
@@ -224,15 +224,15 @@
                 sagittal=True,
                 coronal=True,
                 axial=False,
                 crop_msk=False,
             )
         )
     if out_path is None:
-        out_path = mrt_ref.get_changed_path(file_type="png", format="snp", info={"desc": "vert"})
+        out_path = mrt_ref.get_changed_path(file_type="png", bids_format="snp", info={"desc": "vert"})
     if not isinstance(out_path, list):
         out_path = [out_path]
     create_snapshot(snp_path=out_path, frames=frames)
     return out_path
     # print("[ ]saved snapshot into:", out_path)
 
 
@@ -303,15 +303,15 @@
                 coronal=True,
                 axial=False,
                 crop_msk=False,
                 hide_centroids=hide_centroids,
             )
         )
     if out_path is None:
-        out_path = mrt_ref[0].get_changed_path(file_type="png", format="snp", info={"desc": "vibe"})
+        out_path = mrt_ref[0].get_changed_path(file_type="png", bids_format="snp", info={"desc": "vibe"})
     create_snapshot(snp_path=[out_path], frames=frames, verbose=verbose)
     return out_path
 
 
 def ct_mri_snapshot(
     mrt_ref: Image_Reference,
     ct_ref: Image_Reference,
@@ -341,15 +341,15 @@
             coronal=True,
             axial=False,
             crop_msk=False,
         ),
     ]
     if out_path is None:
         assert isinstance(mrt_ref, BIDS_FILE)
-        out_path = mrt_ref.get_changed_path(file_type="png", format="snp", info={"desc": "vert-ct-mri"})
+        out_path = mrt_ref.get_changed_path(file_type="png", bids_format="snp", info={"desc": "vert-ct-mri"})
     create_snapshot(snp_path=[out_path], frames=frames)
     return out_path
 
 
 def poi_snapshot(
     ct_nii: BIDS_FILE,
     vert_msk: Image_Reference | None,
@@ -464,15 +464,15 @@
             mode="CT",
             sagittal=False,
             coronal=True,
             curve_location=Location.Ligament_Attachment_Point_Flava_Superior_Median,
         ),
     ]
     if out_path is None:
-        out_path = ct_nii.get_changed_path(file_type="png", format="snp", info={"desc": "poi"})
+        out_path = ct_nii.get_changed_path(file_type="png", bids_format="snp", info={"desc": "poi"})
     create_snapshot(snp_path=[out_path], frames=frames)
     # print("[ ]saved snapshot into:", out_path)
 
 
 if __name__ == "__main__":
     # ct_file = BIDS_FILE(
     #    "/media/data/robert/datasets/dataset-poi/derivatives/WS_31/ses-20221024/sub-WS_31_ses-20221024_seq-seriesdescription_space-aligASL_ct.nii.gz",
```

## TPTBox/spine/spinal_cord_segmentation/seg_spinalcordtoolbox.py

```diff
@@ -85,23 +85,23 @@
         # process = subprocess.Popen(cmd_ex_cord, stdout=subprocess.PIPE, universal_newlines=True)
         run_cmd(cmd_ex_cord, print_ignore_list=ignore_list)
         if not __test_seg_file(spinal_cord_file):
             print("[!] The tool failed to segment the spinalcord. Program tries again.")
 
             spinal_cord_file.unlink(missing_ok=True)
             # compute_spinal_cord_with_cut_sacrum
-            msk_file = file.find_changed_path(format="msk")
+            msk_file = file.find_changed_path(bids_format="msk")
             if msk_file is None:
-                msk_file = file.find_changed_path(format="msk", info={"seg": "vert"})
+                msk_file = file.find_changed_path(bids_format="msk", info={"seg": "vert"})
             suc = False
             if msk_file is not None:
                 suc = compute_spinal_cord_with_cut_sacrum(file, msk_file, **args)
             if not suc:
                 spinal_cord_file.unlink(missing_ok=True)
-                file.get_changed_path(file_type="nii.gz", format="msk", info={"label": "spinalcord"})
+                file.get_changed_path(file_type="nii.gz", bids_format="msk", info={"label": "spinalcord"})
                 run_cmd([*cmd_ex_cord, "-centerline", "cnn"], print_ignore_list=ignore_list)
                 if not __test_seg_file(spinal_cord_file):
                     print("[!] The tool failed to segment the spinalcord.Program gives up.")
                     spinal_cord_file.unlink(missing_ok=True)
                     return
         if do_label:
             run_get_cmd_ex_label(file, spinal_cord_file, **args)
@@ -251,15 +251,15 @@
         compute_spinal_cord(bids_file, hot=hot, parent_folder_name="derivatives_spinalcord", override=False, do_label=False)
         return
 
 
 def __bids2spinalcord(bids_file: BIDS_FILE | Path | str, parent_folder_name: str):
     assert not isinstance(bids_file, Path), "out_file must be set, if a Path is provided instead of a BIDS_FILE"
     assert not isinstance(bids_file, str), "out_file must be set, if a Path is provided instead of a BIDS_FILE"
-    return bids_file.get_changed_path(file_type="nii.gz", format="msk", info={"label": "spinalcord"}, parent=parent_folder_name)
+    return bids_file.get_changed_path(file_type="nii.gz", bids_format="msk", info={"label": "spinalcord"}, parent=parent_folder_name)
 
 
 def get_cmd_ex_spinal_cord(
     bids_file: BIDS_FILE | Path | str,
     domain: str = "t2",
     threshold: float = -1,
     out_file: Path | None = None,
@@ -298,15 +298,15 @@
 
     Args:
         bids_file (BIDS_FILE): _description_
 
     Returns:
         _type_: _description_
     """
-    out_file = bids_file.get_changed_path(file_type="nii.gz", format="msk", info={"label": "sct_deepseg"})
+    out_file = bids_file.get_changed_path(file_type="nii.gz", bids_format="msk", info={"label": "sct_deepseg"})
     in_file = bids_file.file["nii.gz"]
     # This ting took ages for a single file because it did not work on gpu
     cmd_ex = ["sct_deepseg", "-i", in_file, "-c", "t2", "-o", out_file, "-task", "seg_exvivo_gm-wm_t2"]
 
     # sct_deepseg -i sub-spinegan0042_ses-20220517_sequ-301_e-1_dixon.nii.gz -c t2 -o out_file -task seg_lumbar_sc_t2w
     return cmd_ex, out_file
     # sct_merge_images
@@ -333,15 +333,15 @@
         parent_folder_name: Parentfolder (like rawdata/derivatives). Defaults to "derivatives"
         override (bool): override only if set to True
     Returns:
         tuple[list[str], BIDS_FILE]: The cmd command and the output filepath
     """
     if out_file is None:
         out_file = bids_file.get_changed_path(
-            file_type="nii.gz", format="msk", info={"label": "spinalcordlabel"}, parent=parent_folder_name
+            file_type="nii.gz", bids_format="msk", info={"label": "spinalcordlabel"}, parent=parent_folder_name
         )
     if not override and out_file.exists():
         return ["echo", f"[?] the spinalcord already exists {out_file.name}."], out_file
 
     in_file = bids_file.file["nii.gz"]
     cmd_ex = ["sct_label_vertebrae", "-i", in_file, "-c", domain, "-s", str(spinal_cord_file), "-o", str(out_file)]
     return cmd_ex, out_file
```

## Comparing `tptbox-0.0.9.dist-info/LICENSE` & `tptbox-0.1.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `tptbox-0.0.9.dist-info/METADATA` & `tptbox-0.1.0.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: TPTBox
-Version: 0.0.9
+Version: 0.1.0
 Summary: A Torso Processing Toolbox capable of processing BIDS-compatible datasets, singular niftys, points of interests, segmentations, and much more.
 Home-page: https://github.com/Hendrik-code/TPTBox
 License: GNU AFFERO GENERAL PUBLIC LICENSE v3.0, 19 November 2007
 Author: Robert Graf
 Author-email: robert.graf@tum.de
 Requires-Python: >=3.10,<4.0
 Classifier: License :: Other/Proprietary License
```

## Comparing `tptbox-0.0.9.dist-info/RECORD` & `tptbox-0.1.0.dist-info/RECORD`

 * *Files 4% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 TPTBox/__init__.py,sha256=dLdT0MXmNt3zIUfknLbkamVa-x3vxLjUc2w4_IViJ90,1119
 TPTBox/core/__init__.py,sha256=iMKh_SsaaHczAmq_4Cy17ZWZ7oIpW1rdj0WeGfLOQ4g,619
 TPTBox/core/bids_constants.py,sha256=G18_6qk0F_eHv-fan30KmD9sWONvfeMWOgaVANaTd4I,3972
-TPTBox/core/bids_files.py,sha256=JAaLQ_uskm1GGBVIu5wnqeJLlp4NV2iiqXK6mCJammo,55059
-TPTBox/core/nii_wrapper.py,sha256=uBk-EIlwWWJMGcXSIk1TRYDxFj-K4Noez96tY6KQYr8,63805
+TPTBox/core/bids_files.py,sha256=zWUe0OwfYee_M3z1V22OTKAicp8Jd4otvMEaEpeqSp4,55801
+TPTBox/core/nii_wrapper.py,sha256=mzw3mKDhW2vX1lGsUnR4_Tn0DtIsBlfb3GCgALWQSUo,64166
 TPTBox/core/nii_wrapper_math.py,sha256=Qb50sYDVuMPWui31C_hjZkbRrlZwUwpgVtyoyAGcoP8,9151
-TPTBox/core/np_utils.py,sha256=XheAsMT6Xp6_f43I5wZEgNtVmYTErnyFDJkeR7aF9XE,37266
+TPTBox/core/np_utils.py,sha256=baioyRE36MGwsYb0Zx0WQQrRdxV6Uf3-wW6cr6vaVsQ,37507
 TPTBox/core/poi.py,sha256=1OlqW2Y_XjFWyF5r5CASJY7sZPXjgYe4cbeStMv8juE,69391
 TPTBox/core/poi_abstract.py,sha256=4L0HKUx-R4-Gj2R7rdq_BAgkXpokOnj62qc9J13VCO4,28688
 TPTBox/core/poi_global.py,sha256=rU08hHG0YpUTGYxj1X2d2idyp44LRjylcNU85zHNEmI,2907
-TPTBox/core/sitk_utils.py,sha256=uQlDE2ID9XrYeBhySLHqqPEmelwFeXGCVD7_tb285ek,18098
+TPTBox/core/sitk_utils.py,sha256=WPsD8mW8Gjvrc0aFUByagiv8PSHVTmhZ-F_KoIHfisc,18197
 TPTBox/core/vert_constants.py,sha256=3NJskOIzrkdssBwha-_abBSir2rQjtSVzHigmWSa4QY,7861
 TPTBox/core/vertebra_pois_non_centroids.py,sha256=tOQXZV7IjJlcJeqe3po58J7dMVUfRvWC0KDFi-ToYdg,45577
 TPTBox/docker/__init__.py,sha256=ln-Xk0IkOyoYkfti6nZruiwhH7_bQmprrpLY5dUXCnE,207
 TPTBox/docker/docker.py,sha256=9f_zgvnHZTpJmjUfKWbl3mtyeRN5J63jyotNgLNbuKA,36551
 TPTBox/docker/docker_run.py,sha256=UQv-qpYFDnUU4VojxxozaKzQWovfEFbFGi1hNPbutCg,1392
 TPTBox/logger/__init__.py,sha256=JFjqzAZ6Tjq40hXMqXtHwSut-o3dBcYBtqhcQamMXZI,165
 TPTBox/logger/log_constants.py,sha256=W2A4KjOXV8m3Hi0gxZJN_nvEL1DRBiv-ljpAmY_NT5I,5063
@@ -20,24 +20,24 @@
 TPTBox/mesh3D/mesh.py,sha256=-p-piOao9RPFbbdn46UTYhtCnUqW2PeFCGsNilDG_wY,4836
 TPTBox/mesh3D/mesh_colors.py,sha256=PCO7pUf8tglbJ_l8sDx9CuhzpVFs2mQn-VcdJcwo3lk,4633
 TPTBox/registration/__init__.py,sha256=rP0Cc84NU66ZDIHvsvTn1ygPCsMLL6o7njpPoZxA_R8,418
 TPTBox/registration/_deepali/test.py,sha256=o9jGhDJLHIK00DN_DpJDKVMFobJxbWEJppRS1EGE0xQ,13413
 TPTBox/registration/ridged_intensity/register.py,sha256=hE29j2moTI23pyZYbmZOWDzpmwzt6XW1rdOZREugJLM,3715
 TPTBox/registration/ridged_points/__init__.py,sha256=4H0bpP143SWiLRVX8lPpFqVgG4p6T6TZrlbiWGRyyS0,144
 TPTBox/registration/ridged_points/point_registration.py,sha256=0xof8xDxnuMnTpDXBg6knLVTYAYXd1jR0NOOTPN-mbw,11219
-TPTBox/registration/script_ax2sag.py,sha256=HX3Fe3tQ4gOJGnvPMGodYRBnKDOCh0KESnlmpIEGOEE,7029
-TPTBox/registration/script_ax2sag_v2.py,sha256=dgvnoEfSf7izhQP2uyWSkScAzV3xYOgrmMAOMsVoJBY,13829
+TPTBox/registration/script_ax2sag.py,sha256=nXAKJHKA006Yau9G1qiVRJh3kPVIvdgUhBVnhm72S-o,7039
+TPTBox/registration/script_ax2sag_v2.py,sha256=tHBOdRV-_-Hca_j9gyn-U3xuW_hLXURVgNE4omzgaYw,13839
 TPTBox/spine/POI_plotter.py,sha256=5ICeKRfz-i4TBkRkY6GsfBZld48B35W81WdrDuunUrM,8053
 TPTBox/spine/mesh3D/vert_mesh_colors.py,sha256=MUK_xLz0rPA3ArkuvwNI9TFVrrzyJTDea8l4p-0h-uA,835
 TPTBox/spine/snapshot2D/__init__.py,sha256=0Tdrhrs3Rb4fALXnbCdn3NdfpRXKYIIXfi9m0wtnY68,221
 TPTBox/spine/snapshot2D/snapshot_modular.py,sha256=c9yMs8iAGCo0ZAfgV0Lin5atGH6w74Sz9tHpdWpMuvo,33768
-TPTBox/spine/snapshot2D/snapshot_templates.py,sha256=WenM71Jlgl8mT54d2FDEAWTil79W90Pd9vzLY4u5iiA,15584
+TPTBox/spine/snapshot2D/snapshot_templates.py,sha256=AYO_7OjxZVecQysaYGS4lZx_sARdzOi1JdKGd0iEXvA,15619
 TPTBox/spine/spinal_cord_segmentation/__count_segmented.py,sha256=IFdZVCzX-n5JbpbE3aXzbDPd-pJcfL4OBp8fv1Y9s7Q,2156
 TPTBox/spine/spinal_cord_segmentation/__init__.py,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
-TPTBox/spine/spinal_cord_segmentation/seg_spinalcordtoolbox.py,sha256=5b6yImif7dMrWUkFhTXLFL1Wq30ZropHiNETqovdF5I,19705
+TPTBox/spine/spinal_cord_segmentation/seg_spinalcordtoolbox.py,sha256=xlOV0uQgP5GBc2YMev8b24ufCPlI-rj5D8is1XqPPco,19735
 TPTBox/stitching/README.md,sha256=jIi2TKigB029La2YeJAec878E7EelU7YCWDcYr-dWXo,2256
 TPTBox/stitching/__init__.py,sha256=bWSBRWS7LstJjZxZI1m4OTezXXthdz2zoT2krOa8YwE,86
 TPTBox/stitching/__stitching_reg.py,sha256=SMKt5bihGXMyOU7-ua1alKfn2FPbA92llckLBToQ11w,11308
 TPTBox/stitching/__stitching_vertical.py,sha256=SngTW9YO0YpjDVVTuQVAtYhc5SkjfmNzBFDPPGgwfBo,10048
 TPTBox/stitching/stitching.jpg,sha256=zUSjKVWNqJdlod-uQvqd_gqvq3ZoLkpgZQaS3TkiJ5Q,326043
 TPTBox/stitching/stitching.py,sha256=0Dw7xGQXlZBorDUFjX0aZg_FTi7lYFsKQOgcwXJBeqk,22293
 TPTBox/stitching/stitching_tools.py,sha256=Jt03jN6CW3wD90dCxLnERiP041IOhrC-uR2dU28FzEI,4427
@@ -48,11 +48,11 @@
 TPTBox/tests/sample_mri/sub-mri_label-6_T2w.nii.gz,sha256=lhSVtCzfwC6vUOs_Rx1wV5O4KAL-2wX18CqlNnUoz0Q,259999
 TPTBox/tests/sample_mri/sub-mri_seg-subreg_label-6_msk.nii.gz,sha256=NMej3czue1ApUdluDMwL90mP8_nEenvfzvtRp-PKJ4U,12846
 TPTBox/tests/sample_mri/sub-mri_seg-vert_label-6_msk.nii.gz,sha256=FO5yej9WVRLdvwydjOjZzhJ6zEPw0hvHdxwvy9NDAjo,12144
 TPTBox/tests/speedtest.py,sha256=_HlkDuREjFCWuwyReKnYpLSLxw5XRXlogWQj2A11r_w,1756
 TPTBox/tests/speedtest_cc3d.py,sha256=NWPxZ8tu46LgxsJpceKBbKsSUhdzIHkQC9yHRy9S8CE,2871
 TPTBox/tests/speedtest_morphological.py,sha256=NdQWYwN6CZSgixYhXMuXFZfOcmn2DRzw0oGuw0eKUg4,1045
 TPTBox/tests/test_utils.py,sha256=OqGYNIt3eyq3uNzx5ltcGpFrTSnqeonRIP3NAEDs7q8,11959
-tptbox-0.0.9.dist-info/LICENSE,sha256=hIahDEOTzuHCU5J2nd07LWwkLW7Hko4UFO__ffsvB-8,34523
-tptbox-0.0.9.dist-info/METADATA,sha256=tPp_gPj3wBZ3QPOmX6Xi-Hvqi1_ggmyFW_v4zz1hlGU,4337
-tptbox-0.0.9.dist-info/WHEEL,sha256=sP946D7jFCHeNz5Iq4fL4Lu-PrWrFsgfLXbbkciIZwg,88
-tptbox-0.0.9.dist-info/RECORD,,
+tptbox-0.1.0.dist-info/LICENSE,sha256=hIahDEOTzuHCU5J2nd07LWwkLW7Hko4UFO__ffsvB-8,34523
+tptbox-0.1.0.dist-info/METADATA,sha256=3m-3dFs0_KDH03yF8aujq13i6rSp8kRgUq9Al5fRcfg,4337
+tptbox-0.1.0.dist-info/WHEEL,sha256=sP946D7jFCHeNz5Iq4fL4Lu-PrWrFsgfLXbbkciIZwg,88
+tptbox-0.1.0.dist-info/RECORD,,
```

